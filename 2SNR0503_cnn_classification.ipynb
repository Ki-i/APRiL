{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki-i/APRiL/blob/master/2SNR0503_cnn_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QiGF43Vh69",
        "outputId": "8c882013-18a8-4182-c4db-06daa9da511d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52AY7dz9WsC0"
      },
      "outputs": [],
      "source": [
        "workspace_dir = '.'\n",
        "#!unzip -q \"/content/drive/My Drive/crypko_data.zip\" -d \"{workspace_dir}/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZHLjPEPEW0iE"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import scipy.io as scio\n",
        "import pylab\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G7ydcVOPsj77"
      },
      "outputs": [],
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DnCNN, self).__init__()\n",
        "        channels=3\n",
        "        num_of_layers=10\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        " \n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self.fc1=nn.Linear( 3*50*100,6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(6,2)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "    def forward(self, x):\n",
        "        y = self.dncnn(x)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        #print(y.size())\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AX1zF1JW_xw"
      },
      "outputs": [],
      "source": [
        "class Model(Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 5)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*2*9, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 6)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.relu1(y)\n",
        "        y = self.pool1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.relu2(y)\n",
        "        y = self.pool2(y)\n",
        "        y = self.conv3(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.pool3(y)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.fc2(y)\n",
        "        # y = self.relu4(y)\n",
        "        # y = self.fc3(y)\n",
        "        # y = self.relu5(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLNyO4Z-XAwy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-vFcTvIaXGG2"
      },
      "outputs": [],
      "source": [
        "def get_data(dataset_path, fm, dev_ratio,SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    datalen=500\n",
        "    x = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1, int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x[i] = data[xkey1]\n",
        "        x[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y[i] = 1\n",
        "        y[i+int(datalen/2)] = 0\n",
        "\n",
        "    data_size = len(y)\n",
        "    train_size = int(data_size * (1 - dev_ratio))\n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(x)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(y)\n",
        "    # print(\"train size:\", train_size)\n",
        "    # print(\"dev size:\", data_size - train_size)\n",
        "    x_train = x[:train_size]\n",
        "    y_train = y[:train_size]\n",
        "    x_dev = x[train_size:]\n",
        "    y_dev = y[train_size:]\n",
        "    return x_train, y_train, x_dev, y_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DYoliGW6XJJv"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "       \n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "       \n",
        "        x = torch.div(x, 255.)\n",
        "      \n",
        "        #print(x.size())\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGk2NrCqPnk",
        "outputId": "aa438a2f-c75a-4c2d-d9a5-aadefa6a4c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25 0.5  0.75 1.  ]\n"
          ]
        }
      ],
      "source": [
        "x=np.array([1,2,3,4])\n",
        "x=x/4\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1coYPwD6v79d"
      },
      "outputs": [],
      "source": [
        "def psnr(target_data, ref_data):\n",
        "    # target:目标图像  ref:参考图像  scale:尺寸大小\n",
        "    # assume RGB image\n",
        "    #target_data = np.array(target)\n",
        "    #target_data = target_data[scale:-scale, scale:-scale]\n",
        "\n",
        "    #ref_data = np.array(ref)\n",
        "    #ref_data = ref_data[scale:-scale, scale:-scale]\n",
        "    im = ref_data.max()\n",
        "    print('参考图像峰值', ref_data.max(), ref_data.min())\n",
        "    print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    target_data = target_data * (ref_data.max() / target_data.max())\n",
        "    #print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    diff = ref_data - target_data\n",
        "    diff = diff.flatten('C')\n",
        "\n",
        "    #rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "    #return 20 * math.log10(math.pow(im,2) / rmse)\n",
        "    mse = np.mean(diff ** 2.)\n",
        "    return 20 * math.log10(math.pow(im,2) / mse)\n",
        "\n",
        "def ab_err(target_data, ref_data):\n",
        "  diff = abs(ref_data - target_data)/ref_data\n",
        "  diff=diff.cpu().data.numpy()\n",
        "  tdiff=diff[0:,0:2]\n",
        "  vdiff=diff[0:,3:5]\n",
        "  \n",
        "  \n",
        "  terr = np.mean(tdiff)\n",
        "  verr = np.mean(vdiff)\n",
        "\n",
        "  return terr,verr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl5D9ZN0XThY",
        "outputId": "634bb4fe-eb6b-4dcc-bfc9-204dd2d59967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0.0000 train acc: 0.4760,train loss: 0.7001, dev acc: 0.4813, dev loss: 0.6976\n",
            "epoch 1.0000 train acc: 0.4885,train loss: 0.6951, dev acc: 0.4813, dev loss: 0.6987\n",
            "epoch 2.0000 train acc: 0.5156,train loss: 0.6869, dev acc: 0.4813, dev loss: 0.7020\n",
            "epoch 3.0000 train acc: 0.5417,train loss: 0.6799, dev acc: 0.4813, dev loss: 0.7028\n",
            "epoch 4.0000 train acc: 0.5885,train loss: 0.6753, dev acc: 0.4813, dev loss: 0.7032\n",
            "epoch 5.0000 train acc: 0.6281,train loss: 0.6620, dev acc: 0.4813, dev loss: 0.7026\n",
            "epoch 6.0000 train acc: 0.6500,train loss: 0.6550, dev acc: 0.4813, dev loss: 0.7032\n",
            "epoch 7.0000 train acc: 0.6406,train loss: 0.6466, dev acc: 0.4813, dev loss: 0.7008\n",
            "epoch 8.0000 train acc: 0.6646,train loss: 0.6385, dev acc: 0.4813, dev loss: 0.6992\n",
            "epoch 9.0000 train acc: 0.7083,train loss: 0.6260, dev acc: 0.4865, dev loss: 0.6867\n",
            "epoch 10.0000 train acc: 0.7323,train loss: 0.6175, dev acc: 0.6375, dev loss: 0.6553\n",
            "epoch 11.0000 train acc: 0.8042,train loss: 0.5990, dev acc: 0.8385, dev loss: 0.6131\n",
            "epoch 12.0000 train acc: 0.8469,train loss: 0.5897, dev acc: 0.9719, dev loss: 0.5820\n",
            "epoch 13.0000 train acc: 0.8260,train loss: 0.5777, dev acc: 0.9969, dev loss: 0.5628\n",
            "epoch 14.0000 train acc: 0.8323,train loss: 0.5544, dev acc: 0.9938, dev loss: 0.5485\n",
            "epoch 15.0000 train acc: 0.8094,train loss: 0.5715, dev acc: 0.9969, dev loss: 0.5368\n",
            "epoch 16.0000 train acc: 0.8625,train loss: 0.5438, dev acc: 1.0000, dev loss: 0.5223\n",
            "epoch 17.0000 train acc: 0.8562,train loss: 0.5380, dev acc: 1.0000, dev loss: 0.5101\n",
            "epoch 18.0000 train acc: 0.8469,train loss: 0.5252, dev acc: 1.0000, dev loss: 0.5040\n",
            "epoch 19.0000 train acc: 0.8885,train loss: 0.5036, dev acc: 1.0000, dev loss: 0.4858\n",
            "epoch 20.0000 train acc: 0.8844,train loss: 0.4946, dev acc: 1.0000, dev loss: 0.4730\n",
            "epoch 21.0000 train acc: 0.8542,train loss: 0.4932, dev acc: 1.0000, dev loss: 0.4615\n",
            "epoch 22.0000 train acc: 0.8781,train loss: 0.4837, dev acc: 1.0000, dev loss: 0.4507\n",
            "epoch 23.0000 train acc: 0.8510,train loss: 0.4711, dev acc: 1.0000, dev loss: 0.4383\n",
            "epoch 24.0000 train acc: 0.8656,train loss: 0.4582, dev acc: 1.0000, dev loss: 0.4258\n",
            "epoch 25.0000 train acc: 0.8583,train loss: 0.4605, dev acc: 1.0000, dev loss: 0.4174\n",
            "epoch 26.0000 train acc: 0.8917,train loss: 0.4201, dev acc: 1.0000, dev loss: 0.4038\n",
            "epoch 27.0000 train acc: 0.8875,train loss: 0.4335, dev acc: 1.0000, dev loss: 0.3979\n",
            "epoch 28.0000 train acc: 0.8823,train loss: 0.4117, dev acc: 1.0000, dev loss: 0.3830\n",
            "epoch 29.0000 train acc: 0.8521,train loss: 0.4155, dev acc: 1.0000, dev loss: 0.3706\n",
            "epoch 30.0000 train acc: 0.9062,train loss: 0.3836, dev acc: 1.0000, dev loss: 0.3644\n",
            "epoch 31.0000 train acc: 0.8938,train loss: 0.3987, dev acc: 1.0000, dev loss: 0.3499\n",
            "epoch 32.0000 train acc: 0.8729,train loss: 0.4063, dev acc: 1.0000, dev loss: 0.3417\n",
            "epoch 33.0000 train acc: 0.8969,train loss: 0.3600, dev acc: 1.0000, dev loss: 0.3333\n",
            "epoch 34.0000 train acc: 0.9042,train loss: 0.3489, dev acc: 1.0000, dev loss: 0.3203\n",
            "epoch 35.0000 train acc: 0.8635,train loss: 0.3772, dev acc: 1.0000, dev loss: 0.3163\n",
            "epoch 36.0000 train acc: 0.8948,train loss: 0.3579, dev acc: 1.0000, dev loss: 0.3063\n",
            "epoch 37.0000 train acc: 0.8958,train loss: 0.3445, dev acc: 1.0000, dev loss: 0.2959\n",
            "epoch 38.0000 train acc: 0.8646,train loss: 0.3572, dev acc: 1.0000, dev loss: 0.2912\n",
            "epoch 39.0000 train acc: 0.8844,train loss: 0.3534, dev acc: 1.0000, dev loss: 0.2843\n",
            "epoch 40.0000 train acc: 0.8938,train loss: 0.3506, dev acc: 1.0000, dev loss: 0.2796\n",
            "epoch 41.0000 train acc: 0.8969,train loss: 0.3324, dev acc: 1.0000, dev loss: 0.2665\n",
            "epoch 42.0000 train acc: 0.8958,train loss: 0.3019, dev acc: 1.0000, dev loss: 0.2574\n",
            "epoch 43.0000 train acc: 0.8885,train loss: 0.3268, dev acc: 1.0000, dev loss: 0.2581\n",
            "epoch 44.0000 train acc: 0.9073,train loss: 0.2972, dev acc: 1.0000, dev loss: 0.2449\n",
            "epoch 45.0000 train acc: 0.9219,train loss: 0.2699, dev acc: 1.0000, dev loss: 0.2406\n",
            "epoch 46.0000 train acc: 0.9292,train loss: 0.2751, dev acc: 1.0000, dev loss: 0.2289\n",
            "epoch 47.0000 train acc: 0.8885,train loss: 0.2767, dev acc: 1.0000, dev loss: 0.2235\n",
            "epoch 48.0000 train acc: 0.9198,train loss: 0.2514, dev acc: 1.0000, dev loss: 0.2109\n",
            "epoch 49.0000 train acc: 0.8969,train loss: 0.2798, dev acc: 1.0000, dev loss: 0.2129\n",
            "epoch 50.0000 train acc: 0.9187,train loss: 0.2717, dev acc: 1.0000, dev loss: 0.2055\n",
            "epoch 51.0000 train acc: 0.8906,train loss: 0.2867, dev acc: 1.0000, dev loss: 0.2025\n",
            "epoch 52.0000 train acc: 0.9104,train loss: 0.2688, dev acc: 1.0000, dev loss: 0.1946\n",
            "epoch 53.0000 train acc: 0.9010,train loss: 0.2640, dev acc: 1.0000, dev loss: 0.1890\n",
            "epoch 54.0000 train acc: 0.9250,train loss: 0.2427, dev acc: 1.0000, dev loss: 0.1838\n",
            "epoch 55.0000 train acc: 0.9104,train loss: 0.2602, dev acc: 1.0000, dev loss: 0.1823\n",
            "epoch 56.0000 train acc: 0.9229,train loss: 0.2287, dev acc: 1.0000, dev loss: 0.1717\n",
            "epoch 57.0000 train acc: 0.8885,train loss: 0.2535, dev acc: 1.0000, dev loss: 0.1749\n",
            "epoch 58.0000 train acc: 0.9104,train loss: 0.2544, dev acc: 1.0000, dev loss: 0.1685\n",
            "epoch 59.0000 train acc: 0.9219,train loss: 0.2260, dev acc: 1.0000, dev loss: 0.1614\n",
            "epoch 60.0000 train acc: 0.9229,train loss: 0.2279, dev acc: 1.0000, dev loss: 0.1562\n",
            "epoch 61.0000 train acc: 0.9323,train loss: 0.2199, dev acc: 1.0000, dev loss: 0.1533\n",
            "epoch 62.0000 train acc: 0.9448,train loss: 0.2052, dev acc: 1.0000, dev loss: 0.1468\n",
            "epoch 63.0000 train acc: 0.9094,train loss: 0.2187, dev acc: 1.0000, dev loss: 0.1436\n",
            "epoch 64.0000 train acc: 0.9281,train loss: 0.2180, dev acc: 1.0000, dev loss: 0.1437\n",
            "epoch 65.0000 train acc: 0.9115,train loss: 0.2019, dev acc: 1.0000, dev loss: 0.1355\n",
            "epoch 66.0000 train acc: 0.9062,train loss: 0.2110, dev acc: 1.0000, dev loss: 0.1346\n",
            "epoch 67.0000 train acc: 0.9385,train loss: 0.1984, dev acc: 1.0000, dev loss: 0.1332\n",
            "epoch 68.0000 train acc: 0.9344,train loss: 0.1857, dev acc: 1.0000, dev loss: 0.1267\n",
            "epoch 69.0000 train acc: 0.9323,train loss: 0.1939, dev acc: 1.0000, dev loss: 0.1236\n",
            "epoch 70.0000 train acc: 0.9281,train loss: 0.1939, dev acc: 1.0000, dev loss: 0.1200\n",
            "epoch 71.0000 train acc: 0.9187,train loss: 0.2036, dev acc: 1.0000, dev loss: 0.1184\n",
            "epoch 72.0000 train acc: 0.9229,train loss: 0.1878, dev acc: 1.0000, dev loss: 0.1164\n",
            "epoch 73.0000 train acc: 0.9167,train loss: 0.1860, dev acc: 1.0000, dev loss: 0.1103\n",
            "epoch 74.0000 train acc: 0.9042,train loss: 0.1882, dev acc: 1.0000, dev loss: 0.1043\n",
            "epoch 75.0000 train acc: 0.9563,train loss: 0.1591, dev acc: 1.0000, dev loss: 0.1013\n",
            "epoch 76.0000 train acc: 0.9448,train loss: 0.1763, dev acc: 1.0000, dev loss: 0.1017\n",
            "epoch 77.0000 train acc: 0.9135,train loss: 0.1752, dev acc: 1.0000, dev loss: 0.0986\n",
            "epoch 78.0000 train acc: 0.9448,train loss: 0.1426, dev acc: 1.0000, dev loss: 0.0925\n",
            "epoch 79.0000 train acc: 0.9396,train loss: 0.1588, dev acc: 1.0000, dev loss: 0.0938\n",
            "epoch 80.0000 train acc: 0.9365,train loss: 0.1571, dev acc: 1.0000, dev loss: 0.0932\n",
            "epoch 81.0000 train acc: 0.9292,train loss: 0.1729, dev acc: 1.0000, dev loss: 0.0909\n",
            "epoch 82.0000 train acc: 0.9344,train loss: 0.1569, dev acc: 1.0000, dev loss: 0.0906\n",
            "epoch 83.0000 train acc: 0.9302,train loss: 0.1645, dev acc: 1.0000, dev loss: 0.0879\n",
            "epoch 84.0000 train acc: 0.9260,train loss: 0.1727, dev acc: 1.0000, dev loss: 0.0889\n",
            "epoch 85.0000 train acc: 0.9281,train loss: 0.1664, dev acc: 1.0000, dev loss: 0.0849\n",
            "epoch 86.0000 train acc: 0.9437,train loss: 0.1372, dev acc: 1.0000, dev loss: 0.0814\n",
            "epoch 87.0000 train acc: 0.9437,train loss: 0.1445, dev acc: 1.0000, dev loss: 0.0766\n",
            "epoch 88.0000 train acc: 0.9500,train loss: 0.1370, dev acc: 1.0000, dev loss: 0.0756\n",
            "epoch 89.0000 train acc: 0.9292,train loss: 0.1462, dev acc: 1.0000, dev loss: 0.0737\n",
            "epoch 90.0000 train acc: 0.9500,train loss: 0.1333, dev acc: 1.0000, dev loss: 0.0720\n",
            "epoch 91.0000 train acc: 0.9417,train loss: 0.1339, dev acc: 1.0000, dev loss: 0.0686\n",
            "epoch 92.0000 train acc: 0.9104,train loss: 0.1626, dev acc: 1.0000, dev loss: 0.0715\n",
            "epoch 93.0000 train acc: 0.9385,train loss: 0.1320, dev acc: 1.0000, dev loss: 0.0691\n",
            "epoch 94.0000 train acc: 0.9479,train loss: 0.1264, dev acc: 1.0000, dev loss: 0.0673\n",
            "epoch 95.0000 train acc: 0.9500,train loss: 0.1322, dev acc: 1.0000, dev loss: 0.0665\n",
            "epoch 96.0000 train acc: 0.9563,train loss: 0.1263, dev acc: 1.0000, dev loss: 0.0621\n",
            "epoch 97.0000 train acc: 0.9271,train loss: 0.1381, dev acc: 1.0000, dev loss: 0.0642\n",
            "epoch 98.0000 train acc: 0.9437,train loss: 0.1343, dev acc: 1.0000, dev loss: 0.0636\n",
            "epoch 99.0000 train acc: 0.9531,train loss: 0.1262, dev acc: 1.0000, dev loss: 0.0593\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f3739d7c4c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_dev_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skyblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imgname' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    batch_size = 32\n",
        "    lr=1e-3\n",
        "    #lr=1e-4#loss:11.72 10.74\n",
        "    #lr=1e-3#9.6519\n",
        "    #lr=0.01#8.3690\n",
        "    #lr=0.1#8.2 7.72 7.71 ..7156.7147\n",
        "    log_dir='/content/drive/My Drive/ClassificationModel0503.pth'\n",
        "    #数据集加载\n",
        "    dataset_path = '/content/drive/My Drive/'\n",
        "    x_train, y_train, x_dev, y_dev = get_data(dataset_path, 'TrainDataClassification.mat', 0.4,2)\n",
        "    #print(x_train[0])\n",
        "    train_dataset = MyDataset(x_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    dev_dataset = MyDataset(x_dev, y_dev)\n",
        "    dev_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "    model = DnCNN()\n",
        "    #model = Model()\n",
        "    #模型加载\n",
        "    start_epoch=0\n",
        "    '''\n",
        "    if os.path.exists(log_dir):\n",
        "        checkpoint = torch.load(log_dir)\n",
        "        model.load_state_dict(checkpoint['net'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        print('无保存模型，将从头开始训练！')\n",
        "    '''\n",
        "    sgd = SGD(model.parameters(), lr)\n",
        "\n",
        "    cost = CrossEntropyLoss()\n",
        "    criterion = MSELoss(reduction='sum')\n",
        "    epoch = 100\n",
        "    use_GPU = True\n",
        "    if use_GPU:\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    epoch_train_loss_list = []\n",
        "    epoch_dev_loss_list = []\n",
        "    epoch_train_acc_list = []\n",
        "    epoch_dev_acc_list = []\n",
        "\n",
        "    for _epoch in range(epoch):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_dev_loss = 0\n",
        "        epoch_train_acc = 0\n",
        "        epoch_dev_acc = 0\n",
        "        train_num=0\n",
        "        dev_num = 0\n",
        "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "            s = train_label.shape[0]\n",
        "            sgd.zero_grad()\n",
        "            predict_y = model(train_x.to(device))\n",
        "            #print(train_label.size())\n",
        "            #print(predict_y.size())\n",
        "            #loss = cost(predict_y, train_label.to(device))\n",
        "            loss = F.cross_entropy(predict_y, train_label.to(device))\n",
        "            epoch_train_loss += loss.item()\n",
        "            label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "            acc = np.sum(label_pred == train_label.numpy())\n",
        "            # print(\"batch Train acc:\",acc / s)\n",
        "            epoch_train_acc += acc / s\n",
        "            train_num+=1\n",
        "            loss.backward()\n",
        "            sgd.step()\n",
        "\n",
        "        correct = 0\n",
        "        _sum = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (dev_x, dev_label) in enumerate(dev_loader):\n",
        "                s = dev_label.shape[0]\n",
        "                predict_y = model(dev_x.to(device))\n",
        "                # print(predict_y[0], dev_label[0])\n",
        "                loss = cost(predict_y, dev_label.to(device))\n",
        "                epoch_dev_loss += loss.item()\n",
        "                label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "                acc = np.sum(label_pred == dev_label.numpy())\n",
        "                batch_acc=acc / s\n",
        "                dev_num+=1\n",
        "                # print(\"batch_acc::\",batch_acc)\n",
        "                epoch_dev_acc += acc / s\n",
        "                # print(\"devacc\", acc);\n",
        "        epoch_train_loss_list.append(epoch_train_loss / train_num)\n",
        "        epoch_dev_loss_list.append(epoch_dev_loss / train_num)\n",
        "        epoch_train_acc_list.append(epoch_train_acc / dev_num)\n",
        "        epoch_dev_acc_list.append(epoch_dev_acc / dev_num)\n",
        "        print(\"epoch {:.4f} train acc: {:.4f},train loss: {:.4f}, dev acc: {:.4f}, dev loss: {:.4f}\".format(_epoch,epoch_train_acc / train_num, epoch_train_loss / train_num,epoch_dev_acc / dev_num, epoch_dev_loss / dev_num))\n",
        "   \n",
        "    \n",
        "    state = {'net':model.state_dict(),  'epoch':epoch}\n",
        "    torch.save(state, log_dir)\n",
        "    t = np.arange(1, len(epoch_train_loss_list) + 1)\n",
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ],
      "metadata": {
        "id": "px1s0sYqk-Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data(dataset_path, fm, SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    '''\n",
        "    datalen=500\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "    '''   \n",
        "    datalen=250\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,datalen):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        #xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        #x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        #y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "\n",
        "    \n",
        "    return x_test, y_test\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "        #label=label.float()\n",
        "        x = torch.div(x, 255.)\n",
        "        #print(label)\n",
        "        #label = torch.div(label, 10000.)\n",
        "        #print(x)\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ],
      "metadata": {
        "id": "MIEC7MelezSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "2CvKfHmdWlBp",
        "outputId": "3f0e8c16-5deb-4888-cead-cc8eda32aa79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d554eb841dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#loss = criterion(predict_y, train_label.to(device)) / (2 * len(train_x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#terror,verror,acc=ab_err(predict_y,test_label.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mepoch_dev_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (100) to match target batch_size (24)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 24\n",
        "use_GPU = True\n",
        "if use_GPU:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "model = DnCNN()\n",
        "model.to(device)\n",
        "print(torch.cuda.is_available())\n",
        "log_dir = '/content/drive/My Drive/ClassificationModel0425.pth'\n",
        "if os.path.exists(log_dir):\n",
        "    checkpoint = torch.load(log_dir)\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    print('加载失败')\n",
        "dataset_path=\"/content/drive/My Drive/\"\n",
        "SNR_acc_list = []\n",
        "for SNR in range(-5, 5):\n",
        "    x_test, y_test = get_test_data(dataset_path, 'TrainDataClassification.mat', SNR)\n",
        "    test_dataset = MyTestDataset(x_test, y_test)\n",
        "    train_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    test_num = 0\n",
        "    test_derror=0\n",
        "    test_verror=0\n",
        "    test_acc = 0\n",
        "    for idx, (test_x, test_label) in enumerate(train_loader):\n",
        "        epoch_dev_acc = 0\n",
        "        train_num = 0\n",
        "        dev_num = 0\n",
        "        epoch_dev_derror = 0\n",
        "        epoch_dev_verror = 0\n",
        "        epoch_train_derror = 0\n",
        "        epoch_train_verror = 0\n",
        "        s = test_label.shape[0]\n",
        "        predict_y = model(test_x.to(device))\n",
        "        \n",
        "        loss = F.cross_entropy(predict_y, test_label.to(device))\n",
        "            \n",
        "        epoch_dev_loss += loss.item()\n",
        "        label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "        acc = np.sum(label_pred == test_label.numpy())\n",
        "        batch_acc=acc / s\n",
        "        print(batch_acc)\n",
        "\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        test_acc += acc/s\n",
        "        \n",
        "        test_num += 1\n",
        "    #print(test_acc)\n",
        "    #print(test_num )\n",
        "        # print(\"------\")\n",
        "        # print(label_pred)\n",
        "        # print(dev_label.numpy())\n",
        "        # print(\"------\")\n",
        "        # acc = np.sum(label_pred == dev_label.numpy())\n",
        "        # batch_acc=acc / s\n",
        "\n",
        "    print(test_acc / test_num)\n",
        "    SNR_acc_list.append(test_acc / test_num)\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        # epoch_dev_acc += acc / s\n",
        "        # print(\"devacc\", acc);\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "SNR = np.linspace(-5, 5, 10, endpoint=False)\n",
        "SNR=np.arange(1, len(SNR_acc_list) + 1)\n",
        "print(np.shape(SNR))\n",
        "print(np.shape(SNR_acc_list))\n",
        "plt.title('acc_SNR')\n",
        "plt.plot(SNR, SNR_acc_list, color='red', label='train loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6gpSPZhgmCpJ",
        "outputId": "2684ce65-2eb9-4fcc-cfd3-8ae1e591f788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.9\n",
            "0.7484848484848484\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.756060606060606\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.75\n",
            "0.875\n",
            "0.7916666666666666\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.7810606060606061\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.8333333333333334\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.5833333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.9583333333333334\n",
            "0.7916666666666666\n",
            "0.7\n",
            "0.7568181818181817\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.75\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.625\n",
            "0.8333333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.625\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.8\n",
            "0.7204545454545455\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.8333333333333334\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7\n",
            "0.7265151515151514\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.6939393939393939\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.5416666666666666\n",
            "0.7083333333333334\n",
            "0.5\n",
            "0.625\n",
            "0.5416666666666666\n",
            "0.625\n",
            "0.9\n",
            "0.6462121212121212\n",
            "(10,)\n",
            "(10,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0503 cnn_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}