{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki-i/APRiL/blob/master/0SNR0503_cnn_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QiGF43Vh69",
        "outputId": "8c882013-18a8-4182-c4db-06daa9da511d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52AY7dz9WsC0"
      },
      "outputs": [],
      "source": [
        "workspace_dir = '.'\n",
        "#!unzip -q \"/content/drive/My Drive/crypko_data.zip\" -d \"{workspace_dir}/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZHLjPEPEW0iE"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import scipy.io as scio\n",
        "import pylab\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G7ydcVOPsj77"
      },
      "outputs": [],
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DnCNN, self).__init__()\n",
        "        channels=3\n",
        "        num_of_layers=10\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        " \n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self.fc1=nn.Linear( 3*50*100,6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(6,2)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "    def forward(self, x):\n",
        "        y = self.dncnn(x)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        #print(y.size())\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AX1zF1JW_xw"
      },
      "outputs": [],
      "source": [
        "class Model(Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 5)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*2*9, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 6)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.relu1(y)\n",
        "        y = self.pool1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.relu2(y)\n",
        "        y = self.pool2(y)\n",
        "        y = self.conv3(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.pool3(y)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.fc2(y)\n",
        "        # y = self.relu4(y)\n",
        "        # y = self.fc3(y)\n",
        "        # y = self.relu5(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLNyO4Z-XAwy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-vFcTvIaXGG2"
      },
      "outputs": [],
      "source": [
        "def get_data(dataset_path, fm, dev_ratio,SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    datalen=500\n",
        "    x = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1, int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x[i] = data[xkey1]\n",
        "        x[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y[i] = 1\n",
        "        y[i+int(datalen/2)] = 0\n",
        "\n",
        "    data_size = len(y)\n",
        "    train_size = int(data_size * (1 - dev_ratio))\n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(x)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(y)\n",
        "    # print(\"train size:\", train_size)\n",
        "    # print(\"dev size:\", data_size - train_size)\n",
        "    x_train = x[:train_size]\n",
        "    y_train = y[:train_size]\n",
        "    x_dev = x[train_size:]\n",
        "    y_dev = y[train_size:]\n",
        "    return x_train, y_train, x_dev, y_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DYoliGW6XJJv"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "       \n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "       \n",
        "        x = torch.div(x, 255.)\n",
        "      \n",
        "        #print(x.size())\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGk2NrCqPnk",
        "outputId": "aa438a2f-c75a-4c2d-d9a5-aadefa6a4c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25 0.5  0.75 1.  ]\n"
          ]
        }
      ],
      "source": [
        "x=np.array([1,2,3,4])\n",
        "x=x/4\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1coYPwD6v79d"
      },
      "outputs": [],
      "source": [
        "def psnr(target_data, ref_data):\n",
        "    # target:目标图像  ref:参考图像  scale:尺寸大小\n",
        "    # assume RGB image\n",
        "    #target_data = np.array(target)\n",
        "    #target_data = target_data[scale:-scale, scale:-scale]\n",
        "\n",
        "    #ref_data = np.array(ref)\n",
        "    #ref_data = ref_data[scale:-scale, scale:-scale]\n",
        "    im = ref_data.max()\n",
        "    print('参考图像峰值', ref_data.max(), ref_data.min())\n",
        "    print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    target_data = target_data * (ref_data.max() / target_data.max())\n",
        "    #print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    diff = ref_data - target_data\n",
        "    diff = diff.flatten('C')\n",
        "\n",
        "    #rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "    #return 20 * math.log10(math.pow(im,2) / rmse)\n",
        "    mse = np.mean(diff ** 2.)\n",
        "    return 20 * math.log10(math.pow(im,2) / mse)\n",
        "\n",
        "def ab_err(target_data, ref_data):\n",
        "  diff = abs(ref_data - target_data)/ref_data\n",
        "  diff=diff.cpu().data.numpy()\n",
        "  tdiff=diff[0:,0:2]\n",
        "  vdiff=diff[0:,3:5]\n",
        "  \n",
        "  \n",
        "  terr = np.mean(tdiff)\n",
        "  verr = np.mean(vdiff)\n",
        "\n",
        "  return terr,verr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl5D9ZN0XThY",
        "outputId": "278da22f-2a44-47e3-cd1d-1754dbf310b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0.0000 train acc: 0.4677,train loss: 0.7091, dev acc: 0.4677, dev loss: 0.7034\n",
            "epoch 1.0000 train acc: 0.4677,train loss: 0.6928, dev acc: 0.4677, dev loss: 0.7033\n",
            "epoch 2.0000 train acc: 0.4677,train loss: 0.6784, dev acc: 0.4677, dev loss: 0.7048\n",
            "epoch 3.0000 train acc: 0.4708,train loss: 0.6668, dev acc: 0.4677, dev loss: 0.7048\n",
            "epoch 4.0000 train acc: 0.4854,train loss: 0.6646, dev acc: 0.4677, dev loss: 0.7047\n",
            "epoch 5.0000 train acc: 0.5156,train loss: 0.6446, dev acc: 0.4677, dev loss: 0.7039\n",
            "epoch 6.0000 train acc: 0.5385,train loss: 0.6367, dev acc: 0.4677, dev loss: 0.7033\n",
            "epoch 7.0000 train acc: 0.5896,train loss: 0.6261, dev acc: 0.4677, dev loss: 0.7021\n",
            "epoch 8.0000 train acc: 0.6323,train loss: 0.6109, dev acc: 0.4677, dev loss: 0.6988\n",
            "epoch 9.0000 train acc: 0.7021,train loss: 0.5963, dev acc: 0.4677, dev loss: 0.6771\n",
            "epoch 10.0000 train acc: 0.7115,train loss: 0.5840, dev acc: 0.6094, dev loss: 0.6286\n",
            "epoch 11.0000 train acc: 0.7302,train loss: 0.5856, dev acc: 0.8823, dev loss: 0.5774\n",
            "epoch 12.0000 train acc: 0.7729,train loss: 0.5583, dev acc: 0.9563, dev loss: 0.5473\n",
            "epoch 13.0000 train acc: 0.8385,train loss: 0.5360, dev acc: 0.9844, dev loss: 0.5262\n",
            "epoch 14.0000 train acc: 0.7812,train loss: 0.5444, dev acc: 0.9906, dev loss: 0.5117\n",
            "epoch 15.0000 train acc: 0.8083,train loss: 0.5267, dev acc: 0.9906, dev loss: 0.4976\n",
            "epoch 16.0000 train acc: 0.8365,train loss: 0.5167, dev acc: 0.9844, dev loss: 0.4935\n",
            "epoch 17.0000 train acc: 0.8135,train loss: 0.5052, dev acc: 0.9969, dev loss: 0.4705\n",
            "epoch 18.0000 train acc: 0.7469,train loss: 0.5266, dev acc: 0.9938, dev loss: 0.4692\n",
            "epoch 19.0000 train acc: 0.8260,train loss: 0.4972, dev acc: 0.9969, dev loss: 0.4484\n",
            "epoch 20.0000 train acc: 0.8656,train loss: 0.4586, dev acc: 0.9969, dev loss: 0.4324\n",
            "epoch 21.0000 train acc: 0.8083,train loss: 0.4832, dev acc: 0.9938, dev loss: 0.4424\n",
            "epoch 22.0000 train acc: 0.8448,train loss: 0.4628, dev acc: 1.0000, dev loss: 0.4167\n",
            "epoch 23.0000 train acc: 0.8510,train loss: 0.4317, dev acc: 1.0000, dev loss: 0.4007\n",
            "epoch 24.0000 train acc: 0.8187,train loss: 0.4599, dev acc: 1.0000, dev loss: 0.3932\n",
            "epoch 25.0000 train acc: 0.8052,train loss: 0.4554, dev acc: 1.0000, dev loss: 0.3866\n",
            "epoch 26.0000 train acc: 0.8187,train loss: 0.4431, dev acc: 1.0000, dev loss: 0.3743\n",
            "epoch 27.0000 train acc: 0.8177,train loss: 0.4339, dev acc: 1.0000, dev loss: 0.3646\n",
            "epoch 28.0000 train acc: 0.8479,train loss: 0.4256, dev acc: 1.0000, dev loss: 0.3567\n",
            "epoch 29.0000 train acc: 0.8229,train loss: 0.4079, dev acc: 1.0000, dev loss: 0.3476\n",
            "epoch 30.0000 train acc: 0.8698,train loss: 0.3793, dev acc: 1.0000, dev loss: 0.3370\n",
            "epoch 31.0000 train acc: 0.8250,train loss: 0.4062, dev acc: 1.0000, dev loss: 0.3299\n",
            "epoch 32.0000 train acc: 0.8052,train loss: 0.4049, dev acc: 1.0000, dev loss: 0.3320\n",
            "epoch 33.0000 train acc: 0.8583,train loss: 0.3664, dev acc: 1.0000, dev loss: 0.3188\n",
            "epoch 34.0000 train acc: 0.8427,train loss: 0.3733, dev acc: 1.0000, dev loss: 0.3056\n",
            "epoch 35.0000 train acc: 0.8323,train loss: 0.3770, dev acc: 1.0000, dev loss: 0.3146\n",
            "epoch 36.0000 train acc: 0.8010,train loss: 0.3924, dev acc: 1.0000, dev loss: 0.2974\n",
            "epoch 37.0000 train acc: 0.8438,train loss: 0.3585, dev acc: 1.0000, dev loss: 0.2866\n",
            "epoch 38.0000 train acc: 0.8219,train loss: 0.3865, dev acc: 1.0000, dev loss: 0.2983\n",
            "epoch 39.0000 train acc: 0.8281,train loss: 0.3496, dev acc: 1.0000, dev loss: 0.2754\n",
            "epoch 40.0000 train acc: 0.8271,train loss: 0.3561, dev acc: 1.0000, dev loss: 0.2788\n",
            "epoch 41.0000 train acc: 0.7979,train loss: 0.3775, dev acc: 1.0000, dev loss: 0.2671\n",
            "epoch 42.0000 train acc: 0.7865,train loss: 0.3822, dev acc: 1.0000, dev loss: 0.2708\n",
            "epoch 43.0000 train acc: 0.8375,train loss: 0.3299, dev acc: 1.0000, dev loss: 0.2636\n",
            "epoch 44.0000 train acc: 0.8073,train loss: 0.3812, dev acc: 1.0000, dev loss: 0.2519\n",
            "epoch 45.0000 train acc: 0.8271,train loss: 0.3374, dev acc: 1.0000, dev loss: 0.2468\n",
            "epoch 46.0000 train acc: 0.8094,train loss: 0.3658, dev acc: 1.0000, dev loss: 0.2464\n",
            "epoch 47.0000 train acc: 0.7927,train loss: 0.3644, dev acc: 1.0000, dev loss: 0.2460\n",
            "epoch 48.0000 train acc: 0.8417,train loss: 0.3199, dev acc: 1.0000, dev loss: 0.2321\n",
            "epoch 49.0000 train acc: 0.8313,train loss: 0.3279, dev acc: 1.0000, dev loss: 0.2290\n",
            "epoch 50.0000 train acc: 0.8187,train loss: 0.3470, dev acc: 1.0000, dev loss: 0.2235\n",
            "epoch 51.0000 train acc: 0.8198,train loss: 0.3367, dev acc: 1.0000, dev loss: 0.2277\n",
            "epoch 52.0000 train acc: 0.8562,train loss: 0.3106, dev acc: 1.0000, dev loss: 0.2141\n",
            "epoch 53.0000 train acc: 0.8781,train loss: 0.2909, dev acc: 1.0000, dev loss: 0.2087\n",
            "epoch 54.0000 train acc: 0.7812,train loss: 0.3356, dev acc: 1.0000, dev loss: 0.2083\n",
            "epoch 55.0000 train acc: 0.8125,train loss: 0.3255, dev acc: 1.0000, dev loss: 0.2036\n",
            "epoch 56.0000 train acc: 0.8448,train loss: 0.2904, dev acc: 1.0000, dev loss: 0.1964\n",
            "epoch 57.0000 train acc: 0.8260,train loss: 0.3237, dev acc: 1.0000, dev loss: 0.2044\n",
            "epoch 58.0000 train acc: 0.8292,train loss: 0.3030, dev acc: 1.0000, dev loss: 0.1887\n",
            "epoch 59.0000 train acc: 0.8365,train loss: 0.3025, dev acc: 1.0000, dev loss: 0.1933\n",
            "epoch 60.0000 train acc: 0.8500,train loss: 0.2910, dev acc: 1.0000, dev loss: 0.1874\n",
            "epoch 61.0000 train acc: 0.8104,train loss: 0.2989, dev acc: 1.0000, dev loss: 0.1933\n",
            "epoch 62.0000 train acc: 0.8438,train loss: 0.2886, dev acc: 1.0000, dev loss: 0.1816\n",
            "epoch 63.0000 train acc: 0.8844,train loss: 0.2568, dev acc: 1.0000, dev loss: 0.1770\n",
            "epoch 64.0000 train acc: 0.8438,train loss: 0.2758, dev acc: 1.0000, dev loss: 0.1826\n",
            "epoch 65.0000 train acc: 0.8500,train loss: 0.2793, dev acc: 1.0000, dev loss: 0.1675\n",
            "epoch 66.0000 train acc: 0.8219,train loss: 0.2920, dev acc: 1.0000, dev loss: 0.1706\n",
            "epoch 67.0000 train acc: 0.8542,train loss: 0.2715, dev acc: 1.0000, dev loss: 0.1649\n",
            "epoch 68.0000 train acc: 0.8635,train loss: 0.2530, dev acc: 1.0000, dev loss: 0.1625\n",
            "epoch 69.0000 train acc: 0.8823,train loss: 0.2340, dev acc: 1.0000, dev loss: 0.1534\n",
            "epoch 70.0000 train acc: 0.8604,train loss: 0.2591, dev acc: 1.0000, dev loss: 0.1523\n",
            "epoch 71.0000 train acc: 0.8854,train loss: 0.2455, dev acc: 1.0000, dev loss: 0.1496\n",
            "epoch 72.0000 train acc: 0.8583,train loss: 0.2503, dev acc: 1.0000, dev loss: 0.1453\n",
            "epoch 73.0000 train acc: 0.8938,train loss: 0.2257, dev acc: 1.0000, dev loss: 0.1419\n",
            "epoch 74.0000 train acc: 0.8698,train loss: 0.2407, dev acc: 1.0000, dev loss: 0.1418\n",
            "epoch 75.0000 train acc: 0.8698,train loss: 0.2738, dev acc: 1.0000, dev loss: 0.1504\n",
            "epoch 76.0000 train acc: 0.8708,train loss: 0.2426, dev acc: 1.0000, dev loss: 0.1501\n",
            "epoch 77.0000 train acc: 0.8875,train loss: 0.2317, dev acc: 1.0000, dev loss: 0.1397\n",
            "epoch 78.0000 train acc: 0.8823,train loss: 0.2372, dev acc: 1.0000, dev loss: 0.1314\n",
            "epoch 79.0000 train acc: 0.8958,train loss: 0.2222, dev acc: 1.0000, dev loss: 0.1303\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2ae1389cd22a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_dev_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skyblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imgname' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    batch_size = 32\n",
        "    lr=1e-3\n",
        "    #lr=1e-4#loss:11.72 10.74\n",
        "    #lr=1e-3#9.6519\n",
        "    #lr=0.01#8.3690\n",
        "    #lr=0.1#8.2 7.72 7.71 ..7156.7147\n",
        "    log_dir='/content/drive/My Drive/ClassificationModel0503.pth'\n",
        "    #数据集加载\n",
        "    dataset_path = '/content/drive/My Drive/'\n",
        "    x_train, y_train, x_dev, y_dev = get_data(dataset_path, 'TrainDataClassification.mat', 0.4,0)\n",
        "    #print(x_train[0])\n",
        "    train_dataset = MyDataset(x_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    dev_dataset = MyDataset(x_dev, y_dev)\n",
        "    dev_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "    model = DnCNN()\n",
        "    #model = Model()\n",
        "    #模型加载\n",
        "    start_epoch=0\n",
        "    '''\n",
        "    if os.path.exists(log_dir):\n",
        "        checkpoint = torch.load(log_dir)\n",
        "        model.load_state_dict(checkpoint['net'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        print('无保存模型，将从头开始训练！')\n",
        "    '''\n",
        "    sgd = SGD(model.parameters(), lr)\n",
        "\n",
        "    cost = CrossEntropyLoss()\n",
        "    criterion = MSELoss(reduction='sum')\n",
        "    epoch = 80\n",
        "    use_GPU = True\n",
        "    if use_GPU:\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    epoch_train_loss_list = []\n",
        "    epoch_dev_loss_list = []\n",
        "    epoch_train_acc_list = []\n",
        "    epoch_dev_acc_list = []\n",
        "\n",
        "    for _epoch in range(epoch):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_dev_loss = 0\n",
        "        epoch_train_acc = 0\n",
        "        epoch_dev_acc = 0\n",
        "        train_num=0\n",
        "        dev_num = 0\n",
        "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "            s = train_label.shape[0]\n",
        "            sgd.zero_grad()\n",
        "            predict_y = model(train_x.to(device))\n",
        "            #print(train_label.size())\n",
        "            #print(predict_y.size())\n",
        "            #loss = cost(predict_y, train_label.to(device))\n",
        "            loss = F.cross_entropy(predict_y, train_label.to(device))\n",
        "            epoch_train_loss += loss.item()\n",
        "            label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "            acc = np.sum(label_pred == train_label.numpy())\n",
        "            # print(\"batch Train acc:\",acc / s)\n",
        "            epoch_train_acc += acc / s\n",
        "            train_num+=1\n",
        "            loss.backward()\n",
        "            sgd.step()\n",
        "\n",
        "        correct = 0\n",
        "        _sum = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (dev_x, dev_label) in enumerate(dev_loader):\n",
        "                s = dev_label.shape[0]\n",
        "                predict_y = model(dev_x.to(device))\n",
        "                # print(predict_y[0], dev_label[0])\n",
        "                loss = cost(predict_y, dev_label.to(device))\n",
        "                epoch_dev_loss += loss.item()\n",
        "                label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "                acc = np.sum(label_pred == dev_label.numpy())\n",
        "                batch_acc=acc / s\n",
        "                dev_num+=1\n",
        "                # print(\"batch_acc::\",batch_acc)\n",
        "                epoch_dev_acc += acc / s\n",
        "                # print(\"devacc\", acc);\n",
        "        epoch_train_loss_list.append(epoch_train_loss / train_num)\n",
        "        epoch_dev_loss_list.append(epoch_dev_loss / train_num)\n",
        "        epoch_train_acc_list.append(epoch_train_acc / dev_num)\n",
        "        epoch_dev_acc_list.append(epoch_dev_acc / dev_num)\n",
        "        print(\"epoch {:.4f} train acc: {:.4f},train loss: {:.4f}, dev acc: {:.4f}, dev loss: {:.4f}\".format(_epoch,epoch_train_acc / train_num, epoch_train_loss / train_num,epoch_dev_acc / dev_num, epoch_dev_loss / dev_num))\n",
        "   \n",
        "    \n",
        "    state = {'net':model.state_dict(),  'epoch':epoch}\n",
        "    torch.save(state, log_dir)\n",
        "    t = np.arange(1, len(epoch_train_loss_list) + 1)\n",
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ],
      "metadata": {
        "id": "px1s0sYqk-Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data(dataset_path, fm, SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    '''\n",
        "    datalen=500\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "    '''   \n",
        "    datalen=250\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,datalen):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        #xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        #x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        #y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "\n",
        "    \n",
        "    return x_test, y_test\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "        #label=label.float()\n",
        "        x = torch.div(x, 255.)\n",
        "        #print(label)\n",
        "        #label = torch.div(label, 10000.)\n",
        "        #print(x)\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ],
      "metadata": {
        "id": "MIEC7MelezSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "2CvKfHmdWlBp",
        "outputId": "3f0e8c16-5deb-4888-cead-cc8eda32aa79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d554eb841dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#loss = criterion(predict_y, train_label.to(device)) / (2 * len(train_x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#terror,verror,acc=ab_err(predict_y,test_label.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mepoch_dev_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (100) to match target batch_size (24)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 24\n",
        "use_GPU = True\n",
        "if use_GPU:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "model = DnCNN()\n",
        "model.to(device)\n",
        "print(torch.cuda.is_available())\n",
        "log_dir = '/content/drive/My Drive/ClassificationModel0425.pth'\n",
        "if os.path.exists(log_dir):\n",
        "    checkpoint = torch.load(log_dir)\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    print('加载失败')\n",
        "dataset_path=\"/content/drive/My Drive/\"\n",
        "SNR_acc_list = []\n",
        "for SNR in range(-5, 5):\n",
        "    x_test, y_test = get_test_data(dataset_path, 'TrainDataClassification.mat', SNR)\n",
        "    test_dataset = MyTestDataset(x_test, y_test)\n",
        "    train_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    test_num = 0\n",
        "    test_derror=0\n",
        "    test_verror=0\n",
        "    test_acc = 0\n",
        "    for idx, (test_x, test_label) in enumerate(train_loader):\n",
        "        epoch_dev_acc = 0\n",
        "        train_num = 0\n",
        "        dev_num = 0\n",
        "        epoch_dev_derror = 0\n",
        "        epoch_dev_verror = 0\n",
        "        epoch_train_derror = 0\n",
        "        epoch_train_verror = 0\n",
        "        s = test_label.shape[0]\n",
        "        predict_y = model(test_x.to(device))\n",
        "        \n",
        "        loss = F.cross_entropy(predict_y, test_label.to(device))\n",
        "            \n",
        "        epoch_dev_loss += loss.item()\n",
        "        label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "        acc = np.sum(label_pred == test_label.numpy())\n",
        "        batch_acc=acc / s\n",
        "        print(batch_acc)\n",
        "\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        test_acc += acc/s\n",
        "        \n",
        "        test_num += 1\n",
        "    #print(test_acc)\n",
        "    #print(test_num )\n",
        "        # print(\"------\")\n",
        "        # print(label_pred)\n",
        "        # print(dev_label.numpy())\n",
        "        # print(\"------\")\n",
        "        # acc = np.sum(label_pred == dev_label.numpy())\n",
        "        # batch_acc=acc / s\n",
        "\n",
        "    print(test_acc / test_num)\n",
        "    SNR_acc_list.append(test_acc / test_num)\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        # epoch_dev_acc += acc / s\n",
        "        # print(\"devacc\", acc);\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "SNR = np.linspace(-5, 5, 10, endpoint=False)\n",
        "SNR=np.arange(1, len(SNR_acc_list) + 1)\n",
        "print(np.shape(SNR))\n",
        "print(np.shape(SNR_acc_list))\n",
        "plt.title('acc_SNR')\n",
        "plt.plot(SNR, SNR_acc_list, color='red', label='train loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6gpSPZhgmCpJ",
        "outputId": "2684ce65-2eb9-4fcc-cfd3-8ae1e591f788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.9\n",
            "0.7484848484848484\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.756060606060606\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.75\n",
            "0.875\n",
            "0.7916666666666666\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.7810606060606061\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.8333333333333334\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.5833333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.9583333333333334\n",
            "0.7916666666666666\n",
            "0.7\n",
            "0.7568181818181817\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.75\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.625\n",
            "0.8333333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.625\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.8\n",
            "0.7204545454545455\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.8333333333333334\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7\n",
            "0.7265151515151514\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.6939393939393939\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.5416666666666666\n",
            "0.7083333333333334\n",
            "0.5\n",
            "0.625\n",
            "0.5416666666666666\n",
            "0.625\n",
            "0.9\n",
            "0.6462121212121212\n",
            "(10,)\n",
            "(10,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0503 cnn_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}