{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki-i/APRiL/blob/master/cnn_classification1040901.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QiGF43Vh69",
        "outputId": "be207611-825c-4863-fd50-a409341b5d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52AY7dz9WsC0"
      },
      "outputs": [],
      "source": [
        "workspace_dir = '.'\n",
        "#!unzip -q \"/content/drive/My Drive/crypko_data.zip\" -d \"{workspace_dir}/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZHLjPEPEW0iE"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import scipy.io as scio\n",
        "import pylab\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G7ydcVOPsj77"
      },
      "outputs": [],
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DnCNN, self).__init__()\n",
        "        channels=2\n",
        "        num_of_layers=10\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        " \n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self.fc1=nn.Linear( 2*50*100,6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(6,2)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "    def forward(self, x):\n",
        "        y = self.dncnn(x)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        #print(y.size())\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AX1zF1JW_xw"
      },
      "outputs": [],
      "source": [
        "class Model(Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 5)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*2*9, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 6)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.relu1(y)\n",
        "        y = self.pool1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.relu2(y)\n",
        "        y = self.pool2(y)\n",
        "        y = self.conv3(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.pool3(y)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.fc2(y)\n",
        "        # y = self.relu4(y)\n",
        "        # y = self.fc3(y)\n",
        "        # y = self.relu5(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLNyO4Z-XAwy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-vFcTvIaXGG2"
      },
      "outputs": [],
      "source": [
        "def get_data(dataset_path, fm, dev_ratio):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    datalen=1000\n",
        "    x = np.zeros((datalen, 2, 50, 100), dtype=np.float)\n",
        "    y = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1, datalen):\n",
        "        xkey = 'x' + str(i)\n",
        "        #print(xkey)\n",
        "        x[i] = data[xkey]\n",
        "        \n",
        "        ykey = 'y' + str(i)\n",
        "        if(i<=datalen/2):\n",
        "          y[i] = 1#噪声\n",
        "        else:\n",
        "          y[i] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "        \n",
        "\n",
        "    data_size = len(y)\n",
        "    train_size = int(data_size * (1 - dev_ratio))\n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(x)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(y)\n",
        "    # print(\"train size:\", train_size)\n",
        "    # print(\"dev size:\", data_size - train_size)\n",
        "    x_train = x[:train_size]\n",
        "    y_train = y[:train_size]\n",
        "    x_dev = x[train_size:]\n",
        "    y_dev = y[train_size:]\n",
        "    return x_train, y_train, x_dev, y_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DYoliGW6XJJv"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "       \n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "       \n",
        "        x = torch.div(x, 255.)\n",
        "      \n",
        "        #print(x.size())\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGk2NrCqPnk",
        "outputId": "aa438a2f-c75a-4c2d-d9a5-aadefa6a4c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25 0.5  0.75 1.  ]\n"
          ]
        }
      ],
      "source": [
        "x=np.array([1,2,3,4])\n",
        "x=x/4\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1coYPwD6v79d"
      },
      "outputs": [],
      "source": [
        "def psnr(target_data, ref_data):\n",
        "    # target:目标图像  ref:参考图像  scale:尺寸大小\n",
        "    # assume RGB image\n",
        "    #target_data = np.array(target)\n",
        "    #target_data = target_data[scale:-scale, scale:-scale]\n",
        "\n",
        "    #ref_data = np.array(ref)\n",
        "    #ref_data = ref_data[scale:-scale, scale:-scale]\n",
        "    im = ref_data.max()\n",
        "    print('参考图像峰值', ref_data.max(), ref_data.min())\n",
        "    print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    target_data = target_data * (ref_data.max() / target_data.max())\n",
        "    #print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    diff = ref_data - target_data\n",
        "    diff = diff.flatten('C')\n",
        "\n",
        "    #rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "    #return 20 * math.log10(math.pow(im,2) / rmse)\n",
        "    mse = np.mean(diff ** 2.)\n",
        "    return 20 * math.log10(math.pow(im,2) / mse)\n",
        "\n",
        "def ab_err(target_data, ref_data):\n",
        "  diff = abs(ref_data - target_data)/ref_data\n",
        "  diff=diff.cpu().data.numpy()\n",
        "  tdiff=diff[0:,0:2]\n",
        "  vdiff=diff[0:,3:5]\n",
        "  \n",
        "  \n",
        "  terr = np.mean(tdiff)\n",
        "  verr = np.mean(vdiff)\n",
        "\n",
        "  return terr,verr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl5D9ZN0XThY",
        "outputId": "cf4e0a54-3efb-4670-c8bd-0ea74c440968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0.0000 train acc: 0.7712,train loss: 0.5162, dev acc: 0.4900, dev loss: 0.7031\n",
            "epoch 1.0000 train acc: 0.8313,train loss: 0.3047, dev acc: 0.4900, dev loss: 0.6680\n",
            "epoch 2.0000 train acc: 0.8400,train loss: 0.2198, dev acc: 1.0000, dev loss: 0.3821\n",
            "epoch 3.0000 train acc: 0.8462,train loss: 0.1921, dev acc: 1.0000, dev loss: 0.0401\n",
            "epoch 4.0000 train acc: 0.8500,train loss: 0.1741, dev acc: 1.0000, dev loss: 0.0137\n",
            "epoch 5.0000 train acc: 0.8688,train loss: 0.1464, dev acc: 1.0000, dev loss: 0.0088\n",
            "epoch 6.0000 train acc: 0.8912,train loss: 0.1436, dev acc: 1.0000, dev loss: 0.0060\n",
            "epoch 7.0000 train acc: 0.9500,train loss: 0.1374, dev acc: 1.0000, dev loss: 0.0041\n",
            "epoch 8.0000 train acc: 0.9525,train loss: 0.1255, dev acc: 1.0000, dev loss: 0.0027\n",
            "epoch 9.0000 train acc: 0.9500,train loss: 0.1158, dev acc: 1.0000, dev loss: 0.0016\n",
            "epoch 10.0000 train acc: 0.9575,train loss: 0.0875, dev acc: 1.0000, dev loss: 0.0009\n",
            "epoch 11.0000 train acc: 0.9525,train loss: 0.0828, dev acc: 1.0000, dev loss: 0.0005\n",
            "epoch 12.0000 train acc: 0.9613,train loss: 0.0652, dev acc: 1.0000, dev loss: 0.0003\n",
            "epoch 13.0000 train acc: 0.9563,train loss: 0.0576, dev acc: 1.0000, dev loss: 0.0002\n",
            "epoch 14.0000 train acc: 0.9563,train loss: 0.0542, dev acc: 1.0000, dev loss: 0.0001\n",
            "epoch 15.0000 train acc: 0.9575,train loss: 0.0497, dev acc: 1.0000, dev loss: 0.0001\n",
            "epoch 16.0000 train acc: 0.9587,train loss: 0.0460, dev acc: 1.0000, dev loss: 0.0001\n",
            "epoch 17.0000 train acc: 0.9537,train loss: 0.0472, dev acc: 1.0000, dev loss: 0.0001\n",
            "epoch 18.0000 train acc: 0.9463,train loss: 0.0524, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 19.0000 train acc: 0.9500,train loss: 0.0468, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 20.0000 train acc: 0.9513,train loss: 0.0482, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 21.0000 train acc: 0.9537,train loss: 0.0451, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 22.0000 train acc: 0.9425,train loss: 0.0527, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 23.0000 train acc: 0.9500,train loss: 0.0462, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 24.0000 train acc: 0.9500,train loss: 0.0447, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 25.0000 train acc: 0.9675,train loss: 0.0308, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 26.0000 train acc: 0.9587,train loss: 0.0384, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 27.0000 train acc: 0.9575,train loss: 0.0416, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 28.0000 train acc: 0.9587,train loss: 0.0372, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 29.0000 train acc: 0.9475,train loss: 0.0451, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 30.0000 train acc: 0.9550,train loss: 0.0397, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 31.0000 train acc: 0.9587,train loss: 0.0372, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 32.0000 train acc: 0.9500,train loss: 0.0452, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 33.0000 train acc: 0.9587,train loss: 0.0339, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 34.0000 train acc: 0.9663,train loss: 0.0281, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 35.0000 train acc: 0.9513,train loss: 0.0404, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 36.0000 train acc: 0.9550,train loss: 0.0407, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 37.0000 train acc: 0.9375,train loss: 0.0510, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 38.0000 train acc: 0.9587,train loss: 0.0384, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 39.0000 train acc: 0.9413,train loss: 0.0463, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 40.0000 train acc: 0.9550,train loss: 0.0368, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 41.0000 train acc: 0.9350,train loss: 0.0548, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 42.0000 train acc: 0.9463,train loss: 0.0427, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 43.0000 train acc: 0.9537,train loss: 0.0373, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 44.0000 train acc: 0.9487,train loss: 0.0415, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 45.0000 train acc: 0.9487,train loss: 0.0428, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 46.0000 train acc: 0.9425,train loss: 0.0472, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 47.0000 train acc: 0.9525,train loss: 0.0379, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 48.0000 train acc: 0.9637,train loss: 0.0326, dev acc: 1.0000, dev loss: 0.0000\n",
            "epoch 49.0000 train acc: 0.9475,train loss: 0.0404, dev acc: 1.0000, dev loss: 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d5fe88ac9ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_dev_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skyblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imgname' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    batch_size = 32\n",
        "    lr=1e-3\n",
        "    #lr=1e-4#loss:11.72 10.74\n",
        "    #lr=1e-3#9.6519\n",
        "    #lr=0.01#8.3690\n",
        "    #lr=0.1#8.2 7.72 7.71 ..7156.7147\n",
        "    log_dir='/content/drive/My Drive/model.pth'\n",
        "    #数据集加载\n",
        "    dataset_path = '/content/drive/My Drive/'\n",
        "    x_train, y_train, x_dev, y_dev = get_data(dataset_path, 'TrainData0.mat', 0.4)\n",
        "    #print(x_train[0])\n",
        "    train_dataset = MyDataset(x_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    dev_dataset = MyDataset(x_dev, y_dev)\n",
        "    dev_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "    model = DnCNN()\n",
        "    #model = Model()\n",
        "    #模型加载\n",
        "    start_epoch=0\n",
        "    '''\n",
        "    if os.path.exists(log_dir):\n",
        "        checkpoint = torch.load(log_dir)\n",
        "        model.load_state_dict(checkpoint['net'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        print('无保存模型，将从头开始训练！')\n",
        "    '''\n",
        "    sgd = SGD(model.parameters(), lr)\n",
        "\n",
        "    cost = CrossEntropyLoss()\n",
        "    criterion = MSELoss(reduction='sum')\n",
        "    epoch = 50\n",
        "    use_GPU = True\n",
        "    if use_GPU:\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    epoch_train_loss_list = []\n",
        "    epoch_dev_loss_list = []\n",
        "    epoch_train_acc_list = []\n",
        "    epoch_dev_acc_list = []\n",
        "\n",
        "    for _epoch in range(epoch):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_dev_loss = 0\n",
        "        epoch_train_acc = 0\n",
        "        epoch_dev_acc = 0\n",
        "        train_num=0\n",
        "        dev_num = 0\n",
        "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "            s = train_label.shape[0]\n",
        "            sgd.zero_grad()\n",
        "            predict_y = model(train_x.to(device))\n",
        "            #print(train_label.size())\n",
        "            #print(predict_y.size())\n",
        "            #loss = cost(predict_y, train_label.to(device))\n",
        "            loss = F.cross_entropy(predict_y, train_label.to(device))\n",
        "            epoch_train_loss += loss.item()\n",
        "            label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "            acc = np.sum(label_pred == train_label.numpy())\n",
        "            # print(\"batch Train acc:\",acc / s)\n",
        "            epoch_train_acc += acc / s\n",
        "            train_num+=1\n",
        "            loss.backward()\n",
        "            sgd.step()\n",
        "\n",
        "        correct = 0\n",
        "        _sum = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (dev_x, dev_label) in enumerate(dev_loader):\n",
        "                s = dev_label.shape[0]\n",
        "                predict_y = model(dev_x.to(device))\n",
        "                # print(predict_y[0], dev_label[0])\n",
        "                loss = cost(predict_y, dev_label.to(device))\n",
        "                epoch_dev_loss += loss.item()\n",
        "                label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "                # print(\"------\")\n",
        "                # print(label_pred)\n",
        "                # print(dev_label.numpy())\n",
        "                # print(\"------\")\n",
        "                acc = np.sum(label_pred == dev_label.numpy())\n",
        "                batch_acc=acc / s\n",
        "                dev_num+=1\n",
        "                # print(\"batch_acc::\",batch_acc)\n",
        "                epoch_dev_acc += acc / s\n",
        "                # print(\"devacc\", acc);\n",
        "        epoch_train_loss_list.append(epoch_train_loss / train_num)\n",
        "        epoch_dev_loss_list.append(epoch_dev_loss / train_num)\n",
        "        epoch_train_acc_list.append(epoch_train_acc / dev_num)\n",
        "        epoch_dev_acc_list.append(epoch_dev_acc / dev_num)\n",
        "        print(\"epoch {:.4f} train acc: {:.4f},train loss: {:.4f}, dev acc: {:.4f}, dev loss: {:.4f}\".format(_epoch,epoch_train_acc / train_num, epoch_train_loss / train_num,epoch_dev_acc / dev_num, epoch_dev_loss / dev_num))\n",
        "    t = np.arange(1, len(epoch_train_loss_list) + 1)\n",
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ],
      "metadata": {
        "id": "px1s0sYqk-Eu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cnn_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}