{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki-i/APRiL/blob/master/3SNR0503_cnn_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QiGF43Vh69",
        "outputId": "8c882013-18a8-4182-c4db-06daa9da511d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52AY7dz9WsC0"
      },
      "outputs": [],
      "source": [
        "workspace_dir = '.'\n",
        "#!unzip -q \"/content/drive/My Drive/crypko_data.zip\" -d \"{workspace_dir}/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZHLjPEPEW0iE"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import scipy.io as scio\n",
        "import pylab\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G7ydcVOPsj77"
      },
      "outputs": [],
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DnCNN, self).__init__()\n",
        "        channels=3\n",
        "        num_of_layers=10\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        " \n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self.fc1=nn.Linear( 3*50*100,6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(6,2)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "    def forward(self, x):\n",
        "        y = self.dncnn(x)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        #print(y.size())\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AX1zF1JW_xw"
      },
      "outputs": [],
      "source": [
        "class Model(Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 5)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*2*9, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 6)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.relu1(y)\n",
        "        y = self.pool1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.relu2(y)\n",
        "        y = self.pool2(y)\n",
        "        y = self.conv3(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.pool3(y)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.fc2(y)\n",
        "        # y = self.relu4(y)\n",
        "        # y = self.fc3(y)\n",
        "        # y = self.relu5(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLNyO4Z-XAwy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-vFcTvIaXGG2"
      },
      "outputs": [],
      "source": [
        "def get_data(dataset_path, fm, dev_ratio,SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    datalen=500\n",
        "    x = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1, int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x[i] = data[xkey1]\n",
        "        x[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y[i] = 1\n",
        "        y[i+int(datalen/2)] = 0\n",
        "\n",
        "    data_size = len(y)\n",
        "    train_size = int(data_size * (1 - dev_ratio))\n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(x)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(y)\n",
        "    # print(\"train size:\", train_size)\n",
        "    # print(\"dev size:\", data_size - train_size)\n",
        "    x_train = x[:train_size]\n",
        "    y_train = y[:train_size]\n",
        "    x_dev = x[train_size:]\n",
        "    y_dev = y[train_size:]\n",
        "    return x_train, y_train, x_dev, y_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DYoliGW6XJJv"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "       \n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "       \n",
        "        x = torch.div(x, 255.)\n",
        "      \n",
        "        #print(x.size())\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGk2NrCqPnk",
        "outputId": "aa438a2f-c75a-4c2d-d9a5-aadefa6a4c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25 0.5  0.75 1.  ]\n"
          ]
        }
      ],
      "source": [
        "x=np.array([1,2,3,4])\n",
        "x=x/4\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1coYPwD6v79d"
      },
      "outputs": [],
      "source": [
        "def psnr(target_data, ref_data):\n",
        "    # target:目标图像  ref:参考图像  scale:尺寸大小\n",
        "    # assume RGB image\n",
        "    #target_data = np.array(target)\n",
        "    #target_data = target_data[scale:-scale, scale:-scale]\n",
        "\n",
        "    #ref_data = np.array(ref)\n",
        "    #ref_data = ref_data[scale:-scale, scale:-scale]\n",
        "    im = ref_data.max()\n",
        "    print('参考图像峰值', ref_data.max(), ref_data.min())\n",
        "    print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    target_data = target_data * (ref_data.max() / target_data.max())\n",
        "    #print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    diff = ref_data - target_data\n",
        "    diff = diff.flatten('C')\n",
        "\n",
        "    #rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "    #return 20 * math.log10(math.pow(im,2) / rmse)\n",
        "    mse = np.mean(diff ** 2.)\n",
        "    return 20 * math.log10(math.pow(im,2) / mse)\n",
        "\n",
        "def ab_err(target_data, ref_data):\n",
        "  diff = abs(ref_data - target_data)/ref_data\n",
        "  diff=diff.cpu().data.numpy()\n",
        "  tdiff=diff[0:,0:2]\n",
        "  vdiff=diff[0:,3:5]\n",
        "  \n",
        "  \n",
        "  terr = np.mean(tdiff)\n",
        "  verr = np.mean(vdiff)\n",
        "\n",
        "  return terr,verr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl5D9ZN0XThY",
        "outputId": "2434f91d-6489-47b5-add2-ad511fd3cd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0.0000 train acc: 0.4813,train loss: 0.7152, dev acc: 0.4813, dev loss: 0.7151\n",
            "epoch 1.0000 train acc: 0.5531,train loss: 0.6956, dev acc: 0.4813, dev loss: 0.7081\n",
            "epoch 2.0000 train acc: 0.6292,train loss: 0.6619, dev acc: 0.4813, dev loss: 0.7247\n",
            "epoch 3.0000 train acc: 0.6781,train loss: 0.6445, dev acc: 0.4813, dev loss: 0.7338\n",
            "epoch 4.0000 train acc: 0.7104,train loss: 0.6272, dev acc: 0.4813, dev loss: 0.7361\n",
            "epoch 5.0000 train acc: 0.7667,train loss: 0.6051, dev acc: 0.4813, dev loss: 0.7357\n",
            "epoch 6.0000 train acc: 0.7969,train loss: 0.5941, dev acc: 0.4813, dev loss: 0.7361\n",
            "epoch 7.0000 train acc: 0.7937,train loss: 0.5693, dev acc: 0.4875, dev loss: 0.7184\n",
            "epoch 8.0000 train acc: 0.8063,train loss: 0.5600, dev acc: 0.5906, dev loss: 0.6815\n",
            "epoch 9.0000 train acc: 0.8198,train loss: 0.5470, dev acc: 0.7406, dev loss: 0.6542\n",
            "epoch 10.0000 train acc: 0.8198,train loss: 0.5325, dev acc: 0.9594, dev loss: 0.5947\n",
            "epoch 11.0000 train acc: 0.8104,train loss: 0.5363, dev acc: 0.9906, dev loss: 0.5335\n",
            "epoch 12.0000 train acc: 0.8479,train loss: 0.5162, dev acc: 0.9938, dev loss: 0.4959\n",
            "epoch 13.0000 train acc: 0.8479,train loss: 0.5021, dev acc: 0.9938, dev loss: 0.4776\n",
            "epoch 14.0000 train acc: 0.8688,train loss: 0.4762, dev acc: 0.9938, dev loss: 0.4621\n",
            "epoch 15.0000 train acc: 0.8625,train loss: 0.4666, dev acc: 1.0000, dev loss: 0.4484\n",
            "epoch 16.0000 train acc: 0.8750,train loss: 0.4581, dev acc: 1.0000, dev loss: 0.4366\n",
            "epoch 17.0000 train acc: 0.8396,train loss: 0.4704, dev acc: 1.0000, dev loss: 0.4244\n",
            "epoch 18.0000 train acc: 0.8875,train loss: 0.4360, dev acc: 1.0000, dev loss: 0.4134\n",
            "epoch 19.0000 train acc: 0.8938,train loss: 0.4169, dev acc: 1.0000, dev loss: 0.4016\n",
            "epoch 20.0000 train acc: 0.8573,train loss: 0.4355, dev acc: 1.0000, dev loss: 0.3920\n",
            "epoch 21.0000 train acc: 0.8885,train loss: 0.4169, dev acc: 1.0000, dev loss: 0.3814\n",
            "epoch 22.0000 train acc: 0.8906,train loss: 0.3967, dev acc: 1.0000, dev loss: 0.3708\n",
            "epoch 23.0000 train acc: 0.8979,train loss: 0.3954, dev acc: 1.0000, dev loss: 0.3611\n",
            "epoch 24.0000 train acc: 0.9281,train loss: 0.3896, dev acc: 1.0000, dev loss: 0.3514\n",
            "epoch 25.0000 train acc: 0.8917,train loss: 0.3857, dev acc: 1.0000, dev loss: 0.3434\n",
            "epoch 26.0000 train acc: 0.9156,train loss: 0.3712, dev acc: 1.0000, dev loss: 0.3340\n",
            "epoch 27.0000 train acc: 0.9010,train loss: 0.3631, dev acc: 1.0000, dev loss: 0.3245\n",
            "epoch 28.0000 train acc: 0.9135,train loss: 0.3503, dev acc: 1.0000, dev loss: 0.3166\n",
            "epoch 29.0000 train acc: 0.9375,train loss: 0.3492, dev acc: 1.0000, dev loss: 0.3085\n",
            "epoch 30.0000 train acc: 0.9167,train loss: 0.3486, dev acc: 1.0000, dev loss: 0.2976\n",
            "epoch 31.0000 train acc: 0.9437,train loss: 0.3324, dev acc: 1.0000, dev loss: 0.2903\n",
            "epoch 32.0000 train acc: 0.9375,train loss: 0.3242, dev acc: 1.0000, dev loss: 0.2822\n",
            "epoch 33.0000 train acc: 0.9135,train loss: 0.3418, dev acc: 1.0000, dev loss: 0.2790\n",
            "epoch 34.0000 train acc: 0.9313,train loss: 0.3227, dev acc: 1.0000, dev loss: 0.2685\n",
            "epoch 35.0000 train acc: 0.9375,train loss: 0.3101, dev acc: 1.0000, dev loss: 0.2614\n",
            "epoch 36.0000 train acc: 0.9083,train loss: 0.3046, dev acc: 1.0000, dev loss: 0.2542\n",
            "epoch 37.0000 train acc: 0.9469,train loss: 0.2828, dev acc: 1.0000, dev loss: 0.2463\n",
            "epoch 38.0000 train acc: 0.9406,train loss: 0.3033, dev acc: 1.0000, dev loss: 0.2424\n",
            "epoch 39.0000 train acc: 0.9198,train loss: 0.3014, dev acc: 1.0000, dev loss: 0.2370\n",
            "epoch 40.0000 train acc: 0.9500,train loss: 0.3065, dev acc: 1.0000, dev loss: 0.2297\n",
            "epoch 41.0000 train acc: 0.9656,train loss: 0.2682, dev acc: 1.0000, dev loss: 0.2213\n",
            "epoch 42.0000 train acc: 0.9240,train loss: 0.3078, dev acc: 1.0000, dev loss: 0.2162\n",
            "epoch 43.0000 train acc: 0.9563,train loss: 0.2645, dev acc: 1.0000, dev loss: 0.2100\n",
            "epoch 44.0000 train acc: 0.9406,train loss: 0.2675, dev acc: 1.0000, dev loss: 0.2048\n",
            "epoch 45.0000 train acc: 0.9563,train loss: 0.2675, dev acc: 1.0000, dev loss: 0.1984\n",
            "epoch 46.0000 train acc: 0.9563,train loss: 0.2589, dev acc: 1.0000, dev loss: 0.1945\n",
            "epoch 47.0000 train acc: 0.9656,train loss: 0.2408, dev acc: 1.0000, dev loss: 0.1898\n",
            "epoch 48.0000 train acc: 0.9531,train loss: 0.2411, dev acc: 1.0000, dev loss: 0.1831\n",
            "epoch 49.0000 train acc: 0.9688,train loss: 0.2387, dev acc: 1.0000, dev loss: 0.1788\n",
            "epoch 50.0000 train acc: 0.9563,train loss: 0.2459, dev acc: 1.0000, dev loss: 0.1742\n",
            "epoch 51.0000 train acc: 0.9656,train loss: 0.2347, dev acc: 1.0000, dev loss: 0.1712\n",
            "epoch 52.0000 train acc: 0.9750,train loss: 0.2154, dev acc: 1.0000, dev loss: 0.1643\n",
            "epoch 53.0000 train acc: 0.9625,train loss: 0.2477, dev acc: 1.0000, dev loss: 0.1628\n",
            "epoch 54.0000 train acc: 0.9563,train loss: 0.2373, dev acc: 1.0000, dev loss: 0.1572\n",
            "epoch 55.0000 train acc: 0.9698,train loss: 0.2463, dev acc: 1.0000, dev loss: 0.1548\n",
            "epoch 56.0000 train acc: 0.9812,train loss: 0.1868, dev acc: 1.0000, dev loss: 0.1478\n",
            "epoch 57.0000 train acc: 0.9656,train loss: 0.1962, dev acc: 1.0000, dev loss: 0.1457\n",
            "epoch 58.0000 train acc: 0.9781,train loss: 0.2079, dev acc: 1.0000, dev loss: 0.1425\n",
            "epoch 59.0000 train acc: 0.9563,train loss: 0.2067, dev acc: 1.0000, dev loss: 0.1384\n",
            "epoch 60.0000 train acc: 0.9437,train loss: 0.2203, dev acc: 1.0000, dev loss: 0.1344\n",
            "epoch 61.0000 train acc: 0.9750,train loss: 0.2199, dev acc: 1.0000, dev loss: 0.1333\n",
            "epoch 62.0000 train acc: 0.9698,train loss: 0.1960, dev acc: 1.0000, dev loss: 0.1300\n",
            "epoch 63.0000 train acc: 0.9781,train loss: 0.2043, dev acc: 1.0000, dev loss: 0.1268\n",
            "epoch 64.0000 train acc: 0.9750,train loss: 0.2035, dev acc: 1.0000, dev loss: 0.1227\n",
            "epoch 65.0000 train acc: 0.9750,train loss: 0.1912, dev acc: 1.0000, dev loss: 0.1218\n",
            "epoch 66.0000 train acc: 0.9812,train loss: 0.1796, dev acc: 1.0000, dev loss: 0.1161\n",
            "epoch 67.0000 train acc: 0.9781,train loss: 0.1790, dev acc: 1.0000, dev loss: 0.1137\n",
            "epoch 68.0000 train acc: 0.9781,train loss: 0.1986, dev acc: 1.0000, dev loss: 0.1120\n",
            "epoch 69.0000 train acc: 0.9844,train loss: 0.1761, dev acc: 1.0000, dev loss: 0.1087\n",
            "epoch 70.0000 train acc: 0.9750,train loss: 0.1867, dev acc: 1.0000, dev loss: 0.1056\n",
            "epoch 71.0000 train acc: 0.9844,train loss: 0.1851, dev acc: 1.0000, dev loss: 0.1020\n",
            "epoch 72.0000 train acc: 0.9812,train loss: 0.1575, dev acc: 1.0000, dev loss: 0.1028\n",
            "epoch 73.0000 train acc: 0.9781,train loss: 0.1590, dev acc: 1.0000, dev loss: 0.0999\n",
            "epoch 74.0000 train acc: 0.9750,train loss: 0.1744, dev acc: 1.0000, dev loss: 0.0963\n",
            "epoch 75.0000 train acc: 0.9885,train loss: 0.1527, dev acc: 1.0000, dev loss: 0.0929\n",
            "epoch 76.0000 train acc: 0.9688,train loss: 0.1754, dev acc: 1.0000, dev loss: 0.0917\n",
            "epoch 77.0000 train acc: 0.9781,train loss: 0.1685, dev acc: 1.0000, dev loss: 0.0898\n",
            "epoch 78.0000 train acc: 0.9938,train loss: 0.1417, dev acc: 1.0000, dev loss: 0.0885\n",
            "epoch 79.0000 train acc: 0.9844,train loss: 0.1635, dev acc: 1.0000, dev loss: 0.0858\n",
            "epoch 80.0000 train acc: 0.9906,train loss: 0.1415, dev acc: 1.0000, dev loss: 0.0850\n",
            "epoch 81.0000 train acc: 0.9906,train loss: 0.1339, dev acc: 1.0000, dev loss: 0.0826\n",
            "epoch 82.0000 train acc: 0.9844,train loss: 0.1719, dev acc: 1.0000, dev loss: 0.0822\n",
            "epoch 83.0000 train acc: 0.9812,train loss: 0.1517, dev acc: 1.0000, dev loss: 0.0784\n",
            "epoch 84.0000 train acc: 0.9938,train loss: 0.1304, dev acc: 1.0000, dev loss: 0.0757\n",
            "epoch 85.0000 train acc: 0.9750,train loss: 0.1571, dev acc: 1.0000, dev loss: 0.0761\n",
            "epoch 86.0000 train acc: 0.9885,train loss: 0.1495, dev acc: 1.0000, dev loss: 0.0736\n",
            "epoch 87.0000 train acc: 0.9750,train loss: 0.1524, dev acc: 1.0000, dev loss: 0.0732\n",
            "epoch 88.0000 train acc: 0.9938,train loss: 0.1609, dev acc: 1.0000, dev loss: 0.0708\n",
            "epoch 89.0000 train acc: 0.9750,train loss: 0.1466, dev acc: 1.0000, dev loss: 0.0690\n",
            "epoch 90.0000 train acc: 0.9885,train loss: 0.1527, dev acc: 1.0000, dev loss: 0.0681\n",
            "epoch 91.0000 train acc: 0.9844,train loss: 0.1389, dev acc: 1.0000, dev loss: 0.0662\n",
            "epoch 92.0000 train acc: 0.9844,train loss: 0.1433, dev acc: 1.0000, dev loss: 0.0652\n",
            "epoch 93.0000 train acc: 0.9740,train loss: 0.1298, dev acc: 1.0000, dev loss: 0.0637\n",
            "epoch 94.0000 train acc: 0.9781,train loss: 0.1492, dev acc: 1.0000, dev loss: 0.0627\n",
            "epoch 95.0000 train acc: 0.9844,train loss: 0.1297, dev acc: 1.0000, dev loss: 0.0611\n",
            "epoch 96.0000 train acc: 0.9875,train loss: 0.1164, dev acc: 1.0000, dev loss: 0.0598\n",
            "epoch 97.0000 train acc: 0.9906,train loss: 0.1243, dev acc: 1.0000, dev loss: 0.0593\n",
            "epoch 98.0000 train acc: 0.9875,train loss: 0.1247, dev acc: 1.0000, dev loss: 0.0572\n",
            "epoch 99.0000 train acc: 0.9844,train loss: 0.1403, dev acc: 1.0000, dev loss: 0.0554\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f1215e248f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_dev_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skyblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imgname' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    batch_size = 32\n",
        "    lr=1e-3\n",
        "    #lr=1e-4#loss:11.72 10.74\n",
        "    #lr=1e-3#9.6519\n",
        "    #lr=0.01#8.3690\n",
        "    #lr=0.1#8.2 7.72 7.71 ..7156.7147\n",
        "    log_dir='/content/drive/My Drive/ClassificationModel0503.pth'\n",
        "    #数据集加载\n",
        "    dataset_path = '/content/drive/My Drive/'\n",
        "    x_train, y_train, x_dev, y_dev = get_data(dataset_path, 'TrainDataClassification.mat', 0.4,3)\n",
        "    #print(x_train[0])\n",
        "    train_dataset = MyDataset(x_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    dev_dataset = MyDataset(x_dev, y_dev)\n",
        "    dev_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "    model = DnCNN()\n",
        "    #model = Model()\n",
        "    #模型加载\n",
        "    start_epoch=0\n",
        "    '''\n",
        "    if os.path.exists(log_dir):\n",
        "        checkpoint = torch.load(log_dir)\n",
        "        model.load_state_dict(checkpoint['net'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        print('无保存模型，将从头开始训练！')\n",
        "    '''\n",
        "    sgd = SGD(model.parameters(), lr)\n",
        "\n",
        "    cost = CrossEntropyLoss()\n",
        "    criterion = MSELoss(reduction='sum')\n",
        "    epoch = 100\n",
        "    use_GPU = True\n",
        "    if use_GPU:\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    epoch_train_loss_list = []\n",
        "    epoch_dev_loss_list = []\n",
        "    epoch_train_acc_list = []\n",
        "    epoch_dev_acc_list = []\n",
        "\n",
        "    for _epoch in range(epoch):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_dev_loss = 0\n",
        "        epoch_train_acc = 0\n",
        "        epoch_dev_acc = 0\n",
        "        train_num=0\n",
        "        dev_num = 0\n",
        "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "            s = train_label.shape[0]\n",
        "            sgd.zero_grad()\n",
        "            predict_y = model(train_x.to(device))\n",
        "            #print(train_label.size())\n",
        "            #print(predict_y.size())\n",
        "            #loss = cost(predict_y, train_label.to(device))\n",
        "            loss = F.cross_entropy(predict_y, train_label.to(device))\n",
        "            epoch_train_loss += loss.item()\n",
        "            label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "            acc = np.sum(label_pred == train_label.numpy())\n",
        "            # print(\"batch Train acc:\",acc / s)\n",
        "            epoch_train_acc += acc / s\n",
        "            train_num+=1\n",
        "            loss.backward()\n",
        "            sgd.step()\n",
        "\n",
        "        correct = 0\n",
        "        _sum = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (dev_x, dev_label) in enumerate(dev_loader):\n",
        "                s = dev_label.shape[0]\n",
        "                predict_y = model(dev_x.to(device))\n",
        "                # print(predict_y[0], dev_label[0])\n",
        "                loss = cost(predict_y, dev_label.to(device))\n",
        "                epoch_dev_loss += loss.item()\n",
        "                label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "                acc = np.sum(label_pred == dev_label.numpy())\n",
        "                batch_acc=acc / s\n",
        "                dev_num+=1\n",
        "                # print(\"batch_acc::\",batch_acc)\n",
        "                epoch_dev_acc += acc / s\n",
        "                # print(\"devacc\", acc);\n",
        "        epoch_train_loss_list.append(epoch_train_loss / train_num)\n",
        "        epoch_dev_loss_list.append(epoch_dev_loss / train_num)\n",
        "        epoch_train_acc_list.append(epoch_train_acc / dev_num)\n",
        "        epoch_dev_acc_list.append(epoch_dev_acc / dev_num)\n",
        "        print(\"epoch {:.4f} train acc: {:.4f},train loss: {:.4f}, dev acc: {:.4f}, dev loss: {:.4f}\".format(_epoch,epoch_train_acc / train_num, epoch_train_loss / train_num,epoch_dev_acc / dev_num, epoch_dev_loss / dev_num))\n",
        "   \n",
        "    \n",
        "    state = {'net':model.state_dict(),  'epoch':epoch}\n",
        "    torch.save(state, log_dir)\n",
        "    t = np.arange(1, len(epoch_train_loss_list) + 1)\n",
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ],
      "metadata": {
        "id": "px1s0sYqk-Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data(dataset_path, fm, SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    '''\n",
        "    datalen=500\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "    '''   \n",
        "    datalen=250\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,datalen):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        #xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        #x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        #y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "\n",
        "    \n",
        "    return x_test, y_test\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "        #label=label.float()\n",
        "        x = torch.div(x, 255.)\n",
        "        #print(label)\n",
        "        #label = torch.div(label, 10000.)\n",
        "        #print(x)\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ],
      "metadata": {
        "id": "MIEC7MelezSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "2CvKfHmdWlBp",
        "outputId": "3f0e8c16-5deb-4888-cead-cc8eda32aa79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d554eb841dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#loss = criterion(predict_y, train_label.to(device)) / (2 * len(train_x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#terror,verror,acc=ab_err(predict_y,test_label.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mepoch_dev_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (100) to match target batch_size (24)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 24\n",
        "use_GPU = True\n",
        "if use_GPU:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "model = DnCNN()\n",
        "model.to(device)\n",
        "print(torch.cuda.is_available())\n",
        "log_dir = '/content/drive/My Drive/ClassificationModel0425.pth'\n",
        "if os.path.exists(log_dir):\n",
        "    checkpoint = torch.load(log_dir)\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    print('加载失败')\n",
        "dataset_path=\"/content/drive/My Drive/\"\n",
        "SNR_acc_list = []\n",
        "for SNR in range(-5, 5):\n",
        "    x_test, y_test = get_test_data(dataset_path, 'TrainDataClassification.mat', SNR)\n",
        "    test_dataset = MyTestDataset(x_test, y_test)\n",
        "    train_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    test_num = 0\n",
        "    test_derror=0\n",
        "    test_verror=0\n",
        "    test_acc = 0\n",
        "    for idx, (test_x, test_label) in enumerate(train_loader):\n",
        "        epoch_dev_acc = 0\n",
        "        train_num = 0\n",
        "        dev_num = 0\n",
        "        epoch_dev_derror = 0\n",
        "        epoch_dev_verror = 0\n",
        "        epoch_train_derror = 0\n",
        "        epoch_train_verror = 0\n",
        "        s = test_label.shape[0]\n",
        "        predict_y = model(test_x.to(device))\n",
        "        \n",
        "        loss = F.cross_entropy(predict_y, test_label.to(device))\n",
        "            \n",
        "        epoch_dev_loss += loss.item()\n",
        "        label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "        acc = np.sum(label_pred == test_label.numpy())\n",
        "        batch_acc=acc / s\n",
        "        print(batch_acc)\n",
        "\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        test_acc += acc/s\n",
        "        \n",
        "        test_num += 1\n",
        "    #print(test_acc)\n",
        "    #print(test_num )\n",
        "        # print(\"------\")\n",
        "        # print(label_pred)\n",
        "        # print(dev_label.numpy())\n",
        "        # print(\"------\")\n",
        "        # acc = np.sum(label_pred == dev_label.numpy())\n",
        "        # batch_acc=acc / s\n",
        "\n",
        "    print(test_acc / test_num)\n",
        "    SNR_acc_list.append(test_acc / test_num)\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        # epoch_dev_acc += acc / s\n",
        "        # print(\"devacc\", acc);\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "SNR = np.linspace(-5, 5, 10, endpoint=False)\n",
        "SNR=np.arange(1, len(SNR_acc_list) + 1)\n",
        "print(np.shape(SNR))\n",
        "print(np.shape(SNR_acc_list))\n",
        "plt.title('acc_SNR')\n",
        "plt.plot(SNR, SNR_acc_list, color='red', label='train loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6gpSPZhgmCpJ",
        "outputId": "2684ce65-2eb9-4fcc-cfd3-8ae1e591f788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.9\n",
            "0.7484848484848484\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.756060606060606\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.75\n",
            "0.875\n",
            "0.7916666666666666\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.7810606060606061\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.8333333333333334\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.5833333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.9583333333333334\n",
            "0.7916666666666666\n",
            "0.7\n",
            "0.7568181818181817\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.75\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.625\n",
            "0.8333333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.625\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.8\n",
            "0.7204545454545455\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.8333333333333334\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7\n",
            "0.7265151515151514\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.6939393939393939\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.5416666666666666\n",
            "0.7083333333333334\n",
            "0.5\n",
            "0.625\n",
            "0.5416666666666666\n",
            "0.625\n",
            "0.9\n",
            "0.6462121212121212\n",
            "(10,)\n",
            "(10,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0503 cnn_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}