{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki-i/APRiL/blob/master/4SNR0503_cnn_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QiGF43Vh69",
        "outputId": "8c882013-18a8-4182-c4db-06daa9da511d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52AY7dz9WsC0"
      },
      "outputs": [],
      "source": [
        "workspace_dir = '.'\n",
        "#!unzip -q \"/content/drive/My Drive/crypko_data.zip\" -d \"{workspace_dir}/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZHLjPEPEW0iE"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import scipy.io as scio\n",
        "import pylab\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G7ydcVOPsj77"
      },
      "outputs": [],
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DnCNN, self).__init__()\n",
        "        channels=3\n",
        "        num_of_layers=10\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        " \n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self.fc1=nn.Linear( 3*50*100,6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(6,2)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "    def forward(self, x):\n",
        "        y = self.dncnn(x)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        #print(y.size())\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AX1zF1JW_xw"
      },
      "outputs": [],
      "source": [
        "class Model(Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 5)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*2*9, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 6)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.relu1(y)\n",
        "        y = self.pool1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.relu2(y)\n",
        "        y = self.pool2(y)\n",
        "        y = self.conv3(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.pool3(y)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.fc2(y)\n",
        "        # y = self.relu4(y)\n",
        "        # y = self.fc3(y)\n",
        "        # y = self.relu5(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLNyO4Z-XAwy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-vFcTvIaXGG2"
      },
      "outputs": [],
      "source": [
        "def get_data(dataset_path, fm, dev_ratio,SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    datalen=500\n",
        "    x = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1, int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x[i] = data[xkey1]\n",
        "        x[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y[i] = 1\n",
        "        y[i+int(datalen/2)] = 0\n",
        "\n",
        "    data_size = len(y)\n",
        "    train_size = int(data_size * (1 - dev_ratio))\n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(x)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(y)\n",
        "    # print(\"train size:\", train_size)\n",
        "    # print(\"dev size:\", data_size - train_size)\n",
        "    x_train = x[:train_size]\n",
        "    y_train = y[:train_size]\n",
        "    x_dev = x[train_size:]\n",
        "    y_dev = y[train_size:]\n",
        "    return x_train, y_train, x_dev, y_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DYoliGW6XJJv"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "       \n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "       \n",
        "        x = torch.div(x, 255.)\n",
        "      \n",
        "        #print(x.size())\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGk2NrCqPnk",
        "outputId": "aa438a2f-c75a-4c2d-d9a5-aadefa6a4c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25 0.5  0.75 1.  ]\n"
          ]
        }
      ],
      "source": [
        "x=np.array([1,2,3,4])\n",
        "x=x/4\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1coYPwD6v79d"
      },
      "outputs": [],
      "source": [
        "def psnr(target_data, ref_data):\n",
        "    # target:目标图像  ref:参考图像  scale:尺寸大小\n",
        "    # assume RGB image\n",
        "    #target_data = np.array(target)\n",
        "    #target_data = target_data[scale:-scale, scale:-scale]\n",
        "\n",
        "    #ref_data = np.array(ref)\n",
        "    #ref_data = ref_data[scale:-scale, scale:-scale]\n",
        "    im = ref_data.max()\n",
        "    print('参考图像峰值', ref_data.max(), ref_data.min())\n",
        "    print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    target_data = target_data * (ref_data.max() / target_data.max())\n",
        "    #print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    diff = ref_data - target_data\n",
        "    diff = diff.flatten('C')\n",
        "\n",
        "    #rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "    #return 20 * math.log10(math.pow(im,2) / rmse)\n",
        "    mse = np.mean(diff ** 2.)\n",
        "    return 20 * math.log10(math.pow(im,2) / mse)\n",
        "\n",
        "def ab_err(target_data, ref_data):\n",
        "  diff = abs(ref_data - target_data)/ref_data\n",
        "  diff=diff.cpu().data.numpy()\n",
        "  tdiff=diff[0:,0:2]\n",
        "  vdiff=diff[0:,3:5]\n",
        "  \n",
        "  \n",
        "  terr = np.mean(tdiff)\n",
        "  verr = np.mean(vdiff)\n",
        "\n",
        "  return terr,verr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl5D9ZN0XThY",
        "outputId": "64806095-17d9-45d7-9126-d9196001db53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0.0000 train acc: 0.5167,train loss: 0.7026, dev acc: 0.5021, dev loss: 0.7013\n",
            "epoch 1.0000 train acc: 0.5448,train loss: 0.6902, dev acc: 0.5021, dev loss: 0.6992\n",
            "epoch 2.0000 train acc: 0.5594,train loss: 0.6841, dev acc: 0.5021, dev loss: 0.6972\n",
            "epoch 3.0000 train acc: 0.5990,train loss: 0.6735, dev acc: 0.5021, dev loss: 0.6965\n",
            "epoch 4.0000 train acc: 0.6135,train loss: 0.6587, dev acc: 0.5021, dev loss: 0.6954\n",
            "epoch 5.0000 train acc: 0.6865,train loss: 0.6429, dev acc: 0.5021, dev loss: 0.6963\n",
            "epoch 6.0000 train acc: 0.7167,train loss: 0.6303, dev acc: 0.5021, dev loss: 0.7001\n",
            "epoch 7.0000 train acc: 0.7271,train loss: 0.6147, dev acc: 0.5021, dev loss: 0.6955\n",
            "epoch 8.0000 train acc: 0.7740,train loss: 0.5999, dev acc: 0.5021, dev loss: 0.6943\n",
            "epoch 9.0000 train acc: 0.8438,train loss: 0.5683, dev acc: 0.5167, dev loss: 0.6816\n",
            "epoch 10.0000 train acc: 0.7937,train loss: 0.5663, dev acc: 0.6208, dev loss: 0.6376\n",
            "epoch 11.0000 train acc: 0.8281,train loss: 0.5587, dev acc: 0.8031, dev loss: 0.5797\n",
            "epoch 12.0000 train acc: 0.8135,train loss: 0.5385, dev acc: 0.9594, dev loss: 0.5373\n",
            "epoch 13.0000 train acc: 0.8417,train loss: 0.5273, dev acc: 0.9812, dev loss: 0.5089\n",
            "epoch 14.0000 train acc: 0.8719,train loss: 0.5034, dev acc: 0.9875, dev loss: 0.4885\n",
            "epoch 15.0000 train acc: 0.8635,train loss: 0.4960, dev acc: 0.9969, dev loss: 0.4722\n",
            "epoch 16.0000 train acc: 0.9031,train loss: 0.4662, dev acc: 0.9969, dev loss: 0.4565\n",
            "epoch 17.0000 train acc: 0.9062,train loss: 0.4538, dev acc: 0.9969, dev loss: 0.4415\n",
            "epoch 18.0000 train acc: 0.9250,train loss: 0.4458, dev acc: 0.9969, dev loss: 0.4283\n",
            "epoch 19.0000 train acc: 0.9042,train loss: 0.4489, dev acc: 0.9969, dev loss: 0.4150\n",
            "epoch 20.0000 train acc: 0.9313,train loss: 0.4111, dev acc: 0.9969, dev loss: 0.4015\n",
            "epoch 21.0000 train acc: 0.9000,train loss: 0.4220, dev acc: 1.0000, dev loss: 0.3886\n",
            "epoch 22.0000 train acc: 0.8740,train loss: 0.4223, dev acc: 1.0000, dev loss: 0.3831\n",
            "epoch 23.0000 train acc: 0.8938,train loss: 0.4089, dev acc: 1.0000, dev loss: 0.3682\n",
            "epoch 24.0000 train acc: 0.9031,train loss: 0.3866, dev acc: 1.0000, dev loss: 0.3578\n",
            "epoch 25.0000 train acc: 0.9125,train loss: 0.3726, dev acc: 1.0000, dev loss: 0.3446\n",
            "epoch 26.0000 train acc: 0.8885,train loss: 0.3778, dev acc: 1.0000, dev loss: 0.3387\n",
            "epoch 27.0000 train acc: 0.9219,train loss: 0.3454, dev acc: 1.0000, dev loss: 0.3267\n",
            "epoch 28.0000 train acc: 0.9135,train loss: 0.3559, dev acc: 1.0000, dev loss: 0.3136\n",
            "epoch 29.0000 train acc: 0.9375,train loss: 0.3386, dev acc: 1.0000, dev loss: 0.3022\n",
            "epoch 30.0000 train acc: 0.9073,train loss: 0.3249, dev acc: 1.0000, dev loss: 0.2933\n",
            "epoch 31.0000 train acc: 0.9187,train loss: 0.3186, dev acc: 1.0000, dev loss: 0.2842\n",
            "epoch 32.0000 train acc: 0.9281,train loss: 0.3015, dev acc: 1.0000, dev loss: 0.2731\n",
            "epoch 33.0000 train acc: 0.9062,train loss: 0.2995, dev acc: 1.0000, dev loss: 0.2643\n",
            "epoch 34.0000 train acc: 0.9135,train loss: 0.3197, dev acc: 1.0000, dev loss: 0.2589\n",
            "epoch 35.0000 train acc: 0.9281,train loss: 0.2766, dev acc: 1.0000, dev loss: 0.2467\n",
            "epoch 36.0000 train acc: 0.9219,train loss: 0.2851, dev acc: 1.0000, dev loss: 0.2413\n",
            "epoch 37.0000 train acc: 0.9104,train loss: 0.2738, dev acc: 1.0000, dev loss: 0.2350\n",
            "epoch 38.0000 train acc: 0.9437,train loss: 0.2629, dev acc: 1.0000, dev loss: 0.2261\n",
            "epoch 39.0000 train acc: 0.9417,train loss: 0.2538, dev acc: 1.0000, dev loss: 0.2180\n",
            "epoch 40.0000 train acc: 0.9344,train loss: 0.2568, dev acc: 1.0000, dev loss: 0.2115\n",
            "epoch 41.0000 train acc: 0.9094,train loss: 0.2538, dev acc: 1.0000, dev loss: 0.2037\n",
            "epoch 42.0000 train acc: 0.9385,train loss: 0.2427, dev acc: 1.0000, dev loss: 0.1993\n",
            "epoch 43.0000 train acc: 0.9250,train loss: 0.2441, dev acc: 1.0000, dev loss: 0.1940\n",
            "epoch 44.0000 train acc: 0.9344,train loss: 0.2428, dev acc: 1.0000, dev loss: 0.1881\n",
            "epoch 45.0000 train acc: 0.9375,train loss: 0.2223, dev acc: 1.0000, dev loss: 0.1812\n",
            "epoch 46.0000 train acc: 0.9437,train loss: 0.2205, dev acc: 1.0000, dev loss: 0.1753\n",
            "epoch 47.0000 train acc: 0.9281,train loss: 0.2203, dev acc: 1.0000, dev loss: 0.1702\n",
            "epoch 48.0000 train acc: 0.9625,train loss: 0.1908, dev acc: 1.0000, dev loss: 0.1647\n",
            "epoch 49.0000 train acc: 0.9375,train loss: 0.2124, dev acc: 1.0000, dev loss: 0.1598\n",
            "epoch 50.0000 train acc: 0.9281,train loss: 0.2133, dev acc: 1.0000, dev loss: 0.1565\n",
            "epoch 51.0000 train acc: 0.9250,train loss: 0.2169, dev acc: 1.0000, dev loss: 0.1520\n",
            "epoch 52.0000 train acc: 0.9656,train loss: 0.1821, dev acc: 1.0000, dev loss: 0.1476\n",
            "epoch 53.0000 train acc: 0.9344,train loss: 0.2030, dev acc: 1.0000, dev loss: 0.1416\n",
            "epoch 54.0000 train acc: 0.9469,train loss: 0.1910, dev acc: 1.0000, dev loss: 0.1372\n",
            "epoch 55.0000 train acc: 0.9323,train loss: 0.2115, dev acc: 1.0000, dev loss: 0.1370\n",
            "epoch 56.0000 train acc: 0.9427,train loss: 0.1949, dev acc: 1.0000, dev loss: 0.1313\n",
            "epoch 57.0000 train acc: 0.9437,train loss: 0.1755, dev acc: 1.0000, dev loss: 0.1264\n",
            "epoch 58.0000 train acc: 0.9427,train loss: 0.1618, dev acc: 1.0000, dev loss: 0.1188\n",
            "epoch 59.0000 train acc: 0.9469,train loss: 0.1719, dev acc: 1.0000, dev loss: 0.1187\n",
            "epoch 60.0000 train acc: 0.9563,train loss: 0.1566, dev acc: 1.0000, dev loss: 0.1139\n",
            "epoch 61.0000 train acc: 0.9344,train loss: 0.1741, dev acc: 1.0000, dev loss: 0.1142\n",
            "epoch 62.0000 train acc: 0.9500,train loss: 0.1626, dev acc: 1.0000, dev loss: 0.1083\n",
            "epoch 63.0000 train acc: 0.9375,train loss: 0.1651, dev acc: 1.0000, dev loss: 0.1067\n",
            "epoch 64.0000 train acc: 0.9354,train loss: 0.1673, dev acc: 1.0000, dev loss: 0.1044\n",
            "epoch 65.0000 train acc: 0.9500,train loss: 0.1608, dev acc: 1.0000, dev loss: 0.1018\n",
            "epoch 66.0000 train acc: 0.9344,train loss: 0.1686, dev acc: 1.0000, dev loss: 0.1007\n",
            "epoch 67.0000 train acc: 0.9375,train loss: 0.1676, dev acc: 1.0000, dev loss: 0.0969\n",
            "epoch 68.0000 train acc: 0.9698,train loss: 0.1314, dev acc: 1.0000, dev loss: 0.0906\n",
            "epoch 69.0000 train acc: 0.9479,train loss: 0.1562, dev acc: 1.0000, dev loss: 0.0909\n",
            "epoch 70.0000 train acc: 0.9594,train loss: 0.1444, dev acc: 1.0000, dev loss: 0.0884\n",
            "epoch 71.0000 train acc: 0.9469,train loss: 0.1446, dev acc: 1.0000, dev loss: 0.0875\n",
            "epoch 72.0000 train acc: 0.9469,train loss: 0.1446, dev acc: 1.0000, dev loss: 0.0834\n",
            "epoch 73.0000 train acc: 0.9469,train loss: 0.1379, dev acc: 1.0000, dev loss: 0.0816\n",
            "epoch 74.0000 train acc: 0.9375,train loss: 0.1344, dev acc: 1.0000, dev loss: 0.0771\n",
            "epoch 75.0000 train acc: 0.9688,train loss: 0.1204, dev acc: 1.0000, dev loss: 0.0754\n",
            "epoch 76.0000 train acc: 0.9656,train loss: 0.1247, dev acc: 1.0000, dev loss: 0.0741\n",
            "epoch 77.0000 train acc: 0.9531,train loss: 0.1157, dev acc: 1.0000, dev loss: 0.0709\n",
            "epoch 78.0000 train acc: 0.9563,train loss: 0.1278, dev acc: 1.0000, dev loss: 0.0741\n",
            "epoch 79.0000 train acc: 0.9604,train loss: 0.1200, dev acc: 1.0000, dev loss: 0.0715\n",
            "epoch 80.0000 train acc: 0.9719,train loss: 0.1175, dev acc: 1.0000, dev loss: 0.0685\n",
            "epoch 81.0000 train acc: 0.9437,train loss: 0.1312, dev acc: 1.0000, dev loss: 0.0666\n",
            "epoch 82.0000 train acc: 0.9625,train loss: 0.1180, dev acc: 1.0000, dev loss: 0.0619\n",
            "epoch 83.0000 train acc: 0.9542,train loss: 0.1181, dev acc: 1.0000, dev loss: 0.0610\n",
            "epoch 84.0000 train acc: 0.9531,train loss: 0.1095, dev acc: 1.0000, dev loss: 0.0607\n",
            "epoch 85.0000 train acc: 0.9469,train loss: 0.1169, dev acc: 1.0000, dev loss: 0.0596\n",
            "epoch 86.0000 train acc: 0.9385,train loss: 0.1228, dev acc: 1.0000, dev loss: 0.0572\n",
            "epoch 87.0000 train acc: 0.9500,train loss: 0.1123, dev acc: 1.0000, dev loss: 0.0556\n",
            "epoch 88.0000 train acc: 0.9469,train loss: 0.1219, dev acc: 1.0000, dev loss: 0.0555\n",
            "epoch 89.0000 train acc: 0.9844,train loss: 0.0875, dev acc: 1.0000, dev loss: 0.0523\n",
            "epoch 90.0000 train acc: 0.9656,train loss: 0.0945, dev acc: 1.0000, dev loss: 0.0523\n",
            "epoch 91.0000 train acc: 0.9469,train loss: 0.1069, dev acc: 1.0000, dev loss: 0.0509\n",
            "epoch 92.0000 train acc: 0.9323,train loss: 0.1144, dev acc: 1.0000, dev loss: 0.0490\n",
            "epoch 93.0000 train acc: 0.9385,train loss: 0.1098, dev acc: 1.0000, dev loss: 0.0491\n",
            "epoch 94.0000 train acc: 0.9448,train loss: 0.1125, dev acc: 1.0000, dev loss: 0.0503\n",
            "epoch 95.0000 train acc: 0.9688,train loss: 0.0967, dev acc: 1.0000, dev loss: 0.0468\n",
            "epoch 96.0000 train acc: 0.9281,train loss: 0.1145, dev acc: 1.0000, dev loss: 0.0459\n",
            "epoch 97.0000 train acc: 0.9510,train loss: 0.0990, dev acc: 1.0000, dev loss: 0.0445\n",
            "epoch 98.0000 train acc: 0.9292,train loss: 0.1142, dev acc: 1.0000, dev loss: 0.0447\n",
            "epoch 99.0000 train acc: 0.9417,train loss: 0.1115, dev acc: 1.0000, dev loss: 0.0431\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c6fc08e3b52a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_dev_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skyblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imgname' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    batch_size = 32\n",
        "    lr=1e-3\n",
        "    #lr=1e-4#loss:11.72 10.74\n",
        "    #lr=1e-3#9.6519\n",
        "    #lr=0.01#8.3690\n",
        "    #lr=0.1#8.2 7.72 7.71 ..7156.7147\n",
        "    log_dir='/content/drive/My Drive/ClassificationModel0503.pth'\n",
        "    #数据集加载\n",
        "    dataset_path = '/content/drive/My Drive/'\n",
        "    x_train, y_train, x_dev, y_dev = get_data(dataset_path, 'TrainDataClassification.mat', 0.4,4)\n",
        "    #print(x_train[0])\n",
        "    train_dataset = MyDataset(x_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    dev_dataset = MyDataset(x_dev, y_dev)\n",
        "    dev_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "    model = DnCNN()\n",
        "    #model = Model()\n",
        "    #模型加载\n",
        "    start_epoch=0\n",
        "    '''\n",
        "    if os.path.exists(log_dir):\n",
        "        checkpoint = torch.load(log_dir)\n",
        "        model.load_state_dict(checkpoint['net'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        print('无保存模型，将从头开始训练！')\n",
        "    '''\n",
        "    sgd = SGD(model.parameters(), lr)\n",
        "\n",
        "    cost = CrossEntropyLoss()\n",
        "    criterion = MSELoss(reduction='sum')\n",
        "    epoch = 100\n",
        "    use_GPU = True\n",
        "    if use_GPU:\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    epoch_train_loss_list = []\n",
        "    epoch_dev_loss_list = []\n",
        "    epoch_train_acc_list = []\n",
        "    epoch_dev_acc_list = []\n",
        "\n",
        "    for _epoch in range(epoch):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_dev_loss = 0\n",
        "        epoch_train_acc = 0\n",
        "        epoch_dev_acc = 0\n",
        "        train_num=0\n",
        "        dev_num = 0\n",
        "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "            s = train_label.shape[0]\n",
        "            sgd.zero_grad()\n",
        "            predict_y = model(train_x.to(device))\n",
        "            #print(train_label.size())\n",
        "            #print(predict_y.size())\n",
        "            #loss = cost(predict_y, train_label.to(device))\n",
        "            loss = F.cross_entropy(predict_y, train_label.to(device))\n",
        "            epoch_train_loss += loss.item()\n",
        "            label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "            acc = np.sum(label_pred == train_label.numpy())\n",
        "            # print(\"batch Train acc:\",acc / s)\n",
        "            epoch_train_acc += acc / s\n",
        "            train_num+=1\n",
        "            loss.backward()\n",
        "            sgd.step()\n",
        "\n",
        "        correct = 0\n",
        "        _sum = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (dev_x, dev_label) in enumerate(dev_loader):\n",
        "                s = dev_label.shape[0]\n",
        "                predict_y = model(dev_x.to(device))\n",
        "                # print(predict_y[0], dev_label[0])\n",
        "                loss = cost(predict_y, dev_label.to(device))\n",
        "                epoch_dev_loss += loss.item()\n",
        "                label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "                acc = np.sum(label_pred == dev_label.numpy())\n",
        "                batch_acc=acc / s\n",
        "                dev_num+=1\n",
        "                # print(\"batch_acc::\",batch_acc)\n",
        "                epoch_dev_acc += acc / s\n",
        "                # print(\"devacc\", acc);\n",
        "        epoch_train_loss_list.append(epoch_train_loss / train_num)\n",
        "        epoch_dev_loss_list.append(epoch_dev_loss / train_num)\n",
        "        epoch_train_acc_list.append(epoch_train_acc / dev_num)\n",
        "        epoch_dev_acc_list.append(epoch_dev_acc / dev_num)\n",
        "        print(\"epoch {:.4f} train acc: {:.4f},train loss: {:.4f}, dev acc: {:.4f}, dev loss: {:.4f}\".format(_epoch,epoch_train_acc / train_num, epoch_train_loss / train_num,epoch_dev_acc / dev_num, epoch_dev_loss / dev_num))\n",
        "   \n",
        "    \n",
        "    state = {'net':model.state_dict(),  'epoch':epoch}\n",
        "    torch.save(state, log_dir)\n",
        "    t = np.arange(1, len(epoch_train_loss_list) + 1)\n",
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ],
      "metadata": {
        "id": "px1s0sYqk-Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data(dataset_path, fm, SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    '''\n",
        "    datalen=500\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "    '''   \n",
        "    datalen=250\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,datalen):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        #xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        #x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        #y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "\n",
        "    \n",
        "    return x_test, y_test\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "        #label=label.float()\n",
        "        x = torch.div(x, 255.)\n",
        "        #print(label)\n",
        "        #label = torch.div(label, 10000.)\n",
        "        #print(x)\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ],
      "metadata": {
        "id": "MIEC7MelezSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "2CvKfHmdWlBp",
        "outputId": "3f0e8c16-5deb-4888-cead-cc8eda32aa79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d554eb841dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#loss = criterion(predict_y, train_label.to(device)) / (2 * len(train_x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#terror,verror,acc=ab_err(predict_y,test_label.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mepoch_dev_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (100) to match target batch_size (24)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 24\n",
        "use_GPU = True\n",
        "if use_GPU:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "model = DnCNN()\n",
        "model.to(device)\n",
        "print(torch.cuda.is_available())\n",
        "log_dir = '/content/drive/My Drive/ClassificationModel0425.pth'\n",
        "if os.path.exists(log_dir):\n",
        "    checkpoint = torch.load(log_dir)\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    print('加载失败')\n",
        "dataset_path=\"/content/drive/My Drive/\"\n",
        "SNR_acc_list = []\n",
        "for SNR in range(-5, 5):\n",
        "    x_test, y_test = get_test_data(dataset_path, 'TrainDataClassification.mat', SNR)\n",
        "    test_dataset = MyTestDataset(x_test, y_test)\n",
        "    train_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    test_num = 0\n",
        "    test_derror=0\n",
        "    test_verror=0\n",
        "    test_acc = 0\n",
        "    for idx, (test_x, test_label) in enumerate(train_loader):\n",
        "        epoch_dev_acc = 0\n",
        "        train_num = 0\n",
        "        dev_num = 0\n",
        "        epoch_dev_derror = 0\n",
        "        epoch_dev_verror = 0\n",
        "        epoch_train_derror = 0\n",
        "        epoch_train_verror = 0\n",
        "        s = test_label.shape[0]\n",
        "        predict_y = model(test_x.to(device))\n",
        "        \n",
        "        loss = F.cross_entropy(predict_y, test_label.to(device))\n",
        "            \n",
        "        epoch_dev_loss += loss.item()\n",
        "        label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "        acc = np.sum(label_pred == test_label.numpy())\n",
        "        batch_acc=acc / s\n",
        "        print(batch_acc)\n",
        "\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        test_acc += acc/s\n",
        "        \n",
        "        test_num += 1\n",
        "    #print(test_acc)\n",
        "    #print(test_num )\n",
        "        # print(\"------\")\n",
        "        # print(label_pred)\n",
        "        # print(dev_label.numpy())\n",
        "        # print(\"------\")\n",
        "        # acc = np.sum(label_pred == dev_label.numpy())\n",
        "        # batch_acc=acc / s\n",
        "\n",
        "    print(test_acc / test_num)\n",
        "    SNR_acc_list.append(test_acc / test_num)\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        # epoch_dev_acc += acc / s\n",
        "        # print(\"devacc\", acc);\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "SNR = np.linspace(-5, 5, 10, endpoint=False)\n",
        "SNR=np.arange(1, len(SNR_acc_list) + 1)\n",
        "print(np.shape(SNR))\n",
        "print(np.shape(SNR_acc_list))\n",
        "plt.title('acc_SNR')\n",
        "plt.plot(SNR, SNR_acc_list, color='red', label='train loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6gpSPZhgmCpJ",
        "outputId": "2684ce65-2eb9-4fcc-cfd3-8ae1e591f788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.9\n",
            "0.7484848484848484\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.756060606060606\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.75\n",
            "0.875\n",
            "0.7916666666666666\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.7810606060606061\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.8333333333333334\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.5833333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.9583333333333334\n",
            "0.7916666666666666\n",
            "0.7\n",
            "0.7568181818181817\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.75\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.625\n",
            "0.8333333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.625\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.8\n",
            "0.7204545454545455\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.8333333333333334\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7\n",
            "0.7265151515151514\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.6939393939393939\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.5416666666666666\n",
            "0.7083333333333334\n",
            "0.5\n",
            "0.625\n",
            "0.5416666666666666\n",
            "0.625\n",
            "0.9\n",
            "0.6462121212121212\n",
            "(10,)\n",
            "(10,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0503 cnn_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}