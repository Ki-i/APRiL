{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki-i/APRiL/blob/master/1SNR0503_cnn_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QiGF43Vh69",
        "outputId": "8c882013-18a8-4182-c4db-06daa9da511d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52AY7dz9WsC0"
      },
      "outputs": [],
      "source": [
        "workspace_dir = '.'\n",
        "#!unzip -q \"/content/drive/My Drive/crypko_data.zip\" -d \"{workspace_dir}/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZHLjPEPEW0iE"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import scipy.io as scio\n",
        "import pylab\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G7ydcVOPsj77"
      },
      "outputs": [],
      "source": [
        "class DnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DnCNN, self).__init__()\n",
        "        channels=3\n",
        "        num_of_layers=10\n",
        "        kernel_size = 3\n",
        "        padding = 1\n",
        "        features = 64\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(num_of_layers-2):\n",
        "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
        " \n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self.fc1=nn.Linear( 3*50*100,6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(6,2)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "    def forward(self, x):\n",
        "        y = self.dncnn(x)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "        #print(y.size())\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AX1zF1JW_xw"
      },
      "outputs": [],
      "source": [
        "class Model(Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 5)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64*2*9, 64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 6)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        y = self.relu1(y)\n",
        "        y = self.pool1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.relu2(y)\n",
        "        y = self.pool2(y)\n",
        "        y = self.conv3(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.pool3(y)\n",
        "        #print(y.size())\n",
        "        y = y.view(y.shape[0], -1)\n",
        "        y = self.fc1(y)\n",
        "        y = self.dropout(y)\n",
        "        y = self.relu3(y)\n",
        "        y = self.fc2(y)\n",
        "        # y = self.relu4(y)\n",
        "        # y = self.fc3(y)\n",
        "        # y = self.relu5(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLNyO4Z-XAwy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-vFcTvIaXGG2"
      },
      "outputs": [],
      "source": [
        "def get_data(dataset_path, fm, dev_ratio,SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    datalen=500\n",
        "    x = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1, int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x[i] = data[xkey1]\n",
        "        x[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y[i] = 1\n",
        "        y[i+int(datalen/2)] = 0\n",
        "\n",
        "    data_size = len(y)\n",
        "    train_size = int(data_size * (1 - dev_ratio))\n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(x)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(y)\n",
        "    # print(\"train size:\", train_size)\n",
        "    # print(\"dev size:\", data_size - train_size)\n",
        "    x_train = x[:train_size]\n",
        "    y_train = y[:train_size]\n",
        "    x_dev = x[train_size:]\n",
        "    y_dev = y[train_size:]\n",
        "    return x_train, y_train, x_dev, y_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DYoliGW6XJJv"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "       \n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "       \n",
        "        x = torch.div(x, 255.)\n",
        "      \n",
        "        #print(x.size())\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxGk2NrCqPnk",
        "outputId": "aa438a2f-c75a-4c2d-d9a5-aadefa6a4c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25 0.5  0.75 1.  ]\n"
          ]
        }
      ],
      "source": [
        "x=np.array([1,2,3,4])\n",
        "x=x/4\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1coYPwD6v79d"
      },
      "outputs": [],
      "source": [
        "def psnr(target_data, ref_data):\n",
        "    # target:目标图像  ref:参考图像  scale:尺寸大小\n",
        "    # assume RGB image\n",
        "    #target_data = np.array(target)\n",
        "    #target_data = target_data[scale:-scale, scale:-scale]\n",
        "\n",
        "    #ref_data = np.array(ref)\n",
        "    #ref_data = ref_data[scale:-scale, scale:-scale]\n",
        "    im = ref_data.max()\n",
        "    print('参考图像峰值', ref_data.max(), ref_data.min())\n",
        "    print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    target_data = target_data * (ref_data.max() / target_data.max())\n",
        "    #print('实际图像峰值', target_data.max(), target_data.min())\n",
        "    diff = ref_data - target_data\n",
        "    diff = diff.flatten('C')\n",
        "\n",
        "    #rmse = math.sqrt(np.mean(diff ** 2.))\n",
        "    #return 20 * math.log10(math.pow(im,2) / rmse)\n",
        "    mse = np.mean(diff ** 2.)\n",
        "    return 20 * math.log10(math.pow(im,2) / mse)\n",
        "\n",
        "def ab_err(target_data, ref_data):\n",
        "  diff = abs(ref_data - target_data)/ref_data\n",
        "  diff=diff.cpu().data.numpy()\n",
        "  tdiff=diff[0:,0:2]\n",
        "  vdiff=diff[0:,3:5]\n",
        "  \n",
        "  \n",
        "  terr = np.mean(tdiff)\n",
        "  verr = np.mean(vdiff)\n",
        "\n",
        "  return terr,verr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rl5D9ZN0XThY",
        "outputId": "fc4e63a2-ee5d-45a9-8f0b-e8f6216777f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0.0000 train acc: 0.4885,train loss: 0.7069, dev acc: 0.4760, dev loss: 0.7012\n",
            "epoch 1.0000 train acc: 0.4854,train loss: 0.6931, dev acc: 0.4760, dev loss: 0.7018\n",
            "epoch 2.0000 train acc: 0.5563,train loss: 0.6758, dev acc: 0.4760, dev loss: 0.7034\n",
            "epoch 3.0000 train acc: 0.5833,train loss: 0.6592, dev acc: 0.4760, dev loss: 0.7034\n",
            "epoch 4.0000 train acc: 0.6510,train loss: 0.6424, dev acc: 0.4760, dev loss: 0.7039\n",
            "epoch 5.0000 train acc: 0.7198,train loss: 0.6223, dev acc: 0.4760, dev loss: 0.7051\n",
            "epoch 6.0000 train acc: 0.7708,train loss: 0.6007, dev acc: 0.4760, dev loss: 0.7082\n",
            "epoch 7.0000 train acc: 0.7635,train loss: 0.5863, dev acc: 0.4729, dev loss: 0.6995\n",
            "epoch 8.0000 train acc: 0.7406,train loss: 0.5815, dev acc: 0.5281, dev loss: 0.6889\n",
            "epoch 9.0000 train acc: 0.8135,train loss: 0.5510, dev acc: 0.7240, dev loss: 0.6565\n",
            "epoch 10.0000 train acc: 0.7729,train loss: 0.5466, dev acc: 0.8719, dev loss: 0.5957\n",
            "epoch 11.0000 train acc: 0.7969,train loss: 0.5262, dev acc: 0.9844, dev loss: 0.5345\n",
            "epoch 12.0000 train acc: 0.7854,train loss: 0.5178, dev acc: 0.9969, dev loss: 0.4994\n",
            "epoch 13.0000 train acc: 0.8229,train loss: 0.4971, dev acc: 0.9969, dev loss: 0.4797\n",
            "epoch 14.0000 train acc: 0.8052,train loss: 0.4853, dev acc: 0.9969, dev loss: 0.4625\n",
            "epoch 15.0000 train acc: 0.8021,train loss: 0.4813, dev acc: 0.9969, dev loss: 0.4493\n",
            "epoch 16.0000 train acc: 0.8198,train loss: 0.4539, dev acc: 1.0000, dev loss: 0.4351\n",
            "epoch 17.0000 train acc: 0.8115,train loss: 0.4512, dev acc: 1.0000, dev loss: 0.4202\n",
            "epoch 18.0000 train acc: 0.8125,train loss: 0.4437, dev acc: 1.0000, dev loss: 0.4043\n",
            "epoch 19.0000 train acc: 0.8656,train loss: 0.4149, dev acc: 1.0000, dev loss: 0.3964\n",
            "epoch 20.0000 train acc: 0.8417,train loss: 0.4037, dev acc: 1.0000, dev loss: 0.3783\n",
            "epoch 21.0000 train acc: 0.8406,train loss: 0.3980, dev acc: 1.0000, dev loss: 0.3655\n",
            "epoch 22.0000 train acc: 0.8427,train loss: 0.3694, dev acc: 1.0000, dev loss: 0.3526\n",
            "epoch 23.0000 train acc: 0.8167,train loss: 0.3784, dev acc: 1.0000, dev loss: 0.3403\n",
            "epoch 24.0000 train acc: 0.8260,train loss: 0.3793, dev acc: 1.0000, dev loss: 0.3307\n",
            "epoch 25.0000 train acc: 0.8333,train loss: 0.3525, dev acc: 1.0000, dev loss: 0.3216\n",
            "epoch 26.0000 train acc: 0.8719,train loss: 0.3313, dev acc: 1.0000, dev loss: 0.3065\n",
            "epoch 27.0000 train acc: 0.8354,train loss: 0.3410, dev acc: 1.0000, dev loss: 0.2971\n",
            "epoch 28.0000 train acc: 0.8448,train loss: 0.3267, dev acc: 1.0000, dev loss: 0.2888\n",
            "epoch 29.0000 train acc: 0.8271,train loss: 0.3213, dev acc: 1.0000, dev loss: 0.2777\n",
            "epoch 30.0000 train acc: 0.8333,train loss: 0.3135, dev acc: 1.0000, dev loss: 0.2696\n",
            "epoch 31.0000 train acc: 0.8740,train loss: 0.2726, dev acc: 1.0000, dev loss: 0.2579\n",
            "epoch 32.0000 train acc: 0.8573,train loss: 0.2905, dev acc: 1.0000, dev loss: 0.2527\n",
            "epoch 33.0000 train acc: 0.8438,train loss: 0.2806, dev acc: 1.0000, dev loss: 0.2422\n",
            "epoch 34.0000 train acc: 0.8323,train loss: 0.2865, dev acc: 1.0000, dev loss: 0.2348\n",
            "epoch 35.0000 train acc: 0.8802,train loss: 0.2626, dev acc: 1.0000, dev loss: 0.2270\n",
            "epoch 36.0000 train acc: 0.8302,train loss: 0.2763, dev acc: 1.0000, dev loss: 0.2228\n",
            "epoch 37.0000 train acc: 0.8521,train loss: 0.2569, dev acc: 1.0000, dev loss: 0.2150\n",
            "epoch 38.0000 train acc: 0.8448,train loss: 0.2508, dev acc: 1.0000, dev loss: 0.2075\n",
            "epoch 39.0000 train acc: 0.8260,train loss: 0.2631, dev acc: 1.0000, dev loss: 0.2023\n",
            "epoch 40.0000 train acc: 0.8229,train loss: 0.2655, dev acc: 1.0000, dev loss: 0.1967\n",
            "epoch 41.0000 train acc: 0.8573,train loss: 0.2475, dev acc: 1.0000, dev loss: 0.1933\n",
            "epoch 42.0000 train acc: 0.8594,train loss: 0.2426, dev acc: 1.0000, dev loss: 0.1883\n",
            "epoch 43.0000 train acc: 0.8323,train loss: 0.2467, dev acc: 1.0000, dev loss: 0.1837\n",
            "epoch 44.0000 train acc: 0.7958,train loss: 0.2668, dev acc: 1.0000, dev loss: 0.1795\n",
            "epoch 45.0000 train acc: 0.8333,train loss: 0.2335, dev acc: 1.0000, dev loss: 0.1695\n",
            "epoch 46.0000 train acc: 0.8562,train loss: 0.2158, dev acc: 1.0000, dev loss: 0.1639\n",
            "epoch 47.0000 train acc: 0.8792,train loss: 0.1892, dev acc: 1.0000, dev loss: 0.1573\n",
            "epoch 48.0000 train acc: 0.8562,train loss: 0.2086, dev acc: 1.0000, dev loss: 0.1528\n",
            "epoch 49.0000 train acc: 0.8490,train loss: 0.2109, dev acc: 1.0000, dev loss: 0.1518\n",
            "epoch 50.0000 train acc: 0.8479,train loss: 0.2043, dev acc: 1.0000, dev loss: 0.1473\n",
            "epoch 51.0000 train acc: 0.8375,train loss: 0.2127, dev acc: 1.0000, dev loss: 0.1463\n",
            "epoch 52.0000 train acc: 0.8458,train loss: 0.2023, dev acc: 1.0000, dev loss: 0.1399\n",
            "epoch 53.0000 train acc: 0.8365,train loss: 0.2110, dev acc: 1.0000, dev loss: 0.1374\n",
            "epoch 54.0000 train acc: 0.8448,train loss: 0.1983, dev acc: 1.0000, dev loss: 0.1332\n",
            "epoch 55.0000 train acc: 0.8448,train loss: 0.1951, dev acc: 1.0000, dev loss: 0.1311\n",
            "epoch 56.0000 train acc: 0.8615,train loss: 0.1864, dev acc: 1.0000, dev loss: 0.1300\n",
            "epoch 57.0000 train acc: 0.8615,train loss: 0.1833, dev acc: 1.0000, dev loss: 0.1250\n",
            "epoch 58.0000 train acc: 0.8427,train loss: 0.1906, dev acc: 1.0000, dev loss: 0.1225\n",
            "epoch 59.0000 train acc: 0.8281,train loss: 0.2005, dev acc: 1.0000, dev loss: 0.1214\n",
            "epoch 60.0000 train acc: 0.8344,train loss: 0.1955, dev acc: 1.0000, dev loss: 0.1161\n",
            "epoch 61.0000 train acc: 0.8500,train loss: 0.1780, dev acc: 1.0000, dev loss: 0.1141\n",
            "epoch 62.0000 train acc: 0.8250,train loss: 0.2035, dev acc: 1.0000, dev loss: 0.1141\n",
            "epoch 63.0000 train acc: 0.8562,train loss: 0.1805, dev acc: 1.0000, dev loss: 0.1100\n",
            "epoch 64.0000 train acc: 0.8375,train loss: 0.1860, dev acc: 1.0000, dev loss: 0.1081\n",
            "epoch 65.0000 train acc: 0.8000,train loss: 0.2073, dev acc: 1.0000, dev loss: 0.1054\n",
            "epoch 66.0000 train acc: 0.8500,train loss: 0.1756, dev acc: 1.0000, dev loss: 0.1039\n",
            "epoch 67.0000 train acc: 0.8333,train loss: 0.1813, dev acc: 1.0000, dev loss: 0.1004\n",
            "epoch 68.0000 train acc: 0.8542,train loss: 0.1716, dev acc: 1.0000, dev loss: 0.0997\n",
            "epoch 69.0000 train acc: 0.8365,train loss: 0.1802, dev acc: 1.0000, dev loss: 0.0952\n",
            "epoch 70.0000 train acc: 0.8396,train loss: 0.1681, dev acc: 1.0000, dev loss: 0.0932\n",
            "epoch 71.0000 train acc: 0.8469,train loss: 0.1655, dev acc: 1.0000, dev loss: 0.0922\n",
            "epoch 72.0000 train acc: 0.8323,train loss: 0.1794, dev acc: 1.0000, dev loss: 0.0907\n",
            "epoch 73.0000 train acc: 0.8479,train loss: 0.1633, dev acc: 1.0000, dev loss: 0.0894\n",
            "epoch 74.0000 train acc: 0.8323,train loss: 0.1742, dev acc: 1.0000, dev loss: 0.0888\n",
            "epoch 75.0000 train acc: 0.8438,train loss: 0.1691, dev acc: 1.0000, dev loss: 0.0858\n",
            "epoch 76.0000 train acc: 0.8396,train loss: 0.1610, dev acc: 1.0000, dev loss: 0.0828\n",
            "epoch 77.0000 train acc: 0.8427,train loss: 0.1581, dev acc: 1.0000, dev loss: 0.0817\n",
            "epoch 78.0000 train acc: 0.8677,train loss: 0.1448, dev acc: 1.0000, dev loss: 0.0798\n",
            "epoch 79.0000 train acc: 0.8271,train loss: 0.1783, dev acc: 1.0000, dev loss: 0.0805\n",
            "epoch 80.0000 train acc: 0.8510,train loss: 0.1576, dev acc: 1.0000, dev loss: 0.0779\n",
            "epoch 81.0000 train acc: 0.8177,train loss: 0.1777, dev acc: 1.0000, dev loss: 0.0781\n",
            "epoch 82.0000 train acc: 0.8281,train loss: 0.1692, dev acc: 1.0000, dev loss: 0.0760\n",
            "epoch 83.0000 train acc: 0.8375,train loss: 0.1667, dev acc: 1.0000, dev loss: 0.0759\n",
            "epoch 84.0000 train acc: 0.8198,train loss: 0.1843, dev acc: 1.0000, dev loss: 0.0746\n",
            "epoch 85.0000 train acc: 0.8250,train loss: 0.1645, dev acc: 1.0000, dev loss: 0.0712\n",
            "epoch 86.0000 train acc: 0.8458,train loss: 0.1527, dev acc: 1.0000, dev loss: 0.0720\n",
            "epoch 87.0000 train acc: 0.8552,train loss: 0.1469, dev acc: 1.0000, dev loss: 0.0700\n",
            "epoch 88.0000 train acc: 0.8354,train loss: 0.1624, dev acc: 1.0000, dev loss: 0.0683\n",
            "epoch 89.0000 train acc: 0.8427,train loss: 0.1549, dev acc: 1.0000, dev loss: 0.0680\n",
            "epoch 90.0000 train acc: 0.8271,train loss: 0.1616, dev acc: 1.0000, dev loss: 0.0664\n",
            "epoch 91.0000 train acc: 0.8333,train loss: 0.1536, dev acc: 1.0000, dev loss: 0.0655\n",
            "epoch 92.0000 train acc: 0.8156,train loss: 0.1651, dev acc: 1.0000, dev loss: 0.0641\n",
            "epoch 93.0000 train acc: 0.8417,train loss: 0.1499, dev acc: 1.0000, dev loss: 0.0627\n",
            "epoch 94.0000 train acc: 0.8594,train loss: 0.1442, dev acc: 1.0000, dev loss: 0.0618\n",
            "epoch 95.0000 train acc: 0.8375,train loss: 0.1513, dev acc: 1.0000, dev loss: 0.0619\n",
            "epoch 96.0000 train acc: 0.8552,train loss: 0.1363, dev acc: 1.0000, dev loss: 0.0597\n",
            "epoch 97.0000 train acc: 0.8552,train loss: 0.1383, dev acc: 1.0000, dev loss: 0.0585\n",
            "epoch 98.0000 train acc: 0.8625,train loss: 0.1345, dev acc: 1.0000, dev loss: 0.0572\n",
            "epoch 99.0000 train acc: 0.8469,train loss: 0.1431, dev acc: 1.0000, dev loss: 0.0571\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9e1f22f00e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_train_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_dev_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skyblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dev loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imgname' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    batch_size = 32\n",
        "    lr=1e-3\n",
        "    #lr=1e-4#loss:11.72 10.74\n",
        "    #lr=1e-3#9.6519\n",
        "    #lr=0.01#8.3690\n",
        "    #lr=0.1#8.2 7.72 7.71 ..7156.7147\n",
        "    log_dir='/content/drive/My Drive/ClassificationModel0503.pth'\n",
        "    #数据集加载\n",
        "    dataset_path = '/content/drive/My Drive/'\n",
        "    x_train, y_train, x_dev, y_dev = get_data(dataset_path, 'TrainDataClassification.mat', 0.4,1)\n",
        "    #print(x_train[0])\n",
        "    train_dataset = MyDataset(x_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    dev_dataset = MyDataset(x_dev, y_dev)\n",
        "    dev_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "\n",
        "    model = DnCNN()\n",
        "    #model = Model()\n",
        "    #模型加载\n",
        "    start_epoch=0\n",
        "    '''\n",
        "    if os.path.exists(log_dir):\n",
        "        checkpoint = torch.load(log_dir)\n",
        "        model.load_state_dict(checkpoint['net'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        print('无保存模型，将从头开始训练！')\n",
        "    '''\n",
        "    sgd = SGD(model.parameters(), lr)\n",
        "\n",
        "    cost = CrossEntropyLoss()\n",
        "    criterion = MSELoss(reduction='sum')\n",
        "    epoch = 100\n",
        "    use_GPU = True\n",
        "    if use_GPU:\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    epoch_train_loss_list = []\n",
        "    epoch_dev_loss_list = []\n",
        "    epoch_train_acc_list = []\n",
        "    epoch_dev_acc_list = []\n",
        "\n",
        "    for _epoch in range(epoch):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0\n",
        "        epoch_dev_loss = 0\n",
        "        epoch_train_acc = 0\n",
        "        epoch_dev_acc = 0\n",
        "        train_num=0\n",
        "        dev_num = 0\n",
        "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
        "            s = train_label.shape[0]\n",
        "            sgd.zero_grad()\n",
        "            predict_y = model(train_x.to(device))\n",
        "            #print(train_label.size())\n",
        "            #print(predict_y.size())\n",
        "            #loss = cost(predict_y, train_label.to(device))\n",
        "            loss = F.cross_entropy(predict_y, train_label.to(device))\n",
        "            epoch_train_loss += loss.item()\n",
        "            label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "            acc = np.sum(label_pred == train_label.numpy())\n",
        "            # print(\"batch Train acc:\",acc / s)\n",
        "            epoch_train_acc += acc / s\n",
        "            train_num+=1\n",
        "            loss.backward()\n",
        "            sgd.step()\n",
        "\n",
        "        correct = 0\n",
        "        _sum = 0\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (dev_x, dev_label) in enumerate(dev_loader):\n",
        "                s = dev_label.shape[0]\n",
        "                predict_y = model(dev_x.to(device))\n",
        "                # print(predict_y[0], dev_label[0])\n",
        "                loss = cost(predict_y, dev_label.to(device))\n",
        "                epoch_dev_loss += loss.item()\n",
        "                label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "                acc = np.sum(label_pred == dev_label.numpy())\n",
        "                batch_acc=acc / s\n",
        "                dev_num+=1\n",
        "                # print(\"batch_acc::\",batch_acc)\n",
        "                epoch_dev_acc += acc / s\n",
        "                # print(\"devacc\", acc);\n",
        "        epoch_train_loss_list.append(epoch_train_loss / train_num)\n",
        "        epoch_dev_loss_list.append(epoch_dev_loss / train_num)\n",
        "        epoch_train_acc_list.append(epoch_train_acc / dev_num)\n",
        "        epoch_dev_acc_list.append(epoch_dev_acc / dev_num)\n",
        "        print(\"epoch {:.4f} train acc: {:.4f},train loss: {:.4f}, dev acc: {:.4f}, dev loss: {:.4f}\".format(_epoch,epoch_train_acc / train_num, epoch_train_loss / train_num,epoch_dev_acc / dev_num, epoch_dev_loss / dev_num))\n",
        "   \n",
        "    \n",
        "    state = {'net':model.state_dict(),  'epoch':epoch}\n",
        "    torch.save(state, log_dir)\n",
        "    t = np.arange(1, len(epoch_train_loss_list) + 1)\n",
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    acc_plot = plt.subplot(2, 2, 1)\n",
        "    plt.title('acc')\n",
        "    plt.plot(t, epoch_train_acc_list, color='red', label='train acc')\n",
        "    plt.plot(t, epoch_dev_acc_list, color='blue', label='dev acc')\n",
        "    loss_plot = plt.subplot(2, 2, 2)\n",
        "    plt.title('loss ')\n",
        "    plt.plot(t, epoch_train_loss_list, color='red', label='train loss')\n",
        "    plt.plot(t, epoch_dev_loss_list, color='skyblue', label='dev loss')\n",
        "    plt.savefig(imgname)"
      ],
      "metadata": {
        "id": "px1s0sYqk-Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_data(dataset_path, fm, SNR):\n",
        "    print(\"load data from path1:\", dataset_path)\n",
        "    data = scio.loadmat(os.path.join(dataset_path, fm))\n",
        "\n",
        "    del data['__header__']\n",
        "    del data['__globals__']\n",
        "    del data['__version__']\n",
        "    # print(x_data.keys())\n",
        "    # print(y_data.keys())\n",
        "    # print(int(len(x_data)/3))\n",
        "    #datalen = int(len(x_data) / 3)\n",
        "    '''\n",
        "    datalen=500\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,int(datalen/2)):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "    '''   \n",
        "    datalen=250\n",
        "    x_test = np.zeros((datalen, 3, 50, 100), dtype=np.float)\n",
        "    y_test = np.zeros(datalen, dtype=np.uint8)\n",
        "    for i in range(1,datalen):\n",
        "        xkey1 = 'x' + str((SNR+5)*250+i)\n",
        "        #xkey2 = 'x' + str((SNR+5)*250+2500+i)\n",
        "        #print(xkey)\n",
        "        x_test[i] = data[xkey1]\n",
        "        #x_test[i+int(datalen/2)] = data[xkey2]\n",
        "        \n",
        "        y_test[i] = 1\n",
        "        #y_test[i+int(datalen/2)] = 0\n",
        "        #if i==1:\n",
        "        #  print(x[1])\n",
        "        #  print(y_data[ykey])\n",
        "        #  print(y[1])\n",
        "\n",
        "    \n",
        "    return x_test, y_test\n",
        "class MyTestDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "        self.data_size = len(self.y)\n",
        "        #norm_mean = [0.485, 0.456, 0.406]\n",
        "        #norm_std = [0.229, 0.224, 0.225]\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.ToTensor(),\n",
        "            # transforms.Normalize(norm_mean, norm_std),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        '''\n",
        "        这个函数是关键，通过item(索引)来取数据集中的数据，\n",
        "        一般来说在这里才将图像数据加载入内存，之前存的是图像的保存路径\n",
        "        '''\n",
        "        ycut=self.y[item]\n",
        "        #ycut=ycut[101:-6:400,1:-5:500]\n",
        "\n",
        "        label = torch.tensor(ycut,dtype=torch.long)\n",
        "        #label = torch.reshape(label, (1, -1))\n",
        "        xcut = self.x[item]\n",
        "        #xcut = xcut[101:-6:400,1:-5:500]\n",
        "        x = torch.from_numpy(xcut)\n",
        "        #x=x.unsqueeze(0)\n",
        "        #label=label.squeeze(0)\n",
        "        x=x.float()\n",
        "        #label=label.float()\n",
        "        x = torch.div(x, 255.)\n",
        "        #print(label)\n",
        "        #label = torch.div(label, 10000.)\n",
        "        #print(x)\n",
        "        #print(label)\n",
        "        #label=torch.div(label, 255.)\n",
        "        return x, label"
      ],
      "metadata": {
        "id": "MIEC7MelezSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "2CvKfHmdWlBp",
        "outputId": "3f0e8c16-5deb-4888-cead-cc8eda32aa79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-d554eb841dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#loss = criterion(predict_y, train_label.to(device)) / (2 * len(train_x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#terror,verror,acc=ab_err(predict_y,test_label.to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mepoch_dev_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (100) to match target batch_size (24)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 24\n",
        "use_GPU = True\n",
        "if use_GPU:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "model = DnCNN()\n",
        "model.to(device)\n",
        "print(torch.cuda.is_available())\n",
        "log_dir = '/content/drive/My Drive/ClassificationModel0425.pth'\n",
        "if os.path.exists(log_dir):\n",
        "    checkpoint = torch.load(log_dir)\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print('加载 epoch {} 成功！'.format(start_epoch))\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    print('加载失败')\n",
        "dataset_path=\"/content/drive/My Drive/\"\n",
        "SNR_acc_list = []\n",
        "for SNR in range(-5, 5):\n",
        "    x_test, y_test = get_test_data(dataset_path, 'TrainDataClassification.mat', SNR)\n",
        "    test_dataset = MyTestDataset(x_test, y_test)\n",
        "    train_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    test_num = 0\n",
        "    test_derror=0\n",
        "    test_verror=0\n",
        "    test_acc = 0\n",
        "    for idx, (test_x, test_label) in enumerate(train_loader):\n",
        "        epoch_dev_acc = 0\n",
        "        train_num = 0\n",
        "        dev_num = 0\n",
        "        epoch_dev_derror = 0\n",
        "        epoch_dev_verror = 0\n",
        "        epoch_train_derror = 0\n",
        "        epoch_train_verror = 0\n",
        "        s = test_label.shape[0]\n",
        "        predict_y = model(test_x.to(device))\n",
        "        \n",
        "        loss = F.cross_entropy(predict_y, test_label.to(device))\n",
        "            \n",
        "        epoch_dev_loss += loss.item()\n",
        "        label_pred = np.argmax(predict_y.cpu().data.numpy(), axis=1)\n",
        "        acc = np.sum(label_pred == test_label.numpy())\n",
        "        batch_acc=acc / s\n",
        "        print(batch_acc)\n",
        "\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        test_acc += acc/s\n",
        "        \n",
        "        test_num += 1\n",
        "    #print(test_acc)\n",
        "    #print(test_num )\n",
        "        # print(\"------\")\n",
        "        # print(label_pred)\n",
        "        # print(dev_label.numpy())\n",
        "        # print(\"------\")\n",
        "        # acc = np.sum(label_pred == dev_label.numpy())\n",
        "        # batch_acc=acc / s\n",
        "\n",
        "    print(test_acc / test_num)\n",
        "    SNR_acc_list.append(test_acc / test_num)\n",
        "        # print(\"batch_acc::\",batch_acc)\n",
        "        # epoch_dev_acc += acc / s\n",
        "        # print(\"devacc\", acc);\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "SNR = np.linspace(-5, 5, 10, endpoint=False)\n",
        "SNR=np.arange(1, len(SNR_acc_list) + 1)\n",
        "print(np.shape(SNR))\n",
        "print(np.shape(SNR_acc_list))\n",
        "plt.title('acc_SNR')\n",
        "plt.plot(SNR, SNR_acc_list, color='red', label='train loss')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6gpSPZhgmCpJ",
        "outputId": "2684ce65-2eb9-4fcc-cfd3-8ae1e591f788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "加载 epoch 50 成功！\n",
            "load data from path1: /content/drive/My Drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.9\n",
            "0.7484848484848484\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.756060606060606\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.9166666666666666\n",
            "0.75\n",
            "0.875\n",
            "0.7916666666666666\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.7810606060606061\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.8333333333333334\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.625\n",
            "0.5833333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.9166666666666666\n",
            "0.7916666666666666\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.9583333333333334\n",
            "0.7916666666666666\n",
            "0.7\n",
            "0.7568181818181817\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.875\n",
            "0.75\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.75\n",
            "0.625\n",
            "0.8333333333333334\n",
            "0.9\n",
            "0.7636363636363637\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.625\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.625\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.8\n",
            "0.7204545454545455\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.6666666666666666\n",
            "0.875\n",
            "0.6666666666666666\n",
            "0.7083333333333334\n",
            "0.8333333333333334\n",
            "0.7916666666666666\n",
            "0.75\n",
            "0.7083333333333334\n",
            "0.7\n",
            "0.7265151515151514\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.8333333333333334\n",
            "0.7083333333333334\n",
            "0.5833333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.7083333333333334\n",
            "0.625\n",
            "0.8\n",
            "0.6939393939393939\n",
            "load data from path1: /content/drive/My Drive/\n",
            "0.5833333333333334\n",
            "0.5833333333333334\n",
            "0.7083333333333334\n",
            "0.7916666666666666\n",
            "0.5416666666666666\n",
            "0.7083333333333334\n",
            "0.5\n",
            "0.625\n",
            "0.5416666666666666\n",
            "0.625\n",
            "0.9\n",
            "0.6462121212121212\n",
            "(10,)\n",
            "(10,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "0503 cnn_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}