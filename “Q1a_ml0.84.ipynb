{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ki-i/APRiL/blob/master/%E2%80%9CQ1a_ml0.84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8-rg-XyMYJBf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUEnEy4cZfaC",
        "outputId": "1abadd42-2039-4d27-ba5e-c5fb92e88bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.io import loadmat\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "data = pd.read_excel(\"/content/drive/My Drive/shumo_data/Q1data.xlsx\")\n",
        "feats = [f for f in data if f not in [ \"ID\",\"数据集划分\",\"kuozhang\"]]#选择特征\n",
        "\n",
        "def load_data(train_pos,dev_pos):\n",
        "    data = pd.read_excel(\"/content/drive/My Drive/shumo_data/Q1data.xlsx\")\n",
        "    feats = [f for f in data if f not in [\"ID\", \"数据集划分\", \"kuozhang\"]]  # 选择特征\n",
        "\n",
        "    print(feats)\n",
        "    # 创建MinMaxScaler对象\n",
        "    scaler = MinMaxScaler()\n",
        "    # 对特征进行最小-最大归一化\n",
        "    data[feats] = scaler.fit_transform(data[feats])\n",
        "    # 使用条件索引划分数据\n",
        "\n",
        "    df_train = data[data['数据集划分'] == '训练']\n",
        "\n",
        "    X = df_train.drop(columns=[\"ID\", \"数据集划分\", \"kuozhang\"])\n",
        "    y = df_train[\"kuozhang\"]\n",
        "\n",
        "    # 将数据集分为训练集和测试集\n",
        "    X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=30)\n",
        "        # 使用 iloc 选择除第一行以外的所有行\n",
        "    # 使用 .values 方法将新 DataFrame 转换为 NumPy 数组\n",
        "    X_train = X_train.iloc[1:].values\n",
        "    X_dev = X_dev.iloc[1:].values\n",
        "    y_train = y_train.iloc[1:].values\n",
        "    y_dev = y_dev.iloc[1:].values\n",
        "    x_train, y_train, x_dev, y_dev = sample(X_train, y_train, X_dev, y_dev, train_pos=train_pos,\n",
        "                                            train_neg=train_pos,dev_pos=dev_pos,dev_neg=dev_pos)\n",
        "    # x_dev, y_dev = sample(x_dev, y_dev,positive_num=2,nagetive_num=2,vaild_class=valid_class,train=False,only_invalid=False)\n",
        "    return x_train, y_train, x_dev, y_dev\n",
        "\n",
        "\n",
        "def sample(x_data_raw, y_data_raw, x_dev, y_dev, train_pos=3, train_neg=3,dev_neg=3,dev_pos=3):\n",
        "    print(\"train_pos\",train_pos,\"dev_pos\",dev_pos)\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    x_dev_data = []\n",
        "    y_dev_data = []\n",
        "    class_list = np.unique(y_data_raw)\n",
        "    p_count = 0\n",
        "    n_count = 0\n",
        "    for class_i in class_list:\n",
        "        x_i = x_data_raw[y_data_raw == class_i]\n",
        "        test_i = x_dev[y_dev == class_i]\n",
        "        x_j = x_data_raw[y_data_raw != class_i]\n",
        "        print(\"x_i_len\", class_i, len(x_i))\n",
        "        for x in x_i:\n",
        "            print(len(x_i),train_pos)\n",
        "\n",
        "            indexList = random.sample(range(len(x_i)), train_pos)\n",
        "            for index in indexList:\n",
        "                print(\"index\",index)\n",
        "                print(x_i.shape,index,type(x_i))\n",
        "                x_same_class = x_i[index]\n",
        "                positive_sample = [x, x_same_class]\n",
        "                x_data.append(positive_sample)\n",
        "                y_data.append([1])\n",
        "                p_count += 1\n",
        "\n",
        "            indexList = random.sample(range(len(x_j)), train_neg)\n",
        "            for index in indexList:\n",
        "                x_other_class = x_j[index]\n",
        "                negative_sample = [x, x_other_class]\n",
        "                x_data.append(negative_sample)\n",
        "                y_data.append([0])\n",
        "                n_count += 1\n",
        "\n",
        "        for test_x in test_i:\n",
        "            indexList = random.sample(range(len(x_i)), int(dev_pos))\n",
        "            for index in indexList:\n",
        "                x_same_class = x_i[index]\n",
        "                positive_sample = [test_x, x_same_class]\n",
        "                x_dev_data.append(positive_sample)\n",
        "                y_dev_data.append([1])\n",
        "                p_count += 1\n",
        "            indexList = random.sample(range(len(x_j)), int(dev_neg))\n",
        "            for index in indexList:\n",
        "                x_other_class = x_j[index]\n",
        "                negative_sample = [test_x, x_other_class]\n",
        "                x_dev_data.append(negative_sample)\n",
        "                y_dev_data.append([0])\n",
        "                n_count += 1\n",
        "    print(\"train\", len(x_data), \"train_negative\", len(x_dev_data), p_count, n_count)\n",
        "    # y_data = np.array(y_data)\n",
        "    # state = np.random.get_state()\n",
        "    # np.random.shuffle(x_data)\n",
        "    # np.random.set_state(state)\n",
        "    # np.random.shuffle(y_data)\n",
        "    return x_data, y_data, x_dev_data, y_dev_data\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.data = x\n",
        "        self.label = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is None:\n",
        "            return self.data[idx]\n",
        "        return self.data[idx][0], self.data[idx][1], torch.tensor(self.label[idx], dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "POCCzpoASG7P"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ufkpH8nnZCCu"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "from torch import nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "class DNNModel(Module):\n",
        "    def __init__(self):\n",
        "        super(DNNModel, self).__init__()\n",
        "        self.fc_1=nn.Linear(75,128)\n",
        "        self.relu1 = nn.ReLU()  # 添加ReLU激活函数\n",
        "        self.fc_2 = nn.Linear(128, 64)\n",
        "        self.out = nn.Linear(64,1)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def _forward(self,x):\n",
        "        x=self.fc_1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        y=self.fc_2(x)\n",
        "        return y\n",
        "\n",
        "    def forward(self, x_1,x_2):\n",
        "        y_1 = self._forward(x_1)\n",
        "        y_2 = self._forward(x_2)\n",
        "        # dis = torch.cat((y_1, y_2), dim=1)\n",
        "        dis = torch.abs(y_1 - y_2)\n",
        "        logits = self.out(dis)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "lr=0.001\n",
        "num_epoches=15000\n",
        "use_GPU=1\n",
        "\n",
        "train_pos=3\n",
        "dev_pos=3\n",
        "\n",
        "model_save_path='model_realimag_0910+0427static2_sample_2.pt' #模型保存路径\n",
        "\n",
        "def loss_fn(logits, labels):\n",
        "    loss_fn = F.binary_cross_entropy_with_logits(logits, labels)\n",
        "    return loss_fn\n",
        "\n",
        "#指定训练数据路径和参与训练的设备id\n",
        "# append_list=[('data/0407_normal_单帧/0407static2_normal.mat','RFF')]\n",
        "\n",
        "x_train, y_train, x_dev, y_dev = load_data(train_pos=train_pos,dev_pos=dev_pos)\n",
        "print('train len', len(x_train), len(x_dev))\n",
        "hparams ={\n",
        "    'in_feature': len(x_train[0]),\n",
        "    'out_feature': 200\n",
        "}\n",
        "\n",
        "train_dataset = MyDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=64,drop_last=True)\n",
        "\n",
        "dev_dataset = MyDataset(x_dev, y_dev)\n",
        "dev_dataloader = DataLoader(dev_dataset,batch_size=64,drop_last=True)\n",
        "l1_lambda=0.01\n",
        "model = DNNModel()\n",
        "# sgd = SGD([\n",
        "#     {'params': model.parameters(), 'weight_decay': l1_lambda}\n",
        "# ], lr=float(lr), weight_decay=0.001)\n",
        "\n",
        "sgd = SGD(model.parameters(), lr=float(lr))\n",
        "num_epoches = int(num_epoches)\n",
        "\n",
        "if use_GPU:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "min_loss=1\n",
        "epoch_train_loss_list = []\n",
        "epoch_dev_loss_list = []\n",
        "epoch_train_acc_list = []\n",
        "epoch_dev_acc_list = []\n",
        "print(\"ooooooooooooooo\")\n",
        "for epoch in range(num_epoches):\n",
        "    epoch_train_loss=0\n",
        "    epoch_train_acc=0\n",
        "    epoch_dev_loss=0\n",
        "    epoch_dev_acc=0\n",
        "    train_num=0\n",
        "    dev_num=0\n",
        "    for x_1,x_2,label in train_dataloader:\n",
        "        s = len(label)\n",
        "        # print(label)\n",
        "        sgd.zero_grad()\n",
        "        predict_y = model(x_1.to(device).float(), x_2.to(device).float())\n",
        "        loss = loss_fn(predict_y, label.to(device))\n",
        "        epoch_train_loss += loss.item()\n",
        "        label_pred = np.where(predict_y.cpu().data.numpy() > 0, 1, 0)\n",
        "        # print(label_pred)\n",
        "        acc = np.sum(label_pred == label.numpy())\n",
        "        epoch_train_acc += acc / s\n",
        "        train_num += 1\n",
        "        loss.backward()\n",
        "        sgd.step()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x_1, x_2, label in dev_dataloader:\n",
        "            s = len(label)\n",
        "            sgd.zero_grad()\n",
        "            predict_y = model(x_1.to(device).float(), x_2.to(device).float())\n",
        "            loss = loss_fn(predict_y, label.to(device))\n",
        "            epoch_dev_loss += loss.item()\n",
        "            label_pred = np.where(predict_y.cpu().data.numpy() > 0, 1, 0)\n",
        "            acc = np.sum(label_pred == label.numpy())\n",
        "            epoch_dev_acc += acc / s\n",
        "            dev_num += 1\n",
        "    epoch_train_loss_list.append(epoch_train_loss / train_num)\n",
        "    epoch_dev_loss_list.append(epoch_dev_loss / dev_num)\n",
        "    epoch_train_acc_list.append(epoch_train_acc / train_num)\n",
        "    epoch_dev_acc_list.append(epoch_dev_acc / dev_num)\n",
        "    dev_loss =epoch_dev_loss / dev_num\n",
        "    # if dev_loss <min_loss:\n",
        "    #     print('save')\n",
        "    #     min_loss = dev_loss\n",
        "    #     torch.save(model, model_save_path)\n",
        "    print(\"epoch11 {:.4f} train acc: {:.4f},train loss: {:.4f}, dev acc: {:.4f}, dev loss: {:.4f}\".format(epoch,\n",
        "                                                                                                        epoch_train_acc / train_num,\n",
        "                                                                                                        epoch_train_loss / train_num,\n",
        "                                                                                                        epoch_dev_acc / dev_num,\n",
        "                                                                                                        epoch_dev_loss / dev_num))\n",
        "\n",
        "\n",
        "\n",
        "t = np.arange(1, len(epoch_train_acc_list) + 1)\n",
        "acc_plot = plt.subplot(1,2, 1)\n",
        "plt.title('acc')\n",
        "plt.plot(t, epoch_train_acc_list, color='turquoise', label='train acc')\n",
        "plt.plot(t, epoch_dev_acc_list, color='dodgerblue', label='dev acc')\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(alpha=0.4,linestyle='--',)\n",
        "loss_plot = plt.subplot(1, 2, 2)\n",
        "plt.title('loss ')\n",
        "plt.plot(t, epoch_train_loss_list, color='turquoise', label='train loss')\n",
        "plt.plot(t, epoch_dev_acc_list, color='dodgerblue', label='dev loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(alpha=0.4,linestyle='--',)\n",
        "plt.savefig('ensem-0114_train_info3.jpg', dpi=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7IHDeOcSlvf",
        "outputId": "6a6293d4-7004-40ae-972b-3c7fc56e6d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['90天mRS', '流水号', '年龄', '性别', '脑出血前mRS评分', '高血压病史', '卒中病史', '糖尿病史', '房颤史', '冠心病史', '吸烟史', '饮酒史', '发病到首次影像检查时间间隔', '脑室引流', '止血治疗', '降颅压治疗', '降压治疗', '镇静、镇痛治疗', '止吐护胃', '营养神经', '高压', '低压', 'HM_volume1', 'HM_ACA_R_Ratio', 'HM_MCA_R_Ratio', 'HM_PCA_R_Ratio', 'HM_Pons_Medulla_R_Ratio', 'HM_Cerebellum_R_Ratio', 'HM_ACA_L_Ratio', 'HM_MCA_L_Ratio', 'HM_PCA_L_Ratio', 'HM_Pons_Medulla_L_Ratio', 'HM_Cerebellum_L_Ratio', 'ED_volume', 'ED_ACA_R_Ratio', 'ED_MCA_R_Ratio', 'ED_PCA_R_Ratio', 'ED_Pons_Medulla_R_Ratio', 'ED_Cerebellum_R_Ratio', 'ED_ACA_L_Ratio', 'ED_MCA_L_Ratio', 'ED_PCA_L_Ratio', 'ED_Pons_Medulla_L_Ratio', 'ED_Cerebellum_L_Ratio', 'original_shape_Elongation', 'original_shape_Flatness', 'original_shape_LeastAxisLength', 'original_shape_MajorAxisLength', 'original_shape_Maximum2DDiameterColumn', 'original_shape_Maximum2DDiameterRow', 'original_shape_Maximum2DDiameterSlice', 'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength', 'original_shape_Sphericity', 'original_shape_SurfaceArea', 'original_shape_SurfaceVolumeRatio', 'original_shape_VoxelVolume', 'NCCT_original_firstorder_10Percentile', 'NCCT_original_firstorder_90Percentile', 'NCCT_original_firstorder_Energy', 'NCCT_original_firstorder_Entropy', 'NCCT_original_firstorder_InterquartileRange', 'NCCT_original_firstorder_Kurtosis', 'NCCT_original_firstorder_Maximum', 'NCCT_original_firstorder_MeanAbsoluteDeviation', 'NCCT_original_firstorder_Mean', 'NCCT_original_firstorder_Median', 'NCCT_original_firstorder_Minimum', 'NCCT_original_firstorder_Range', 'NCCT_original_firstorder_RobustMeanAbsoluteDeviation', 'NCCT_original_firstorder_RootMeanSquared', 'NCCT_original_firstorder_Skewness', 'NCCT_original_firstorder_Uniformity', 'NCCT_original_firstorder_Variance']\n",
            "train_pos 3 dev_pos 3\n",
            "x_i_len 0.0 60\n",
            "60 3\n",
            "index 38\n",
            "(60, 75) 38 <class 'numpy.ndarray'>\n",
            "index 36\n",
            "(60, 75) 36 <class 'numpy.ndarray'>\n",
            "index 11\n",
            "(60, 75) 11 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 7\n",
            "(60, 75) 7 <class 'numpy.ndarray'>\n",
            "index 55\n",
            "(60, 75) 55 <class 'numpy.ndarray'>\n",
            "index 0\n",
            "(60, 75) 0 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 19\n",
            "(60, 75) 19 <class 'numpy.ndarray'>\n",
            "index 57\n",
            "(60, 75) 57 <class 'numpy.ndarray'>\n",
            "index 28\n",
            "(60, 75) 28 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 6\n",
            "(60, 75) 6 <class 'numpy.ndarray'>\n",
            "index 57\n",
            "(60, 75) 57 <class 'numpy.ndarray'>\n",
            "index 5\n",
            "(60, 75) 5 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 59\n",
            "(60, 75) 59 <class 'numpy.ndarray'>\n",
            "index 21\n",
            "(60, 75) 21 <class 'numpy.ndarray'>\n",
            "index 33\n",
            "(60, 75) 33 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 56\n",
            "(60, 75) 56 <class 'numpy.ndarray'>\n",
            "index 51\n",
            "(60, 75) 51 <class 'numpy.ndarray'>\n",
            "index 15\n",
            "(60, 75) 15 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 20\n",
            "(60, 75) 20 <class 'numpy.ndarray'>\n",
            "index 26\n",
            "(60, 75) 26 <class 'numpy.ndarray'>\n",
            "index 15\n",
            "(60, 75) 15 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 34\n",
            "(60, 75) 34 <class 'numpy.ndarray'>\n",
            "index 53\n",
            "(60, 75) 53 <class 'numpy.ndarray'>\n",
            "index 36\n",
            "(60, 75) 36 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 57\n",
            "(60, 75) 57 <class 'numpy.ndarray'>\n",
            "index 26\n",
            "(60, 75) 26 <class 'numpy.ndarray'>\n",
            "index 36\n",
            "(60, 75) 36 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 53\n",
            "(60, 75) 53 <class 'numpy.ndarray'>\n",
            "index 55\n",
            "(60, 75) 55 <class 'numpy.ndarray'>\n",
            "index 20\n",
            "(60, 75) 20 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 54\n",
            "(60, 75) 54 <class 'numpy.ndarray'>\n",
            "index 25\n",
            "(60, 75) 25 <class 'numpy.ndarray'>\n",
            "index 4\n",
            "(60, 75) 4 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 40\n",
            "(60, 75) 40 <class 'numpy.ndarray'>\n",
            "index 5\n",
            "(60, 75) 5 <class 'numpy.ndarray'>\n",
            "index 9\n",
            "(60, 75) 9 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 10\n",
            "(60, 75) 10 <class 'numpy.ndarray'>\n",
            "index 59\n",
            "(60, 75) 59 <class 'numpy.ndarray'>\n",
            "index 5\n",
            "(60, 75) 5 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 39\n",
            "(60, 75) 39 <class 'numpy.ndarray'>\n",
            "index 14\n",
            "(60, 75) 14 <class 'numpy.ndarray'>\n",
            "index 35\n",
            "(60, 75) 35 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 35\n",
            "(60, 75) 35 <class 'numpy.ndarray'>\n",
            "index 37\n",
            "(60, 75) 37 <class 'numpy.ndarray'>\n",
            "index 10\n",
            "(60, 75) 10 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 52\n",
            "(60, 75) 52 <class 'numpy.ndarray'>\n",
            "index 23\n",
            "(60, 75) 23 <class 'numpy.ndarray'>\n",
            "index 31\n",
            "(60, 75) 31 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 10\n",
            "(60, 75) 10 <class 'numpy.ndarray'>\n",
            "index 11\n",
            "(60, 75) 11 <class 'numpy.ndarray'>\n",
            "index 5\n",
            "(60, 75) 5 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 5\n",
            "(60, 75) 5 <class 'numpy.ndarray'>\n",
            "index 50\n",
            "(60, 75) 50 <class 'numpy.ndarray'>\n",
            "index 34\n",
            "(60, 75) 34 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 33\n",
            "(60, 75) 33 <class 'numpy.ndarray'>\n",
            "index 16\n",
            "(60, 75) 16 <class 'numpy.ndarray'>\n",
            "index 59\n",
            "(60, 75) 59 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 33\n",
            "(60, 75) 33 <class 'numpy.ndarray'>\n",
            "index 53\n",
            "(60, 75) 53 <class 'numpy.ndarray'>\n",
            "index 13\n",
            "(60, 75) 13 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 28\n",
            "(60, 75) 28 <class 'numpy.ndarray'>\n",
            "index 29\n",
            "(60, 75) 29 <class 'numpy.ndarray'>\n",
            "index 37\n",
            "(60, 75) 37 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 22\n",
            "(60, 75) 22 <class 'numpy.ndarray'>\n",
            "index 15\n",
            "(60, 75) 15 <class 'numpy.ndarray'>\n",
            "index 11\n",
            "(60, 75) 11 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 44\n",
            "(60, 75) 44 <class 'numpy.ndarray'>\n",
            "index 53\n",
            "(60, 75) 53 <class 'numpy.ndarray'>\n",
            "index 29\n",
            "(60, 75) 29 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 51\n",
            "(60, 75) 51 <class 'numpy.ndarray'>\n",
            "index 23\n",
            "(60, 75) 23 <class 'numpy.ndarray'>\n",
            "index 56\n",
            "(60, 75) 56 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 35\n",
            "(60, 75) 35 <class 'numpy.ndarray'>\n",
            "index 37\n",
            "(60, 75) 37 <class 'numpy.ndarray'>\n",
            "index 16\n",
            "(60, 75) 16 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 11\n",
            "(60, 75) 11 <class 'numpy.ndarray'>\n",
            "index 1\n",
            "(60, 75) 1 <class 'numpy.ndarray'>\n",
            "index 6\n",
            "(60, 75) 6 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 23\n",
            "(60, 75) 23 <class 'numpy.ndarray'>\n",
            "index 46\n",
            "(60, 75) 46 <class 'numpy.ndarray'>\n",
            "index 4\n",
            "(60, 75) 4 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 45\n",
            "(60, 75) 45 <class 'numpy.ndarray'>\n",
            "index 31\n",
            "(60, 75) 31 <class 'numpy.ndarray'>\n",
            "index 52\n",
            "(60, 75) 52 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 32\n",
            "(60, 75) 32 <class 'numpy.ndarray'>\n",
            "index 25\n",
            "(60, 75) 25 <class 'numpy.ndarray'>\n",
            "index 56\n",
            "(60, 75) 56 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 11\n",
            "(60, 75) 11 <class 'numpy.ndarray'>\n",
            "index 1\n",
            "(60, 75) 1 <class 'numpy.ndarray'>\n",
            "index 49\n",
            "(60, 75) 49 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 44\n",
            "(60, 75) 44 <class 'numpy.ndarray'>\n",
            "index 2\n",
            "(60, 75) 2 <class 'numpy.ndarray'>\n",
            "index 54\n",
            "(60, 75) 54 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 21\n",
            "(60, 75) 21 <class 'numpy.ndarray'>\n",
            "index 52\n",
            "(60, 75) 52 <class 'numpy.ndarray'>\n",
            "index 13\n",
            "(60, 75) 13 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 41\n",
            "(60, 75) 41 <class 'numpy.ndarray'>\n",
            "index 19\n",
            "(60, 75) 19 <class 'numpy.ndarray'>\n",
            "index 38\n",
            "(60, 75) 38 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 31\n",
            "(60, 75) 31 <class 'numpy.ndarray'>\n",
            "index 46\n",
            "(60, 75) 46 <class 'numpy.ndarray'>\n",
            "index 22\n",
            "(60, 75) 22 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 34\n",
            "(60, 75) 34 <class 'numpy.ndarray'>\n",
            "index 28\n",
            "(60, 75) 28 <class 'numpy.ndarray'>\n",
            "index 46\n",
            "(60, 75) 46 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 4\n",
            "(60, 75) 4 <class 'numpy.ndarray'>\n",
            "index 37\n",
            "(60, 75) 37 <class 'numpy.ndarray'>\n",
            "index 45\n",
            "(60, 75) 45 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 8\n",
            "(60, 75) 8 <class 'numpy.ndarray'>\n",
            "index 52\n",
            "(60, 75) 52 <class 'numpy.ndarray'>\n",
            "index 5\n",
            "(60, 75) 5 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 43\n",
            "(60, 75) 43 <class 'numpy.ndarray'>\n",
            "index 50\n",
            "(60, 75) 50 <class 'numpy.ndarray'>\n",
            "index 17\n",
            "(60, 75) 17 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 0\n",
            "(60, 75) 0 <class 'numpy.ndarray'>\n",
            "index 21\n",
            "(60, 75) 21 <class 'numpy.ndarray'>\n",
            "index 43\n",
            "(60, 75) 43 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 59\n",
            "(60, 75) 59 <class 'numpy.ndarray'>\n",
            "index 29\n",
            "(60, 75) 29 <class 'numpy.ndarray'>\n",
            "index 4\n",
            "(60, 75) 4 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 13\n",
            "(60, 75) 13 <class 'numpy.ndarray'>\n",
            "index 23\n",
            "(60, 75) 23 <class 'numpy.ndarray'>\n",
            "index 22\n",
            "(60, 75) 22 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 20\n",
            "(60, 75) 20 <class 'numpy.ndarray'>\n",
            "index 47\n",
            "(60, 75) 47 <class 'numpy.ndarray'>\n",
            "index 28\n",
            "(60, 75) 28 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 46\n",
            "(60, 75) 46 <class 'numpy.ndarray'>\n",
            "index 31\n",
            "(60, 75) 31 <class 'numpy.ndarray'>\n",
            "index 55\n",
            "(60, 75) 55 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 23\n",
            "(60, 75) 23 <class 'numpy.ndarray'>\n",
            "index 40\n",
            "(60, 75) 40 <class 'numpy.ndarray'>\n",
            "index 18\n",
            "(60, 75) 18 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 15\n",
            "(60, 75) 15 <class 'numpy.ndarray'>\n",
            "index 24\n",
            "(60, 75) 24 <class 'numpy.ndarray'>\n",
            "index 49\n",
            "(60, 75) 49 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 5\n",
            "(60, 75) 5 <class 'numpy.ndarray'>\n",
            "index 47\n",
            "(60, 75) 47 <class 'numpy.ndarray'>\n",
            "index 55\n",
            "(60, 75) 55 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 19\n",
            "(60, 75) 19 <class 'numpy.ndarray'>\n",
            "index 32\n",
            "(60, 75) 32 <class 'numpy.ndarray'>\n",
            "index 38\n",
            "(60, 75) 38 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 33\n",
            "(60, 75) 33 <class 'numpy.ndarray'>\n",
            "index 54\n",
            "(60, 75) 54 <class 'numpy.ndarray'>\n",
            "index 55\n",
            "(60, 75) 55 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 29\n",
            "(60, 75) 29 <class 'numpy.ndarray'>\n",
            "index 51\n",
            "(60, 75) 51 <class 'numpy.ndarray'>\n",
            "index 3\n",
            "(60, 75) 3 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 44\n",
            "(60, 75) 44 <class 'numpy.ndarray'>\n",
            "index 38\n",
            "(60, 75) 38 <class 'numpy.ndarray'>\n",
            "index 15\n",
            "(60, 75) 15 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 19\n",
            "(60, 75) 19 <class 'numpy.ndarray'>\n",
            "index 29\n",
            "(60, 75) 29 <class 'numpy.ndarray'>\n",
            "index 47\n",
            "(60, 75) 47 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 22\n",
            "(60, 75) 22 <class 'numpy.ndarray'>\n",
            "index 47\n",
            "(60, 75) 47 <class 'numpy.ndarray'>\n",
            "index 26\n",
            "(60, 75) 26 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 31\n",
            "(60, 75) 31 <class 'numpy.ndarray'>\n",
            "index 42\n",
            "(60, 75) 42 <class 'numpy.ndarray'>\n",
            "index 43\n",
            "(60, 75) 43 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 14\n",
            "(60, 75) 14 <class 'numpy.ndarray'>\n",
            "index 20\n",
            "(60, 75) 20 <class 'numpy.ndarray'>\n",
            "index 27\n",
            "(60, 75) 27 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 8\n",
            "(60, 75) 8 <class 'numpy.ndarray'>\n",
            "index 49\n",
            "(60, 75) 49 <class 'numpy.ndarray'>\n",
            "index 37\n",
            "(60, 75) 37 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 14\n",
            "(60, 75) 14 <class 'numpy.ndarray'>\n",
            "index 17\n",
            "(60, 75) 17 <class 'numpy.ndarray'>\n",
            "index 0\n",
            "(60, 75) 0 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 16\n",
            "(60, 75) 16 <class 'numpy.ndarray'>\n",
            "index 45\n",
            "(60, 75) 45 <class 'numpy.ndarray'>\n",
            "index 8\n",
            "(60, 75) 8 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 8\n",
            "(60, 75) 8 <class 'numpy.ndarray'>\n",
            "index 57\n",
            "(60, 75) 57 <class 'numpy.ndarray'>\n",
            "index 26\n",
            "(60, 75) 26 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 8\n",
            "(60, 75) 8 <class 'numpy.ndarray'>\n",
            "index 33\n",
            "(60, 75) 33 <class 'numpy.ndarray'>\n",
            "index 24\n",
            "(60, 75) 24 <class 'numpy.ndarray'>\n",
            "60 3\n",
            "index 0\n",
            "(60, 75) 0 <class 'numpy.ndarray'>\n",
            "index 51\n",
            "(60, 75) 51 <class 'numpy.ndarray'>\n",
            "index 13\n",
            "(60, 75) 13 <class 'numpy.ndarray'>\n",
            "x_i_len 1.0 19\n",
            "19 3\n",
            "index 14\n",
            "(19, 75) 14 <class 'numpy.ndarray'>\n",
            "index 0\n",
            "(19, 75) 0 <class 'numpy.ndarray'>\n",
            "index 4\n",
            "(19, 75) 4 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 7\n",
            "(19, 75) 7 <class 'numpy.ndarray'>\n",
            "index 12\n",
            "(19, 75) 12 <class 'numpy.ndarray'>\n",
            "index 1\n",
            "(19, 75) 1 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 9\n",
            "(19, 75) 9 <class 'numpy.ndarray'>\n",
            "index 18\n",
            "(19, 75) 18 <class 'numpy.ndarray'>\n",
            "index 14\n",
            "(19, 75) 14 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 15\n",
            "(19, 75) 15 <class 'numpy.ndarray'>\n",
            "index 10\n",
            "(19, 75) 10 <class 'numpy.ndarray'>\n",
            "index 11\n",
            "(19, 75) 11 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 15\n",
            "(19, 75) 15 <class 'numpy.ndarray'>\n",
            "index 3\n",
            "(19, 75) 3 <class 'numpy.ndarray'>\n",
            "index 10\n",
            "(19, 75) 10 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 1\n",
            "(19, 75) 1 <class 'numpy.ndarray'>\n",
            "index 16\n",
            "(19, 75) 16 <class 'numpy.ndarray'>\n",
            "index 7\n",
            "(19, 75) 7 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 9\n",
            "(19, 75) 9 <class 'numpy.ndarray'>\n",
            "index 8\n",
            "(19, 75) 8 <class 'numpy.ndarray'>\n",
            "index 18\n",
            "(19, 75) 18 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 0\n",
            "(19, 75) 0 <class 'numpy.ndarray'>\n",
            "index 6\n",
            "(19, 75) 6 <class 'numpy.ndarray'>\n",
            "index 18\n",
            "(19, 75) 18 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 6\n",
            "(19, 75) 6 <class 'numpy.ndarray'>\n",
            "index 7\n",
            "(19, 75) 7 <class 'numpy.ndarray'>\n",
            "index 13\n",
            "(19, 75) 13 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 14\n",
            "(19, 75) 14 <class 'numpy.ndarray'>\n",
            "index 3\n",
            "(19, 75) 3 <class 'numpy.ndarray'>\n",
            "index 9\n",
            "(19, 75) 9 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 15\n",
            "(19, 75) 15 <class 'numpy.ndarray'>\n",
            "index 6\n",
            "(19, 75) 6 <class 'numpy.ndarray'>\n",
            "index 11\n",
            "(19, 75) 11 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 13\n",
            "(19, 75) 13 <class 'numpy.ndarray'>\n",
            "index 11\n",
            "(19, 75) 11 <class 'numpy.ndarray'>\n",
            "index 1\n",
            "(19, 75) 1 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 10\n",
            "(19, 75) 10 <class 'numpy.ndarray'>\n",
            "index 17\n",
            "(19, 75) 17 <class 'numpy.ndarray'>\n",
            "index 16\n",
            "(19, 75) 16 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 3\n",
            "(19, 75) 3 <class 'numpy.ndarray'>\n",
            "index 17\n",
            "(19, 75) 17 <class 'numpy.ndarray'>\n",
            "index 10\n",
            "(19, 75) 10 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 15\n",
            "(19, 75) 15 <class 'numpy.ndarray'>\n",
            "index 16\n",
            "(19, 75) 16 <class 'numpy.ndarray'>\n",
            "index 8\n",
            "(19, 75) 8 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 11\n",
            "(19, 75) 11 <class 'numpy.ndarray'>\n",
            "index 6\n",
            "(19, 75) 6 <class 'numpy.ndarray'>\n",
            "index 18\n",
            "(19, 75) 18 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 9\n",
            "(19, 75) 9 <class 'numpy.ndarray'>\n",
            "index 6\n",
            "(19, 75) 6 <class 'numpy.ndarray'>\n",
            "index 2\n",
            "(19, 75) 2 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 17\n",
            "(19, 75) 17 <class 'numpy.ndarray'>\n",
            "index 18\n",
            "(19, 75) 18 <class 'numpy.ndarray'>\n",
            "index 12\n",
            "(19, 75) 12 <class 'numpy.ndarray'>\n",
            "19 3\n",
            "index 15\n",
            "(19, 75) 15 <class 'numpy.ndarray'>\n",
            "index 16\n",
            "(19, 75) 16 <class 'numpy.ndarray'>\n",
            "index 14\n",
            "(19, 75) 14 <class 'numpy.ndarray'>\n",
            "train 474 train_negative 114 294 294\n",
            "train len 474 114\n",
            "ooooooooooooooo\n",
            "epoch11 0.0000 train acc: 0.5045,train loss: 0.6942, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 1.0000 train acc: 0.4754,train loss: 0.6936, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 2.0000 train acc: 0.4754,train loss: 0.6936, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 3.0000 train acc: 0.4754,train loss: 0.6936, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 4.0000 train acc: 0.4754,train loss: 0.6936, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 5.0000 train acc: 0.4754,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 6.0000 train acc: 0.4754,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 7.0000 train acc: 0.4754,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 8.0000 train acc: 0.4777,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6937\n",
            "epoch11 9.0000 train acc: 0.4777,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 10.0000 train acc: 0.4777,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 11.0000 train acc: 0.4754,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 12.0000 train acc: 0.4754,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 13.0000 train acc: 0.4777,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 14.0000 train acc: 0.4799,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 15.0000 train acc: 0.4799,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 16.0000 train acc: 0.4799,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 17.0000 train acc: 0.4799,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 18.0000 train acc: 0.4799,train loss: 0.6935, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 19.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 20.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 21.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 22.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 23.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 24.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 25.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 26.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 27.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 28.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6936\n",
            "epoch11 29.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6935\n",
            "epoch11 30.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.5000, dev loss: 0.6935\n",
            "epoch11 31.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 32.0000 train acc: 0.4799,train loss: 0.6934, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 33.0000 train acc: 0.4799,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 34.0000 train acc: 0.4821,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 35.0000 train acc: 0.4821,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 36.0000 train acc: 0.4844,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 37.0000 train acc: 0.4844,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 38.0000 train acc: 0.4844,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 39.0000 train acc: 0.4844,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 40.0000 train acc: 0.4844,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 41.0000 train acc: 0.4844,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 42.0000 train acc: 0.4866,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 43.0000 train acc: 0.4866,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 44.0000 train acc: 0.4866,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 45.0000 train acc: 0.4866,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 46.0000 train acc: 0.4866,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 47.0000 train acc: 0.4866,train loss: 0.6933, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 48.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6935\n",
            "epoch11 49.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 50.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 51.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 52.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 53.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 54.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 55.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 56.0000 train acc: 0.4866,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 57.0000 train acc: 0.4888,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 58.0000 train acc: 0.4911,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 59.0000 train acc: 0.4911,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 60.0000 train acc: 0.4911,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 61.0000 train acc: 0.4911,train loss: 0.6932, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 62.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 63.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 64.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 65.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 66.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 67.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 68.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6934\n",
            "epoch11 69.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 70.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 71.0000 train acc: 0.4911,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 72.0000 train acc: 0.4933,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 73.0000 train acc: 0.4933,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 74.0000 train acc: 0.4933,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 75.0000 train acc: 0.4933,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 76.0000 train acc: 0.4933,train loss: 0.6931, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 77.0000 train acc: 0.4955,train loss: 0.6930, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 78.0000 train acc: 0.4955,train loss: 0.6930, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 79.0000 train acc: 0.4933,train loss: 0.6930, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 80.0000 train acc: 0.4933,train loss: 0.6930, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 81.0000 train acc: 0.4933,train loss: 0.6930, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 82.0000 train acc: 0.4933,train loss: 0.6930, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 83.0000 train acc: 0.4955,train loss: 0.6930, dev acc: 0.4844, dev loss: 0.6933\n",
            "epoch11 84.0000 train acc: 0.4955,train loss: 0.6930, dev acc: 0.4688, dev loss: 0.6933\n",
            "epoch11 85.0000 train acc: 0.4978,train loss: 0.6930, dev acc: 0.4688, dev loss: 0.6933\n",
            "epoch11 86.0000 train acc: 0.4978,train loss: 0.6930, dev acc: 0.4688, dev loss: 0.6933\n",
            "epoch11 87.0000 train acc: 0.4978,train loss: 0.6930, dev acc: 0.4688, dev loss: 0.6933\n",
            "epoch11 88.0000 train acc: 0.4978,train loss: 0.6930, dev acc: 0.4688, dev loss: 0.6933\n",
            "epoch11 89.0000 train acc: 0.4978,train loss: 0.6930, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 90.0000 train acc: 0.4978,train loss: 0.6930, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 91.0000 train acc: 0.4978,train loss: 0.6930, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 92.0000 train acc: 0.4978,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 93.0000 train acc: 0.4978,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 94.0000 train acc: 0.4978,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 95.0000 train acc: 0.4978,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 96.0000 train acc: 0.4978,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 97.0000 train acc: 0.4978,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 98.0000 train acc: 0.4978,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 99.0000 train acc: 0.5000,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 100.0000 train acc: 0.5000,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 101.0000 train acc: 0.5000,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 102.0000 train acc: 0.5000,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 103.0000 train acc: 0.5000,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 104.0000 train acc: 0.5022,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 105.0000 train acc: 0.5022,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 106.0000 train acc: 0.5022,train loss: 0.6929, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 107.0000 train acc: 0.5000,train loss: 0.6928, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 108.0000 train acc: 0.5000,train loss: 0.6928, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 109.0000 train acc: 0.5022,train loss: 0.6928, dev acc: 0.4688, dev loss: 0.6932\n",
            "epoch11 110.0000 train acc: 0.5022,train loss: 0.6928, dev acc: 0.4688, dev loss: 0.6931\n",
            "epoch11 111.0000 train acc: 0.5022,train loss: 0.6928, dev acc: 0.4688, dev loss: 0.6931\n",
            "epoch11 112.0000 train acc: 0.5022,train loss: 0.6928, dev acc: 0.4688, dev loss: 0.6931\n",
            "epoch11 113.0000 train acc: 0.5022,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 114.0000 train acc: 0.5022,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 115.0000 train acc: 0.5022,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 116.0000 train acc: 0.5022,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 117.0000 train acc: 0.5000,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 118.0000 train acc: 0.5000,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 119.0000 train acc: 0.5000,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 120.0000 train acc: 0.4978,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 121.0000 train acc: 0.4978,train loss: 0.6928, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 122.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 123.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 124.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 125.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 126.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 127.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 128.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 129.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6931\n",
            "epoch11 130.0000 train acc: 0.4978,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 131.0000 train acc: 0.5000,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 132.0000 train acc: 0.5000,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 133.0000 train acc: 0.5000,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 134.0000 train acc: 0.5000,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 135.0000 train acc: 0.5045,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 136.0000 train acc: 0.5067,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 137.0000 train acc: 0.5045,train loss: 0.6927, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 138.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 139.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 140.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 141.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 142.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 143.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 144.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 145.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 146.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 147.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4844, dev loss: 0.6930\n",
            "epoch11 148.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4688, dev loss: 0.6930\n",
            "epoch11 149.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4688, dev loss: 0.6930\n",
            "epoch11 150.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 151.0000 train acc: 0.5045,train loss: 0.6926, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 152.0000 train acc: 0.5067,train loss: 0.6926, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 153.0000 train acc: 0.5089,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 154.0000 train acc: 0.5089,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 155.0000 train acc: 0.5089,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 156.0000 train acc: 0.5089,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 157.0000 train acc: 0.5089,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 158.0000 train acc: 0.5089,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 159.0000 train acc: 0.5112,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 160.0000 train acc: 0.5112,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 161.0000 train acc: 0.5134,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 162.0000 train acc: 0.5134,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 163.0000 train acc: 0.5134,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 164.0000 train acc: 0.5134,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 165.0000 train acc: 0.5134,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 166.0000 train acc: 0.5134,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 167.0000 train acc: 0.5134,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 168.0000 train acc: 0.5134,train loss: 0.6925, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 169.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 170.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 171.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6929\n",
            "epoch11 172.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 173.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 174.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 175.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 176.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 177.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 178.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 179.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 180.0000 train acc: 0.5179,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 181.0000 train acc: 0.5179,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 182.0000 train acc: 0.5179,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 183.0000 train acc: 0.5179,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 184.0000 train acc: 0.5156,train loss: 0.6924, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 185.0000 train acc: 0.5179,train loss: 0.6923, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 186.0000 train acc: 0.5179,train loss: 0.6923, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 187.0000 train acc: 0.5179,train loss: 0.6923, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 188.0000 train acc: 0.5179,train loss: 0.6923, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 189.0000 train acc: 0.5179,train loss: 0.6923, dev acc: 0.4688, dev loss: 0.6928\n",
            "epoch11 190.0000 train acc: 0.5179,train loss: 0.6923, dev acc: 0.4844, dev loss: 0.6928\n",
            "epoch11 191.0000 train acc: 0.5179,train loss: 0.6923, dev acc: 0.4844, dev loss: 0.6928\n",
            "epoch11 192.0000 train acc: 0.5201,train loss: 0.6923, dev acc: 0.4844, dev loss: 0.6927\n",
            "epoch11 193.0000 train acc: 0.5201,train loss: 0.6923, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 194.0000 train acc: 0.5201,train loss: 0.6923, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 195.0000 train acc: 0.5201,train loss: 0.6923, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 196.0000 train acc: 0.5201,train loss: 0.6923, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 197.0000 train acc: 0.5246,train loss: 0.6923, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 198.0000 train acc: 0.5246,train loss: 0.6923, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 199.0000 train acc: 0.5246,train loss: 0.6923, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 200.0000 train acc: 0.5246,train loss: 0.6923, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 201.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 202.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 203.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 204.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 205.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 206.0000 train acc: 0.5223,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 207.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 208.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 209.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 210.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 211.0000 train acc: 0.5246,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 212.0000 train acc: 0.5268,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6927\n",
            "epoch11 213.0000 train acc: 0.5268,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 214.0000 train acc: 0.5268,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 215.0000 train acc: 0.5268,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 216.0000 train acc: 0.5290,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 217.0000 train acc: 0.5290,train loss: 0.6922, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 218.0000 train acc: 0.5290,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 219.0000 train acc: 0.5290,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 220.0000 train acc: 0.5290,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 221.0000 train acc: 0.5290,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 222.0000 train acc: 0.5290,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 223.0000 train acc: 0.5290,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 224.0000 train acc: 0.5290,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 225.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 226.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 227.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 228.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 229.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 230.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 231.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 232.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 233.0000 train acc: 0.5312,train loss: 0.6921, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 234.0000 train acc: 0.5312,train loss: 0.6920, dev acc: 0.5000, dev loss: 0.6926\n",
            "epoch11 235.0000 train acc: 0.5312,train loss: 0.6920, dev acc: 0.5000, dev loss: 0.6925\n",
            "epoch11 236.0000 train acc: 0.5312,train loss: 0.6920, dev acc: 0.5000, dev loss: 0.6925\n",
            "epoch11 237.0000 train acc: 0.5312,train loss: 0.6920, dev acc: 0.5000, dev loss: 0.6925\n",
            "epoch11 238.0000 train acc: 0.5312,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 239.0000 train acc: 0.5312,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 240.0000 train acc: 0.5312,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 241.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 242.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 243.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 244.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 245.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 246.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 247.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 248.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 249.0000 train acc: 0.5290,train loss: 0.6920, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 250.0000 train acc: 0.5312,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 251.0000 train acc: 0.5312,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 252.0000 train acc: 0.5312,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 253.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 254.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6925\n",
            "epoch11 255.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 256.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 257.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 258.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 259.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 260.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 261.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 262.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 263.0000 train acc: 0.5335,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 264.0000 train acc: 0.5379,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 265.0000 train acc: 0.5379,train loss: 0.6919, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 266.0000 train acc: 0.5379,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 267.0000 train acc: 0.5402,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 268.0000 train acc: 0.5402,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 269.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 270.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 271.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 272.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 273.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 274.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 275.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6924\n",
            "epoch11 276.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 277.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 278.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 279.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 280.0000 train acc: 0.5424,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 281.0000 train acc: 0.5446,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 282.0000 train acc: 0.5446,train loss: 0.6918, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 283.0000 train acc: 0.5446,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 284.0000 train acc: 0.5446,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 285.0000 train acc: 0.5446,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 286.0000 train acc: 0.5446,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 287.0000 train acc: 0.5424,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 288.0000 train acc: 0.5424,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 289.0000 train acc: 0.5424,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 290.0000 train acc: 0.5424,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 291.0000 train acc: 0.5424,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 292.0000 train acc: 0.5424,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 293.0000 train acc: 0.5424,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 294.0000 train acc: 0.5424,train loss: 0.6917, dev acc: 0.4844, dev loss: 0.6923\n",
            "epoch11 295.0000 train acc: 0.5446,train loss: 0.6917, dev acc: 0.5000, dev loss: 0.6923\n",
            "epoch11 296.0000 train acc: 0.5446,train loss: 0.6917, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 297.0000 train acc: 0.5446,train loss: 0.6917, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 298.0000 train acc: 0.5446,train loss: 0.6917, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 299.0000 train acc: 0.5446,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 300.0000 train acc: 0.5469,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 301.0000 train acc: 0.5469,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 302.0000 train acc: 0.5469,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 303.0000 train acc: 0.5491,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 304.0000 train acc: 0.5491,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 305.0000 train acc: 0.5513,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 306.0000 train acc: 0.5513,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 307.0000 train acc: 0.5513,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 308.0000 train acc: 0.5513,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 309.0000 train acc: 0.5513,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 310.0000 train acc: 0.5513,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 311.0000 train acc: 0.5491,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 312.0000 train acc: 0.5491,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 313.0000 train acc: 0.5491,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 314.0000 train acc: 0.5469,train loss: 0.6916, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 315.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 316.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6922\n",
            "epoch11 317.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 318.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 319.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 320.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 321.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 322.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 323.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 324.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 325.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 326.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 327.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 328.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 329.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 330.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 331.0000 train acc: 0.5469,train loss: 0.6915, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 332.0000 train acc: 0.5446,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 333.0000 train acc: 0.5446,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 334.0000 train acc: 0.5469,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 335.0000 train acc: 0.5469,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 336.0000 train acc: 0.5491,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6921\n",
            "epoch11 337.0000 train acc: 0.5491,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 338.0000 train acc: 0.5491,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 339.0000 train acc: 0.5491,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 340.0000 train acc: 0.5469,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 341.0000 train acc: 0.5469,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 342.0000 train acc: 0.5469,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 343.0000 train acc: 0.5469,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 344.0000 train acc: 0.5469,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 345.0000 train acc: 0.5491,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 346.0000 train acc: 0.5491,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 347.0000 train acc: 0.5491,train loss: 0.6914, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 348.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 349.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 350.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 351.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 352.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 353.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 354.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 355.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 356.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6920\n",
            "epoch11 357.0000 train acc: 0.5491,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 358.0000 train acc: 0.5469,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 359.0000 train acc: 0.5469,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 360.0000 train acc: 0.5469,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 361.0000 train acc: 0.5469,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 362.0000 train acc: 0.5469,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 363.0000 train acc: 0.5469,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 364.0000 train acc: 0.5469,train loss: 0.6913, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 365.0000 train acc: 0.5469,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 366.0000 train acc: 0.5469,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 367.0000 train acc: 0.5469,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 368.0000 train acc: 0.5469,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 369.0000 train acc: 0.5469,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 370.0000 train acc: 0.5469,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 371.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 372.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 373.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 374.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 375.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 376.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 377.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6919\n",
            "epoch11 378.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6918\n",
            "epoch11 379.0000 train acc: 0.5446,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6918\n",
            "epoch11 380.0000 train acc: 0.5469,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6918\n",
            "epoch11 381.0000 train acc: 0.5469,train loss: 0.6912, dev acc: 0.5000, dev loss: 0.6918\n",
            "epoch11 382.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 383.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 384.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 385.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 386.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 387.0000 train acc: 0.5469,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 388.0000 train acc: 0.5469,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 389.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 390.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 391.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 392.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 393.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 394.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 395.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 396.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 397.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 398.0000 train acc: 0.5446,train loss: 0.6911, dev acc: 0.5156, dev loss: 0.6918\n",
            "epoch11 399.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5156, dev loss: 0.6917\n",
            "epoch11 400.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 401.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 402.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 403.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 404.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 405.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 406.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 407.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 408.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 409.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 410.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 411.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 412.0000 train acc: 0.5424,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 413.0000 train acc: 0.5446,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 414.0000 train acc: 0.5446,train loss: 0.6910, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 415.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 416.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 417.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 418.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 419.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6917\n",
            "epoch11 420.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 421.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 422.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 423.0000 train acc: 0.5446,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 424.0000 train acc: 0.5469,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 425.0000 train acc: 0.5469,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 426.0000 train acc: 0.5469,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 427.0000 train acc: 0.5469,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 428.0000 train acc: 0.5469,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 429.0000 train acc: 0.5469,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 430.0000 train acc: 0.5469,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 431.0000 train acc: 0.5469,train loss: 0.6909, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 432.0000 train acc: 0.5469,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 433.0000 train acc: 0.5469,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 434.0000 train acc: 0.5469,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 435.0000 train acc: 0.5491,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 436.0000 train acc: 0.5491,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 437.0000 train acc: 0.5491,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6916\n",
            "epoch11 438.0000 train acc: 0.5491,train loss: 0.6908, dev acc: 0.5469, dev loss: 0.6916\n",
            "epoch11 439.0000 train acc: 0.5491,train loss: 0.6908, dev acc: 0.5469, dev loss: 0.6916\n",
            "epoch11 440.0000 train acc: 0.5513,train loss: 0.6908, dev acc: 0.5469, dev loss: 0.6915\n",
            "epoch11 441.0000 train acc: 0.5513,train loss: 0.6908, dev acc: 0.5469, dev loss: 0.6915\n",
            "epoch11 442.0000 train acc: 0.5513,train loss: 0.6908, dev acc: 0.5469, dev loss: 0.6915\n",
            "epoch11 443.0000 train acc: 0.5513,train loss: 0.6908, dev acc: 0.5469, dev loss: 0.6915\n",
            "epoch11 444.0000 train acc: 0.5513,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 445.0000 train acc: 0.5513,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 446.0000 train acc: 0.5536,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 447.0000 train acc: 0.5536,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 448.0000 train acc: 0.5536,train loss: 0.6908, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 449.0000 train acc: 0.5536,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 450.0000 train acc: 0.5536,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 451.0000 train acc: 0.5536,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 452.0000 train acc: 0.5536,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 453.0000 train acc: 0.5536,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 454.0000 train acc: 0.5558,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 455.0000 train acc: 0.5558,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 456.0000 train acc: 0.5558,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 457.0000 train acc: 0.5580,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 458.0000 train acc: 0.5580,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 459.0000 train acc: 0.5580,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 460.0000 train acc: 0.5580,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6915\n",
            "epoch11 461.0000 train acc: 0.5580,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6914\n",
            "epoch11 462.0000 train acc: 0.5580,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6914\n",
            "epoch11 463.0000 train acc: 0.5580,train loss: 0.6907, dev acc: 0.5312, dev loss: 0.6914\n",
            "epoch11 464.0000 train acc: 0.5580,train loss: 0.6907, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 465.0000 train acc: 0.5580,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 466.0000 train acc: 0.5603,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 467.0000 train acc: 0.5603,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 468.0000 train acc: 0.5603,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 469.0000 train acc: 0.5603,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 470.0000 train acc: 0.5603,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 471.0000 train acc: 0.5625,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 472.0000 train acc: 0.5625,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 473.0000 train acc: 0.5647,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 474.0000 train acc: 0.5647,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 475.0000 train acc: 0.5647,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 476.0000 train acc: 0.5647,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 477.0000 train acc: 0.5647,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 478.0000 train acc: 0.5647,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 479.0000 train acc: 0.5670,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 480.0000 train acc: 0.5670,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 481.0000 train acc: 0.5692,train loss: 0.6906, dev acc: 0.5156, dev loss: 0.6914\n",
            "epoch11 482.0000 train acc: 0.5692,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 483.0000 train acc: 0.5692,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 484.0000 train acc: 0.5692,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 485.0000 train acc: 0.5714,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 486.0000 train acc: 0.5714,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 487.0000 train acc: 0.5714,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 488.0000 train acc: 0.5714,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 489.0000 train acc: 0.5714,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 490.0000 train acc: 0.5714,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 491.0000 train acc: 0.5737,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 492.0000 train acc: 0.5737,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 493.0000 train acc: 0.5737,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 494.0000 train acc: 0.5737,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 495.0000 train acc: 0.5737,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 496.0000 train acc: 0.5737,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 497.0000 train acc: 0.5737,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 498.0000 train acc: 0.5804,train loss: 0.6905, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 499.0000 train acc: 0.5804,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 500.0000 train acc: 0.5804,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 501.0000 train acc: 0.5804,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 502.0000 train acc: 0.5781,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6913\n",
            "epoch11 503.0000 train acc: 0.5804,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 504.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 505.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 506.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 507.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 508.0000 train acc: 0.5804,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 509.0000 train acc: 0.5804,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 510.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 511.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 512.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 513.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 514.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 515.0000 train acc: 0.5826,train loss: 0.6904, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 516.0000 train acc: 0.5848,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 517.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 518.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 519.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 520.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 521.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 522.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 523.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6912\n",
            "epoch11 524.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 525.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 526.0000 train acc: 0.5826,train loss: 0.6903, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 527.0000 train acc: 0.5848,train loss: 0.6903, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 528.0000 train acc: 0.5848,train loss: 0.6903, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 529.0000 train acc: 0.5848,train loss: 0.6903, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 530.0000 train acc: 0.5848,train loss: 0.6903, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 531.0000 train acc: 0.5848,train loss: 0.6903, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 532.0000 train acc: 0.5848,train loss: 0.6903, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 533.0000 train acc: 0.5848,train loss: 0.6902, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 534.0000 train acc: 0.5848,train loss: 0.6902, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 535.0000 train acc: 0.5848,train loss: 0.6902, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 536.0000 train acc: 0.5848,train loss: 0.6902, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 537.0000 train acc: 0.5826,train loss: 0.6902, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 538.0000 train acc: 0.5826,train loss: 0.6902, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 539.0000 train acc: 0.5826,train loss: 0.6902, dev acc: 0.5156, dev loss: 0.6911\n",
            "epoch11 540.0000 train acc: 0.5826,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 541.0000 train acc: 0.5826,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 542.0000 train acc: 0.5804,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 543.0000 train acc: 0.5804,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 544.0000 train acc: 0.5804,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6911\n",
            "epoch11 545.0000 train acc: 0.5804,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 546.0000 train acc: 0.5804,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 547.0000 train acc: 0.5804,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 548.0000 train acc: 0.5804,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 549.0000 train acc: 0.5804,train loss: 0.6902, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 550.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 551.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 552.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 553.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 554.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 555.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 556.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 557.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 558.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 559.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 560.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 561.0000 train acc: 0.5804,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 562.0000 train acc: 0.5826,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 563.0000 train acc: 0.5826,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 564.0000 train acc: 0.5848,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6910\n",
            "epoch11 565.0000 train acc: 0.5848,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 566.0000 train acc: 0.5848,train loss: 0.6901, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 567.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 568.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 569.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 570.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 571.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 572.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 573.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 574.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 575.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 576.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 577.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 578.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 579.0000 train acc: 0.5848,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 580.0000 train acc: 0.5871,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 581.0000 train acc: 0.5893,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 582.0000 train acc: 0.5893,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 583.0000 train acc: 0.5893,train loss: 0.6900, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 584.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6909\n",
            "epoch11 585.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 586.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 587.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 588.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 589.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 590.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 591.0000 train acc: 0.5915,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 592.0000 train acc: 0.5915,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 593.0000 train acc: 0.5915,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 594.0000 train acc: 0.5915,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 595.0000 train acc: 0.5915,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 596.0000 train acc: 0.5915,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 597.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 598.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 599.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 600.0000 train acc: 0.5893,train loss: 0.6899, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 601.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 602.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 603.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 604.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 605.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6908\n",
            "epoch11 606.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 607.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 608.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 609.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 610.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 611.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 612.0000 train acc: 0.5893,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 613.0000 train acc: 0.5915,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 614.0000 train acc: 0.5960,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 615.0000 train acc: 0.5960,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 616.0000 train acc: 0.5960,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 617.0000 train acc: 0.5960,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 618.0000 train acc: 0.5960,train loss: 0.6898, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 619.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 620.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 621.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 622.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 623.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 624.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6907\n",
            "epoch11 625.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 626.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 627.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 628.0000 train acc: 0.5982,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 629.0000 train acc: 0.5982,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 630.0000 train acc: 0.5982,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 631.0000 train acc: 0.5982,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 632.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 633.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 634.0000 train acc: 0.5960,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 635.0000 train acc: 0.5982,train loss: 0.6897, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 636.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 637.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 638.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 639.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 640.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 641.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 642.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 643.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 644.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6906\n",
            "epoch11 645.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 646.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 647.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 648.0000 train acc: 0.5982,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 649.0000 train acc: 0.6004,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 650.0000 train acc: 0.6004,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 651.0000 train acc: 0.6004,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 652.0000 train acc: 0.6004,train loss: 0.6896, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 653.0000 train acc: 0.6004,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 654.0000 train acc: 0.6004,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 655.0000 train acc: 0.6004,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 656.0000 train acc: 0.6027,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 657.0000 train acc: 0.6049,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 658.0000 train acc: 0.6071,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 659.0000 train acc: 0.6071,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 660.0000 train acc: 0.6094,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 661.0000 train acc: 0.6094,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 662.0000 train acc: 0.6094,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 663.0000 train acc: 0.6094,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 664.0000 train acc: 0.6116,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6905\n",
            "epoch11 665.0000 train acc: 0.6116,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 666.0000 train acc: 0.6116,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 667.0000 train acc: 0.6116,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 668.0000 train acc: 0.6138,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 669.0000 train acc: 0.6138,train loss: 0.6895, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 670.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 671.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 672.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 673.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 674.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 675.0000 train acc: 0.6161,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 676.0000 train acc: 0.6161,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 677.0000 train acc: 0.6161,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 678.0000 train acc: 0.6161,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 679.0000 train acc: 0.6161,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 680.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 681.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 682.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 683.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 684.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6904\n",
            "epoch11 685.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 686.0000 train acc: 0.6138,train loss: 0.6894, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 687.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 688.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 689.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 690.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 691.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 692.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 693.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 694.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 695.0000 train acc: 0.6138,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 696.0000 train acc: 0.6161,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 697.0000 train acc: 0.6161,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 698.0000 train acc: 0.6161,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 699.0000 train acc: 0.6161,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 700.0000 train acc: 0.6161,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 701.0000 train acc: 0.6161,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 702.0000 train acc: 0.6161,train loss: 0.6893, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 703.0000 train acc: 0.6161,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 704.0000 train acc: 0.6161,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6903\n",
            "epoch11 705.0000 train acc: 0.6183,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 706.0000 train acc: 0.6183,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 707.0000 train acc: 0.6183,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 708.0000 train acc: 0.6183,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 709.0000 train acc: 0.6183,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 710.0000 train acc: 0.6183,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 711.0000 train acc: 0.6183,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 712.0000 train acc: 0.6205,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 713.0000 train acc: 0.6205,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 714.0000 train acc: 0.6205,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 715.0000 train acc: 0.6205,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 716.0000 train acc: 0.6205,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 717.0000 train acc: 0.6205,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 718.0000 train acc: 0.6205,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 719.0000 train acc: 0.6205,train loss: 0.6892, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 720.0000 train acc: 0.6205,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 721.0000 train acc: 0.6205,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 722.0000 train acc: 0.6205,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 723.0000 train acc: 0.6205,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6902\n",
            "epoch11 724.0000 train acc: 0.6205,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 725.0000 train acc: 0.6205,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 726.0000 train acc: 0.6205,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 727.0000 train acc: 0.6228,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 728.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 729.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 730.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 731.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 732.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 733.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 734.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 735.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 736.0000 train acc: 0.6250,train loss: 0.6891, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 737.0000 train acc: 0.6272,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 738.0000 train acc: 0.6272,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 739.0000 train acc: 0.6295,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 740.0000 train acc: 0.6295,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 741.0000 train acc: 0.6295,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 742.0000 train acc: 0.6295,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 743.0000 train acc: 0.6295,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6901\n",
            "epoch11 744.0000 train acc: 0.6295,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 745.0000 train acc: 0.6317,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 746.0000 train acc: 0.6339,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 747.0000 train acc: 0.6339,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 748.0000 train acc: 0.6339,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 749.0000 train acc: 0.6339,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 750.0000 train acc: 0.6362,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 751.0000 train acc: 0.6362,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 752.0000 train acc: 0.6384,train loss: 0.6890, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 753.0000 train acc: 0.6384,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 754.0000 train acc: 0.6384,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 755.0000 train acc: 0.6384,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 756.0000 train acc: 0.6362,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 757.0000 train acc: 0.6384,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 758.0000 train acc: 0.6384,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 759.0000 train acc: 0.6406,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 760.0000 train acc: 0.6406,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 761.0000 train acc: 0.6406,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6900\n",
            "epoch11 762.0000 train acc: 0.6406,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 763.0000 train acc: 0.6406,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 764.0000 train acc: 0.6406,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 765.0000 train acc: 0.6406,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 766.0000 train acc: 0.6429,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 767.0000 train acc: 0.6429,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 768.0000 train acc: 0.6429,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 769.0000 train acc: 0.6429,train loss: 0.6889, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 770.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 771.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 772.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 773.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 774.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 775.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 776.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 777.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 778.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 779.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 780.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6899\n",
            "epoch11 781.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6898\n",
            "epoch11 782.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6898\n",
            "epoch11 783.0000 train acc: 0.6451,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6898\n",
            "epoch11 784.0000 train acc: 0.6473,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6898\n",
            "epoch11 785.0000 train acc: 0.6473,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6898\n",
            "epoch11 786.0000 train acc: 0.6473,train loss: 0.6888, dev acc: 0.5312, dev loss: 0.6898\n",
            "epoch11 787.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 788.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 789.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 790.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 791.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 792.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 793.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 794.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 795.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5469, dev loss: 0.6898\n",
            "epoch11 796.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5625, dev loss: 0.6898\n",
            "epoch11 797.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5625, dev loss: 0.6898\n",
            "epoch11 798.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5625, dev loss: 0.6898\n",
            "epoch11 799.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 800.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 801.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 802.0000 train acc: 0.6473,train loss: 0.6887, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 803.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 804.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 805.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 806.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 807.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 808.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 809.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 810.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 811.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 812.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 813.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 814.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 815.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 816.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6897\n",
            "epoch11 817.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5625, dev loss: 0.6896\n",
            "epoch11 818.0000 train acc: 0.6473,train loss: 0.6886, dev acc: 0.5781, dev loss: 0.6896\n",
            "epoch11 819.0000 train acc: 0.6451,train loss: 0.6886, dev acc: 0.5781, dev loss: 0.6896\n",
            "epoch11 820.0000 train acc: 0.6451,train loss: 0.6885, dev acc: 0.5938, dev loss: 0.6896\n",
            "epoch11 821.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.5938, dev loss: 0.6896\n",
            "epoch11 822.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.5938, dev loss: 0.6896\n",
            "epoch11 823.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 824.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 825.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 826.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 827.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 828.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 829.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 830.0000 train acc: 0.6473,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 831.0000 train acc: 0.6496,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 832.0000 train acc: 0.6518,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 833.0000 train acc: 0.6518,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 834.0000 train acc: 0.6518,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6896\n",
            "epoch11 835.0000 train acc: 0.6518,train loss: 0.6885, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 836.0000 train acc: 0.6518,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 837.0000 train acc: 0.6518,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 838.0000 train acc: 0.6518,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 839.0000 train acc: 0.6518,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 840.0000 train acc: 0.6518,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 841.0000 train acc: 0.6518,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 842.0000 train acc: 0.6518,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 843.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 844.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 845.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 846.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 847.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 848.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 849.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 850.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 851.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 852.0000 train acc: 0.6496,train loss: 0.6884, dev acc: 0.6094, dev loss: 0.6895\n",
            "epoch11 853.0000 train acc: 0.6496,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 854.0000 train acc: 0.6496,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 855.0000 train acc: 0.6496,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 856.0000 train acc: 0.6473,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 857.0000 train acc: 0.6473,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 858.0000 train acc: 0.6473,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 859.0000 train acc: 0.6473,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 860.0000 train acc: 0.6451,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 861.0000 train acc: 0.6451,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 862.0000 train acc: 0.6451,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 863.0000 train acc: 0.6451,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 864.0000 train acc: 0.6451,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 865.0000 train acc: 0.6451,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 866.0000 train acc: 0.6451,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 867.0000 train acc: 0.6496,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 868.0000 train acc: 0.6496,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 869.0000 train acc: 0.6496,train loss: 0.6883, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 870.0000 train acc: 0.6496,train loss: 0.6882, dev acc: 0.6094, dev loss: 0.6894\n",
            "epoch11 871.0000 train acc: 0.6496,train loss: 0.6882, dev acc: 0.6094, dev loss: 0.6893\n",
            "epoch11 872.0000 train acc: 0.6518,train loss: 0.6882, dev acc: 0.6094, dev loss: 0.6893\n",
            "epoch11 873.0000 train acc: 0.6518,train loss: 0.6882, dev acc: 0.6094, dev loss: 0.6893\n",
            "epoch11 874.0000 train acc: 0.6540,train loss: 0.6882, dev acc: 0.6094, dev loss: 0.6893\n",
            "epoch11 875.0000 train acc: 0.6540,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 876.0000 train acc: 0.6540,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 877.0000 train acc: 0.6540,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 878.0000 train acc: 0.6540,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 879.0000 train acc: 0.6540,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 880.0000 train acc: 0.6540,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 881.0000 train acc: 0.6540,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 882.0000 train acc: 0.6562,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 883.0000 train acc: 0.6562,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 884.0000 train acc: 0.6562,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 885.0000 train acc: 0.6562,train loss: 0.6882, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 886.0000 train acc: 0.6562,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 887.0000 train acc: 0.6562,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 888.0000 train acc: 0.6562,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6893\n",
            "epoch11 889.0000 train acc: 0.6562,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 890.0000 train acc: 0.6562,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 891.0000 train acc: 0.6562,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 892.0000 train acc: 0.6585,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 893.0000 train acc: 0.6585,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 894.0000 train acc: 0.6585,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 895.0000 train acc: 0.6585,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 896.0000 train acc: 0.6585,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 897.0000 train acc: 0.6585,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 898.0000 train acc: 0.6607,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 899.0000 train acc: 0.6629,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 900.0000 train acc: 0.6629,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 901.0000 train acc: 0.6652,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 902.0000 train acc: 0.6652,train loss: 0.6881, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 903.0000 train acc: 0.6652,train loss: 0.6880, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 904.0000 train acc: 0.6652,train loss: 0.6880, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 905.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 906.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.5938, dev loss: 0.6892\n",
            "epoch11 907.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.5938, dev loss: 0.6891\n",
            "epoch11 908.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.5938, dev loss: 0.6891\n",
            "epoch11 909.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.5938, dev loss: 0.6891\n",
            "epoch11 910.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 911.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 912.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 913.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 914.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 915.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 916.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 917.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 918.0000 train acc: 0.6629,train loss: 0.6880, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 919.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 920.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 921.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 922.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 923.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6891\n",
            "epoch11 924.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 925.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 926.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 927.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 928.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 929.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 930.0000 train acc: 0.6629,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 931.0000 train acc: 0.6652,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 932.0000 train acc: 0.6652,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 933.0000 train acc: 0.6652,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 934.0000 train acc: 0.6652,train loss: 0.6879, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 935.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 936.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 937.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 938.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 939.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 940.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6890\n",
            "epoch11 941.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 942.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 943.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 944.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 945.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 946.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 947.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 948.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 949.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 950.0000 train acc: 0.6652,train loss: 0.6878, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 951.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 952.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 953.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 954.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 955.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 956.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 957.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 958.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6889\n",
            "epoch11 959.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 960.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 961.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 962.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 963.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 964.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 965.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 966.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 967.0000 train acc: 0.6652,train loss: 0.6877, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 968.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 969.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 970.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 971.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 972.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 973.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 974.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 975.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6888\n",
            "epoch11 976.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 977.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 978.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 979.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 980.0000 train acc: 0.6652,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 981.0000 train acc: 0.6674,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 982.0000 train acc: 0.6674,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 983.0000 train acc: 0.6696,train loss: 0.6876, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 984.0000 train acc: 0.6696,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 985.0000 train acc: 0.6696,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 986.0000 train acc: 0.6696,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 987.0000 train acc: 0.6696,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 988.0000 train acc: 0.6696,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 989.0000 train acc: 0.6696,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 990.0000 train acc: 0.6696,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 991.0000 train acc: 0.6719,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 992.0000 train acc: 0.6719,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 993.0000 train acc: 0.6719,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6887\n",
            "epoch11 994.0000 train acc: 0.6719,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6886\n",
            "epoch11 995.0000 train acc: 0.6719,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6886\n",
            "epoch11 996.0000 train acc: 0.6719,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6886\n",
            "epoch11 997.0000 train acc: 0.6719,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6886\n",
            "epoch11 998.0000 train acc: 0.6741,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6886\n",
            "epoch11 999.0000 train acc: 0.6741,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6886\n",
            "epoch11 1000.0000 train acc: 0.6763,train loss: 0.6875, dev acc: 0.6094, dev loss: 0.6886\n",
            "epoch11 1001.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6094, dev loss: 0.6886\n",
            "epoch11 1002.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1003.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1004.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1005.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1006.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1007.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1008.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1009.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1010.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6886\n",
            "epoch11 1011.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1012.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1013.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1014.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1015.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1016.0000 train acc: 0.6763,train loss: 0.6874, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1017.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1018.0000 train acc: 0.6786,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1019.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1020.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1021.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1022.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1023.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1024.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1025.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1026.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1027.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6885\n",
            "epoch11 1028.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1029.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1030.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1031.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1032.0000 train acc: 0.6763,train loss: 0.6873, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1033.0000 train acc: 0.6763,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1034.0000 train acc: 0.6741,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1035.0000 train acc: 0.6741,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1036.0000 train acc: 0.6741,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1037.0000 train acc: 0.6741,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1038.0000 train acc: 0.6741,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1039.0000 train acc: 0.6741,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1040.0000 train acc: 0.6763,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1041.0000 train acc: 0.6763,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1042.0000 train acc: 0.6763,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1043.0000 train acc: 0.6763,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1044.0000 train acc: 0.6763,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6884\n",
            "epoch11 1045.0000 train acc: 0.6763,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1046.0000 train acc: 0.6763,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1047.0000 train acc: 0.6786,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1048.0000 train acc: 0.6786,train loss: 0.6872, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1049.0000 train acc: 0.6786,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1050.0000 train acc: 0.6808,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1051.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1052.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1053.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1054.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1055.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1056.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1057.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1058.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1059.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1060.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6883\n",
            "epoch11 1061.0000 train acc: 0.6830,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1062.0000 train acc: 0.6808,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1063.0000 train acc: 0.6808,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1064.0000 train acc: 0.6808,train loss: 0.6871, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1065.0000 train acc: 0.6808,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1066.0000 train acc: 0.6808,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1067.0000 train acc: 0.6808,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1068.0000 train acc: 0.6808,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1069.0000 train acc: 0.6808,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1070.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1071.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1072.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1073.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1074.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1075.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1076.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1077.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6882\n",
            "epoch11 1078.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1079.0000 train acc: 0.6830,train loss: 0.6870, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1080.0000 train acc: 0.6853,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1081.0000 train acc: 0.6853,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1082.0000 train acc: 0.6853,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1083.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1084.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1085.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1086.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1087.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1088.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1089.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1090.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1091.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1092.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1093.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1094.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6881\n",
            "epoch11 1095.0000 train acc: 0.6875,train loss: 0.6869, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1096.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1097.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1098.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1099.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1100.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1101.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1102.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1103.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1104.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1105.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1106.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1107.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1108.0000 train acc: 0.6875,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1109.0000 train acc: 0.6875,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1110.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1111.0000 train acc: 0.6853,train loss: 0.6868, dev acc: 0.6250, dev loss: 0.6880\n",
            "epoch11 1112.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1113.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1114.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1115.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1116.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1117.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1118.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1119.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1120.0000 train acc: 0.6853,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1121.0000 train acc: 0.6875,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1122.0000 train acc: 0.6875,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1123.0000 train acc: 0.6875,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1124.0000 train acc: 0.6897,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1125.0000 train acc: 0.6897,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1126.0000 train acc: 0.6897,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1127.0000 train acc: 0.6897,train loss: 0.6867, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1128.0000 train acc: 0.6897,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6879\n",
            "epoch11 1129.0000 train acc: 0.6920,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1130.0000 train acc: 0.6920,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1131.0000 train acc: 0.6920,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1132.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1133.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1134.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1135.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1136.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1137.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1138.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1139.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1140.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1141.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1142.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1143.0000 train acc: 0.6942,train loss: 0.6866, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1144.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1145.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1146.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6878\n",
            "epoch11 1147.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1148.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1149.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1150.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1151.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1152.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1153.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1154.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1155.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1156.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1157.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1158.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1159.0000 train acc: 0.6942,train loss: 0.6865, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1160.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1161.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1162.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6877\n",
            "epoch11 1163.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1164.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1165.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1166.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1167.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1168.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1169.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1170.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1171.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1172.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6250, dev loss: 0.6876\n",
            "epoch11 1173.0000 train acc: 0.6942,train loss: 0.6864, dev acc: 0.6406, dev loss: 0.6876\n",
            "epoch11 1174.0000 train acc: 0.6964,train loss: 0.6864, dev acc: 0.6406, dev loss: 0.6876\n",
            "epoch11 1175.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6876\n",
            "epoch11 1176.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6876\n",
            "epoch11 1177.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6876\n",
            "epoch11 1178.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6876\n",
            "epoch11 1179.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6876\n",
            "epoch11 1180.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1181.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1182.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1183.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1184.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1185.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1186.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1187.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1188.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1189.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1190.0000 train acc: 0.6964,train loss: 0.6863, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1191.0000 train acc: 0.6964,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1192.0000 train acc: 0.6964,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1193.0000 train acc: 0.6964,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1194.0000 train acc: 0.6964,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1195.0000 train acc: 0.6964,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1196.0000 train acc: 0.6964,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6875\n",
            "epoch11 1197.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1198.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1199.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1200.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1201.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1202.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1203.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1204.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1205.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1206.0000 train acc: 0.6987,train loss: 0.6862, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1207.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1208.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1209.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1210.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1211.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1212.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6874\n",
            "epoch11 1213.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1214.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1215.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1216.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1217.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1218.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1219.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1220.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1221.0000 train acc: 0.6987,train loss: 0.6861, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1222.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1223.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1224.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1225.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1226.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1227.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1228.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1229.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6873\n",
            "epoch11 1230.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1231.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1232.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1233.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1234.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1235.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1236.0000 train acc: 0.6987,train loss: 0.6860, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1237.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1238.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1239.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1240.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1241.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1242.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1243.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1244.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1245.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6872\n",
            "epoch11 1246.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1247.0000 train acc: 0.6987,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1248.0000 train acc: 0.7009,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1249.0000 train acc: 0.7009,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1250.0000 train acc: 0.7009,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1251.0000 train acc: 0.7009,train loss: 0.6859, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1252.0000 train acc: 0.7009,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1253.0000 train acc: 0.7009,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1254.0000 train acc: 0.7009,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1255.0000 train acc: 0.7009,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1256.0000 train acc: 0.7009,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1257.0000 train acc: 0.7009,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1258.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1259.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1260.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1261.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6871\n",
            "epoch11 1262.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1263.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1264.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1265.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1266.0000 train acc: 0.7031,train loss: 0.6858, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1267.0000 train acc: 0.7031,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1268.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1269.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1270.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1271.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1272.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1273.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1274.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1275.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1276.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1277.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1278.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6870\n",
            "epoch11 1279.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1280.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1281.0000 train acc: 0.7009,train loss: 0.6857, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1282.0000 train acc: 0.7009,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1283.0000 train acc: 0.7009,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1284.0000 train acc: 0.7009,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1285.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1286.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1287.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1288.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1289.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1290.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1291.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1292.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1293.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1294.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6869\n",
            "epoch11 1295.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1296.0000 train acc: 0.6987,train loss: 0.6856, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1297.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1298.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1299.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1300.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1301.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1302.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1303.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1304.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1305.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1306.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1307.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1308.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1309.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1310.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6868\n",
            "epoch11 1311.0000 train acc: 0.6987,train loss: 0.6855, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1312.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1313.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1314.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1315.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1316.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1317.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1318.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1319.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1320.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1321.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1322.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1323.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1324.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1325.0000 train acc: 0.6987,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1326.0000 train acc: 0.6964,train loss: 0.6854, dev acc: 0.6406, dev loss: 0.6867\n",
            "epoch11 1327.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1328.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1329.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1330.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1331.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1332.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1333.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1334.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1335.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6406, dev loss: 0.6866\n",
            "epoch11 1336.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6250, dev loss: 0.6866\n",
            "epoch11 1337.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6250, dev loss: 0.6866\n",
            "epoch11 1338.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6250, dev loss: 0.6866\n",
            "epoch11 1339.0000 train acc: 0.6964,train loss: 0.6853, dev acc: 0.6250, dev loss: 0.6866\n",
            "epoch11 1340.0000 train acc: 0.6987,train loss: 0.6853, dev acc: 0.6250, dev loss: 0.6866\n",
            "epoch11 1341.0000 train acc: 0.6987,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6866\n",
            "epoch11 1342.0000 train acc: 0.6987,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6866\n",
            "epoch11 1343.0000 train acc: 0.6987,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1344.0000 train acc: 0.6987,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1345.0000 train acc: 0.6987,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1346.0000 train acc: 0.6987,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1347.0000 train acc: 0.6987,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1348.0000 train acc: 0.7009,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1349.0000 train acc: 0.7009,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1350.0000 train acc: 0.7009,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1351.0000 train acc: 0.7009,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1352.0000 train acc: 0.7009,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1353.0000 train acc: 0.7009,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1354.0000 train acc: 0.7009,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1355.0000 train acc: 0.7009,train loss: 0.6852, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1356.0000 train acc: 0.7009,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1357.0000 train acc: 0.7009,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1358.0000 train acc: 0.7009,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6865\n",
            "epoch11 1359.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1360.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1361.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1362.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1363.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1364.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1365.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1366.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1367.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1368.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1369.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1370.0000 train acc: 0.7031,train loss: 0.6851, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1371.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1372.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6250, dev loss: 0.6864\n",
            "epoch11 1373.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6406, dev loss: 0.6864\n",
            "epoch11 1374.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6406, dev loss: 0.6863\n",
            "epoch11 1375.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6406, dev loss: 0.6863\n",
            "epoch11 1376.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6406, dev loss: 0.6863\n",
            "epoch11 1377.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6406, dev loss: 0.6863\n",
            "epoch11 1378.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6406, dev loss: 0.6863\n",
            "epoch11 1379.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6406, dev loss: 0.6863\n",
            "epoch11 1380.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6406, dev loss: 0.6863\n",
            "epoch11 1381.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1382.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1383.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1384.0000 train acc: 0.7031,train loss: 0.6850, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1385.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1386.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1387.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1388.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1389.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6863\n",
            "epoch11 1390.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1391.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1392.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1393.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1394.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1395.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1396.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1397.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1398.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1399.0000 train acc: 0.7031,train loss: 0.6849, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1400.0000 train acc: 0.7031,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1401.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1402.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1403.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1404.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6862\n",
            "epoch11 1405.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1406.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1407.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1408.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1409.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1410.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1411.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1412.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1413.0000 train acc: 0.7009,train loss: 0.6848, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1414.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1415.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1416.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1417.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1418.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1419.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1420.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6861\n",
            "epoch11 1421.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1422.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1423.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1424.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1425.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1426.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1427.0000 train acc: 0.7009,train loss: 0.6847, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1428.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1429.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1430.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1431.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1432.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6562, dev loss: 0.6860\n",
            "epoch11 1433.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6860\n",
            "epoch11 1434.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6860\n",
            "epoch11 1435.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6860\n",
            "epoch11 1436.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1437.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1438.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1439.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1440.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1441.0000 train acc: 0.7009,train loss: 0.6846, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1442.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1443.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1444.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1445.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1446.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1447.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1448.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1449.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1450.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6859\n",
            "epoch11 1451.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1452.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1453.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1454.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1455.0000 train acc: 0.7009,train loss: 0.6845, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1456.0000 train acc: 0.7009,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1457.0000 train acc: 0.7009,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1458.0000 train acc: 0.7009,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1459.0000 train acc: 0.7009,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1460.0000 train acc: 0.7009,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1461.0000 train acc: 0.7009,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1462.0000 train acc: 0.7009,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1463.0000 train acc: 0.7009,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1464.0000 train acc: 0.7031,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1465.0000 train acc: 0.7031,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1466.0000 train acc: 0.7031,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6858\n",
            "epoch11 1467.0000 train acc: 0.7031,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1468.0000 train acc: 0.7031,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1469.0000 train acc: 0.7031,train loss: 0.6844, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1470.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1471.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1472.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1473.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1474.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1475.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1476.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1477.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1478.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1479.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1480.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1481.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6857\n",
            "epoch11 1482.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1483.0000 train acc: 0.7031,train loss: 0.6843, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1484.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1485.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1486.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1487.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1488.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1489.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1490.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1491.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1492.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1493.0000 train acc: 0.7031,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1494.0000 train acc: 0.7054,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1495.0000 train acc: 0.7054,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6856\n",
            "epoch11 1496.0000 train acc: 0.7076,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1497.0000 train acc: 0.7098,train loss: 0.6842, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1498.0000 train acc: 0.7098,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1499.0000 train acc: 0.7098,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1500.0000 train acc: 0.7098,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1501.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1502.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1503.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1504.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1505.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1506.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1507.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1508.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1509.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1510.0000 train acc: 0.7121,train loss: 0.6841, dev acc: 0.6719, dev loss: 0.6855\n",
            "epoch11 1511.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1512.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1513.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1514.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1515.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1516.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1517.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1518.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1519.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6719, dev loss: 0.6854\n",
            "epoch11 1520.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6562, dev loss: 0.6854\n",
            "epoch11 1521.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6562, dev loss: 0.6854\n",
            "epoch11 1522.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6562, dev loss: 0.6854\n",
            "epoch11 1523.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6562, dev loss: 0.6854\n",
            "epoch11 1524.0000 train acc: 0.7121,train loss: 0.6840, dev acc: 0.6562, dev loss: 0.6854\n",
            "epoch11 1525.0000 train acc: 0.7121,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6854\n",
            "epoch11 1526.0000 train acc: 0.7121,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1527.0000 train acc: 0.7121,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1528.0000 train acc: 0.7121,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1529.0000 train acc: 0.7143,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1530.0000 train acc: 0.7143,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1531.0000 train acc: 0.7143,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1532.0000 train acc: 0.7143,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1533.0000 train acc: 0.7143,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1534.0000 train acc: 0.7143,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1535.0000 train acc: 0.7165,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1536.0000 train acc: 0.7143,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1537.0000 train acc: 0.7143,train loss: 0.6839, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1538.0000 train acc: 0.7143,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1539.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6853\n",
            "epoch11 1540.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1541.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1542.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1543.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1544.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1545.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1546.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1547.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1548.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1549.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1550.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1551.0000 train acc: 0.7121,train loss: 0.6838, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1552.0000 train acc: 0.7121,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1553.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1554.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6852\n",
            "epoch11 1555.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1556.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1557.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1558.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1559.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1560.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1561.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1562.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1563.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1564.0000 train acc: 0.7143,train loss: 0.6837, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1565.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1566.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1567.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1568.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1569.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6851\n",
            "epoch11 1570.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1571.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1572.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1573.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1574.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1575.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1576.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1577.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1578.0000 train acc: 0.7143,train loss: 0.6836, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1579.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1580.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1581.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1582.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1583.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6850\n",
            "epoch11 1584.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1585.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1586.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1587.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1588.0000 train acc: 0.7143,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1589.0000 train acc: 0.7165,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1590.0000 train acc: 0.7165,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1591.0000 train acc: 0.7188,train loss: 0.6835, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1592.0000 train acc: 0.7188,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1593.0000 train acc: 0.7188,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1594.0000 train acc: 0.7188,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1595.0000 train acc: 0.7188,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1596.0000 train acc: 0.7188,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1597.0000 train acc: 0.7210,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6849\n",
            "epoch11 1598.0000 train acc: 0.7210,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1599.0000 train acc: 0.7210,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1600.0000 train acc: 0.7210,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1601.0000 train acc: 0.7210,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1602.0000 train acc: 0.7210,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1603.0000 train acc: 0.7210,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1604.0000 train acc: 0.7210,train loss: 0.6834, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1605.0000 train acc: 0.7210,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1606.0000 train acc: 0.7210,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1607.0000 train acc: 0.7210,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1608.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1609.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1610.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1611.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6848\n",
            "epoch11 1612.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1613.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1614.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1615.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1616.0000 train acc: 0.7232,train loss: 0.6833, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1617.0000 train acc: 0.7232,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1618.0000 train acc: 0.7232,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1619.0000 train acc: 0.7232,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1620.0000 train acc: 0.7232,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1621.0000 train acc: 0.7232,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1622.0000 train acc: 0.7232,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1623.0000 train acc: 0.7254,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1624.0000 train acc: 0.7254,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1625.0000 train acc: 0.7254,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1626.0000 train acc: 0.7254,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6847\n",
            "epoch11 1627.0000 train acc: 0.7254,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1628.0000 train acc: 0.7254,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1629.0000 train acc: 0.7254,train loss: 0.6832, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1630.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1631.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1632.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1633.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1634.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1635.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1636.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1637.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1638.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1639.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1640.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6846\n",
            "epoch11 1641.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1642.0000 train acc: 0.7254,train loss: 0.6831, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1643.0000 train acc: 0.7254,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1644.0000 train acc: 0.7254,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1645.0000 train acc: 0.7254,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1646.0000 train acc: 0.7254,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1647.0000 train acc: 0.7254,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1648.0000 train acc: 0.7254,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1649.0000 train acc: 0.7254,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1650.0000 train acc: 0.7254,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1651.0000 train acc: 0.7277,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1652.0000 train acc: 0.7277,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1653.0000 train acc: 0.7277,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1654.0000 train acc: 0.7277,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6845\n",
            "epoch11 1655.0000 train acc: 0.7277,train loss: 0.6830, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1656.0000 train acc: 0.7277,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1657.0000 train acc: 0.7277,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1658.0000 train acc: 0.7277,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1659.0000 train acc: 0.7277,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1660.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1661.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1662.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1663.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1664.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1665.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1666.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1667.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1668.0000 train acc: 0.7254,train loss: 0.6829, dev acc: 0.6562, dev loss: 0.6844\n",
            "epoch11 1669.0000 train acc: 0.7254,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1670.0000 train acc: 0.7254,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1671.0000 train acc: 0.7254,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1672.0000 train acc: 0.7254,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1673.0000 train acc: 0.7254,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1674.0000 train acc: 0.7254,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1675.0000 train acc: 0.7254,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1676.0000 train acc: 0.7254,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1677.0000 train acc: 0.7277,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1678.0000 train acc: 0.7277,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1679.0000 train acc: 0.7277,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1680.0000 train acc: 0.7277,train loss: 0.6828, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1681.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1682.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6843\n",
            "epoch11 1683.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1684.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1685.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1686.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1687.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1688.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1689.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1690.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1691.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1692.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1693.0000 train acc: 0.7277,train loss: 0.6827, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1694.0000 train acc: 0.7277,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1695.0000 train acc: 0.7277,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6842\n",
            "epoch11 1696.0000 train acc: 0.7277,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1697.0000 train acc: 0.7277,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1698.0000 train acc: 0.7277,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1699.0000 train acc: 0.7277,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1700.0000 train acc: 0.7299,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1701.0000 train acc: 0.7299,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1702.0000 train acc: 0.7299,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1703.0000 train acc: 0.7299,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1704.0000 train acc: 0.7299,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1705.0000 train acc: 0.7299,train loss: 0.6826, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1706.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1707.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1708.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1709.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6841\n",
            "epoch11 1710.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1711.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1712.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1713.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1714.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1715.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1716.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1717.0000 train acc: 0.7299,train loss: 0.6825, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1718.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1719.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1720.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1721.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1722.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6840\n",
            "epoch11 1723.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1724.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1725.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1726.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1727.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1728.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1729.0000 train acc: 0.7299,train loss: 0.6824, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1730.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1731.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1732.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1733.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1734.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1735.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6839\n",
            "epoch11 1736.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1737.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1738.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1739.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1740.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1741.0000 train acc: 0.7299,train loss: 0.6823, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1742.0000 train acc: 0.7299,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1743.0000 train acc: 0.7299,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1744.0000 train acc: 0.7299,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1745.0000 train acc: 0.7299,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1746.0000 train acc: 0.7299,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1747.0000 train acc: 0.7277,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1748.0000 train acc: 0.7277,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1749.0000 train acc: 0.7277,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6838\n",
            "epoch11 1750.0000 train acc: 0.7277,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1751.0000 train acc: 0.7277,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1752.0000 train acc: 0.7277,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1753.0000 train acc: 0.7277,train loss: 0.6822, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1754.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1755.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1756.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1757.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1758.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1759.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1760.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1761.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1762.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6837\n",
            "epoch11 1763.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1764.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1765.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1766.0000 train acc: 0.7277,train loss: 0.6821, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1767.0000 train acc: 0.7277,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1768.0000 train acc: 0.7277,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1769.0000 train acc: 0.7277,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1770.0000 train acc: 0.7277,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1771.0000 train acc: 0.7277,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1772.0000 train acc: 0.7299,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1773.0000 train acc: 0.7299,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1774.0000 train acc: 0.7299,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1775.0000 train acc: 0.7299,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6836\n",
            "epoch11 1776.0000 train acc: 0.7299,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1777.0000 train acc: 0.7299,train loss: 0.6820, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1778.0000 train acc: 0.7299,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1779.0000 train acc: 0.7299,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1780.0000 train acc: 0.7299,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1781.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1782.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1783.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1784.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1785.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1786.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1787.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1788.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6835\n",
            "epoch11 1789.0000 train acc: 0.7277,train loss: 0.6819, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1790.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1791.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1792.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1793.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1794.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1795.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1796.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1797.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1798.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1799.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1800.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1801.0000 train acc: 0.7277,train loss: 0.6818, dev acc: 0.6562, dev loss: 0.6834\n",
            "epoch11 1802.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1803.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1804.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1805.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1806.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1807.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1808.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1809.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1810.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1811.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1812.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1813.0000 train acc: 0.7299,train loss: 0.6817, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1814.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6833\n",
            "epoch11 1815.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1816.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1817.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1818.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1819.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1820.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1821.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1822.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1823.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1824.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1825.0000 train acc: 0.7299,train loss: 0.6816, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1826.0000 train acc: 0.7299,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1827.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6832\n",
            "epoch11 1828.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1829.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1830.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1831.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1832.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1833.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1834.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1835.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1836.0000 train acc: 0.7277,train loss: 0.6815, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1837.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1838.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1839.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6831\n",
            "epoch11 1840.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1841.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1842.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1843.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1844.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1845.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1846.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1847.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1848.0000 train acc: 0.7277,train loss: 0.6814, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1849.0000 train acc: 0.7277,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1850.0000 train acc: 0.7299,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1851.0000 train acc: 0.7299,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1852.0000 train acc: 0.7299,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6830\n",
            "epoch11 1853.0000 train acc: 0.7299,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1854.0000 train acc: 0.7299,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1855.0000 train acc: 0.7299,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1856.0000 train acc: 0.7299,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1857.0000 train acc: 0.7299,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1858.0000 train acc: 0.7321,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1859.0000 train acc: 0.7321,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1860.0000 train acc: 0.7321,train loss: 0.6813, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1861.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1862.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1863.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1864.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1865.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6829\n",
            "epoch11 1866.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1867.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1868.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1869.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1870.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1871.0000 train acc: 0.7321,train loss: 0.6812, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1872.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1873.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1874.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1875.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1876.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1877.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1878.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6828\n",
            "epoch11 1879.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1880.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1881.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1882.0000 train acc: 0.7321,train loss: 0.6811, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1883.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1884.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1885.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1886.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1887.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1888.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1889.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1890.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1891.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6827\n",
            "epoch11 1892.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1893.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1894.0000 train acc: 0.7321,train loss: 0.6810, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1895.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1896.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1897.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1898.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1899.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1900.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1901.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1902.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1903.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6826\n",
            "epoch11 1904.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6825\n",
            "epoch11 1905.0000 train acc: 0.7321,train loss: 0.6809, dev acc: 0.6562, dev loss: 0.6825\n",
            "epoch11 1906.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6562, dev loss: 0.6825\n",
            "epoch11 1907.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6562, dev loss: 0.6825\n",
            "epoch11 1908.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6562, dev loss: 0.6825\n",
            "epoch11 1909.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6562, dev loss: 0.6825\n",
            "epoch11 1910.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6719, dev loss: 0.6825\n",
            "epoch11 1911.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6719, dev loss: 0.6825\n",
            "epoch11 1912.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6719, dev loss: 0.6825\n",
            "epoch11 1913.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6719, dev loss: 0.6825\n",
            "epoch11 1914.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6719, dev loss: 0.6825\n",
            "epoch11 1915.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6719, dev loss: 0.6825\n",
            "epoch11 1916.0000 train acc: 0.7321,train loss: 0.6808, dev acc: 0.6719, dev loss: 0.6825\n",
            "epoch11 1917.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1918.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1919.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1920.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1921.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1922.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1923.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1924.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1925.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1926.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1927.0000 train acc: 0.7321,train loss: 0.6807, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1928.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6824\n",
            "epoch11 1929.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1930.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1931.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1932.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1933.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1934.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1935.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1936.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1937.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1938.0000 train acc: 0.7321,train loss: 0.6806, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1939.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1940.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1941.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6823\n",
            "epoch11 1942.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1943.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1944.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1945.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1946.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1947.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1948.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1949.0000 train acc: 0.7321,train loss: 0.6805, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1950.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1951.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1952.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1953.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6822\n",
            "epoch11 1954.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1955.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1956.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1957.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1958.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1959.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1960.0000 train acc: 0.7321,train loss: 0.6804, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1961.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1962.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1963.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1964.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1965.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6821\n",
            "epoch11 1966.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1967.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1968.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1969.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1970.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1971.0000 train acc: 0.7321,train loss: 0.6803, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1972.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1973.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1974.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1975.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1976.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1977.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6820\n",
            "epoch11 1978.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6819\n",
            "epoch11 1979.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6819\n",
            "epoch11 1980.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6819\n",
            "epoch11 1981.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6819\n",
            "epoch11 1982.0000 train acc: 0.7321,train loss: 0.6802, dev acc: 0.6719, dev loss: 0.6819\n",
            "epoch11 1983.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6819\n",
            "epoch11 1984.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6819\n",
            "epoch11 1985.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6819\n",
            "epoch11 1986.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6819\n",
            "epoch11 1987.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6819\n",
            "epoch11 1988.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6819\n",
            "epoch11 1989.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6819\n",
            "epoch11 1990.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1991.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1992.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1993.0000 train acc: 0.7321,train loss: 0.6801, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1994.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1995.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1996.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1997.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1998.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 1999.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 2000.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 2001.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6818\n",
            "epoch11 2002.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2003.0000 train acc: 0.7321,train loss: 0.6800, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2004.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2005.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2006.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2007.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2008.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2009.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2010.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2011.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2012.0000 train acc: 0.7321,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6817\n",
            "epoch11 2013.0000 train acc: 0.7344,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2014.0000 train acc: 0.7344,train loss: 0.6799, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2015.0000 train acc: 0.7344,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2016.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2017.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2018.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2019.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2020.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2021.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2022.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2023.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.6875, dev loss: 0.6816\n",
            "epoch11 2024.0000 train acc: 0.7321,train loss: 0.6798, dev acc: 0.7031, dev loss: 0.6816\n",
            "epoch11 2025.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2026.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2027.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2028.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2029.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2030.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2031.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2032.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2033.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2034.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2035.0000 train acc: 0.7321,train loss: 0.6797, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2036.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6815\n",
            "epoch11 2037.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2038.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2039.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2040.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2041.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2042.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2043.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2044.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2045.0000 train acc: 0.7321,train loss: 0.6796, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2046.0000 train acc: 0.7321,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2047.0000 train acc: 0.7321,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2048.0000 train acc: 0.7321,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6814\n",
            "epoch11 2049.0000 train acc: 0.7321,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2050.0000 train acc: 0.7321,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2051.0000 train acc: 0.7321,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2052.0000 train acc: 0.7321,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2053.0000 train acc: 0.7321,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2054.0000 train acc: 0.7344,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2055.0000 train acc: 0.7344,train loss: 0.6795, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2056.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2057.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2058.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2059.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6813\n",
            "epoch11 2060.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2061.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2062.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2063.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2064.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2065.0000 train acc: 0.7344,train loss: 0.6794, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2066.0000 train acc: 0.7344,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2067.0000 train acc: 0.7321,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2068.0000 train acc: 0.7321,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2069.0000 train acc: 0.7321,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2070.0000 train acc: 0.7321,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2071.0000 train acc: 0.7299,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6812\n",
            "epoch11 2072.0000 train acc: 0.7299,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2073.0000 train acc: 0.7299,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2074.0000 train acc: 0.7299,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2075.0000 train acc: 0.7299,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2076.0000 train acc: 0.7321,train loss: 0.6793, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2077.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2078.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2079.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2080.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2081.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2082.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6811\n",
            "epoch11 2083.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2084.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2085.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2086.0000 train acc: 0.7321,train loss: 0.6792, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2087.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2088.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2089.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2090.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2091.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2092.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2093.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6810\n",
            "epoch11 2094.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2095.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2096.0000 train acc: 0.7321,train loss: 0.6791, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2097.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2098.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2099.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2100.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2101.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2102.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2103.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2104.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6809\n",
            "epoch11 2105.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2106.0000 train acc: 0.7321,train loss: 0.6790, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2107.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2108.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2109.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2110.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2111.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2112.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2113.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2114.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2115.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6808\n",
            "epoch11 2116.0000 train acc: 0.7321,train loss: 0.6789, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2117.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2118.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2119.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2120.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2121.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2122.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2123.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2124.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2125.0000 train acc: 0.7344,train loss: 0.6788, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2126.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6807\n",
            "epoch11 2127.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2128.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2129.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2130.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2131.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2132.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2133.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2134.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2135.0000 train acc: 0.7344,train loss: 0.6787, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2136.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2137.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6806\n",
            "epoch11 2138.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2139.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2140.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2141.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2142.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2143.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2144.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2145.0000 train acc: 0.7344,train loss: 0.6786, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2146.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2147.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2148.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6805\n",
            "epoch11 2149.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2150.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2151.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2152.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2153.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2154.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2155.0000 train acc: 0.7344,train loss: 0.6785, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2156.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2157.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2158.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2159.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6804\n",
            "epoch11 2160.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2161.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2162.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2163.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2164.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2165.0000 train acc: 0.7344,train loss: 0.6784, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2166.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2167.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2168.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2169.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2170.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6803\n",
            "epoch11 2171.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2172.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2173.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2174.0000 train acc: 0.7344,train loss: 0.6783, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2175.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2176.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2177.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2178.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2179.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2180.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2181.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6802\n",
            "epoch11 2182.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2183.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2184.0000 train acc: 0.7344,train loss: 0.6782, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2185.0000 train acc: 0.7344,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2186.0000 train acc: 0.7344,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2187.0000 train acc: 0.7366,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2188.0000 train acc: 0.7366,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2189.0000 train acc: 0.7366,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2190.0000 train acc: 0.7366,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2191.0000 train acc: 0.7366,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2192.0000 train acc: 0.7366,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2193.0000 train acc: 0.7366,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6801\n",
            "epoch11 2194.0000 train acc: 0.7366,train loss: 0.6781, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2195.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2196.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2197.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2198.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2199.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2200.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2201.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2202.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2203.0000 train acc: 0.7366,train loss: 0.6780, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2204.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6800\n",
            "epoch11 2205.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2206.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2207.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2208.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2209.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2210.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2211.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2212.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2213.0000 train acc: 0.7366,train loss: 0.6779, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2214.0000 train acc: 0.7366,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2215.0000 train acc: 0.7366,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6799\n",
            "epoch11 2216.0000 train acc: 0.7366,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2217.0000 train acc: 0.7366,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2218.0000 train acc: 0.7366,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2219.0000 train acc: 0.7388,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2220.0000 train acc: 0.7388,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2221.0000 train acc: 0.7388,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2222.0000 train acc: 0.7388,train loss: 0.6778, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2223.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2224.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2225.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2226.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6798\n",
            "epoch11 2227.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2228.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2229.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2230.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2231.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2232.0000 train acc: 0.7388,train loss: 0.6777, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2233.0000 train acc: 0.7388,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2234.0000 train acc: 0.7411,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2235.0000 train acc: 0.7411,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2236.0000 train acc: 0.7411,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2237.0000 train acc: 0.7433,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6797\n",
            "epoch11 2238.0000 train acc: 0.7433,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2239.0000 train acc: 0.7433,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2240.0000 train acc: 0.7433,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2241.0000 train acc: 0.7433,train loss: 0.6776, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2242.0000 train acc: 0.7433,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2243.0000 train acc: 0.7433,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2244.0000 train acc: 0.7433,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2245.0000 train acc: 0.7455,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2246.0000 train acc: 0.7455,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2247.0000 train acc: 0.7455,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2248.0000 train acc: 0.7455,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6796\n",
            "epoch11 2249.0000 train acc: 0.7455,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2250.0000 train acc: 0.7455,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2251.0000 train acc: 0.7455,train loss: 0.6775, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2252.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2253.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2254.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2255.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2256.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2257.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2258.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2259.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6795\n",
            "epoch11 2260.0000 train acc: 0.7455,train loss: 0.6774, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2261.0000 train acc: 0.7455,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2262.0000 train acc: 0.7455,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2263.0000 train acc: 0.7455,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2264.0000 train acc: 0.7455,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2265.0000 train acc: 0.7455,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2266.0000 train acc: 0.7478,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2267.0000 train acc: 0.7478,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2268.0000 train acc: 0.7478,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2269.0000 train acc: 0.7478,train loss: 0.6773, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2270.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6794\n",
            "epoch11 2271.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2272.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2273.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2274.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2275.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2276.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2277.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2278.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2279.0000 train acc: 0.7478,train loss: 0.6772, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2280.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2281.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6793\n",
            "epoch11 2282.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2283.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2284.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2285.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2286.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2287.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2288.0000 train acc: 0.7478,train loss: 0.6771, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2289.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2290.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2291.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6792\n",
            "epoch11 2292.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2293.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2294.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2295.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2296.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2297.0000 train acc: 0.7478,train loss: 0.6770, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2298.0000 train acc: 0.7478,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2299.0000 train acc: 0.7500,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2300.0000 train acc: 0.7522,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2301.0000 train acc: 0.7522,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2302.0000 train acc: 0.7522,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6791\n",
            "epoch11 2303.0000 train acc: 0.7522,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2304.0000 train acc: 0.7522,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2305.0000 train acc: 0.7522,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2306.0000 train acc: 0.7500,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2307.0000 train acc: 0.7500,train loss: 0.6769, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2308.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2309.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2310.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2311.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2312.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2313.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6790\n",
            "epoch11 2314.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2315.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2316.0000 train acc: 0.7500,train loss: 0.6768, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2317.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2318.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2319.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2320.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2321.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2322.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2323.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6789\n",
            "epoch11 2324.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2325.0000 train acc: 0.7500,train loss: 0.6767, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2326.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2327.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2328.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2329.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2330.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2331.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2332.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2333.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2334.0000 train acc: 0.7500,train loss: 0.6766, dev acc: 0.7031, dev loss: 0.6788\n",
            "epoch11 2335.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2336.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2337.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2338.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2339.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2340.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2341.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2342.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2343.0000 train acc: 0.7500,train loss: 0.6765, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2344.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2345.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6787\n",
            "epoch11 2346.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6786\n",
            "epoch11 2347.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6786\n",
            "epoch11 2348.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6786\n",
            "epoch11 2349.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6786\n",
            "epoch11 2350.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6786\n",
            "epoch11 2351.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6786\n",
            "epoch11 2352.0000 train acc: 0.7500,train loss: 0.6764, dev acc: 0.7031, dev loss: 0.6786\n",
            "epoch11 2353.0000 train acc: 0.7500,train loss: 0.6763, dev acc: 0.7031, dev loss: 0.6786\n",
            "epoch11 2354.0000 train acc: 0.7500,train loss: 0.6763, dev acc: 0.7188, dev loss: 0.6786\n",
            "epoch11 2355.0000 train acc: 0.7500,train loss: 0.6763, dev acc: 0.7188, dev loss: 0.6786\n",
            "epoch11 2356.0000 train acc: 0.7500,train loss: 0.6763, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2357.0000 train acc: 0.7500,train loss: 0.6763, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2358.0000 train acc: 0.7522,train loss: 0.6763, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2359.0000 train acc: 0.7522,train loss: 0.6763, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2360.0000 train acc: 0.7522,train loss: 0.6763, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2361.0000 train acc: 0.7522,train loss: 0.6763, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2362.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2363.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2364.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2365.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6785\n",
            "epoch11 2366.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2367.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2368.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2369.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2370.0000 train acc: 0.7522,train loss: 0.6762, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2371.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2372.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2373.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2374.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2375.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2376.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6784\n",
            "epoch11 2377.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2378.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2379.0000 train acc: 0.7522,train loss: 0.6761, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2380.0000 train acc: 0.7522,train loss: 0.6760, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2381.0000 train acc: 0.7522,train loss: 0.6760, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2382.0000 train acc: 0.7522,train loss: 0.6760, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2383.0000 train acc: 0.7522,train loss: 0.6760, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2384.0000 train acc: 0.7522,train loss: 0.6760, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2385.0000 train acc: 0.7522,train loss: 0.6760, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2386.0000 train acc: 0.7522,train loss: 0.6760, dev acc: 0.7188, dev loss: 0.6783\n",
            "epoch11 2387.0000 train acc: 0.7522,train loss: 0.6760, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2388.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2389.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2390.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2391.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2392.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2393.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2394.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2395.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2396.0000 train acc: 0.7522,train loss: 0.6759, dev acc: 0.7188, dev loss: 0.6782\n",
            "epoch11 2397.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2398.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2399.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2400.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2401.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2402.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2403.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2404.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2405.0000 train acc: 0.7522,train loss: 0.6758, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2406.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6781\n",
            "epoch11 2407.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2408.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2409.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2410.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2411.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2412.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2413.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2414.0000 train acc: 0.7522,train loss: 0.6757, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2415.0000 train acc: 0.7522,train loss: 0.6756, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2416.0000 train acc: 0.7522,train loss: 0.6756, dev acc: 0.7188, dev loss: 0.6780\n",
            "epoch11 2417.0000 train acc: 0.7522,train loss: 0.6756, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2418.0000 train acc: 0.7522,train loss: 0.6756, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2419.0000 train acc: 0.7522,train loss: 0.6756, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2420.0000 train acc: 0.7522,train loss: 0.6756, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2421.0000 train acc: 0.7522,train loss: 0.6756, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2422.0000 train acc: 0.7522,train loss: 0.6756, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2423.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2424.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2425.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6779\n",
            "epoch11 2426.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2427.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2428.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2429.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2430.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2431.0000 train acc: 0.7522,train loss: 0.6755, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2432.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2433.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2434.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2435.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6778\n",
            "epoch11 2436.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2437.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2438.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2439.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2440.0000 train acc: 0.7522,train loss: 0.6754, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2441.0000 train acc: 0.7522,train loss: 0.6753, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2442.0000 train acc: 0.7545,train loss: 0.6753, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2443.0000 train acc: 0.7545,train loss: 0.6753, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2444.0000 train acc: 0.7545,train loss: 0.6753, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2445.0000 train acc: 0.7545,train loss: 0.6753, dev acc: 0.7188, dev loss: 0.6777\n",
            "epoch11 2446.0000 train acc: 0.7545,train loss: 0.6753, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2447.0000 train acc: 0.7545,train loss: 0.6753, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2448.0000 train acc: 0.7545,train loss: 0.6753, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2449.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2450.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2451.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2452.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2453.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2454.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6776\n",
            "epoch11 2455.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2456.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2457.0000 train acc: 0.7545,train loss: 0.6752, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2458.0000 train acc: 0.7545,train loss: 0.6751, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2459.0000 train acc: 0.7545,train loss: 0.6751, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2460.0000 train acc: 0.7545,train loss: 0.6751, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2461.0000 train acc: 0.7545,train loss: 0.6751, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2462.0000 train acc: 0.7545,train loss: 0.6751, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2463.0000 train acc: 0.7545,train loss: 0.6751, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2464.0000 train acc: 0.7545,train loss: 0.6751, dev acc: 0.7188, dev loss: 0.6775\n",
            "epoch11 2465.0000 train acc: 0.7545,train loss: 0.6751, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2466.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2467.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2468.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2469.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2470.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2471.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2472.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2473.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6774\n",
            "epoch11 2474.0000 train acc: 0.7545,train loss: 0.6750, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2475.0000 train acc: 0.7545,train loss: 0.6749, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2476.0000 train acc: 0.7545,train loss: 0.6749, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2477.0000 train acc: 0.7545,train loss: 0.6749, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2478.0000 train acc: 0.7545,train loss: 0.6749, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2479.0000 train acc: 0.7545,train loss: 0.6749, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2480.0000 train acc: 0.7545,train loss: 0.6749, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2481.0000 train acc: 0.7545,train loss: 0.6749, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2482.0000 train acc: 0.7545,train loss: 0.6749, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2483.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6773\n",
            "epoch11 2484.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2485.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2486.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2487.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2488.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2489.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2490.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2491.0000 train acc: 0.7545,train loss: 0.6748, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2492.0000 train acc: 0.7545,train loss: 0.6747, dev acc: 0.7188, dev loss: 0.6772\n",
            "epoch11 2493.0000 train acc: 0.7545,train loss: 0.6747, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2494.0000 train acc: 0.7545,train loss: 0.6747, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2495.0000 train acc: 0.7545,train loss: 0.6747, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2496.0000 train acc: 0.7545,train loss: 0.6747, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2497.0000 train acc: 0.7545,train loss: 0.6747, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2498.0000 train acc: 0.7545,train loss: 0.6747, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2499.0000 train acc: 0.7545,train loss: 0.6747, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2500.0000 train acc: 0.7545,train loss: 0.6746, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2501.0000 train acc: 0.7545,train loss: 0.6746, dev acc: 0.7188, dev loss: 0.6771\n",
            "epoch11 2502.0000 train acc: 0.7545,train loss: 0.6746, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2503.0000 train acc: 0.7545,train loss: 0.6746, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2504.0000 train acc: 0.7522,train loss: 0.6746, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2505.0000 train acc: 0.7522,train loss: 0.6746, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2506.0000 train acc: 0.7522,train loss: 0.6746, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2507.0000 train acc: 0.7522,train loss: 0.6746, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2508.0000 train acc: 0.7522,train loss: 0.6745, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2509.0000 train acc: 0.7522,train loss: 0.6745, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2510.0000 train acc: 0.7522,train loss: 0.6745, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2511.0000 train acc: 0.7522,train loss: 0.6745, dev acc: 0.7188, dev loss: 0.6770\n",
            "epoch11 2512.0000 train acc: 0.7522,train loss: 0.6745, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2513.0000 train acc: 0.7522,train loss: 0.6745, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2514.0000 train acc: 0.7545,train loss: 0.6745, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2515.0000 train acc: 0.7545,train loss: 0.6745, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2516.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2517.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2518.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2519.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2520.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6769\n",
            "epoch11 2521.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2522.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2523.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2524.0000 train acc: 0.7545,train loss: 0.6744, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2525.0000 train acc: 0.7545,train loss: 0.6743, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2526.0000 train acc: 0.7545,train loss: 0.6743, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2527.0000 train acc: 0.7545,train loss: 0.6743, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2528.0000 train acc: 0.7545,train loss: 0.6743, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2529.0000 train acc: 0.7545,train loss: 0.6743, dev acc: 0.7188, dev loss: 0.6768\n",
            "epoch11 2530.0000 train acc: 0.7545,train loss: 0.6743, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2531.0000 train acc: 0.7545,train loss: 0.6743, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2532.0000 train acc: 0.7545,train loss: 0.6743, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2533.0000 train acc: 0.7545,train loss: 0.6742, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2534.0000 train acc: 0.7545,train loss: 0.6742, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2535.0000 train acc: 0.7545,train loss: 0.6742, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2536.0000 train acc: 0.7545,train loss: 0.6742, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2537.0000 train acc: 0.7545,train loss: 0.6742, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2538.0000 train acc: 0.7545,train loss: 0.6742, dev acc: 0.7188, dev loss: 0.6767\n",
            "epoch11 2539.0000 train acc: 0.7545,train loss: 0.6742, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2540.0000 train acc: 0.7545,train loss: 0.6742, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2541.0000 train acc: 0.7545,train loss: 0.6741, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2542.0000 train acc: 0.7545,train loss: 0.6741, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2543.0000 train acc: 0.7545,train loss: 0.6741, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2544.0000 train acc: 0.7545,train loss: 0.6741, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2545.0000 train acc: 0.7545,train loss: 0.6741, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2546.0000 train acc: 0.7545,train loss: 0.6741, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2547.0000 train acc: 0.7545,train loss: 0.6741, dev acc: 0.7188, dev loss: 0.6766\n",
            "epoch11 2548.0000 train acc: 0.7545,train loss: 0.6741, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2549.0000 train acc: 0.7545,train loss: 0.6740, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2550.0000 train acc: 0.7545,train loss: 0.6740, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2551.0000 train acc: 0.7545,train loss: 0.6740, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2552.0000 train acc: 0.7545,train loss: 0.6740, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2553.0000 train acc: 0.7545,train loss: 0.6740, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2554.0000 train acc: 0.7545,train loss: 0.6740, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2555.0000 train acc: 0.7545,train loss: 0.6740, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2556.0000 train acc: 0.7545,train loss: 0.6740, dev acc: 0.7188, dev loss: 0.6765\n",
            "epoch11 2557.0000 train acc: 0.7545,train loss: 0.6739, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2558.0000 train acc: 0.7545,train loss: 0.6739, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2559.0000 train acc: 0.7545,train loss: 0.6739, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2560.0000 train acc: 0.7545,train loss: 0.6739, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2561.0000 train acc: 0.7545,train loss: 0.6739, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2562.0000 train acc: 0.7545,train loss: 0.6739, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2563.0000 train acc: 0.7545,train loss: 0.6739, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2564.0000 train acc: 0.7545,train loss: 0.6739, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2565.0000 train acc: 0.7545,train loss: 0.6738, dev acc: 0.7188, dev loss: 0.6764\n",
            "epoch11 2566.0000 train acc: 0.7545,train loss: 0.6738, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2567.0000 train acc: 0.7545,train loss: 0.6738, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2568.0000 train acc: 0.7545,train loss: 0.6738, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2569.0000 train acc: 0.7545,train loss: 0.6738, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2570.0000 train acc: 0.7545,train loss: 0.6738, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2571.0000 train acc: 0.7545,train loss: 0.6738, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2572.0000 train acc: 0.7545,train loss: 0.6738, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2573.0000 train acc: 0.7545,train loss: 0.6737, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2574.0000 train acc: 0.7545,train loss: 0.6737, dev acc: 0.7188, dev loss: 0.6763\n",
            "epoch11 2575.0000 train acc: 0.7545,train loss: 0.6737, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2576.0000 train acc: 0.7545,train loss: 0.6737, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2577.0000 train acc: 0.7545,train loss: 0.6737, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2578.0000 train acc: 0.7545,train loss: 0.6737, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2579.0000 train acc: 0.7545,train loss: 0.6737, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2580.0000 train acc: 0.7545,train loss: 0.6737, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2581.0000 train acc: 0.7545,train loss: 0.6736, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2582.0000 train acc: 0.7545,train loss: 0.6736, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2583.0000 train acc: 0.7545,train loss: 0.6736, dev acc: 0.7188, dev loss: 0.6762\n",
            "epoch11 2584.0000 train acc: 0.7545,train loss: 0.6736, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2585.0000 train acc: 0.7545,train loss: 0.6736, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2586.0000 train acc: 0.7545,train loss: 0.6736, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2587.0000 train acc: 0.7545,train loss: 0.6736, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2588.0000 train acc: 0.7545,train loss: 0.6736, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2589.0000 train acc: 0.7545,train loss: 0.6735, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2590.0000 train acc: 0.7545,train loss: 0.6735, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2591.0000 train acc: 0.7545,train loss: 0.6735, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2592.0000 train acc: 0.7545,train loss: 0.6735, dev acc: 0.7188, dev loss: 0.6761\n",
            "epoch11 2593.0000 train acc: 0.7545,train loss: 0.6735, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2594.0000 train acc: 0.7545,train loss: 0.6735, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2595.0000 train acc: 0.7545,train loss: 0.6735, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2596.0000 train acc: 0.7545,train loss: 0.6734, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2597.0000 train acc: 0.7545,train loss: 0.6734, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2598.0000 train acc: 0.7545,train loss: 0.6734, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2599.0000 train acc: 0.7545,train loss: 0.6734, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2600.0000 train acc: 0.7545,train loss: 0.6734, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2601.0000 train acc: 0.7545,train loss: 0.6734, dev acc: 0.7188, dev loss: 0.6760\n",
            "epoch11 2602.0000 train acc: 0.7545,train loss: 0.6734, dev acc: 0.7188, dev loss: 0.6759\n",
            "epoch11 2603.0000 train acc: 0.7545,train loss: 0.6734, dev acc: 0.7188, dev loss: 0.6759\n",
            "epoch11 2604.0000 train acc: 0.7545,train loss: 0.6733, dev acc: 0.7188, dev loss: 0.6759\n",
            "epoch11 2605.0000 train acc: 0.7545,train loss: 0.6733, dev acc: 0.7031, dev loss: 0.6759\n",
            "epoch11 2606.0000 train acc: 0.7545,train loss: 0.6733, dev acc: 0.7031, dev loss: 0.6759\n",
            "epoch11 2607.0000 train acc: 0.7545,train loss: 0.6733, dev acc: 0.7031, dev loss: 0.6759\n",
            "epoch11 2608.0000 train acc: 0.7545,train loss: 0.6733, dev acc: 0.7031, dev loss: 0.6759\n",
            "epoch11 2609.0000 train acc: 0.7545,train loss: 0.6733, dev acc: 0.7031, dev loss: 0.6759\n",
            "epoch11 2610.0000 train acc: 0.7545,train loss: 0.6733, dev acc: 0.7031, dev loss: 0.6759\n",
            "epoch11 2611.0000 train acc: 0.7545,train loss: 0.6733, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2612.0000 train acc: 0.7545,train loss: 0.6732, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2613.0000 train acc: 0.7545,train loss: 0.6732, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2614.0000 train acc: 0.7545,train loss: 0.6732, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2615.0000 train acc: 0.7545,train loss: 0.6732, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2616.0000 train acc: 0.7545,train loss: 0.6732, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2617.0000 train acc: 0.7545,train loss: 0.6732, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2618.0000 train acc: 0.7545,train loss: 0.6732, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2619.0000 train acc: 0.7545,train loss: 0.6732, dev acc: 0.7031, dev loss: 0.6758\n",
            "epoch11 2620.0000 train acc: 0.7545,train loss: 0.6731, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2621.0000 train acc: 0.7545,train loss: 0.6731, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2622.0000 train acc: 0.7545,train loss: 0.6731, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2623.0000 train acc: 0.7545,train loss: 0.6731, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2624.0000 train acc: 0.7545,train loss: 0.6731, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2625.0000 train acc: 0.7545,train loss: 0.6731, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2626.0000 train acc: 0.7545,train loss: 0.6731, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2627.0000 train acc: 0.7545,train loss: 0.6730, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2628.0000 train acc: 0.7545,train loss: 0.6730, dev acc: 0.7031, dev loss: 0.6757\n",
            "epoch11 2629.0000 train acc: 0.7545,train loss: 0.6730, dev acc: 0.7031, dev loss: 0.6756\n",
            "epoch11 2630.0000 train acc: 0.7545,train loss: 0.6730, dev acc: 0.7031, dev loss: 0.6756\n",
            "epoch11 2631.0000 train acc: 0.7545,train loss: 0.6730, dev acc: 0.7031, dev loss: 0.6756\n",
            "epoch11 2632.0000 train acc: 0.7545,train loss: 0.6730, dev acc: 0.7188, dev loss: 0.6756\n",
            "epoch11 2633.0000 train acc: 0.7545,train loss: 0.6730, dev acc: 0.7188, dev loss: 0.6756\n",
            "epoch11 2634.0000 train acc: 0.7545,train loss: 0.6730, dev acc: 0.7188, dev loss: 0.6756\n",
            "epoch11 2635.0000 train acc: 0.7545,train loss: 0.6729, dev acc: 0.7188, dev loss: 0.6756\n",
            "epoch11 2636.0000 train acc: 0.7545,train loss: 0.6729, dev acc: 0.7188, dev loss: 0.6756\n",
            "epoch11 2637.0000 train acc: 0.7545,train loss: 0.6729, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2638.0000 train acc: 0.7545,train loss: 0.6729, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2639.0000 train acc: 0.7545,train loss: 0.6729, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2640.0000 train acc: 0.7545,train loss: 0.6729, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2641.0000 train acc: 0.7545,train loss: 0.6729, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2642.0000 train acc: 0.7545,train loss: 0.6729, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2643.0000 train acc: 0.7545,train loss: 0.6728, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2644.0000 train acc: 0.7545,train loss: 0.6728, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2645.0000 train acc: 0.7545,train loss: 0.6728, dev acc: 0.7188, dev loss: 0.6755\n",
            "epoch11 2646.0000 train acc: 0.7545,train loss: 0.6728, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2647.0000 train acc: 0.7545,train loss: 0.6728, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2648.0000 train acc: 0.7545,train loss: 0.6728, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2649.0000 train acc: 0.7545,train loss: 0.6728, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2650.0000 train acc: 0.7545,train loss: 0.6727, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2651.0000 train acc: 0.7545,train loss: 0.6727, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2652.0000 train acc: 0.7545,train loss: 0.6727, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2653.0000 train acc: 0.7545,train loss: 0.6727, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2654.0000 train acc: 0.7545,train loss: 0.6727, dev acc: 0.7188, dev loss: 0.6754\n",
            "epoch11 2655.0000 train acc: 0.7545,train loss: 0.6727, dev acc: 0.7188, dev loss: 0.6753\n",
            "epoch11 2656.0000 train acc: 0.7545,train loss: 0.6727, dev acc: 0.7188, dev loss: 0.6753\n",
            "epoch11 2657.0000 train acc: 0.7545,train loss: 0.6727, dev acc: 0.7188, dev loss: 0.6753\n",
            "epoch11 2658.0000 train acc: 0.7545,train loss: 0.6726, dev acc: 0.7188, dev loss: 0.6753\n",
            "epoch11 2659.0000 train acc: 0.7545,train loss: 0.6726, dev acc: 0.7188, dev loss: 0.6753\n",
            "epoch11 2660.0000 train acc: 0.7545,train loss: 0.6726, dev acc: 0.7188, dev loss: 0.6753\n",
            "epoch11 2661.0000 train acc: 0.7545,train loss: 0.6726, dev acc: 0.7188, dev loss: 0.6753\n",
            "epoch11 2662.0000 train acc: 0.7545,train loss: 0.6726, dev acc: 0.7188, dev loss: 0.6753\n",
            "epoch11 2663.0000 train acc: 0.7545,train loss: 0.6726, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2664.0000 train acc: 0.7545,train loss: 0.6726, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2665.0000 train acc: 0.7567,train loss: 0.6725, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2666.0000 train acc: 0.7567,train loss: 0.6725, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2667.0000 train acc: 0.7567,train loss: 0.6725, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2668.0000 train acc: 0.7567,train loss: 0.6725, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2669.0000 train acc: 0.7567,train loss: 0.6725, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2670.0000 train acc: 0.7567,train loss: 0.6725, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2671.0000 train acc: 0.7567,train loss: 0.6725, dev acc: 0.7188, dev loss: 0.6752\n",
            "epoch11 2672.0000 train acc: 0.7567,train loss: 0.6725, dev acc: 0.7188, dev loss: 0.6751\n",
            "epoch11 2673.0000 train acc: 0.7567,train loss: 0.6724, dev acc: 0.7188, dev loss: 0.6751\n",
            "epoch11 2674.0000 train acc: 0.7567,train loss: 0.6724, dev acc: 0.7188, dev loss: 0.6751\n",
            "epoch11 2675.0000 train acc: 0.7589,train loss: 0.6724, dev acc: 0.7188, dev loss: 0.6751\n",
            "epoch11 2676.0000 train acc: 0.7589,train loss: 0.6724, dev acc: 0.7188, dev loss: 0.6751\n",
            "epoch11 2677.0000 train acc: 0.7589,train loss: 0.6724, dev acc: 0.7188, dev loss: 0.6751\n",
            "epoch11 2678.0000 train acc: 0.7589,train loss: 0.6724, dev acc: 0.7344, dev loss: 0.6751\n",
            "epoch11 2679.0000 train acc: 0.7589,train loss: 0.6724, dev acc: 0.7344, dev loss: 0.6751\n",
            "epoch11 2680.0000 train acc: 0.7589,train loss: 0.6724, dev acc: 0.7344, dev loss: 0.6751\n",
            "epoch11 2681.0000 train acc: 0.7589,train loss: 0.6723, dev acc: 0.7344, dev loss: 0.6750\n",
            "epoch11 2682.0000 train acc: 0.7589,train loss: 0.6723, dev acc: 0.7344, dev loss: 0.6750\n",
            "epoch11 2683.0000 train acc: 0.7589,train loss: 0.6723, dev acc: 0.7344, dev loss: 0.6750\n",
            "epoch11 2684.0000 train acc: 0.7589,train loss: 0.6723, dev acc: 0.7344, dev loss: 0.6750\n",
            "epoch11 2685.0000 train acc: 0.7589,train loss: 0.6723, dev acc: 0.7344, dev loss: 0.6750\n",
            "epoch11 2686.0000 train acc: 0.7589,train loss: 0.6723, dev acc: 0.7344, dev loss: 0.6750\n",
            "epoch11 2687.0000 train acc: 0.7589,train loss: 0.6723, dev acc: 0.7344, dev loss: 0.6750\n",
            "epoch11 2688.0000 train acc: 0.7589,train loss: 0.6722, dev acc: 0.7344, dev loss: 0.6750\n",
            "epoch11 2689.0000 train acc: 0.7589,train loss: 0.6722, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2690.0000 train acc: 0.7589,train loss: 0.6722, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2691.0000 train acc: 0.7589,train loss: 0.6722, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2692.0000 train acc: 0.7589,train loss: 0.6722, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2693.0000 train acc: 0.7589,train loss: 0.6722, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2694.0000 train acc: 0.7589,train loss: 0.6722, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2695.0000 train acc: 0.7589,train loss: 0.6722, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2696.0000 train acc: 0.7589,train loss: 0.6721, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2697.0000 train acc: 0.7589,train loss: 0.6721, dev acc: 0.7344, dev loss: 0.6749\n",
            "epoch11 2698.0000 train acc: 0.7589,train loss: 0.6721, dev acc: 0.7344, dev loss: 0.6748\n",
            "epoch11 2699.0000 train acc: 0.7589,train loss: 0.6721, dev acc: 0.7344, dev loss: 0.6748\n",
            "epoch11 2700.0000 train acc: 0.7589,train loss: 0.6721, dev acc: 0.7344, dev loss: 0.6748\n",
            "epoch11 2701.0000 train acc: 0.7589,train loss: 0.6721, dev acc: 0.7344, dev loss: 0.6748\n",
            "epoch11 2702.0000 train acc: 0.7589,train loss: 0.6721, dev acc: 0.7344, dev loss: 0.6748\n",
            "epoch11 2703.0000 train acc: 0.7612,train loss: 0.6720, dev acc: 0.7344, dev loss: 0.6748\n",
            "epoch11 2704.0000 train acc: 0.7612,train loss: 0.6720, dev acc: 0.7344, dev loss: 0.6748\n",
            "epoch11 2705.0000 train acc: 0.7612,train loss: 0.6720, dev acc: 0.7344, dev loss: 0.6748\n",
            "epoch11 2706.0000 train acc: 0.7612,train loss: 0.6720, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2707.0000 train acc: 0.7612,train loss: 0.6720, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2708.0000 train acc: 0.7612,train loss: 0.6720, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2709.0000 train acc: 0.7612,train loss: 0.6720, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2710.0000 train acc: 0.7612,train loss: 0.6720, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2711.0000 train acc: 0.7612,train loss: 0.6719, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2712.0000 train acc: 0.7612,train loss: 0.6719, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2713.0000 train acc: 0.7612,train loss: 0.6719, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2714.0000 train acc: 0.7612,train loss: 0.6719, dev acc: 0.7344, dev loss: 0.6747\n",
            "epoch11 2715.0000 train acc: 0.7612,train loss: 0.6719, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2716.0000 train acc: 0.7612,train loss: 0.6719, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2717.0000 train acc: 0.7612,train loss: 0.6719, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2718.0000 train acc: 0.7612,train loss: 0.6718, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2719.0000 train acc: 0.7612,train loss: 0.6718, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2720.0000 train acc: 0.7612,train loss: 0.6718, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2721.0000 train acc: 0.7612,train loss: 0.6718, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2722.0000 train acc: 0.7612,train loss: 0.6718, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2723.0000 train acc: 0.7612,train loss: 0.6718, dev acc: 0.7344, dev loss: 0.6746\n",
            "epoch11 2724.0000 train acc: 0.7612,train loss: 0.6718, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2725.0000 train acc: 0.7612,train loss: 0.6717, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2726.0000 train acc: 0.7612,train loss: 0.6717, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2727.0000 train acc: 0.7612,train loss: 0.6717, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2728.0000 train acc: 0.7612,train loss: 0.6717, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2729.0000 train acc: 0.7612,train loss: 0.6717, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2730.0000 train acc: 0.7612,train loss: 0.6717, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2731.0000 train acc: 0.7612,train loss: 0.6717, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2732.0000 train acc: 0.7612,train loss: 0.6717, dev acc: 0.7344, dev loss: 0.6745\n",
            "epoch11 2733.0000 train acc: 0.7612,train loss: 0.6716, dev acc: 0.7344, dev loss: 0.6744\n",
            "epoch11 2734.0000 train acc: 0.7612,train loss: 0.6716, dev acc: 0.7344, dev loss: 0.6744\n",
            "epoch11 2735.0000 train acc: 0.7634,train loss: 0.6716, dev acc: 0.7344, dev loss: 0.6744\n",
            "epoch11 2736.0000 train acc: 0.7634,train loss: 0.6716, dev acc: 0.7344, dev loss: 0.6744\n",
            "epoch11 2737.0000 train acc: 0.7634,train loss: 0.6716, dev acc: 0.7344, dev loss: 0.6744\n",
            "epoch11 2738.0000 train acc: 0.7634,train loss: 0.6716, dev acc: 0.7344, dev loss: 0.6744\n",
            "epoch11 2739.0000 train acc: 0.7634,train loss: 0.6716, dev acc: 0.7344, dev loss: 0.6744\n",
            "epoch11 2740.0000 train acc: 0.7634,train loss: 0.6715, dev acc: 0.7344, dev loss: 0.6744\n",
            "epoch11 2741.0000 train acc: 0.7634,train loss: 0.6715, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2742.0000 train acc: 0.7634,train loss: 0.6715, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2743.0000 train acc: 0.7634,train loss: 0.6715, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2744.0000 train acc: 0.7634,train loss: 0.6715, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2745.0000 train acc: 0.7634,train loss: 0.6715, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2746.0000 train acc: 0.7634,train loss: 0.6715, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2747.0000 train acc: 0.7634,train loss: 0.6714, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2748.0000 train acc: 0.7634,train loss: 0.6714, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2749.0000 train acc: 0.7656,train loss: 0.6714, dev acc: 0.7344, dev loss: 0.6743\n",
            "epoch11 2750.0000 train acc: 0.7656,train loss: 0.6714, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2751.0000 train acc: 0.7656,train loss: 0.6714, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2752.0000 train acc: 0.7656,train loss: 0.6714, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2753.0000 train acc: 0.7656,train loss: 0.6714, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2754.0000 train acc: 0.7679,train loss: 0.6714, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2755.0000 train acc: 0.7679,train loss: 0.6713, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2756.0000 train acc: 0.7679,train loss: 0.6713, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2757.0000 train acc: 0.7679,train loss: 0.6713, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2758.0000 train acc: 0.7679,train loss: 0.6713, dev acc: 0.7344, dev loss: 0.6742\n",
            "epoch11 2759.0000 train acc: 0.7679,train loss: 0.6713, dev acc: 0.7344, dev loss: 0.6741\n",
            "epoch11 2760.0000 train acc: 0.7679,train loss: 0.6713, dev acc: 0.7344, dev loss: 0.6741\n",
            "epoch11 2761.0000 train acc: 0.7679,train loss: 0.6713, dev acc: 0.7344, dev loss: 0.6741\n",
            "epoch11 2762.0000 train acc: 0.7679,train loss: 0.6712, dev acc: 0.7344, dev loss: 0.6741\n",
            "epoch11 2763.0000 train acc: 0.7679,train loss: 0.6712, dev acc: 0.7344, dev loss: 0.6741\n",
            "epoch11 2764.0000 train acc: 0.7679,train loss: 0.6712, dev acc: 0.7344, dev loss: 0.6741\n",
            "epoch11 2765.0000 train acc: 0.7679,train loss: 0.6712, dev acc: 0.7344, dev loss: 0.6741\n",
            "epoch11 2766.0000 train acc: 0.7679,train loss: 0.6712, dev acc: 0.7344, dev loss: 0.6741\n",
            "epoch11 2767.0000 train acc: 0.7679,train loss: 0.6712, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2768.0000 train acc: 0.7679,train loss: 0.6712, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2769.0000 train acc: 0.7679,train loss: 0.6711, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2770.0000 train acc: 0.7679,train loss: 0.6711, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2771.0000 train acc: 0.7679,train loss: 0.6711, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2772.0000 train acc: 0.7679,train loss: 0.6711, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2773.0000 train acc: 0.7679,train loss: 0.6711, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2774.0000 train acc: 0.7679,train loss: 0.6711, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2775.0000 train acc: 0.7679,train loss: 0.6711, dev acc: 0.7344, dev loss: 0.6740\n",
            "epoch11 2776.0000 train acc: 0.7679,train loss: 0.6711, dev acc: 0.7344, dev loss: 0.6739\n",
            "epoch11 2777.0000 train acc: 0.7679,train loss: 0.6710, dev acc: 0.7344, dev loss: 0.6739\n",
            "epoch11 2778.0000 train acc: 0.7679,train loss: 0.6710, dev acc: 0.7344, dev loss: 0.6739\n",
            "epoch11 2779.0000 train acc: 0.7679,train loss: 0.6710, dev acc: 0.7344, dev loss: 0.6739\n",
            "epoch11 2780.0000 train acc: 0.7679,train loss: 0.6710, dev acc: 0.7344, dev loss: 0.6739\n",
            "epoch11 2781.0000 train acc: 0.7679,train loss: 0.6710, dev acc: 0.7344, dev loss: 0.6739\n",
            "epoch11 2782.0000 train acc: 0.7679,train loss: 0.6710, dev acc: 0.7344, dev loss: 0.6739\n",
            "epoch11 2783.0000 train acc: 0.7679,train loss: 0.6710, dev acc: 0.7344, dev loss: 0.6739\n",
            "epoch11 2784.0000 train acc: 0.7679,train loss: 0.6709, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2785.0000 train acc: 0.7679,train loss: 0.6709, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2786.0000 train acc: 0.7679,train loss: 0.6709, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2787.0000 train acc: 0.7679,train loss: 0.6709, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2788.0000 train acc: 0.7679,train loss: 0.6709, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2789.0000 train acc: 0.7679,train loss: 0.6709, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2790.0000 train acc: 0.7679,train loss: 0.6709, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2791.0000 train acc: 0.7679,train loss: 0.6708, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2792.0000 train acc: 0.7679,train loss: 0.6708, dev acc: 0.7344, dev loss: 0.6738\n",
            "epoch11 2793.0000 train acc: 0.7679,train loss: 0.6708, dev acc: 0.7344, dev loss: 0.6737\n",
            "epoch11 2794.0000 train acc: 0.7679,train loss: 0.6708, dev acc: 0.7344, dev loss: 0.6737\n",
            "epoch11 2795.0000 train acc: 0.7679,train loss: 0.6708, dev acc: 0.7344, dev loss: 0.6737\n",
            "epoch11 2796.0000 train acc: 0.7679,train loss: 0.6708, dev acc: 0.7344, dev loss: 0.6737\n",
            "epoch11 2797.0000 train acc: 0.7679,train loss: 0.6708, dev acc: 0.7344, dev loss: 0.6737\n",
            "epoch11 2798.0000 train acc: 0.7679,train loss: 0.6707, dev acc: 0.7344, dev loss: 0.6737\n",
            "epoch11 2799.0000 train acc: 0.7679,train loss: 0.6707, dev acc: 0.7344, dev loss: 0.6737\n",
            "epoch11 2800.0000 train acc: 0.7679,train loss: 0.6707, dev acc: 0.7344, dev loss: 0.6737\n",
            "epoch11 2801.0000 train acc: 0.7679,train loss: 0.6707, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2802.0000 train acc: 0.7679,train loss: 0.6707, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2803.0000 train acc: 0.7679,train loss: 0.6707, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2804.0000 train acc: 0.7679,train loss: 0.6707, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2805.0000 train acc: 0.7679,train loss: 0.6706, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2806.0000 train acc: 0.7679,train loss: 0.6706, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2807.0000 train acc: 0.7679,train loss: 0.6706, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2808.0000 train acc: 0.7679,train loss: 0.6706, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2809.0000 train acc: 0.7679,train loss: 0.6706, dev acc: 0.7344, dev loss: 0.6736\n",
            "epoch11 2810.0000 train acc: 0.7679,train loss: 0.6706, dev acc: 0.7344, dev loss: 0.6735\n",
            "epoch11 2811.0000 train acc: 0.7679,train loss: 0.6706, dev acc: 0.7344, dev loss: 0.6735\n",
            "epoch11 2812.0000 train acc: 0.7679,train loss: 0.6705, dev acc: 0.7344, dev loss: 0.6735\n",
            "epoch11 2813.0000 train acc: 0.7679,train loss: 0.6705, dev acc: 0.7344, dev loss: 0.6735\n",
            "epoch11 2814.0000 train acc: 0.7679,train loss: 0.6705, dev acc: 0.7344, dev loss: 0.6735\n",
            "epoch11 2815.0000 train acc: 0.7679,train loss: 0.6705, dev acc: 0.7344, dev loss: 0.6735\n",
            "epoch11 2816.0000 train acc: 0.7679,train loss: 0.6705, dev acc: 0.7344, dev loss: 0.6735\n",
            "epoch11 2817.0000 train acc: 0.7679,train loss: 0.6705, dev acc: 0.7344, dev loss: 0.6735\n",
            "epoch11 2818.0000 train acc: 0.7679,train loss: 0.6705, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2819.0000 train acc: 0.7679,train loss: 0.6705, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2820.0000 train acc: 0.7679,train loss: 0.6704, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2821.0000 train acc: 0.7679,train loss: 0.6704, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2822.0000 train acc: 0.7679,train loss: 0.6704, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2823.0000 train acc: 0.7679,train loss: 0.6704, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2824.0000 train acc: 0.7679,train loss: 0.6704, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2825.0000 train acc: 0.7679,train loss: 0.6704, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2826.0000 train acc: 0.7679,train loss: 0.6704, dev acc: 0.7344, dev loss: 0.6734\n",
            "epoch11 2827.0000 train acc: 0.7679,train loss: 0.6703, dev acc: 0.7344, dev loss: 0.6733\n",
            "epoch11 2828.0000 train acc: 0.7679,train loss: 0.6703, dev acc: 0.7344, dev loss: 0.6733\n",
            "epoch11 2829.0000 train acc: 0.7679,train loss: 0.6703, dev acc: 0.7344, dev loss: 0.6733\n",
            "epoch11 2830.0000 train acc: 0.7679,train loss: 0.6703, dev acc: 0.7344, dev loss: 0.6733\n",
            "epoch11 2831.0000 train acc: 0.7679,train loss: 0.6703, dev acc: 0.7344, dev loss: 0.6733\n",
            "epoch11 2832.0000 train acc: 0.7679,train loss: 0.6703, dev acc: 0.7344, dev loss: 0.6733\n",
            "epoch11 2833.0000 train acc: 0.7679,train loss: 0.6703, dev acc: 0.7344, dev loss: 0.6733\n",
            "epoch11 2834.0000 train acc: 0.7679,train loss: 0.6702, dev acc: 0.7344, dev loss: 0.6733\n",
            "epoch11 2835.0000 train acc: 0.7679,train loss: 0.6702, dev acc: 0.7344, dev loss: 0.6732\n",
            "epoch11 2836.0000 train acc: 0.7679,train loss: 0.6702, dev acc: 0.7344, dev loss: 0.6732\n",
            "epoch11 2837.0000 train acc: 0.7679,train loss: 0.6702, dev acc: 0.7344, dev loss: 0.6732\n",
            "epoch11 2838.0000 train acc: 0.7679,train loss: 0.6702, dev acc: 0.7344, dev loss: 0.6732\n",
            "epoch11 2839.0000 train acc: 0.7679,train loss: 0.6702, dev acc: 0.7344, dev loss: 0.6732\n",
            "epoch11 2840.0000 train acc: 0.7679,train loss: 0.6702, dev acc: 0.7344, dev loss: 0.6732\n",
            "epoch11 2841.0000 train acc: 0.7679,train loss: 0.6701, dev acc: 0.7344, dev loss: 0.6732\n",
            "epoch11 2842.0000 train acc: 0.7679,train loss: 0.6701, dev acc: 0.7344, dev loss: 0.6732\n",
            "epoch11 2843.0000 train acc: 0.7679,train loss: 0.6701, dev acc: 0.7344, dev loss: 0.6731\n",
            "epoch11 2844.0000 train acc: 0.7679,train loss: 0.6701, dev acc: 0.7344, dev loss: 0.6731\n",
            "epoch11 2845.0000 train acc: 0.7679,train loss: 0.6701, dev acc: 0.7344, dev loss: 0.6731\n",
            "epoch11 2846.0000 train acc: 0.7679,train loss: 0.6701, dev acc: 0.7344, dev loss: 0.6731\n",
            "epoch11 2847.0000 train acc: 0.7679,train loss: 0.6700, dev acc: 0.7344, dev loss: 0.6731\n",
            "epoch11 2848.0000 train acc: 0.7679,train loss: 0.6700, dev acc: 0.7344, dev loss: 0.6731\n",
            "epoch11 2849.0000 train acc: 0.7679,train loss: 0.6700, dev acc: 0.7344, dev loss: 0.6731\n",
            "epoch11 2850.0000 train acc: 0.7679,train loss: 0.6700, dev acc: 0.7344, dev loss: 0.6731\n",
            "epoch11 2851.0000 train acc: 0.7679,train loss: 0.6700, dev acc: 0.7344, dev loss: 0.6730\n",
            "epoch11 2852.0000 train acc: 0.7679,train loss: 0.6700, dev acc: 0.7344, dev loss: 0.6730\n",
            "epoch11 2853.0000 train acc: 0.7679,train loss: 0.6700, dev acc: 0.7344, dev loss: 0.6730\n",
            "epoch11 2854.0000 train acc: 0.7679,train loss: 0.6699, dev acc: 0.7344, dev loss: 0.6730\n",
            "epoch11 2855.0000 train acc: 0.7679,train loss: 0.6699, dev acc: 0.7344, dev loss: 0.6730\n",
            "epoch11 2856.0000 train acc: 0.7679,train loss: 0.6699, dev acc: 0.7344, dev loss: 0.6730\n",
            "epoch11 2857.0000 train acc: 0.7701,train loss: 0.6699, dev acc: 0.7344, dev loss: 0.6730\n",
            "epoch11 2858.0000 train acc: 0.7701,train loss: 0.6699, dev acc: 0.7344, dev loss: 0.6730\n",
            "epoch11 2859.0000 train acc: 0.7701,train loss: 0.6699, dev acc: 0.7344, dev loss: 0.6729\n",
            "epoch11 2860.0000 train acc: 0.7701,train loss: 0.6699, dev acc: 0.7344, dev loss: 0.6729\n",
            "epoch11 2861.0000 train acc: 0.7701,train loss: 0.6698, dev acc: 0.7344, dev loss: 0.6729\n",
            "epoch11 2862.0000 train acc: 0.7701,train loss: 0.6698, dev acc: 0.7344, dev loss: 0.6729\n",
            "epoch11 2863.0000 train acc: 0.7701,train loss: 0.6698, dev acc: 0.7344, dev loss: 0.6729\n",
            "epoch11 2864.0000 train acc: 0.7701,train loss: 0.6698, dev acc: 0.7344, dev loss: 0.6729\n",
            "epoch11 2865.0000 train acc: 0.7701,train loss: 0.6698, dev acc: 0.7344, dev loss: 0.6729\n",
            "epoch11 2866.0000 train acc: 0.7701,train loss: 0.6698, dev acc: 0.7344, dev loss: 0.6729\n",
            "epoch11 2867.0000 train acc: 0.7701,train loss: 0.6698, dev acc: 0.7344, dev loss: 0.6728\n",
            "epoch11 2868.0000 train acc: 0.7701,train loss: 0.6697, dev acc: 0.7344, dev loss: 0.6728\n",
            "epoch11 2869.0000 train acc: 0.7701,train loss: 0.6697, dev acc: 0.7344, dev loss: 0.6728\n",
            "epoch11 2870.0000 train acc: 0.7701,train loss: 0.6697, dev acc: 0.7344, dev loss: 0.6728\n",
            "epoch11 2871.0000 train acc: 0.7701,train loss: 0.6697, dev acc: 0.7344, dev loss: 0.6728\n",
            "epoch11 2872.0000 train acc: 0.7701,train loss: 0.6697, dev acc: 0.7344, dev loss: 0.6728\n",
            "epoch11 2873.0000 train acc: 0.7701,train loss: 0.6697, dev acc: 0.7344, dev loss: 0.6728\n",
            "epoch11 2874.0000 train acc: 0.7701,train loss: 0.6697, dev acc: 0.7344, dev loss: 0.6728\n",
            "epoch11 2875.0000 train acc: 0.7701,train loss: 0.6696, dev acc: 0.7344, dev loss: 0.6727\n",
            "epoch11 2876.0000 train acc: 0.7701,train loss: 0.6696, dev acc: 0.7344, dev loss: 0.6727\n",
            "epoch11 2877.0000 train acc: 0.7701,train loss: 0.6696, dev acc: 0.7344, dev loss: 0.6727\n",
            "epoch11 2878.0000 train acc: 0.7701,train loss: 0.6696, dev acc: 0.7344, dev loss: 0.6727\n",
            "epoch11 2879.0000 train acc: 0.7701,train loss: 0.6696, dev acc: 0.7344, dev loss: 0.6727\n",
            "epoch11 2880.0000 train acc: 0.7701,train loss: 0.6696, dev acc: 0.7344, dev loss: 0.6727\n",
            "epoch11 2881.0000 train acc: 0.7701,train loss: 0.6696, dev acc: 0.7344, dev loss: 0.6727\n",
            "epoch11 2882.0000 train acc: 0.7701,train loss: 0.6695, dev acc: 0.7344, dev loss: 0.6727\n",
            "epoch11 2883.0000 train acc: 0.7701,train loss: 0.6695, dev acc: 0.7344, dev loss: 0.6726\n",
            "epoch11 2884.0000 train acc: 0.7701,train loss: 0.6695, dev acc: 0.7344, dev loss: 0.6726\n",
            "epoch11 2885.0000 train acc: 0.7701,train loss: 0.6695, dev acc: 0.7344, dev loss: 0.6726\n",
            "epoch11 2886.0000 train acc: 0.7701,train loss: 0.6695, dev acc: 0.7344, dev loss: 0.6726\n",
            "epoch11 2887.0000 train acc: 0.7701,train loss: 0.6695, dev acc: 0.7344, dev loss: 0.6726\n",
            "epoch11 2888.0000 train acc: 0.7701,train loss: 0.6695, dev acc: 0.7344, dev loss: 0.6726\n",
            "epoch11 2889.0000 train acc: 0.7701,train loss: 0.6694, dev acc: 0.7344, dev loss: 0.6726\n",
            "epoch11 2890.0000 train acc: 0.7701,train loss: 0.6694, dev acc: 0.7344, dev loss: 0.6726\n",
            "epoch11 2891.0000 train acc: 0.7701,train loss: 0.6694, dev acc: 0.7344, dev loss: 0.6725\n",
            "epoch11 2892.0000 train acc: 0.7701,train loss: 0.6694, dev acc: 0.7344, dev loss: 0.6725\n",
            "epoch11 2893.0000 train acc: 0.7701,train loss: 0.6694, dev acc: 0.7344, dev loss: 0.6725\n",
            "epoch11 2894.0000 train acc: 0.7701,train loss: 0.6694, dev acc: 0.7344, dev loss: 0.6725\n",
            "epoch11 2895.0000 train acc: 0.7701,train loss: 0.6693, dev acc: 0.7344, dev loss: 0.6725\n",
            "epoch11 2896.0000 train acc: 0.7701,train loss: 0.6693, dev acc: 0.7344, dev loss: 0.6725\n",
            "epoch11 2897.0000 train acc: 0.7701,train loss: 0.6693, dev acc: 0.7344, dev loss: 0.6725\n",
            "epoch11 2898.0000 train acc: 0.7701,train loss: 0.6693, dev acc: 0.7344, dev loss: 0.6725\n",
            "epoch11 2899.0000 train acc: 0.7701,train loss: 0.6693, dev acc: 0.7344, dev loss: 0.6724\n",
            "epoch11 2900.0000 train acc: 0.7701,train loss: 0.6693, dev acc: 0.7344, dev loss: 0.6724\n",
            "epoch11 2901.0000 train acc: 0.7701,train loss: 0.6693, dev acc: 0.7344, dev loss: 0.6724\n",
            "epoch11 2902.0000 train acc: 0.7701,train loss: 0.6692, dev acc: 0.7344, dev loss: 0.6724\n",
            "epoch11 2903.0000 train acc: 0.7701,train loss: 0.6692, dev acc: 0.7344, dev loss: 0.6724\n",
            "epoch11 2904.0000 train acc: 0.7701,train loss: 0.6692, dev acc: 0.7344, dev loss: 0.6724\n",
            "epoch11 2905.0000 train acc: 0.7701,train loss: 0.6692, dev acc: 0.7344, dev loss: 0.6724\n",
            "epoch11 2906.0000 train acc: 0.7701,train loss: 0.6692, dev acc: 0.7344, dev loss: 0.6723\n",
            "epoch11 2907.0000 train acc: 0.7701,train loss: 0.6692, dev acc: 0.7344, dev loss: 0.6723\n",
            "epoch11 2908.0000 train acc: 0.7701,train loss: 0.6692, dev acc: 0.7344, dev loss: 0.6723\n",
            "epoch11 2909.0000 train acc: 0.7701,train loss: 0.6691, dev acc: 0.7344, dev loss: 0.6723\n",
            "epoch11 2910.0000 train acc: 0.7701,train loss: 0.6691, dev acc: 0.7344, dev loss: 0.6723\n",
            "epoch11 2911.0000 train acc: 0.7701,train loss: 0.6691, dev acc: 0.7344, dev loss: 0.6723\n",
            "epoch11 2912.0000 train acc: 0.7701,train loss: 0.6691, dev acc: 0.7344, dev loss: 0.6723\n",
            "epoch11 2913.0000 train acc: 0.7701,train loss: 0.6691, dev acc: 0.7344, dev loss: 0.6723\n",
            "epoch11 2914.0000 train acc: 0.7701,train loss: 0.6691, dev acc: 0.7344, dev loss: 0.6722\n",
            "epoch11 2915.0000 train acc: 0.7701,train loss: 0.6691, dev acc: 0.7344, dev loss: 0.6722\n",
            "epoch11 2916.0000 train acc: 0.7701,train loss: 0.6690, dev acc: 0.7344, dev loss: 0.6722\n",
            "epoch11 2917.0000 train acc: 0.7701,train loss: 0.6690, dev acc: 0.7344, dev loss: 0.6722\n",
            "epoch11 2918.0000 train acc: 0.7701,train loss: 0.6690, dev acc: 0.7344, dev loss: 0.6722\n",
            "epoch11 2919.0000 train acc: 0.7701,train loss: 0.6690, dev acc: 0.7344, dev loss: 0.6722\n",
            "epoch11 2920.0000 train acc: 0.7701,train loss: 0.6690, dev acc: 0.7344, dev loss: 0.6722\n",
            "epoch11 2921.0000 train acc: 0.7701,train loss: 0.6690, dev acc: 0.7344, dev loss: 0.6722\n",
            "epoch11 2922.0000 train acc: 0.7701,train loss: 0.6689, dev acc: 0.7344, dev loss: 0.6721\n",
            "epoch11 2923.0000 train acc: 0.7701,train loss: 0.6689, dev acc: 0.7344, dev loss: 0.6721\n",
            "epoch11 2924.0000 train acc: 0.7701,train loss: 0.6689, dev acc: 0.7344, dev loss: 0.6721\n",
            "epoch11 2925.0000 train acc: 0.7701,train loss: 0.6689, dev acc: 0.7344, dev loss: 0.6721\n",
            "epoch11 2926.0000 train acc: 0.7701,train loss: 0.6689, dev acc: 0.7344, dev loss: 0.6721\n",
            "epoch11 2927.0000 train acc: 0.7701,train loss: 0.6689, dev acc: 0.7344, dev loss: 0.6721\n",
            "epoch11 2928.0000 train acc: 0.7701,train loss: 0.6689, dev acc: 0.7344, dev loss: 0.6721\n",
            "epoch11 2929.0000 train acc: 0.7701,train loss: 0.6688, dev acc: 0.7344, dev loss: 0.6721\n",
            "epoch11 2930.0000 train acc: 0.7701,train loss: 0.6688, dev acc: 0.7344, dev loss: 0.6720\n",
            "epoch11 2931.0000 train acc: 0.7701,train loss: 0.6688, dev acc: 0.7344, dev loss: 0.6720\n",
            "epoch11 2932.0000 train acc: 0.7701,train loss: 0.6688, dev acc: 0.7344, dev loss: 0.6720\n",
            "epoch11 2933.0000 train acc: 0.7701,train loss: 0.6688, dev acc: 0.7344, dev loss: 0.6720\n",
            "epoch11 2934.0000 train acc: 0.7701,train loss: 0.6688, dev acc: 0.7344, dev loss: 0.6720\n",
            "epoch11 2935.0000 train acc: 0.7723,train loss: 0.6688, dev acc: 0.7344, dev loss: 0.6720\n",
            "epoch11 2936.0000 train acc: 0.7723,train loss: 0.6687, dev acc: 0.7344, dev loss: 0.6720\n",
            "epoch11 2937.0000 train acc: 0.7723,train loss: 0.6687, dev acc: 0.7344, dev loss: 0.6720\n",
            "epoch11 2938.0000 train acc: 0.7723,train loss: 0.6687, dev acc: 0.7344, dev loss: 0.6719\n",
            "epoch11 2939.0000 train acc: 0.7723,train loss: 0.6687, dev acc: 0.7344, dev loss: 0.6719\n",
            "epoch11 2940.0000 train acc: 0.7723,train loss: 0.6687, dev acc: 0.7344, dev loss: 0.6719\n",
            "epoch11 2941.0000 train acc: 0.7723,train loss: 0.6687, dev acc: 0.7344, dev loss: 0.6719\n",
            "epoch11 2942.0000 train acc: 0.7723,train loss: 0.6686, dev acc: 0.7344, dev loss: 0.6719\n",
            "epoch11 2943.0000 train acc: 0.7723,train loss: 0.6686, dev acc: 0.7344, dev loss: 0.6719\n",
            "epoch11 2944.0000 train acc: 0.7723,train loss: 0.6686, dev acc: 0.7344, dev loss: 0.6719\n",
            "epoch11 2945.0000 train acc: 0.7723,train loss: 0.6686, dev acc: 0.7344, dev loss: 0.6719\n",
            "epoch11 2946.0000 train acc: 0.7723,train loss: 0.6686, dev acc: 0.7344, dev loss: 0.6718\n",
            "epoch11 2947.0000 train acc: 0.7723,train loss: 0.6686, dev acc: 0.7344, dev loss: 0.6718\n",
            "epoch11 2948.0000 train acc: 0.7723,train loss: 0.6686, dev acc: 0.7344, dev loss: 0.6718\n",
            "epoch11 2949.0000 train acc: 0.7723,train loss: 0.6685, dev acc: 0.7344, dev loss: 0.6718\n",
            "epoch11 2950.0000 train acc: 0.7723,train loss: 0.6685, dev acc: 0.7344, dev loss: 0.6718\n",
            "epoch11 2951.0000 train acc: 0.7723,train loss: 0.6685, dev acc: 0.7344, dev loss: 0.6718\n",
            "epoch11 2952.0000 train acc: 0.7723,train loss: 0.6685, dev acc: 0.7344, dev loss: 0.6718\n",
            "epoch11 2953.0000 train acc: 0.7723,train loss: 0.6685, dev acc: 0.7344, dev loss: 0.6718\n",
            "epoch11 2954.0000 train acc: 0.7723,train loss: 0.6685, dev acc: 0.7344, dev loss: 0.6717\n",
            "epoch11 2955.0000 train acc: 0.7723,train loss: 0.6685, dev acc: 0.7344, dev loss: 0.6717\n",
            "epoch11 2956.0000 train acc: 0.7723,train loss: 0.6684, dev acc: 0.7344, dev loss: 0.6717\n",
            "epoch11 2957.0000 train acc: 0.7723,train loss: 0.6684, dev acc: 0.7344, dev loss: 0.6717\n",
            "epoch11 2958.0000 train acc: 0.7723,train loss: 0.6684, dev acc: 0.7344, dev loss: 0.6717\n",
            "epoch11 2959.0000 train acc: 0.7723,train loss: 0.6684, dev acc: 0.7344, dev loss: 0.6717\n",
            "epoch11 2960.0000 train acc: 0.7723,train loss: 0.6684, dev acc: 0.7344, dev loss: 0.6717\n",
            "epoch11 2961.0000 train acc: 0.7723,train loss: 0.6684, dev acc: 0.7344, dev loss: 0.6717\n",
            "epoch11 2962.0000 train acc: 0.7723,train loss: 0.6683, dev acc: 0.7344, dev loss: 0.6716\n",
            "epoch11 2963.0000 train acc: 0.7723,train loss: 0.6683, dev acc: 0.7344, dev loss: 0.6716\n",
            "epoch11 2964.0000 train acc: 0.7723,train loss: 0.6683, dev acc: 0.7344, dev loss: 0.6716\n",
            "epoch11 2965.0000 train acc: 0.7723,train loss: 0.6683, dev acc: 0.7344, dev loss: 0.6716\n",
            "epoch11 2966.0000 train acc: 0.7723,train loss: 0.6683, dev acc: 0.7344, dev loss: 0.6716\n",
            "epoch11 2967.0000 train acc: 0.7723,train loss: 0.6683, dev acc: 0.7344, dev loss: 0.6716\n",
            "epoch11 2968.0000 train acc: 0.7723,train loss: 0.6683, dev acc: 0.7344, dev loss: 0.6716\n",
            "epoch11 2969.0000 train acc: 0.7723,train loss: 0.6682, dev acc: 0.7344, dev loss: 0.6716\n",
            "epoch11 2970.0000 train acc: 0.7723,train loss: 0.6682, dev acc: 0.7344, dev loss: 0.6715\n",
            "epoch11 2971.0000 train acc: 0.7723,train loss: 0.6682, dev acc: 0.7344, dev loss: 0.6715\n",
            "epoch11 2972.0000 train acc: 0.7723,train loss: 0.6682, dev acc: 0.7344, dev loss: 0.6715\n",
            "epoch11 2973.0000 train acc: 0.7723,train loss: 0.6682, dev acc: 0.7344, dev loss: 0.6715\n",
            "epoch11 2974.0000 train acc: 0.7723,train loss: 0.6682, dev acc: 0.7344, dev loss: 0.6715\n",
            "epoch11 2975.0000 train acc: 0.7723,train loss: 0.6681, dev acc: 0.7344, dev loss: 0.6715\n",
            "epoch11 2976.0000 train acc: 0.7723,train loss: 0.6681, dev acc: 0.7344, dev loss: 0.6715\n",
            "epoch11 2977.0000 train acc: 0.7723,train loss: 0.6681, dev acc: 0.7344, dev loss: 0.6714\n",
            "epoch11 2978.0000 train acc: 0.7723,train loss: 0.6681, dev acc: 0.7344, dev loss: 0.6714\n",
            "epoch11 2979.0000 train acc: 0.7723,train loss: 0.6681, dev acc: 0.7344, dev loss: 0.6714\n",
            "epoch11 2980.0000 train acc: 0.7723,train loss: 0.6681, dev acc: 0.7344, dev loss: 0.6714\n",
            "epoch11 2981.0000 train acc: 0.7723,train loss: 0.6681, dev acc: 0.7344, dev loss: 0.6714\n",
            "epoch11 2982.0000 train acc: 0.7723,train loss: 0.6680, dev acc: 0.7344, dev loss: 0.6714\n",
            "epoch11 2983.0000 train acc: 0.7723,train loss: 0.6680, dev acc: 0.7344, dev loss: 0.6714\n",
            "epoch11 2984.0000 train acc: 0.7723,train loss: 0.6680, dev acc: 0.7344, dev loss: 0.6714\n",
            "epoch11 2985.0000 train acc: 0.7723,train loss: 0.6680, dev acc: 0.7344, dev loss: 0.6713\n",
            "epoch11 2986.0000 train acc: 0.7723,train loss: 0.6680, dev acc: 0.7344, dev loss: 0.6713\n",
            "epoch11 2987.0000 train acc: 0.7723,train loss: 0.6680, dev acc: 0.7344, dev loss: 0.6713\n",
            "epoch11 2988.0000 train acc: 0.7723,train loss: 0.6679, dev acc: 0.7344, dev loss: 0.6713\n",
            "epoch11 2989.0000 train acc: 0.7723,train loss: 0.6679, dev acc: 0.7344, dev loss: 0.6713\n",
            "epoch11 2990.0000 train acc: 0.7723,train loss: 0.6679, dev acc: 0.7344, dev loss: 0.6713\n",
            "epoch11 2991.0000 train acc: 0.7723,train loss: 0.6679, dev acc: 0.7344, dev loss: 0.6713\n",
            "epoch11 2992.0000 train acc: 0.7723,train loss: 0.6679, dev acc: 0.7344, dev loss: 0.6713\n",
            "epoch11 2993.0000 train acc: 0.7723,train loss: 0.6679, dev acc: 0.7344, dev loss: 0.6712\n",
            "epoch11 2994.0000 train acc: 0.7723,train loss: 0.6679, dev acc: 0.7344, dev loss: 0.6712\n",
            "epoch11 2995.0000 train acc: 0.7723,train loss: 0.6678, dev acc: 0.7344, dev loss: 0.6712\n",
            "epoch11 2996.0000 train acc: 0.7723,train loss: 0.6678, dev acc: 0.7344, dev loss: 0.6712\n",
            "epoch11 2997.0000 train acc: 0.7723,train loss: 0.6678, dev acc: 0.7344, dev loss: 0.6712\n",
            "epoch11 2998.0000 train acc: 0.7723,train loss: 0.6678, dev acc: 0.7344, dev loss: 0.6712\n",
            "epoch11 2999.0000 train acc: 0.7723,train loss: 0.6678, dev acc: 0.7344, dev loss: 0.6712\n",
            "epoch11 3000.0000 train acc: 0.7723,train loss: 0.6678, dev acc: 0.7344, dev loss: 0.6712\n",
            "epoch11 3001.0000 train acc: 0.7723,train loss: 0.6677, dev acc: 0.7344, dev loss: 0.6711\n",
            "epoch11 3002.0000 train acc: 0.7723,train loss: 0.6677, dev acc: 0.7344, dev loss: 0.6711\n",
            "epoch11 3003.0000 train acc: 0.7723,train loss: 0.6677, dev acc: 0.7344, dev loss: 0.6711\n",
            "epoch11 3004.0000 train acc: 0.7723,train loss: 0.6677, dev acc: 0.7344, dev loss: 0.6711\n",
            "epoch11 3005.0000 train acc: 0.7723,train loss: 0.6677, dev acc: 0.7344, dev loss: 0.6711\n",
            "epoch11 3006.0000 train acc: 0.7723,train loss: 0.6677, dev acc: 0.7344, dev loss: 0.6711\n",
            "epoch11 3007.0000 train acc: 0.7723,train loss: 0.6677, dev acc: 0.7344, dev loss: 0.6711\n",
            "epoch11 3008.0000 train acc: 0.7723,train loss: 0.6676, dev acc: 0.7344, dev loss: 0.6710\n",
            "epoch11 3009.0000 train acc: 0.7723,train loss: 0.6676, dev acc: 0.7344, dev loss: 0.6710\n",
            "epoch11 3010.0000 train acc: 0.7723,train loss: 0.6676, dev acc: 0.7344, dev loss: 0.6710\n",
            "epoch11 3011.0000 train acc: 0.7723,train loss: 0.6676, dev acc: 0.7344, dev loss: 0.6710\n",
            "epoch11 3012.0000 train acc: 0.7723,train loss: 0.6676, dev acc: 0.7344, dev loss: 0.6710\n",
            "epoch11 3013.0000 train acc: 0.7723,train loss: 0.6676, dev acc: 0.7344, dev loss: 0.6710\n",
            "epoch11 3014.0000 train acc: 0.7723,train loss: 0.6675, dev acc: 0.7344, dev loss: 0.6710\n",
            "epoch11 3015.0000 train acc: 0.7723,train loss: 0.6675, dev acc: 0.7344, dev loss: 0.6710\n",
            "epoch11 3016.0000 train acc: 0.7723,train loss: 0.6675, dev acc: 0.7344, dev loss: 0.6709\n",
            "epoch11 3017.0000 train acc: 0.7723,train loss: 0.6675, dev acc: 0.7344, dev loss: 0.6709\n",
            "epoch11 3018.0000 train acc: 0.7723,train loss: 0.6675, dev acc: 0.7344, dev loss: 0.6709\n",
            "epoch11 3019.0000 train acc: 0.7723,train loss: 0.6675, dev acc: 0.7344, dev loss: 0.6709\n",
            "epoch11 3020.0000 train acc: 0.7723,train loss: 0.6675, dev acc: 0.7344, dev loss: 0.6709\n",
            "epoch11 3021.0000 train acc: 0.7723,train loss: 0.6674, dev acc: 0.7344, dev loss: 0.6709\n",
            "epoch11 3022.0000 train acc: 0.7723,train loss: 0.6674, dev acc: 0.7344, dev loss: 0.6709\n",
            "epoch11 3023.0000 train acc: 0.7723,train loss: 0.6674, dev acc: 0.7344, dev loss: 0.6708\n",
            "epoch11 3024.0000 train acc: 0.7723,train loss: 0.6674, dev acc: 0.7344, dev loss: 0.6708\n",
            "epoch11 3025.0000 train acc: 0.7723,train loss: 0.6674, dev acc: 0.7344, dev loss: 0.6708\n",
            "epoch11 3026.0000 train acc: 0.7723,train loss: 0.6674, dev acc: 0.7344, dev loss: 0.6708\n",
            "epoch11 3027.0000 train acc: 0.7723,train loss: 0.6673, dev acc: 0.7344, dev loss: 0.6708\n",
            "epoch11 3028.0000 train acc: 0.7723,train loss: 0.6673, dev acc: 0.7344, dev loss: 0.6708\n",
            "epoch11 3029.0000 train acc: 0.7723,train loss: 0.6673, dev acc: 0.7344, dev loss: 0.6708\n",
            "epoch11 3030.0000 train acc: 0.7723,train loss: 0.6673, dev acc: 0.7344, dev loss: 0.6708\n",
            "epoch11 3031.0000 train acc: 0.7723,train loss: 0.6673, dev acc: 0.7344, dev loss: 0.6707\n",
            "epoch11 3032.0000 train acc: 0.7723,train loss: 0.6673, dev acc: 0.7344, dev loss: 0.6707\n",
            "epoch11 3033.0000 train acc: 0.7723,train loss: 0.6672, dev acc: 0.7344, dev loss: 0.6707\n",
            "epoch11 3034.0000 train acc: 0.7723,train loss: 0.6672, dev acc: 0.7344, dev loss: 0.6707\n",
            "epoch11 3035.0000 train acc: 0.7723,train loss: 0.6672, dev acc: 0.7344, dev loss: 0.6707\n",
            "epoch11 3036.0000 train acc: 0.7723,train loss: 0.6672, dev acc: 0.7344, dev loss: 0.6707\n",
            "epoch11 3037.0000 train acc: 0.7723,train loss: 0.6672, dev acc: 0.7344, dev loss: 0.6707\n",
            "epoch11 3038.0000 train acc: 0.7723,train loss: 0.6672, dev acc: 0.7344, dev loss: 0.6706\n",
            "epoch11 3039.0000 train acc: 0.7723,train loss: 0.6672, dev acc: 0.7344, dev loss: 0.6706\n",
            "epoch11 3040.0000 train acc: 0.7723,train loss: 0.6671, dev acc: 0.7344, dev loss: 0.6706\n",
            "epoch11 3041.0000 train acc: 0.7723,train loss: 0.6671, dev acc: 0.7344, dev loss: 0.6706\n",
            "epoch11 3042.0000 train acc: 0.7723,train loss: 0.6671, dev acc: 0.7344, dev loss: 0.6706\n",
            "epoch11 3043.0000 train acc: 0.7723,train loss: 0.6671, dev acc: 0.7344, dev loss: 0.6706\n",
            "epoch11 3044.0000 train acc: 0.7723,train loss: 0.6671, dev acc: 0.7344, dev loss: 0.6706\n",
            "epoch11 3045.0000 train acc: 0.7723,train loss: 0.6671, dev acc: 0.7344, dev loss: 0.6705\n",
            "epoch11 3046.0000 train acc: 0.7723,train loss: 0.6670, dev acc: 0.7344, dev loss: 0.6705\n",
            "epoch11 3047.0000 train acc: 0.7723,train loss: 0.6670, dev acc: 0.7344, dev loss: 0.6705\n",
            "epoch11 3048.0000 train acc: 0.7723,train loss: 0.6670, dev acc: 0.7344, dev loss: 0.6705\n",
            "epoch11 3049.0000 train acc: 0.7723,train loss: 0.6670, dev acc: 0.7344, dev loss: 0.6705\n",
            "epoch11 3050.0000 train acc: 0.7723,train loss: 0.6670, dev acc: 0.7344, dev loss: 0.6705\n",
            "epoch11 3051.0000 train acc: 0.7723,train loss: 0.6670, dev acc: 0.7344, dev loss: 0.6705\n",
            "epoch11 3052.0000 train acc: 0.7723,train loss: 0.6669, dev acc: 0.7344, dev loss: 0.6705\n",
            "epoch11 3053.0000 train acc: 0.7723,train loss: 0.6669, dev acc: 0.7344, dev loss: 0.6704\n",
            "epoch11 3054.0000 train acc: 0.7723,train loss: 0.6669, dev acc: 0.7344, dev loss: 0.6704\n",
            "epoch11 3055.0000 train acc: 0.7723,train loss: 0.6669, dev acc: 0.7344, dev loss: 0.6704\n",
            "epoch11 3056.0000 train acc: 0.7723,train loss: 0.6669, dev acc: 0.7344, dev loss: 0.6704\n",
            "epoch11 3057.0000 train acc: 0.7746,train loss: 0.6669, dev acc: 0.7344, dev loss: 0.6704\n",
            "epoch11 3058.0000 train acc: 0.7746,train loss: 0.6669, dev acc: 0.7344, dev loss: 0.6704\n",
            "epoch11 3059.0000 train acc: 0.7746,train loss: 0.6668, dev acc: 0.7344, dev loss: 0.6704\n",
            "epoch11 3060.0000 train acc: 0.7746,train loss: 0.6668, dev acc: 0.7500, dev loss: 0.6703\n",
            "epoch11 3061.0000 train acc: 0.7746,train loss: 0.6668, dev acc: 0.7500, dev loss: 0.6703\n",
            "epoch11 3062.0000 train acc: 0.7746,train loss: 0.6668, dev acc: 0.7500, dev loss: 0.6703\n",
            "epoch11 3063.0000 train acc: 0.7746,train loss: 0.6668, dev acc: 0.7500, dev loss: 0.6703\n",
            "epoch11 3064.0000 train acc: 0.7746,train loss: 0.6668, dev acc: 0.7500, dev loss: 0.6703\n",
            "epoch11 3065.0000 train acc: 0.7746,train loss: 0.6667, dev acc: 0.7500, dev loss: 0.6703\n",
            "epoch11 3066.0000 train acc: 0.7746,train loss: 0.6667, dev acc: 0.7500, dev loss: 0.6703\n",
            "epoch11 3067.0000 train acc: 0.7746,train loss: 0.6667, dev acc: 0.7500, dev loss: 0.6702\n",
            "epoch11 3068.0000 train acc: 0.7746,train loss: 0.6667, dev acc: 0.7500, dev loss: 0.6702\n",
            "epoch11 3069.0000 train acc: 0.7746,train loss: 0.6667, dev acc: 0.7500, dev loss: 0.6702\n",
            "epoch11 3070.0000 train acc: 0.7746,train loss: 0.6667, dev acc: 0.7500, dev loss: 0.6702\n",
            "epoch11 3071.0000 train acc: 0.7746,train loss: 0.6666, dev acc: 0.7500, dev loss: 0.6702\n",
            "epoch11 3072.0000 train acc: 0.7746,train loss: 0.6666, dev acc: 0.7500, dev loss: 0.6702\n",
            "epoch11 3073.0000 train acc: 0.7746,train loss: 0.6666, dev acc: 0.7500, dev loss: 0.6702\n",
            "epoch11 3074.0000 train acc: 0.7746,train loss: 0.6666, dev acc: 0.7500, dev loss: 0.6701\n",
            "epoch11 3075.0000 train acc: 0.7746,train loss: 0.6666, dev acc: 0.7500, dev loss: 0.6701\n",
            "epoch11 3076.0000 train acc: 0.7746,train loss: 0.6666, dev acc: 0.7500, dev loss: 0.6701\n",
            "epoch11 3077.0000 train acc: 0.7746,train loss: 0.6665, dev acc: 0.7500, dev loss: 0.6701\n",
            "epoch11 3078.0000 train acc: 0.7746,train loss: 0.6665, dev acc: 0.7500, dev loss: 0.6701\n",
            "epoch11 3079.0000 train acc: 0.7746,train loss: 0.6665, dev acc: 0.7500, dev loss: 0.6701\n",
            "epoch11 3080.0000 train acc: 0.7746,train loss: 0.6665, dev acc: 0.7500, dev loss: 0.6701\n",
            "epoch11 3081.0000 train acc: 0.7746,train loss: 0.6665, dev acc: 0.7500, dev loss: 0.6701\n",
            "epoch11 3082.0000 train acc: 0.7746,train loss: 0.6665, dev acc: 0.7500, dev loss: 0.6700\n",
            "epoch11 3083.0000 train acc: 0.7746,train loss: 0.6665, dev acc: 0.7500, dev loss: 0.6700\n",
            "epoch11 3084.0000 train acc: 0.7746,train loss: 0.6664, dev acc: 0.7500, dev loss: 0.6700\n",
            "epoch11 3085.0000 train acc: 0.7746,train loss: 0.6664, dev acc: 0.7500, dev loss: 0.6700\n",
            "epoch11 3086.0000 train acc: 0.7746,train loss: 0.6664, dev acc: 0.7500, dev loss: 0.6700\n",
            "epoch11 3087.0000 train acc: 0.7746,train loss: 0.6664, dev acc: 0.7500, dev loss: 0.6700\n",
            "epoch11 3088.0000 train acc: 0.7746,train loss: 0.6664, dev acc: 0.7500, dev loss: 0.6700\n",
            "epoch11 3089.0000 train acc: 0.7746,train loss: 0.6664, dev acc: 0.7500, dev loss: 0.6699\n",
            "epoch11 3090.0000 train acc: 0.7746,train loss: 0.6663, dev acc: 0.7500, dev loss: 0.6699\n",
            "epoch11 3091.0000 train acc: 0.7746,train loss: 0.6663, dev acc: 0.7500, dev loss: 0.6699\n",
            "epoch11 3092.0000 train acc: 0.7746,train loss: 0.6663, dev acc: 0.7500, dev loss: 0.6699\n",
            "epoch11 3093.0000 train acc: 0.7746,train loss: 0.6663, dev acc: 0.7500, dev loss: 0.6699\n",
            "epoch11 3094.0000 train acc: 0.7746,train loss: 0.6663, dev acc: 0.7500, dev loss: 0.6699\n",
            "epoch11 3095.0000 train acc: 0.7746,train loss: 0.6663, dev acc: 0.7500, dev loss: 0.6699\n",
            "epoch11 3096.0000 train acc: 0.7746,train loss: 0.6662, dev acc: 0.7500, dev loss: 0.6698\n",
            "epoch11 3097.0000 train acc: 0.7746,train loss: 0.6662, dev acc: 0.7500, dev loss: 0.6698\n",
            "epoch11 3098.0000 train acc: 0.7746,train loss: 0.6662, dev acc: 0.7500, dev loss: 0.6698\n",
            "epoch11 3099.0000 train acc: 0.7746,train loss: 0.6662, dev acc: 0.7500, dev loss: 0.6698\n",
            "epoch11 3100.0000 train acc: 0.7723,train loss: 0.6662, dev acc: 0.7500, dev loss: 0.6698\n",
            "epoch11 3101.0000 train acc: 0.7723,train loss: 0.6662, dev acc: 0.7500, dev loss: 0.6698\n",
            "epoch11 3102.0000 train acc: 0.7723,train loss: 0.6661, dev acc: 0.7500, dev loss: 0.6697\n",
            "epoch11 3103.0000 train acc: 0.7723,train loss: 0.6661, dev acc: 0.7500, dev loss: 0.6697\n",
            "epoch11 3104.0000 train acc: 0.7723,train loss: 0.6661, dev acc: 0.7500, dev loss: 0.6697\n",
            "epoch11 3105.0000 train acc: 0.7723,train loss: 0.6661, dev acc: 0.7500, dev loss: 0.6697\n",
            "epoch11 3106.0000 train acc: 0.7723,train loss: 0.6661, dev acc: 0.7500, dev loss: 0.6697\n",
            "epoch11 3107.0000 train acc: 0.7723,train loss: 0.6661, dev acc: 0.7500, dev loss: 0.6697\n",
            "epoch11 3108.0000 train acc: 0.7723,train loss: 0.6660, dev acc: 0.7500, dev loss: 0.6697\n",
            "epoch11 3109.0000 train acc: 0.7723,train loss: 0.6660, dev acc: 0.7500, dev loss: 0.6696\n",
            "epoch11 3110.0000 train acc: 0.7723,train loss: 0.6660, dev acc: 0.7500, dev loss: 0.6696\n",
            "epoch11 3111.0000 train acc: 0.7723,train loss: 0.6660, dev acc: 0.7500, dev loss: 0.6696\n",
            "epoch11 3112.0000 train acc: 0.7723,train loss: 0.6660, dev acc: 0.7500, dev loss: 0.6696\n",
            "epoch11 3113.0000 train acc: 0.7723,train loss: 0.6660, dev acc: 0.7500, dev loss: 0.6696\n",
            "epoch11 3114.0000 train acc: 0.7723,train loss: 0.6659, dev acc: 0.7500, dev loss: 0.6696\n",
            "epoch11 3115.0000 train acc: 0.7723,train loss: 0.6659, dev acc: 0.7500, dev loss: 0.6696\n",
            "epoch11 3116.0000 train acc: 0.7723,train loss: 0.6659, dev acc: 0.7500, dev loss: 0.6695\n",
            "epoch11 3117.0000 train acc: 0.7723,train loss: 0.6659, dev acc: 0.7500, dev loss: 0.6695\n",
            "epoch11 3118.0000 train acc: 0.7723,train loss: 0.6659, dev acc: 0.7500, dev loss: 0.6695\n",
            "epoch11 3119.0000 train acc: 0.7723,train loss: 0.6659, dev acc: 0.7500, dev loss: 0.6695\n",
            "epoch11 3120.0000 train acc: 0.7723,train loss: 0.6658, dev acc: 0.7500, dev loss: 0.6695\n",
            "epoch11 3121.0000 train acc: 0.7723,train loss: 0.6658, dev acc: 0.7500, dev loss: 0.6695\n",
            "epoch11 3122.0000 train acc: 0.7723,train loss: 0.6658, dev acc: 0.7500, dev loss: 0.6695\n",
            "epoch11 3123.0000 train acc: 0.7723,train loss: 0.6658, dev acc: 0.7500, dev loss: 0.6694\n",
            "epoch11 3124.0000 train acc: 0.7723,train loss: 0.6658, dev acc: 0.7500, dev loss: 0.6694\n",
            "epoch11 3125.0000 train acc: 0.7723,train loss: 0.6658, dev acc: 0.7500, dev loss: 0.6694\n",
            "epoch11 3126.0000 train acc: 0.7723,train loss: 0.6657, dev acc: 0.7500, dev loss: 0.6694\n",
            "epoch11 3127.0000 train acc: 0.7723,train loss: 0.6657, dev acc: 0.7500, dev loss: 0.6694\n",
            "epoch11 3128.0000 train acc: 0.7723,train loss: 0.6657, dev acc: 0.7500, dev loss: 0.6694\n",
            "epoch11 3129.0000 train acc: 0.7723,train loss: 0.6657, dev acc: 0.7500, dev loss: 0.6694\n",
            "epoch11 3130.0000 train acc: 0.7723,train loss: 0.6657, dev acc: 0.7500, dev loss: 0.6693\n",
            "epoch11 3131.0000 train acc: 0.7723,train loss: 0.6657, dev acc: 0.7500, dev loss: 0.6693\n",
            "epoch11 3132.0000 train acc: 0.7723,train loss: 0.6656, dev acc: 0.7500, dev loss: 0.6693\n",
            "epoch11 3133.0000 train acc: 0.7723,train loss: 0.6656, dev acc: 0.7500, dev loss: 0.6693\n",
            "epoch11 3134.0000 train acc: 0.7723,train loss: 0.6656, dev acc: 0.7500, dev loss: 0.6693\n",
            "epoch11 3135.0000 train acc: 0.7723,train loss: 0.6656, dev acc: 0.7500, dev loss: 0.6693\n",
            "epoch11 3136.0000 train acc: 0.7723,train loss: 0.6656, dev acc: 0.7500, dev loss: 0.6693\n",
            "epoch11 3137.0000 train acc: 0.7723,train loss: 0.6656, dev acc: 0.7500, dev loss: 0.6692\n",
            "epoch11 3138.0000 train acc: 0.7723,train loss: 0.6655, dev acc: 0.7500, dev loss: 0.6692\n",
            "epoch11 3139.0000 train acc: 0.7723,train loss: 0.6655, dev acc: 0.7500, dev loss: 0.6692\n",
            "epoch11 3140.0000 train acc: 0.7723,train loss: 0.6655, dev acc: 0.7500, dev loss: 0.6692\n",
            "epoch11 3141.0000 train acc: 0.7723,train loss: 0.6655, dev acc: 0.7500, dev loss: 0.6692\n",
            "epoch11 3142.0000 train acc: 0.7723,train loss: 0.6655, dev acc: 0.7500, dev loss: 0.6692\n",
            "epoch11 3143.0000 train acc: 0.7723,train loss: 0.6655, dev acc: 0.7500, dev loss: 0.6691\n",
            "epoch11 3144.0000 train acc: 0.7723,train loss: 0.6654, dev acc: 0.7500, dev loss: 0.6691\n",
            "epoch11 3145.0000 train acc: 0.7723,train loss: 0.6654, dev acc: 0.7500, dev loss: 0.6691\n",
            "epoch11 3146.0000 train acc: 0.7723,train loss: 0.6654, dev acc: 0.7500, dev loss: 0.6691\n",
            "epoch11 3147.0000 train acc: 0.7723,train loss: 0.6654, dev acc: 0.7500, dev loss: 0.6691\n",
            "epoch11 3148.0000 train acc: 0.7723,train loss: 0.6654, dev acc: 0.7500, dev loss: 0.6691\n",
            "epoch11 3149.0000 train acc: 0.7723,train loss: 0.6654, dev acc: 0.7500, dev loss: 0.6691\n",
            "epoch11 3150.0000 train acc: 0.7723,train loss: 0.6653, dev acc: 0.7500, dev loss: 0.6690\n",
            "epoch11 3151.0000 train acc: 0.7723,train loss: 0.6653, dev acc: 0.7500, dev loss: 0.6690\n",
            "epoch11 3152.0000 train acc: 0.7723,train loss: 0.6653, dev acc: 0.7500, dev loss: 0.6690\n",
            "epoch11 3153.0000 train acc: 0.7723,train loss: 0.6653, dev acc: 0.7500, dev loss: 0.6690\n",
            "epoch11 3154.0000 train acc: 0.7723,train loss: 0.6653, dev acc: 0.7500, dev loss: 0.6690\n",
            "epoch11 3155.0000 train acc: 0.7723,train loss: 0.6653, dev acc: 0.7500, dev loss: 0.6690\n",
            "epoch11 3156.0000 train acc: 0.7723,train loss: 0.6652, dev acc: 0.7500, dev loss: 0.6690\n",
            "epoch11 3157.0000 train acc: 0.7723,train loss: 0.6652, dev acc: 0.7500, dev loss: 0.6689\n",
            "epoch11 3158.0000 train acc: 0.7723,train loss: 0.6652, dev acc: 0.7500, dev loss: 0.6689\n",
            "epoch11 3159.0000 train acc: 0.7723,train loss: 0.6652, dev acc: 0.7500, dev loss: 0.6689\n",
            "epoch11 3160.0000 train acc: 0.7723,train loss: 0.6652, dev acc: 0.7500, dev loss: 0.6689\n",
            "epoch11 3161.0000 train acc: 0.7723,train loss: 0.6652, dev acc: 0.7500, dev loss: 0.6689\n",
            "epoch11 3162.0000 train acc: 0.7723,train loss: 0.6651, dev acc: 0.7500, dev loss: 0.6689\n",
            "epoch11 3163.0000 train acc: 0.7723,train loss: 0.6651, dev acc: 0.7500, dev loss: 0.6688\n",
            "epoch11 3164.0000 train acc: 0.7723,train loss: 0.6651, dev acc: 0.7500, dev loss: 0.6688\n",
            "epoch11 3165.0000 train acc: 0.7723,train loss: 0.6651, dev acc: 0.7500, dev loss: 0.6688\n",
            "epoch11 3166.0000 train acc: 0.7723,train loss: 0.6651, dev acc: 0.7500, dev loss: 0.6688\n",
            "epoch11 3167.0000 train acc: 0.7723,train loss: 0.6651, dev acc: 0.7500, dev loss: 0.6688\n",
            "epoch11 3168.0000 train acc: 0.7723,train loss: 0.6650, dev acc: 0.7500, dev loss: 0.6688\n",
            "epoch11 3169.0000 train acc: 0.7723,train loss: 0.6650, dev acc: 0.7500, dev loss: 0.6688\n",
            "epoch11 3170.0000 train acc: 0.7723,train loss: 0.6650, dev acc: 0.7500, dev loss: 0.6687\n",
            "epoch11 3171.0000 train acc: 0.7723,train loss: 0.6650, dev acc: 0.7500, dev loss: 0.6687\n",
            "epoch11 3172.0000 train acc: 0.7723,train loss: 0.6650, dev acc: 0.7500, dev loss: 0.6687\n",
            "epoch11 3173.0000 train acc: 0.7723,train loss: 0.6649, dev acc: 0.7500, dev loss: 0.6687\n",
            "epoch11 3174.0000 train acc: 0.7723,train loss: 0.6649, dev acc: 0.7500, dev loss: 0.6687\n",
            "epoch11 3175.0000 train acc: 0.7723,train loss: 0.6649, dev acc: 0.7500, dev loss: 0.6687\n",
            "epoch11 3176.0000 train acc: 0.7723,train loss: 0.6649, dev acc: 0.7500, dev loss: 0.6687\n",
            "epoch11 3177.0000 train acc: 0.7723,train loss: 0.6649, dev acc: 0.7500, dev loss: 0.6686\n",
            "epoch11 3178.0000 train acc: 0.7746,train loss: 0.6649, dev acc: 0.7500, dev loss: 0.6686\n",
            "epoch11 3179.0000 train acc: 0.7746,train loss: 0.6648, dev acc: 0.7500, dev loss: 0.6686\n",
            "epoch11 3180.0000 train acc: 0.7746,train loss: 0.6648, dev acc: 0.7500, dev loss: 0.6686\n",
            "epoch11 3181.0000 train acc: 0.7746,train loss: 0.6648, dev acc: 0.7500, dev loss: 0.6686\n",
            "epoch11 3182.0000 train acc: 0.7746,train loss: 0.6648, dev acc: 0.7500, dev loss: 0.6686\n",
            "epoch11 3183.0000 train acc: 0.7746,train loss: 0.6648, dev acc: 0.7500, dev loss: 0.6685\n",
            "epoch11 3184.0000 train acc: 0.7746,train loss: 0.6648, dev acc: 0.7500, dev loss: 0.6685\n",
            "epoch11 3185.0000 train acc: 0.7746,train loss: 0.6647, dev acc: 0.7500, dev loss: 0.6685\n",
            "epoch11 3186.0000 train acc: 0.7746,train loss: 0.6647, dev acc: 0.7500, dev loss: 0.6685\n",
            "epoch11 3187.0000 train acc: 0.7746,train loss: 0.6647, dev acc: 0.7500, dev loss: 0.6685\n",
            "epoch11 3188.0000 train acc: 0.7746,train loss: 0.6647, dev acc: 0.7500, dev loss: 0.6685\n",
            "epoch11 3189.0000 train acc: 0.7746,train loss: 0.6647, dev acc: 0.7500, dev loss: 0.6685\n",
            "epoch11 3190.0000 train acc: 0.7746,train loss: 0.6647, dev acc: 0.7500, dev loss: 0.6684\n",
            "epoch11 3191.0000 train acc: 0.7746,train loss: 0.6646, dev acc: 0.7500, dev loss: 0.6684\n",
            "epoch11 3192.0000 train acc: 0.7746,train loss: 0.6646, dev acc: 0.7500, dev loss: 0.6684\n",
            "epoch11 3193.0000 train acc: 0.7746,train loss: 0.6646, dev acc: 0.7500, dev loss: 0.6684\n",
            "epoch11 3194.0000 train acc: 0.7746,train loss: 0.6646, dev acc: 0.7500, dev loss: 0.6684\n",
            "epoch11 3195.0000 train acc: 0.7746,train loss: 0.6646, dev acc: 0.7500, dev loss: 0.6684\n",
            "epoch11 3196.0000 train acc: 0.7746,train loss: 0.6646, dev acc: 0.7500, dev loss: 0.6683\n",
            "epoch11 3197.0000 train acc: 0.7746,train loss: 0.6645, dev acc: 0.7500, dev loss: 0.6683\n",
            "epoch11 3198.0000 train acc: 0.7746,train loss: 0.6645, dev acc: 0.7500, dev loss: 0.6683\n",
            "epoch11 3199.0000 train acc: 0.7746,train loss: 0.6645, dev acc: 0.7500, dev loss: 0.6683\n",
            "epoch11 3200.0000 train acc: 0.7746,train loss: 0.6645, dev acc: 0.7500, dev loss: 0.6683\n",
            "epoch11 3201.0000 train acc: 0.7746,train loss: 0.6645, dev acc: 0.7500, dev loss: 0.6683\n",
            "epoch11 3202.0000 train acc: 0.7746,train loss: 0.6644, dev acc: 0.7500, dev loss: 0.6683\n",
            "epoch11 3203.0000 train acc: 0.7746,train loss: 0.6644, dev acc: 0.7500, dev loss: 0.6682\n",
            "epoch11 3204.0000 train acc: 0.7746,train loss: 0.6644, dev acc: 0.7500, dev loss: 0.6682\n",
            "epoch11 3205.0000 train acc: 0.7746,train loss: 0.6644, dev acc: 0.7500, dev loss: 0.6682\n",
            "epoch11 3206.0000 train acc: 0.7746,train loss: 0.6644, dev acc: 0.7500, dev loss: 0.6682\n",
            "epoch11 3207.0000 train acc: 0.7746,train loss: 0.6644, dev acc: 0.7500, dev loss: 0.6682\n",
            "epoch11 3208.0000 train acc: 0.7746,train loss: 0.6643, dev acc: 0.7500, dev loss: 0.6682\n",
            "epoch11 3209.0000 train acc: 0.7746,train loss: 0.6643, dev acc: 0.7500, dev loss: 0.6681\n",
            "epoch11 3210.0000 train acc: 0.7746,train loss: 0.6643, dev acc: 0.7500, dev loss: 0.6681\n",
            "epoch11 3211.0000 train acc: 0.7746,train loss: 0.6643, dev acc: 0.7500, dev loss: 0.6681\n",
            "epoch11 3212.0000 train acc: 0.7746,train loss: 0.6643, dev acc: 0.7500, dev loss: 0.6681\n",
            "epoch11 3213.0000 train acc: 0.7746,train loss: 0.6643, dev acc: 0.7500, dev loss: 0.6681\n",
            "epoch11 3214.0000 train acc: 0.7746,train loss: 0.6642, dev acc: 0.7500, dev loss: 0.6681\n",
            "epoch11 3215.0000 train acc: 0.7746,train loss: 0.6642, dev acc: 0.7500, dev loss: 0.6681\n",
            "epoch11 3216.0000 train acc: 0.7746,train loss: 0.6642, dev acc: 0.7500, dev loss: 0.6680\n",
            "epoch11 3217.0000 train acc: 0.7746,train loss: 0.6642, dev acc: 0.7500, dev loss: 0.6680\n",
            "epoch11 3218.0000 train acc: 0.7746,train loss: 0.6642, dev acc: 0.7500, dev loss: 0.6680\n",
            "epoch11 3219.0000 train acc: 0.7746,train loss: 0.6641, dev acc: 0.7500, dev loss: 0.6680\n",
            "epoch11 3220.0000 train acc: 0.7746,train loss: 0.6641, dev acc: 0.7500, dev loss: 0.6680\n",
            "epoch11 3221.0000 train acc: 0.7746,train loss: 0.6641, dev acc: 0.7500, dev loss: 0.6680\n",
            "epoch11 3222.0000 train acc: 0.7746,train loss: 0.6641, dev acc: 0.7500, dev loss: 0.6679\n",
            "epoch11 3223.0000 train acc: 0.7746,train loss: 0.6641, dev acc: 0.7500, dev loss: 0.6679\n",
            "epoch11 3224.0000 train acc: 0.7746,train loss: 0.6641, dev acc: 0.7500, dev loss: 0.6679\n",
            "epoch11 3225.0000 train acc: 0.7746,train loss: 0.6640, dev acc: 0.7500, dev loss: 0.6679\n",
            "epoch11 3226.0000 train acc: 0.7746,train loss: 0.6640, dev acc: 0.7500, dev loss: 0.6679\n",
            "epoch11 3227.0000 train acc: 0.7746,train loss: 0.6640, dev acc: 0.7500, dev loss: 0.6679\n",
            "epoch11 3228.0000 train acc: 0.7746,train loss: 0.6640, dev acc: 0.7500, dev loss: 0.6678\n",
            "epoch11 3229.0000 train acc: 0.7746,train loss: 0.6640, dev acc: 0.7500, dev loss: 0.6678\n",
            "epoch11 3230.0000 train acc: 0.7746,train loss: 0.6640, dev acc: 0.7500, dev loss: 0.6678\n",
            "epoch11 3231.0000 train acc: 0.7746,train loss: 0.6639, dev acc: 0.7500, dev loss: 0.6678\n",
            "epoch11 3232.0000 train acc: 0.7746,train loss: 0.6639, dev acc: 0.7500, dev loss: 0.6678\n",
            "epoch11 3233.0000 train acc: 0.7723,train loss: 0.6639, dev acc: 0.7500, dev loss: 0.6678\n",
            "epoch11 3234.0000 train acc: 0.7723,train loss: 0.6639, dev acc: 0.7500, dev loss: 0.6678\n",
            "epoch11 3235.0000 train acc: 0.7723,train loss: 0.6639, dev acc: 0.7500, dev loss: 0.6677\n",
            "epoch11 3236.0000 train acc: 0.7723,train loss: 0.6638, dev acc: 0.7500, dev loss: 0.6677\n",
            "epoch11 3237.0000 train acc: 0.7723,train loss: 0.6638, dev acc: 0.7500, dev loss: 0.6677\n",
            "epoch11 3238.0000 train acc: 0.7723,train loss: 0.6638, dev acc: 0.7500, dev loss: 0.6677\n",
            "epoch11 3239.0000 train acc: 0.7723,train loss: 0.6638, dev acc: 0.7500, dev loss: 0.6677\n",
            "epoch11 3240.0000 train acc: 0.7723,train loss: 0.6638, dev acc: 0.7500, dev loss: 0.6677\n",
            "epoch11 3241.0000 train acc: 0.7723,train loss: 0.6638, dev acc: 0.7500, dev loss: 0.6676\n",
            "epoch11 3242.0000 train acc: 0.7723,train loss: 0.6637, dev acc: 0.7500, dev loss: 0.6676\n",
            "epoch11 3243.0000 train acc: 0.7723,train loss: 0.6637, dev acc: 0.7500, dev loss: 0.6676\n",
            "epoch11 3244.0000 train acc: 0.7723,train loss: 0.6637, dev acc: 0.7500, dev loss: 0.6676\n",
            "epoch11 3245.0000 train acc: 0.7723,train loss: 0.6637, dev acc: 0.7500, dev loss: 0.6676\n",
            "epoch11 3246.0000 train acc: 0.7723,train loss: 0.6637, dev acc: 0.7500, dev loss: 0.6676\n",
            "epoch11 3247.0000 train acc: 0.7723,train loss: 0.6637, dev acc: 0.7500, dev loss: 0.6675\n",
            "epoch11 3248.0000 train acc: 0.7723,train loss: 0.6636, dev acc: 0.7500, dev loss: 0.6675\n",
            "epoch11 3249.0000 train acc: 0.7723,train loss: 0.6636, dev acc: 0.7500, dev loss: 0.6675\n",
            "epoch11 3250.0000 train acc: 0.7723,train loss: 0.6636, dev acc: 0.7500, dev loss: 0.6675\n",
            "epoch11 3251.0000 train acc: 0.7723,train loss: 0.6636, dev acc: 0.7500, dev loss: 0.6675\n",
            "epoch11 3252.0000 train acc: 0.7723,train loss: 0.6636, dev acc: 0.7500, dev loss: 0.6675\n",
            "epoch11 3253.0000 train acc: 0.7723,train loss: 0.6635, dev acc: 0.7500, dev loss: 0.6674\n",
            "epoch11 3254.0000 train acc: 0.7723,train loss: 0.6635, dev acc: 0.7500, dev loss: 0.6674\n",
            "epoch11 3255.0000 train acc: 0.7723,train loss: 0.6635, dev acc: 0.7500, dev loss: 0.6674\n",
            "epoch11 3256.0000 train acc: 0.7723,train loss: 0.6635, dev acc: 0.7500, dev loss: 0.6674\n",
            "epoch11 3257.0000 train acc: 0.7723,train loss: 0.6635, dev acc: 0.7500, dev loss: 0.6674\n",
            "epoch11 3258.0000 train acc: 0.7723,train loss: 0.6635, dev acc: 0.7500, dev loss: 0.6674\n",
            "epoch11 3259.0000 train acc: 0.7723,train loss: 0.6634, dev acc: 0.7500, dev loss: 0.6674\n",
            "epoch11 3260.0000 train acc: 0.7723,train loss: 0.6634, dev acc: 0.7500, dev loss: 0.6673\n",
            "epoch11 3261.0000 train acc: 0.7723,train loss: 0.6634, dev acc: 0.7500, dev loss: 0.6673\n",
            "epoch11 3262.0000 train acc: 0.7723,train loss: 0.6634, dev acc: 0.7500, dev loss: 0.6673\n",
            "epoch11 3263.0000 train acc: 0.7723,train loss: 0.6634, dev acc: 0.7500, dev loss: 0.6673\n",
            "epoch11 3264.0000 train acc: 0.7723,train loss: 0.6633, dev acc: 0.7500, dev loss: 0.6673\n",
            "epoch11 3265.0000 train acc: 0.7723,train loss: 0.6633, dev acc: 0.7500, dev loss: 0.6673\n",
            "epoch11 3266.0000 train acc: 0.7723,train loss: 0.6633, dev acc: 0.7500, dev loss: 0.6672\n",
            "epoch11 3267.0000 train acc: 0.7723,train loss: 0.6633, dev acc: 0.7500, dev loss: 0.6672\n",
            "epoch11 3268.0000 train acc: 0.7746,train loss: 0.6633, dev acc: 0.7500, dev loss: 0.6672\n",
            "epoch11 3269.0000 train acc: 0.7746,train loss: 0.6633, dev acc: 0.7500, dev loss: 0.6672\n",
            "epoch11 3270.0000 train acc: 0.7746,train loss: 0.6632, dev acc: 0.7500, dev loss: 0.6672\n",
            "epoch11 3271.0000 train acc: 0.7746,train loss: 0.6632, dev acc: 0.7500, dev loss: 0.6672\n",
            "epoch11 3272.0000 train acc: 0.7746,train loss: 0.6632, dev acc: 0.7500, dev loss: 0.6671\n",
            "epoch11 3273.0000 train acc: 0.7746,train loss: 0.6632, dev acc: 0.7500, dev loss: 0.6671\n",
            "epoch11 3274.0000 train acc: 0.7746,train loss: 0.6632, dev acc: 0.7500, dev loss: 0.6671\n",
            "epoch11 3275.0000 train acc: 0.7746,train loss: 0.6631, dev acc: 0.7500, dev loss: 0.6671\n",
            "epoch11 3276.0000 train acc: 0.7746,train loss: 0.6631, dev acc: 0.7500, dev loss: 0.6671\n",
            "epoch11 3277.0000 train acc: 0.7746,train loss: 0.6631, dev acc: 0.7500, dev loss: 0.6671\n",
            "epoch11 3278.0000 train acc: 0.7746,train loss: 0.6631, dev acc: 0.7500, dev loss: 0.6670\n",
            "epoch11 3279.0000 train acc: 0.7746,train loss: 0.6631, dev acc: 0.7500, dev loss: 0.6670\n",
            "epoch11 3280.0000 train acc: 0.7746,train loss: 0.6631, dev acc: 0.7500, dev loss: 0.6670\n",
            "epoch11 3281.0000 train acc: 0.7746,train loss: 0.6630, dev acc: 0.7500, dev loss: 0.6670\n",
            "epoch11 3282.0000 train acc: 0.7746,train loss: 0.6630, dev acc: 0.7500, dev loss: 0.6670\n",
            "epoch11 3283.0000 train acc: 0.7746,train loss: 0.6630, dev acc: 0.7500, dev loss: 0.6670\n",
            "epoch11 3284.0000 train acc: 0.7746,train loss: 0.6630, dev acc: 0.7500, dev loss: 0.6669\n",
            "epoch11 3285.0000 train acc: 0.7746,train loss: 0.6630, dev acc: 0.7500, dev loss: 0.6669\n",
            "epoch11 3286.0000 train acc: 0.7746,train loss: 0.6629, dev acc: 0.7500, dev loss: 0.6669\n",
            "epoch11 3287.0000 train acc: 0.7746,train loss: 0.6629, dev acc: 0.7500, dev loss: 0.6669\n",
            "epoch11 3288.0000 train acc: 0.7746,train loss: 0.6629, dev acc: 0.7500, dev loss: 0.6669\n",
            "epoch11 3289.0000 train acc: 0.7746,train loss: 0.6629, dev acc: 0.7500, dev loss: 0.6669\n",
            "epoch11 3290.0000 train acc: 0.7746,train loss: 0.6629, dev acc: 0.7500, dev loss: 0.6668\n",
            "epoch11 3291.0000 train acc: 0.7746,train loss: 0.6629, dev acc: 0.7500, dev loss: 0.6668\n",
            "epoch11 3292.0000 train acc: 0.7746,train loss: 0.6628, dev acc: 0.7500, dev loss: 0.6668\n",
            "epoch11 3293.0000 train acc: 0.7746,train loss: 0.6628, dev acc: 0.7500, dev loss: 0.6668\n",
            "epoch11 3294.0000 train acc: 0.7746,train loss: 0.6628, dev acc: 0.7500, dev loss: 0.6668\n",
            "epoch11 3295.0000 train acc: 0.7746,train loss: 0.6628, dev acc: 0.7500, dev loss: 0.6668\n",
            "epoch11 3296.0000 train acc: 0.7746,train loss: 0.6628, dev acc: 0.7500, dev loss: 0.6667\n",
            "epoch11 3297.0000 train acc: 0.7746,train loss: 0.6627, dev acc: 0.7500, dev loss: 0.6667\n",
            "epoch11 3298.0000 train acc: 0.7746,train loss: 0.6627, dev acc: 0.7500, dev loss: 0.6667\n",
            "epoch11 3299.0000 train acc: 0.7746,train loss: 0.6627, dev acc: 0.7500, dev loss: 0.6667\n",
            "epoch11 3300.0000 train acc: 0.7746,train loss: 0.6627, dev acc: 0.7500, dev loss: 0.6667\n",
            "epoch11 3301.0000 train acc: 0.7746,train loss: 0.6627, dev acc: 0.7500, dev loss: 0.6667\n",
            "epoch11 3302.0000 train acc: 0.7746,train loss: 0.6626, dev acc: 0.7500, dev loss: 0.6666\n",
            "epoch11 3303.0000 train acc: 0.7746,train loss: 0.6626, dev acc: 0.7500, dev loss: 0.6666\n",
            "epoch11 3304.0000 train acc: 0.7746,train loss: 0.6626, dev acc: 0.7500, dev loss: 0.6666\n",
            "epoch11 3305.0000 train acc: 0.7746,train loss: 0.6626, dev acc: 0.7500, dev loss: 0.6666\n",
            "epoch11 3306.0000 train acc: 0.7746,train loss: 0.6626, dev acc: 0.7500, dev loss: 0.6666\n",
            "epoch11 3307.0000 train acc: 0.7746,train loss: 0.6626, dev acc: 0.7500, dev loss: 0.6666\n",
            "epoch11 3308.0000 train acc: 0.7746,train loss: 0.6625, dev acc: 0.7500, dev loss: 0.6665\n",
            "epoch11 3309.0000 train acc: 0.7746,train loss: 0.6625, dev acc: 0.7500, dev loss: 0.6665\n",
            "epoch11 3310.0000 train acc: 0.7746,train loss: 0.6625, dev acc: 0.7500, dev loss: 0.6665\n",
            "epoch11 3311.0000 train acc: 0.7746,train loss: 0.6625, dev acc: 0.7500, dev loss: 0.6665\n",
            "epoch11 3312.0000 train acc: 0.7746,train loss: 0.6625, dev acc: 0.7500, dev loss: 0.6665\n",
            "epoch11 3313.0000 train acc: 0.7746,train loss: 0.6624, dev acc: 0.7500, dev loss: 0.6665\n",
            "epoch11 3314.0000 train acc: 0.7746,train loss: 0.6624, dev acc: 0.7500, dev loss: 0.6664\n",
            "epoch11 3315.0000 train acc: 0.7746,train loss: 0.6624, dev acc: 0.7500, dev loss: 0.6664\n",
            "epoch11 3316.0000 train acc: 0.7746,train loss: 0.6624, dev acc: 0.7500, dev loss: 0.6664\n",
            "epoch11 3317.0000 train acc: 0.7746,train loss: 0.6624, dev acc: 0.7500, dev loss: 0.6664\n",
            "epoch11 3318.0000 train acc: 0.7746,train loss: 0.6624, dev acc: 0.7500, dev loss: 0.6664\n",
            "epoch11 3319.0000 train acc: 0.7746,train loss: 0.6623, dev acc: 0.7500, dev loss: 0.6664\n",
            "epoch11 3320.0000 train acc: 0.7746,train loss: 0.6623, dev acc: 0.7500, dev loss: 0.6663\n",
            "epoch11 3321.0000 train acc: 0.7746,train loss: 0.6623, dev acc: 0.7500, dev loss: 0.6663\n",
            "epoch11 3322.0000 train acc: 0.7746,train loss: 0.6623, dev acc: 0.7500, dev loss: 0.6663\n",
            "epoch11 3323.0000 train acc: 0.7746,train loss: 0.6623, dev acc: 0.7500, dev loss: 0.6663\n",
            "epoch11 3324.0000 train acc: 0.7746,train loss: 0.6622, dev acc: 0.7500, dev loss: 0.6663\n",
            "epoch11 3325.0000 train acc: 0.7746,train loss: 0.6622, dev acc: 0.7500, dev loss: 0.6663\n",
            "epoch11 3326.0000 train acc: 0.7746,train loss: 0.6622, dev acc: 0.7500, dev loss: 0.6662\n",
            "epoch11 3327.0000 train acc: 0.7746,train loss: 0.6622, dev acc: 0.7500, dev loss: 0.6662\n",
            "epoch11 3328.0000 train acc: 0.7768,train loss: 0.6622, dev acc: 0.7500, dev loss: 0.6662\n",
            "epoch11 3329.0000 train acc: 0.7768,train loss: 0.6621, dev acc: 0.7500, dev loss: 0.6662\n",
            "epoch11 3330.0000 train acc: 0.7768,train loss: 0.6621, dev acc: 0.7500, dev loss: 0.6662\n",
            "epoch11 3331.0000 train acc: 0.7768,train loss: 0.6621, dev acc: 0.7500, dev loss: 0.6662\n",
            "epoch11 3332.0000 train acc: 0.7768,train loss: 0.6621, dev acc: 0.7500, dev loss: 0.6661\n",
            "epoch11 3333.0000 train acc: 0.7768,train loss: 0.6621, dev acc: 0.7500, dev loss: 0.6661\n",
            "epoch11 3334.0000 train acc: 0.7768,train loss: 0.6621, dev acc: 0.7500, dev loss: 0.6661\n",
            "epoch11 3335.0000 train acc: 0.7768,train loss: 0.6620, dev acc: 0.7500, dev loss: 0.6661\n",
            "epoch11 3336.0000 train acc: 0.7768,train loss: 0.6620, dev acc: 0.7500, dev loss: 0.6661\n",
            "epoch11 3337.0000 train acc: 0.7768,train loss: 0.6620, dev acc: 0.7500, dev loss: 0.6661\n",
            "epoch11 3338.0000 train acc: 0.7768,train loss: 0.6620, dev acc: 0.7500, dev loss: 0.6660\n",
            "epoch11 3339.0000 train acc: 0.7790,train loss: 0.6620, dev acc: 0.7500, dev loss: 0.6660\n",
            "epoch11 3340.0000 train acc: 0.7812,train loss: 0.6619, dev acc: 0.7500, dev loss: 0.6660\n",
            "epoch11 3341.0000 train acc: 0.7812,train loss: 0.6619, dev acc: 0.7500, dev loss: 0.6660\n",
            "epoch11 3342.0000 train acc: 0.7812,train loss: 0.6619, dev acc: 0.7500, dev loss: 0.6660\n",
            "epoch11 3343.0000 train acc: 0.7812,train loss: 0.6619, dev acc: 0.7500, dev loss: 0.6660\n",
            "epoch11 3344.0000 train acc: 0.7812,train loss: 0.6619, dev acc: 0.7500, dev loss: 0.6659\n",
            "epoch11 3345.0000 train acc: 0.7812,train loss: 0.6618, dev acc: 0.7500, dev loss: 0.6659\n",
            "epoch11 3346.0000 train acc: 0.7812,train loss: 0.6618, dev acc: 0.7500, dev loss: 0.6659\n",
            "epoch11 3347.0000 train acc: 0.7812,train loss: 0.6618, dev acc: 0.7500, dev loss: 0.6659\n",
            "epoch11 3348.0000 train acc: 0.7812,train loss: 0.6618, dev acc: 0.7500, dev loss: 0.6659\n",
            "epoch11 3349.0000 train acc: 0.7812,train loss: 0.6618, dev acc: 0.7500, dev loss: 0.6659\n",
            "epoch11 3350.0000 train acc: 0.7812,train loss: 0.6618, dev acc: 0.7500, dev loss: 0.6658\n",
            "epoch11 3351.0000 train acc: 0.7812,train loss: 0.6617, dev acc: 0.7500, dev loss: 0.6658\n",
            "epoch11 3352.0000 train acc: 0.7812,train loss: 0.6617, dev acc: 0.7500, dev loss: 0.6658\n",
            "epoch11 3353.0000 train acc: 0.7812,train loss: 0.6617, dev acc: 0.7500, dev loss: 0.6658\n",
            "epoch11 3354.0000 train acc: 0.7812,train loss: 0.6617, dev acc: 0.7500, dev loss: 0.6658\n",
            "epoch11 3355.0000 train acc: 0.7835,train loss: 0.6617, dev acc: 0.7500, dev loss: 0.6658\n",
            "epoch11 3356.0000 train acc: 0.7835,train loss: 0.6616, dev acc: 0.7500, dev loss: 0.6657\n",
            "epoch11 3357.0000 train acc: 0.7835,train loss: 0.6616, dev acc: 0.7500, dev loss: 0.6657\n",
            "epoch11 3358.0000 train acc: 0.7835,train loss: 0.6616, dev acc: 0.7500, dev loss: 0.6657\n",
            "epoch11 3359.0000 train acc: 0.7835,train loss: 0.6616, dev acc: 0.7500, dev loss: 0.6657\n",
            "epoch11 3360.0000 train acc: 0.7835,train loss: 0.6616, dev acc: 0.7500, dev loss: 0.6657\n",
            "epoch11 3361.0000 train acc: 0.7835,train loss: 0.6615, dev acc: 0.7500, dev loss: 0.6657\n",
            "epoch11 3362.0000 train acc: 0.7835,train loss: 0.6615, dev acc: 0.7500, dev loss: 0.6656\n",
            "epoch11 3363.0000 train acc: 0.7835,train loss: 0.6615, dev acc: 0.7500, dev loss: 0.6656\n",
            "epoch11 3364.0000 train acc: 0.7835,train loss: 0.6615, dev acc: 0.7500, dev loss: 0.6656\n",
            "epoch11 3365.0000 train acc: 0.7835,train loss: 0.6615, dev acc: 0.7500, dev loss: 0.6656\n",
            "epoch11 3366.0000 train acc: 0.7835,train loss: 0.6614, dev acc: 0.7500, dev loss: 0.6656\n",
            "epoch11 3367.0000 train acc: 0.7835,train loss: 0.6614, dev acc: 0.7500, dev loss: 0.6656\n",
            "epoch11 3368.0000 train acc: 0.7835,train loss: 0.6614, dev acc: 0.7500, dev loss: 0.6655\n",
            "epoch11 3369.0000 train acc: 0.7835,train loss: 0.6614, dev acc: 0.7500, dev loss: 0.6655\n",
            "epoch11 3370.0000 train acc: 0.7835,train loss: 0.6614, dev acc: 0.7500, dev loss: 0.6655\n",
            "epoch11 3371.0000 train acc: 0.7835,train loss: 0.6614, dev acc: 0.7500, dev loss: 0.6655\n",
            "epoch11 3372.0000 train acc: 0.7835,train loss: 0.6613, dev acc: 0.7500, dev loss: 0.6655\n",
            "epoch11 3373.0000 train acc: 0.7835,train loss: 0.6613, dev acc: 0.7500, dev loss: 0.6654\n",
            "epoch11 3374.0000 train acc: 0.7835,train loss: 0.6613, dev acc: 0.7500, dev loss: 0.6654\n",
            "epoch11 3375.0000 train acc: 0.7835,train loss: 0.6613, dev acc: 0.7500, dev loss: 0.6654\n",
            "epoch11 3376.0000 train acc: 0.7835,train loss: 0.6613, dev acc: 0.7500, dev loss: 0.6654\n",
            "epoch11 3377.0000 train acc: 0.7857,train loss: 0.6612, dev acc: 0.7500, dev loss: 0.6654\n",
            "epoch11 3378.0000 train acc: 0.7857,train loss: 0.6612, dev acc: 0.7500, dev loss: 0.6654\n",
            "epoch11 3379.0000 train acc: 0.7857,train loss: 0.6612, dev acc: 0.7500, dev loss: 0.6653\n",
            "epoch11 3380.0000 train acc: 0.7857,train loss: 0.6612, dev acc: 0.7500, dev loss: 0.6653\n",
            "epoch11 3381.0000 train acc: 0.7857,train loss: 0.6612, dev acc: 0.7500, dev loss: 0.6653\n",
            "epoch11 3382.0000 train acc: 0.7857,train loss: 0.6611, dev acc: 0.7500, dev loss: 0.6653\n",
            "epoch11 3383.0000 train acc: 0.7857,train loss: 0.6611, dev acc: 0.7500, dev loss: 0.6653\n",
            "epoch11 3384.0000 train acc: 0.7857,train loss: 0.6611, dev acc: 0.7500, dev loss: 0.6653\n",
            "epoch11 3385.0000 train acc: 0.7857,train loss: 0.6611, dev acc: 0.7500, dev loss: 0.6652\n",
            "epoch11 3386.0000 train acc: 0.7857,train loss: 0.6611, dev acc: 0.7500, dev loss: 0.6652\n",
            "epoch11 3387.0000 train acc: 0.7857,train loss: 0.6610, dev acc: 0.7500, dev loss: 0.6652\n",
            "epoch11 3388.0000 train acc: 0.7857,train loss: 0.6610, dev acc: 0.7500, dev loss: 0.6652\n",
            "epoch11 3389.0000 train acc: 0.7857,train loss: 0.6610, dev acc: 0.7500, dev loss: 0.6652\n",
            "epoch11 3390.0000 train acc: 0.7857,train loss: 0.6610, dev acc: 0.7500, dev loss: 0.6652\n",
            "epoch11 3391.0000 train acc: 0.7857,train loss: 0.6610, dev acc: 0.7500, dev loss: 0.6651\n",
            "epoch11 3392.0000 train acc: 0.7857,train loss: 0.6610, dev acc: 0.7500, dev loss: 0.6651\n",
            "epoch11 3393.0000 train acc: 0.7857,train loss: 0.6609, dev acc: 0.7500, dev loss: 0.6651\n",
            "epoch11 3394.0000 train acc: 0.7857,train loss: 0.6609, dev acc: 0.7500, dev loss: 0.6651\n",
            "epoch11 3395.0000 train acc: 0.7857,train loss: 0.6609, dev acc: 0.7500, dev loss: 0.6651\n",
            "epoch11 3396.0000 train acc: 0.7857,train loss: 0.6609, dev acc: 0.7500, dev loss: 0.6651\n",
            "epoch11 3397.0000 train acc: 0.7857,train loss: 0.6609, dev acc: 0.7500, dev loss: 0.6650\n",
            "epoch11 3398.0000 train acc: 0.7857,train loss: 0.6608, dev acc: 0.7500, dev loss: 0.6650\n",
            "epoch11 3399.0000 train acc: 0.7857,train loss: 0.6608, dev acc: 0.7500, dev loss: 0.6650\n",
            "epoch11 3400.0000 train acc: 0.7857,train loss: 0.6608, dev acc: 0.7500, dev loss: 0.6650\n",
            "epoch11 3401.0000 train acc: 0.7857,train loss: 0.6608, dev acc: 0.7500, dev loss: 0.6650\n",
            "epoch11 3402.0000 train acc: 0.7857,train loss: 0.6608, dev acc: 0.7500, dev loss: 0.6649\n",
            "epoch11 3403.0000 train acc: 0.7857,train loss: 0.6607, dev acc: 0.7500, dev loss: 0.6649\n",
            "epoch11 3404.0000 train acc: 0.7857,train loss: 0.6607, dev acc: 0.7500, dev loss: 0.6649\n",
            "epoch11 3405.0000 train acc: 0.7857,train loss: 0.6607, dev acc: 0.7500, dev loss: 0.6649\n",
            "epoch11 3406.0000 train acc: 0.7857,train loss: 0.6607, dev acc: 0.7500, dev loss: 0.6649\n",
            "epoch11 3407.0000 train acc: 0.7857,train loss: 0.6607, dev acc: 0.7500, dev loss: 0.6649\n",
            "epoch11 3408.0000 train acc: 0.7857,train loss: 0.6606, dev acc: 0.7500, dev loss: 0.6648\n",
            "epoch11 3409.0000 train acc: 0.7857,train loss: 0.6606, dev acc: 0.7500, dev loss: 0.6648\n",
            "epoch11 3410.0000 train acc: 0.7857,train loss: 0.6606, dev acc: 0.7500, dev loss: 0.6648\n",
            "epoch11 3411.0000 train acc: 0.7857,train loss: 0.6606, dev acc: 0.7500, dev loss: 0.6648\n",
            "epoch11 3412.0000 train acc: 0.7857,train loss: 0.6606, dev acc: 0.7500, dev loss: 0.6648\n",
            "epoch11 3413.0000 train acc: 0.7857,train loss: 0.6605, dev acc: 0.7500, dev loss: 0.6648\n",
            "epoch11 3414.0000 train acc: 0.7857,train loss: 0.6605, dev acc: 0.7500, dev loss: 0.6647\n",
            "epoch11 3415.0000 train acc: 0.7857,train loss: 0.6605, dev acc: 0.7500, dev loss: 0.6647\n",
            "epoch11 3416.0000 train acc: 0.7857,train loss: 0.6605, dev acc: 0.7500, dev loss: 0.6647\n",
            "epoch11 3417.0000 train acc: 0.7857,train loss: 0.6605, dev acc: 0.7500, dev loss: 0.6647\n",
            "epoch11 3418.0000 train acc: 0.7857,train loss: 0.6604, dev acc: 0.7500, dev loss: 0.6647\n",
            "epoch11 3419.0000 train acc: 0.7857,train loss: 0.6604, dev acc: 0.7500, dev loss: 0.6647\n",
            "epoch11 3420.0000 train acc: 0.7857,train loss: 0.6604, dev acc: 0.7500, dev loss: 0.6646\n",
            "epoch11 3421.0000 train acc: 0.7857,train loss: 0.6604, dev acc: 0.7500, dev loss: 0.6646\n",
            "epoch11 3422.0000 train acc: 0.7857,train loss: 0.6604, dev acc: 0.7500, dev loss: 0.6646\n",
            "epoch11 3423.0000 train acc: 0.7857,train loss: 0.6603, dev acc: 0.7500, dev loss: 0.6646\n",
            "epoch11 3424.0000 train acc: 0.7857,train loss: 0.6603, dev acc: 0.7500, dev loss: 0.6646\n",
            "epoch11 3425.0000 train acc: 0.7857,train loss: 0.6603, dev acc: 0.7500, dev loss: 0.6645\n",
            "epoch11 3426.0000 train acc: 0.7857,train loss: 0.6603, dev acc: 0.7500, dev loss: 0.6645\n",
            "epoch11 3427.0000 train acc: 0.7857,train loss: 0.6603, dev acc: 0.7500, dev loss: 0.6645\n",
            "epoch11 3428.0000 train acc: 0.7857,train loss: 0.6602, dev acc: 0.7500, dev loss: 0.6645\n",
            "epoch11 3429.0000 train acc: 0.7857,train loss: 0.6602, dev acc: 0.7500, dev loss: 0.6645\n",
            "epoch11 3430.0000 train acc: 0.7857,train loss: 0.6602, dev acc: 0.7500, dev loss: 0.6645\n",
            "epoch11 3431.0000 train acc: 0.7857,train loss: 0.6602, dev acc: 0.7500, dev loss: 0.6644\n",
            "epoch11 3432.0000 train acc: 0.7857,train loss: 0.6602, dev acc: 0.7500, dev loss: 0.6644\n",
            "epoch11 3433.0000 train acc: 0.7879,train loss: 0.6602, dev acc: 0.7500, dev loss: 0.6644\n",
            "epoch11 3434.0000 train acc: 0.7879,train loss: 0.6601, dev acc: 0.7500, dev loss: 0.6644\n",
            "epoch11 3435.0000 train acc: 0.7879,train loss: 0.6601, dev acc: 0.7500, dev loss: 0.6644\n",
            "epoch11 3436.0000 train acc: 0.7879,train loss: 0.6601, dev acc: 0.7500, dev loss: 0.6644\n",
            "epoch11 3437.0000 train acc: 0.7879,train loss: 0.6601, dev acc: 0.7500, dev loss: 0.6643\n",
            "epoch11 3438.0000 train acc: 0.7879,train loss: 0.6601, dev acc: 0.7500, dev loss: 0.6643\n",
            "epoch11 3439.0000 train acc: 0.7879,train loss: 0.6600, dev acc: 0.7500, dev loss: 0.6643\n",
            "epoch11 3440.0000 train acc: 0.7879,train loss: 0.6600, dev acc: 0.7500, dev loss: 0.6643\n",
            "epoch11 3441.0000 train acc: 0.7879,train loss: 0.6600, dev acc: 0.7500, dev loss: 0.6643\n",
            "epoch11 3442.0000 train acc: 0.7879,train loss: 0.6600, dev acc: 0.7500, dev loss: 0.6642\n",
            "epoch11 3443.0000 train acc: 0.7879,train loss: 0.6600, dev acc: 0.7500, dev loss: 0.6642\n",
            "epoch11 3444.0000 train acc: 0.7879,train loss: 0.6599, dev acc: 0.7500, dev loss: 0.6642\n",
            "epoch11 3445.0000 train acc: 0.7879,train loss: 0.6599, dev acc: 0.7500, dev loss: 0.6642\n",
            "epoch11 3446.0000 train acc: 0.7879,train loss: 0.6599, dev acc: 0.7500, dev loss: 0.6642\n",
            "epoch11 3447.0000 train acc: 0.7879,train loss: 0.6599, dev acc: 0.7500, dev loss: 0.6642\n",
            "epoch11 3448.0000 train acc: 0.7879,train loss: 0.6599, dev acc: 0.7500, dev loss: 0.6641\n",
            "epoch11 3449.0000 train acc: 0.7879,train loss: 0.6598, dev acc: 0.7500, dev loss: 0.6641\n",
            "epoch11 3450.0000 train acc: 0.7879,train loss: 0.6598, dev acc: 0.7500, dev loss: 0.6641\n",
            "epoch11 3451.0000 train acc: 0.7879,train loss: 0.6598, dev acc: 0.7500, dev loss: 0.6641\n",
            "epoch11 3452.0000 train acc: 0.7879,train loss: 0.6598, dev acc: 0.7500, dev loss: 0.6641\n",
            "epoch11 3453.0000 train acc: 0.7879,train loss: 0.6598, dev acc: 0.7500, dev loss: 0.6641\n",
            "epoch11 3454.0000 train acc: 0.7879,train loss: 0.6597, dev acc: 0.7500, dev loss: 0.6640\n",
            "epoch11 3455.0000 train acc: 0.7879,train loss: 0.6597, dev acc: 0.7500, dev loss: 0.6640\n",
            "epoch11 3456.0000 train acc: 0.7879,train loss: 0.6597, dev acc: 0.7500, dev loss: 0.6640\n",
            "epoch11 3457.0000 train acc: 0.7879,train loss: 0.6597, dev acc: 0.7500, dev loss: 0.6640\n",
            "epoch11 3458.0000 train acc: 0.7879,train loss: 0.6597, dev acc: 0.7500, dev loss: 0.6640\n",
            "epoch11 3459.0000 train acc: 0.7879,train loss: 0.6596, dev acc: 0.7500, dev loss: 0.6639\n",
            "epoch11 3460.0000 train acc: 0.7879,train loss: 0.6596, dev acc: 0.7500, dev loss: 0.6639\n",
            "epoch11 3461.0000 train acc: 0.7879,train loss: 0.6596, dev acc: 0.7500, dev loss: 0.6639\n",
            "epoch11 3462.0000 train acc: 0.7879,train loss: 0.6596, dev acc: 0.7500, dev loss: 0.6639\n",
            "epoch11 3463.0000 train acc: 0.7879,train loss: 0.6596, dev acc: 0.7500, dev loss: 0.6639\n",
            "epoch11 3464.0000 train acc: 0.7879,train loss: 0.6595, dev acc: 0.7500, dev loss: 0.6639\n",
            "epoch11 3465.0000 train acc: 0.7879,train loss: 0.6595, dev acc: 0.7500, dev loss: 0.6638\n",
            "epoch11 3466.0000 train acc: 0.7879,train loss: 0.6595, dev acc: 0.7500, dev loss: 0.6638\n",
            "epoch11 3467.0000 train acc: 0.7879,train loss: 0.6595, dev acc: 0.7500, dev loss: 0.6638\n",
            "epoch11 3468.0000 train acc: 0.7879,train loss: 0.6595, dev acc: 0.7500, dev loss: 0.6638\n",
            "epoch11 3469.0000 train acc: 0.7879,train loss: 0.6594, dev acc: 0.7500, dev loss: 0.6638\n",
            "epoch11 3470.0000 train acc: 0.7879,train loss: 0.6594, dev acc: 0.7500, dev loss: 0.6637\n",
            "epoch11 3471.0000 train acc: 0.7879,train loss: 0.6594, dev acc: 0.7500, dev loss: 0.6637\n",
            "epoch11 3472.0000 train acc: 0.7879,train loss: 0.6594, dev acc: 0.7500, dev loss: 0.6637\n",
            "epoch11 3473.0000 train acc: 0.7879,train loss: 0.6594, dev acc: 0.7500, dev loss: 0.6637\n",
            "epoch11 3474.0000 train acc: 0.7879,train loss: 0.6593, dev acc: 0.7500, dev loss: 0.6637\n",
            "epoch11 3475.0000 train acc: 0.7879,train loss: 0.6593, dev acc: 0.7500, dev loss: 0.6637\n",
            "epoch11 3476.0000 train acc: 0.7879,train loss: 0.6593, dev acc: 0.7500, dev loss: 0.6636\n",
            "epoch11 3477.0000 train acc: 0.7879,train loss: 0.6593, dev acc: 0.7500, dev loss: 0.6636\n",
            "epoch11 3478.0000 train acc: 0.7879,train loss: 0.6593, dev acc: 0.7500, dev loss: 0.6636\n",
            "epoch11 3479.0000 train acc: 0.7879,train loss: 0.6592, dev acc: 0.7500, dev loss: 0.6636\n",
            "epoch11 3480.0000 train acc: 0.7879,train loss: 0.6592, dev acc: 0.7500, dev loss: 0.6636\n",
            "epoch11 3481.0000 train acc: 0.7879,train loss: 0.6592, dev acc: 0.7500, dev loss: 0.6635\n",
            "epoch11 3482.0000 train acc: 0.7879,train loss: 0.6592, dev acc: 0.7500, dev loss: 0.6635\n",
            "epoch11 3483.0000 train acc: 0.7879,train loss: 0.6591, dev acc: 0.7500, dev loss: 0.6635\n",
            "epoch11 3484.0000 train acc: 0.7879,train loss: 0.6591, dev acc: 0.7500, dev loss: 0.6635\n",
            "epoch11 3485.0000 train acc: 0.7879,train loss: 0.6591, dev acc: 0.7500, dev loss: 0.6635\n",
            "epoch11 3486.0000 train acc: 0.7879,train loss: 0.6591, dev acc: 0.7500, dev loss: 0.6635\n",
            "epoch11 3487.0000 train acc: 0.7879,train loss: 0.6591, dev acc: 0.7500, dev loss: 0.6634\n",
            "epoch11 3488.0000 train acc: 0.7879,train loss: 0.6590, dev acc: 0.7500, dev loss: 0.6634\n",
            "epoch11 3489.0000 train acc: 0.7879,train loss: 0.6590, dev acc: 0.7500, dev loss: 0.6634\n",
            "epoch11 3490.0000 train acc: 0.7879,train loss: 0.6590, dev acc: 0.7500, dev loss: 0.6634\n",
            "epoch11 3491.0000 train acc: 0.7879,train loss: 0.6590, dev acc: 0.7500, dev loss: 0.6634\n",
            "epoch11 3492.0000 train acc: 0.7879,train loss: 0.6590, dev acc: 0.7500, dev loss: 0.6633\n",
            "epoch11 3493.0000 train acc: 0.7879,train loss: 0.6589, dev acc: 0.7500, dev loss: 0.6633\n",
            "epoch11 3494.0000 train acc: 0.7879,train loss: 0.6589, dev acc: 0.7500, dev loss: 0.6633\n",
            "epoch11 3495.0000 train acc: 0.7879,train loss: 0.6589, dev acc: 0.7500, dev loss: 0.6633\n",
            "epoch11 3496.0000 train acc: 0.7879,train loss: 0.6589, dev acc: 0.7500, dev loss: 0.6633\n",
            "epoch11 3497.0000 train acc: 0.7879,train loss: 0.6589, dev acc: 0.7500, dev loss: 0.6632\n",
            "epoch11 3498.0000 train acc: 0.7879,train loss: 0.6588, dev acc: 0.7500, dev loss: 0.6632\n",
            "epoch11 3499.0000 train acc: 0.7879,train loss: 0.6588, dev acc: 0.7500, dev loss: 0.6632\n",
            "epoch11 3500.0000 train acc: 0.7879,train loss: 0.6588, dev acc: 0.7500, dev loss: 0.6632\n",
            "epoch11 3501.0000 train acc: 0.7879,train loss: 0.6588, dev acc: 0.7500, dev loss: 0.6632\n",
            "epoch11 3502.0000 train acc: 0.7879,train loss: 0.6588, dev acc: 0.7500, dev loss: 0.6632\n",
            "epoch11 3503.0000 train acc: 0.7879,train loss: 0.6587, dev acc: 0.7500, dev loss: 0.6631\n",
            "epoch11 3504.0000 train acc: 0.7879,train loss: 0.6587, dev acc: 0.7500, dev loss: 0.6631\n",
            "epoch11 3505.0000 train acc: 0.7879,train loss: 0.6587, dev acc: 0.7500, dev loss: 0.6631\n",
            "epoch11 3506.0000 train acc: 0.7879,train loss: 0.6587, dev acc: 0.7500, dev loss: 0.6631\n",
            "epoch11 3507.0000 train acc: 0.7879,train loss: 0.6587, dev acc: 0.7500, dev loss: 0.6631\n",
            "epoch11 3508.0000 train acc: 0.7879,train loss: 0.6586, dev acc: 0.7500, dev loss: 0.6630\n",
            "epoch11 3509.0000 train acc: 0.7879,train loss: 0.6586, dev acc: 0.7500, dev loss: 0.6630\n",
            "epoch11 3510.0000 train acc: 0.7879,train loss: 0.6586, dev acc: 0.7500, dev loss: 0.6630\n",
            "epoch11 3511.0000 train acc: 0.7879,train loss: 0.6586, dev acc: 0.7500, dev loss: 0.6630\n",
            "epoch11 3512.0000 train acc: 0.7879,train loss: 0.6585, dev acc: 0.7500, dev loss: 0.6630\n",
            "epoch11 3513.0000 train acc: 0.7879,train loss: 0.6585, dev acc: 0.7500, dev loss: 0.6630\n",
            "epoch11 3514.0000 train acc: 0.7879,train loss: 0.6585, dev acc: 0.7500, dev loss: 0.6629\n",
            "epoch11 3515.0000 train acc: 0.7879,train loss: 0.6585, dev acc: 0.7500, dev loss: 0.6629\n",
            "epoch11 3516.0000 train acc: 0.7879,train loss: 0.6585, dev acc: 0.7500, dev loss: 0.6629\n",
            "epoch11 3517.0000 train acc: 0.7879,train loss: 0.6584, dev acc: 0.7500, dev loss: 0.6629\n",
            "epoch11 3518.0000 train acc: 0.7879,train loss: 0.6584, dev acc: 0.7500, dev loss: 0.6629\n",
            "epoch11 3519.0000 train acc: 0.7879,train loss: 0.6584, dev acc: 0.7500, dev loss: 0.6628\n",
            "epoch11 3520.0000 train acc: 0.7879,train loss: 0.6584, dev acc: 0.7500, dev loss: 0.6628\n",
            "epoch11 3521.0000 train acc: 0.7879,train loss: 0.6584, dev acc: 0.7500, dev loss: 0.6628\n",
            "epoch11 3522.0000 train acc: 0.7879,train loss: 0.6583, dev acc: 0.7500, dev loss: 0.6628\n",
            "epoch11 3523.0000 train acc: 0.7879,train loss: 0.6583, dev acc: 0.7500, dev loss: 0.6628\n",
            "epoch11 3524.0000 train acc: 0.7879,train loss: 0.6583, dev acc: 0.7500, dev loss: 0.6628\n",
            "epoch11 3525.0000 train acc: 0.7879,train loss: 0.6583, dev acc: 0.7500, dev loss: 0.6627\n",
            "epoch11 3526.0000 train acc: 0.7879,train loss: 0.6583, dev acc: 0.7500, dev loss: 0.6627\n",
            "epoch11 3527.0000 train acc: 0.7879,train loss: 0.6582, dev acc: 0.7500, dev loss: 0.6627\n",
            "epoch11 3528.0000 train acc: 0.7879,train loss: 0.6582, dev acc: 0.7500, dev loss: 0.6627\n",
            "epoch11 3529.0000 train acc: 0.7879,train loss: 0.6582, dev acc: 0.7500, dev loss: 0.6627\n",
            "epoch11 3530.0000 train acc: 0.7879,train loss: 0.6582, dev acc: 0.7500, dev loss: 0.6626\n",
            "epoch11 3531.0000 train acc: 0.7879,train loss: 0.6581, dev acc: 0.7500, dev loss: 0.6626\n",
            "epoch11 3532.0000 train acc: 0.7879,train loss: 0.6581, dev acc: 0.7500, dev loss: 0.6626\n",
            "epoch11 3533.0000 train acc: 0.7879,train loss: 0.6581, dev acc: 0.7500, dev loss: 0.6626\n",
            "epoch11 3534.0000 train acc: 0.7879,train loss: 0.6581, dev acc: 0.7500, dev loss: 0.6626\n",
            "epoch11 3535.0000 train acc: 0.7879,train loss: 0.6581, dev acc: 0.7500, dev loss: 0.6625\n",
            "epoch11 3536.0000 train acc: 0.7879,train loss: 0.6580, dev acc: 0.7500, dev loss: 0.6625\n",
            "epoch11 3537.0000 train acc: 0.7857,train loss: 0.6580, dev acc: 0.7500, dev loss: 0.6625\n",
            "epoch11 3538.0000 train acc: 0.7879,train loss: 0.6580, dev acc: 0.7500, dev loss: 0.6625\n",
            "epoch11 3539.0000 train acc: 0.7902,train loss: 0.6580, dev acc: 0.7500, dev loss: 0.6625\n",
            "epoch11 3540.0000 train acc: 0.7902,train loss: 0.6580, dev acc: 0.7500, dev loss: 0.6625\n",
            "epoch11 3541.0000 train acc: 0.7902,train loss: 0.6579, dev acc: 0.7500, dev loss: 0.6624\n",
            "epoch11 3542.0000 train acc: 0.7902,train loss: 0.6579, dev acc: 0.7500, dev loss: 0.6624\n",
            "epoch11 3543.0000 train acc: 0.7902,train loss: 0.6579, dev acc: 0.7500, dev loss: 0.6624\n",
            "epoch11 3544.0000 train acc: 0.7902,train loss: 0.6579, dev acc: 0.7500, dev loss: 0.6624\n",
            "epoch11 3545.0000 train acc: 0.7902,train loss: 0.6578, dev acc: 0.7500, dev loss: 0.6624\n",
            "epoch11 3546.0000 train acc: 0.7902,train loss: 0.6578, dev acc: 0.7500, dev loss: 0.6623\n",
            "epoch11 3547.0000 train acc: 0.7902,train loss: 0.6578, dev acc: 0.7500, dev loss: 0.6623\n",
            "epoch11 3548.0000 train acc: 0.7902,train loss: 0.6578, dev acc: 0.7500, dev loss: 0.6623\n",
            "epoch11 3549.0000 train acc: 0.7902,train loss: 0.6578, dev acc: 0.7500, dev loss: 0.6623\n",
            "epoch11 3550.0000 train acc: 0.7902,train loss: 0.6577, dev acc: 0.7500, dev loss: 0.6623\n",
            "epoch11 3551.0000 train acc: 0.7902,train loss: 0.6577, dev acc: 0.7500, dev loss: 0.6622\n",
            "epoch11 3552.0000 train acc: 0.7902,train loss: 0.6577, dev acc: 0.7500, dev loss: 0.6622\n",
            "epoch11 3553.0000 train acc: 0.7902,train loss: 0.6577, dev acc: 0.7500, dev loss: 0.6622\n",
            "epoch11 3554.0000 train acc: 0.7902,train loss: 0.6577, dev acc: 0.7500, dev loss: 0.6622\n",
            "epoch11 3555.0000 train acc: 0.7902,train loss: 0.6576, dev acc: 0.7500, dev loss: 0.6622\n",
            "epoch11 3556.0000 train acc: 0.7902,train loss: 0.6576, dev acc: 0.7500, dev loss: 0.6622\n",
            "epoch11 3557.0000 train acc: 0.7902,train loss: 0.6576, dev acc: 0.7500, dev loss: 0.6621\n",
            "epoch11 3558.0000 train acc: 0.7902,train loss: 0.6576, dev acc: 0.7500, dev loss: 0.6621\n",
            "epoch11 3559.0000 train acc: 0.7902,train loss: 0.6575, dev acc: 0.7500, dev loss: 0.6621\n",
            "epoch11 3560.0000 train acc: 0.7902,train loss: 0.6575, dev acc: 0.7500, dev loss: 0.6621\n",
            "epoch11 3561.0000 train acc: 0.7902,train loss: 0.6575, dev acc: 0.7500, dev loss: 0.6621\n",
            "epoch11 3562.0000 train acc: 0.7902,train loss: 0.6575, dev acc: 0.7500, dev loss: 0.6620\n",
            "epoch11 3563.0000 train acc: 0.7902,train loss: 0.6575, dev acc: 0.7500, dev loss: 0.6620\n",
            "epoch11 3564.0000 train acc: 0.7902,train loss: 0.6574, dev acc: 0.7500, dev loss: 0.6620\n",
            "epoch11 3565.0000 train acc: 0.7902,train loss: 0.6574, dev acc: 0.7500, dev loss: 0.6620\n",
            "epoch11 3566.0000 train acc: 0.7902,train loss: 0.6574, dev acc: 0.7500, dev loss: 0.6620\n",
            "epoch11 3567.0000 train acc: 0.7902,train loss: 0.6574, dev acc: 0.7500, dev loss: 0.6619\n",
            "epoch11 3568.0000 train acc: 0.7879,train loss: 0.6573, dev acc: 0.7500, dev loss: 0.6619\n",
            "epoch11 3569.0000 train acc: 0.7879,train loss: 0.6573, dev acc: 0.7500, dev loss: 0.6619\n",
            "epoch11 3570.0000 train acc: 0.7879,train loss: 0.6573, dev acc: 0.7500, dev loss: 0.6619\n",
            "epoch11 3571.0000 train acc: 0.7879,train loss: 0.6573, dev acc: 0.7500, dev loss: 0.6619\n",
            "epoch11 3572.0000 train acc: 0.7879,train loss: 0.6573, dev acc: 0.7500, dev loss: 0.6618\n",
            "epoch11 3573.0000 train acc: 0.7879,train loss: 0.6572, dev acc: 0.7500, dev loss: 0.6618\n",
            "epoch11 3574.0000 train acc: 0.7879,train loss: 0.6572, dev acc: 0.7500, dev loss: 0.6618\n",
            "epoch11 3575.0000 train acc: 0.7879,train loss: 0.6572, dev acc: 0.7500, dev loss: 0.6618\n",
            "epoch11 3576.0000 train acc: 0.7879,train loss: 0.6572, dev acc: 0.7500, dev loss: 0.6618\n",
            "epoch11 3577.0000 train acc: 0.7879,train loss: 0.6572, dev acc: 0.7500, dev loss: 0.6617\n",
            "epoch11 3578.0000 train acc: 0.7879,train loss: 0.6571, dev acc: 0.7500, dev loss: 0.6617\n",
            "epoch11 3579.0000 train acc: 0.7879,train loss: 0.6571, dev acc: 0.7500, dev loss: 0.6617\n",
            "epoch11 3580.0000 train acc: 0.7879,train loss: 0.6571, dev acc: 0.7500, dev loss: 0.6617\n",
            "epoch11 3581.0000 train acc: 0.7879,train loss: 0.6571, dev acc: 0.7500, dev loss: 0.6617\n",
            "epoch11 3582.0000 train acc: 0.7879,train loss: 0.6570, dev acc: 0.7500, dev loss: 0.6616\n",
            "epoch11 3583.0000 train acc: 0.7879,train loss: 0.6570, dev acc: 0.7500, dev loss: 0.6616\n",
            "epoch11 3584.0000 train acc: 0.7879,train loss: 0.6570, dev acc: 0.7500, dev loss: 0.6616\n",
            "epoch11 3585.0000 train acc: 0.7879,train loss: 0.6570, dev acc: 0.7500, dev loss: 0.6616\n",
            "epoch11 3586.0000 train acc: 0.7879,train loss: 0.6570, dev acc: 0.7500, dev loss: 0.6616\n",
            "epoch11 3587.0000 train acc: 0.7879,train loss: 0.6569, dev acc: 0.7500, dev loss: 0.6615\n",
            "epoch11 3588.0000 train acc: 0.7879,train loss: 0.6569, dev acc: 0.7500, dev loss: 0.6615\n",
            "epoch11 3589.0000 train acc: 0.7879,train loss: 0.6569, dev acc: 0.7500, dev loss: 0.6615\n",
            "epoch11 3590.0000 train acc: 0.7879,train loss: 0.6569, dev acc: 0.7500, dev loss: 0.6615\n",
            "epoch11 3591.0000 train acc: 0.7879,train loss: 0.6568, dev acc: 0.7500, dev loss: 0.6615\n",
            "epoch11 3592.0000 train acc: 0.7879,train loss: 0.6568, dev acc: 0.7500, dev loss: 0.6614\n",
            "epoch11 3593.0000 train acc: 0.7879,train loss: 0.6568, dev acc: 0.7500, dev loss: 0.6614\n",
            "epoch11 3594.0000 train acc: 0.7879,train loss: 0.6568, dev acc: 0.7500, dev loss: 0.6614\n",
            "epoch11 3595.0000 train acc: 0.7879,train loss: 0.6568, dev acc: 0.7500, dev loss: 0.6614\n",
            "epoch11 3596.0000 train acc: 0.7879,train loss: 0.6567, dev acc: 0.7500, dev loss: 0.6614\n",
            "epoch11 3597.0000 train acc: 0.7879,train loss: 0.6567, dev acc: 0.7500, dev loss: 0.6613\n",
            "epoch11 3598.0000 train acc: 0.7879,train loss: 0.6567, dev acc: 0.7500, dev loss: 0.6613\n",
            "epoch11 3599.0000 train acc: 0.7879,train loss: 0.6567, dev acc: 0.7500, dev loss: 0.6613\n",
            "epoch11 3600.0000 train acc: 0.7879,train loss: 0.6566, dev acc: 0.7500, dev loss: 0.6613\n",
            "epoch11 3601.0000 train acc: 0.7879,train loss: 0.6566, dev acc: 0.7500, dev loss: 0.6613\n",
            "epoch11 3602.0000 train acc: 0.7879,train loss: 0.6566, dev acc: 0.7500, dev loss: 0.6612\n",
            "epoch11 3603.0000 train acc: 0.7879,train loss: 0.6566, dev acc: 0.7500, dev loss: 0.6612\n",
            "epoch11 3604.0000 train acc: 0.7879,train loss: 0.6566, dev acc: 0.7500, dev loss: 0.6612\n",
            "epoch11 3605.0000 train acc: 0.7879,train loss: 0.6565, dev acc: 0.7500, dev loss: 0.6612\n",
            "epoch11 3606.0000 train acc: 0.7879,train loss: 0.6565, dev acc: 0.7500, dev loss: 0.6612\n",
            "epoch11 3607.0000 train acc: 0.7879,train loss: 0.6565, dev acc: 0.7500, dev loss: 0.6611\n",
            "epoch11 3608.0000 train acc: 0.7879,train loss: 0.6565, dev acc: 0.7500, dev loss: 0.6611\n",
            "epoch11 3609.0000 train acc: 0.7879,train loss: 0.6564, dev acc: 0.7500, dev loss: 0.6611\n",
            "epoch11 3610.0000 train acc: 0.7879,train loss: 0.6564, dev acc: 0.7500, dev loss: 0.6611\n",
            "epoch11 3611.0000 train acc: 0.7879,train loss: 0.6564, dev acc: 0.7500, dev loss: 0.6611\n",
            "epoch11 3612.0000 train acc: 0.7879,train loss: 0.6564, dev acc: 0.7500, dev loss: 0.6610\n",
            "epoch11 3613.0000 train acc: 0.7879,train loss: 0.6564, dev acc: 0.7500, dev loss: 0.6610\n",
            "epoch11 3614.0000 train acc: 0.7879,train loss: 0.6563, dev acc: 0.7500, dev loss: 0.6610\n",
            "epoch11 3615.0000 train acc: 0.7879,train loss: 0.6563, dev acc: 0.7500, dev loss: 0.6610\n",
            "epoch11 3616.0000 train acc: 0.7879,train loss: 0.6563, dev acc: 0.7500, dev loss: 0.6610\n",
            "epoch11 3617.0000 train acc: 0.7879,train loss: 0.6563, dev acc: 0.7500, dev loss: 0.6609\n",
            "epoch11 3618.0000 train acc: 0.7879,train loss: 0.6562, dev acc: 0.7500, dev loss: 0.6609\n",
            "epoch11 3619.0000 train acc: 0.7879,train loss: 0.6562, dev acc: 0.7500, dev loss: 0.6609\n",
            "epoch11 3620.0000 train acc: 0.7879,train loss: 0.6562, dev acc: 0.7500, dev loss: 0.6609\n",
            "epoch11 3621.0000 train acc: 0.7879,train loss: 0.6562, dev acc: 0.7500, dev loss: 0.6609\n",
            "epoch11 3622.0000 train acc: 0.7879,train loss: 0.6562, dev acc: 0.7500, dev loss: 0.6608\n",
            "epoch11 3623.0000 train acc: 0.7879,train loss: 0.6561, dev acc: 0.7500, dev loss: 0.6608\n",
            "epoch11 3624.0000 train acc: 0.7879,train loss: 0.6561, dev acc: 0.7500, dev loss: 0.6608\n",
            "epoch11 3625.0000 train acc: 0.7879,train loss: 0.6561, dev acc: 0.7500, dev loss: 0.6608\n",
            "epoch11 3626.0000 train acc: 0.7879,train loss: 0.6561, dev acc: 0.7500, dev loss: 0.6608\n",
            "epoch11 3627.0000 train acc: 0.7879,train loss: 0.6560, dev acc: 0.7500, dev loss: 0.6607\n",
            "epoch11 3628.0000 train acc: 0.7879,train loss: 0.6560, dev acc: 0.7500, dev loss: 0.6607\n",
            "epoch11 3629.0000 train acc: 0.7879,train loss: 0.6560, dev acc: 0.7500, dev loss: 0.6607\n",
            "epoch11 3630.0000 train acc: 0.7879,train loss: 0.6560, dev acc: 0.7500, dev loss: 0.6607\n",
            "epoch11 3631.0000 train acc: 0.7879,train loss: 0.6560, dev acc: 0.7500, dev loss: 0.6607\n",
            "epoch11 3632.0000 train acc: 0.7879,train loss: 0.6559, dev acc: 0.7500, dev loss: 0.6606\n",
            "epoch11 3633.0000 train acc: 0.7879,train loss: 0.6559, dev acc: 0.7500, dev loss: 0.6606\n",
            "epoch11 3634.0000 train acc: 0.7879,train loss: 0.6559, dev acc: 0.7500, dev loss: 0.6606\n",
            "epoch11 3635.0000 train acc: 0.7879,train loss: 0.6559, dev acc: 0.7500, dev loss: 0.6606\n",
            "epoch11 3636.0000 train acc: 0.7879,train loss: 0.6558, dev acc: 0.7500, dev loss: 0.6606\n",
            "epoch11 3637.0000 train acc: 0.7879,train loss: 0.6558, dev acc: 0.7500, dev loss: 0.6605\n",
            "epoch11 3638.0000 train acc: 0.7879,train loss: 0.6558, dev acc: 0.7500, dev loss: 0.6605\n",
            "epoch11 3639.0000 train acc: 0.7879,train loss: 0.6558, dev acc: 0.7500, dev loss: 0.6605\n",
            "epoch11 3640.0000 train acc: 0.7879,train loss: 0.6558, dev acc: 0.7500, dev loss: 0.6605\n",
            "epoch11 3641.0000 train acc: 0.7879,train loss: 0.6557, dev acc: 0.7500, dev loss: 0.6605\n",
            "epoch11 3642.0000 train acc: 0.7879,train loss: 0.6557, dev acc: 0.7500, dev loss: 0.6604\n",
            "epoch11 3643.0000 train acc: 0.7879,train loss: 0.6557, dev acc: 0.7500, dev loss: 0.6604\n",
            "epoch11 3644.0000 train acc: 0.7879,train loss: 0.6557, dev acc: 0.7500, dev loss: 0.6604\n",
            "epoch11 3645.0000 train acc: 0.7879,train loss: 0.6556, dev acc: 0.7500, dev loss: 0.6604\n",
            "epoch11 3646.0000 train acc: 0.7879,train loss: 0.6556, dev acc: 0.7500, dev loss: 0.6604\n",
            "epoch11 3647.0000 train acc: 0.7879,train loss: 0.6556, dev acc: 0.7500, dev loss: 0.6603\n",
            "epoch11 3648.0000 train acc: 0.7879,train loss: 0.6556, dev acc: 0.7500, dev loss: 0.6603\n",
            "epoch11 3649.0000 train acc: 0.7879,train loss: 0.6556, dev acc: 0.7500, dev loss: 0.6603\n",
            "epoch11 3650.0000 train acc: 0.7879,train loss: 0.6555, dev acc: 0.7500, dev loss: 0.6603\n",
            "epoch11 3651.0000 train acc: 0.7879,train loss: 0.6555, dev acc: 0.7500, dev loss: 0.6603\n",
            "epoch11 3652.0000 train acc: 0.7879,train loss: 0.6555, dev acc: 0.7500, dev loss: 0.6602\n",
            "epoch11 3653.0000 train acc: 0.7879,train loss: 0.6555, dev acc: 0.7500, dev loss: 0.6602\n",
            "epoch11 3654.0000 train acc: 0.7879,train loss: 0.6554, dev acc: 0.7500, dev loss: 0.6602\n",
            "epoch11 3655.0000 train acc: 0.7879,train loss: 0.6554, dev acc: 0.7500, dev loss: 0.6602\n",
            "epoch11 3656.0000 train acc: 0.7879,train loss: 0.6554, dev acc: 0.7500, dev loss: 0.6601\n",
            "epoch11 3657.0000 train acc: 0.7879,train loss: 0.6554, dev acc: 0.7500, dev loss: 0.6601\n",
            "epoch11 3658.0000 train acc: 0.7879,train loss: 0.6553, dev acc: 0.7500, dev loss: 0.6601\n",
            "epoch11 3659.0000 train acc: 0.7879,train loss: 0.6553, dev acc: 0.7500, dev loss: 0.6601\n",
            "epoch11 3660.0000 train acc: 0.7879,train loss: 0.6553, dev acc: 0.7500, dev loss: 0.6601\n",
            "epoch11 3661.0000 train acc: 0.7879,train loss: 0.6553, dev acc: 0.7500, dev loss: 0.6600\n",
            "epoch11 3662.0000 train acc: 0.7879,train loss: 0.6553, dev acc: 0.7500, dev loss: 0.6600\n",
            "epoch11 3663.0000 train acc: 0.7879,train loss: 0.6552, dev acc: 0.7500, dev loss: 0.6600\n",
            "epoch11 3664.0000 train acc: 0.7879,train loss: 0.6552, dev acc: 0.7500, dev loss: 0.6600\n",
            "epoch11 3665.0000 train acc: 0.7879,train loss: 0.6552, dev acc: 0.7500, dev loss: 0.6600\n",
            "epoch11 3666.0000 train acc: 0.7879,train loss: 0.6552, dev acc: 0.7500, dev loss: 0.6599\n",
            "epoch11 3667.0000 train acc: 0.7879,train loss: 0.6551, dev acc: 0.7500, dev loss: 0.6599\n",
            "epoch11 3668.0000 train acc: 0.7879,train loss: 0.6551, dev acc: 0.7500, dev loss: 0.6599\n",
            "epoch11 3669.0000 train acc: 0.7879,train loss: 0.6551, dev acc: 0.7500, dev loss: 0.6599\n",
            "epoch11 3670.0000 train acc: 0.7879,train loss: 0.6551, dev acc: 0.7500, dev loss: 0.6599\n",
            "epoch11 3671.0000 train acc: 0.7879,train loss: 0.6550, dev acc: 0.7500, dev loss: 0.6598\n",
            "epoch11 3672.0000 train acc: 0.7879,train loss: 0.6550, dev acc: 0.7500, dev loss: 0.6598\n",
            "epoch11 3673.0000 train acc: 0.7879,train loss: 0.6550, dev acc: 0.7500, dev loss: 0.6598\n",
            "epoch11 3674.0000 train acc: 0.7879,train loss: 0.6550, dev acc: 0.7500, dev loss: 0.6598\n",
            "epoch11 3675.0000 train acc: 0.7879,train loss: 0.6550, dev acc: 0.7500, dev loss: 0.6598\n",
            "epoch11 3676.0000 train acc: 0.7879,train loss: 0.6549, dev acc: 0.7500, dev loss: 0.6597\n",
            "epoch11 3677.0000 train acc: 0.7879,train loss: 0.6549, dev acc: 0.7500, dev loss: 0.6597\n",
            "epoch11 3678.0000 train acc: 0.7879,train loss: 0.6549, dev acc: 0.7500, dev loss: 0.6597\n",
            "epoch11 3679.0000 train acc: 0.7879,train loss: 0.6549, dev acc: 0.7500, dev loss: 0.6597\n",
            "epoch11 3680.0000 train acc: 0.7879,train loss: 0.6548, dev acc: 0.7500, dev loss: 0.6597\n",
            "epoch11 3681.0000 train acc: 0.7879,train loss: 0.6548, dev acc: 0.7500, dev loss: 0.6596\n",
            "epoch11 3682.0000 train acc: 0.7879,train loss: 0.6548, dev acc: 0.7500, dev loss: 0.6596\n",
            "epoch11 3683.0000 train acc: 0.7879,train loss: 0.6548, dev acc: 0.7500, dev loss: 0.6596\n",
            "epoch11 3684.0000 train acc: 0.7879,train loss: 0.6548, dev acc: 0.7500, dev loss: 0.6596\n",
            "epoch11 3685.0000 train acc: 0.7879,train loss: 0.6547, dev acc: 0.7500, dev loss: 0.6595\n",
            "epoch11 3686.0000 train acc: 0.7879,train loss: 0.6547, dev acc: 0.7344, dev loss: 0.6595\n",
            "epoch11 3687.0000 train acc: 0.7879,train loss: 0.6547, dev acc: 0.7344, dev loss: 0.6595\n",
            "epoch11 3688.0000 train acc: 0.7879,train loss: 0.6547, dev acc: 0.7344, dev loss: 0.6595\n",
            "epoch11 3689.0000 train acc: 0.7879,train loss: 0.6546, dev acc: 0.7344, dev loss: 0.6595\n",
            "epoch11 3690.0000 train acc: 0.7879,train loss: 0.6546, dev acc: 0.7344, dev loss: 0.6594\n",
            "epoch11 3691.0000 train acc: 0.7879,train loss: 0.6546, dev acc: 0.7344, dev loss: 0.6594\n",
            "epoch11 3692.0000 train acc: 0.7879,train loss: 0.6546, dev acc: 0.7344, dev loss: 0.6594\n",
            "epoch11 3693.0000 train acc: 0.7879,train loss: 0.6545, dev acc: 0.7344, dev loss: 0.6594\n",
            "epoch11 3694.0000 train acc: 0.7879,train loss: 0.6545, dev acc: 0.7344, dev loss: 0.6594\n",
            "epoch11 3695.0000 train acc: 0.7879,train loss: 0.6545, dev acc: 0.7344, dev loss: 0.6593\n",
            "epoch11 3696.0000 train acc: 0.7879,train loss: 0.6545, dev acc: 0.7344, dev loss: 0.6593\n",
            "epoch11 3697.0000 train acc: 0.7879,train loss: 0.6544, dev acc: 0.7344, dev loss: 0.6593\n",
            "epoch11 3698.0000 train acc: 0.7879,train loss: 0.6544, dev acc: 0.7344, dev loss: 0.6593\n",
            "epoch11 3699.0000 train acc: 0.7879,train loss: 0.6544, dev acc: 0.7344, dev loss: 0.6593\n",
            "epoch11 3700.0000 train acc: 0.7879,train loss: 0.6544, dev acc: 0.7344, dev loss: 0.6592\n",
            "epoch11 3701.0000 train acc: 0.7879,train loss: 0.6544, dev acc: 0.7344, dev loss: 0.6592\n",
            "epoch11 3702.0000 train acc: 0.7879,train loss: 0.6543, dev acc: 0.7344, dev loss: 0.6592\n",
            "epoch11 3703.0000 train acc: 0.7879,train loss: 0.6543, dev acc: 0.7344, dev loss: 0.6592\n",
            "epoch11 3704.0000 train acc: 0.7879,train loss: 0.6543, dev acc: 0.7344, dev loss: 0.6591\n",
            "epoch11 3705.0000 train acc: 0.7879,train loss: 0.6543, dev acc: 0.7344, dev loss: 0.6591\n",
            "epoch11 3706.0000 train acc: 0.7879,train loss: 0.6542, dev acc: 0.7344, dev loss: 0.6591\n",
            "epoch11 3707.0000 train acc: 0.7879,train loss: 0.6542, dev acc: 0.7344, dev loss: 0.6591\n",
            "epoch11 3708.0000 train acc: 0.7879,train loss: 0.6542, dev acc: 0.7344, dev loss: 0.6591\n",
            "epoch11 3709.0000 train acc: 0.7879,train loss: 0.6542, dev acc: 0.7344, dev loss: 0.6590\n",
            "epoch11 3710.0000 train acc: 0.7879,train loss: 0.6541, dev acc: 0.7344, dev loss: 0.6590\n",
            "epoch11 3711.0000 train acc: 0.7879,train loss: 0.6541, dev acc: 0.7500, dev loss: 0.6590\n",
            "epoch11 3712.0000 train acc: 0.7879,train loss: 0.6541, dev acc: 0.7500, dev loss: 0.6590\n",
            "epoch11 3713.0000 train acc: 0.7879,train loss: 0.6541, dev acc: 0.7500, dev loss: 0.6590\n",
            "epoch11 3714.0000 train acc: 0.7879,train loss: 0.6541, dev acc: 0.7500, dev loss: 0.6589\n",
            "epoch11 3715.0000 train acc: 0.7879,train loss: 0.6540, dev acc: 0.7500, dev loss: 0.6589\n",
            "epoch11 3716.0000 train acc: 0.7902,train loss: 0.6540, dev acc: 0.7500, dev loss: 0.6589\n",
            "epoch11 3717.0000 train acc: 0.7902,train loss: 0.6540, dev acc: 0.7500, dev loss: 0.6589\n",
            "epoch11 3718.0000 train acc: 0.7902,train loss: 0.6540, dev acc: 0.7500, dev loss: 0.6589\n",
            "epoch11 3719.0000 train acc: 0.7902,train loss: 0.6539, dev acc: 0.7500, dev loss: 0.6588\n",
            "epoch11 3720.0000 train acc: 0.7902,train loss: 0.6539, dev acc: 0.7500, dev loss: 0.6588\n",
            "epoch11 3721.0000 train acc: 0.7902,train loss: 0.6539, dev acc: 0.7500, dev loss: 0.6588\n",
            "epoch11 3722.0000 train acc: 0.7902,train loss: 0.6539, dev acc: 0.7500, dev loss: 0.6588\n",
            "epoch11 3723.0000 train acc: 0.7902,train loss: 0.6538, dev acc: 0.7500, dev loss: 0.6587\n",
            "epoch11 3724.0000 train acc: 0.7902,train loss: 0.6538, dev acc: 0.7500, dev loss: 0.6587\n",
            "epoch11 3725.0000 train acc: 0.7902,train loss: 0.6538, dev acc: 0.7500, dev loss: 0.6587\n",
            "epoch11 3726.0000 train acc: 0.7902,train loss: 0.6538, dev acc: 0.7500, dev loss: 0.6587\n",
            "epoch11 3727.0000 train acc: 0.7902,train loss: 0.6537, dev acc: 0.7500, dev loss: 0.6587\n",
            "epoch11 3728.0000 train acc: 0.7902,train loss: 0.6537, dev acc: 0.7500, dev loss: 0.6586\n",
            "epoch11 3729.0000 train acc: 0.7902,train loss: 0.6537, dev acc: 0.7500, dev loss: 0.6586\n",
            "epoch11 3730.0000 train acc: 0.7902,train loss: 0.6537, dev acc: 0.7500, dev loss: 0.6586\n",
            "epoch11 3731.0000 train acc: 0.7902,train loss: 0.6536, dev acc: 0.7500, dev loss: 0.6586\n",
            "epoch11 3732.0000 train acc: 0.7924,train loss: 0.6536, dev acc: 0.7500, dev loss: 0.6586\n",
            "epoch11 3733.0000 train acc: 0.7924,train loss: 0.6536, dev acc: 0.7500, dev loss: 0.6585\n",
            "epoch11 3734.0000 train acc: 0.7924,train loss: 0.6536, dev acc: 0.7500, dev loss: 0.6585\n",
            "epoch11 3735.0000 train acc: 0.7924,train loss: 0.6536, dev acc: 0.7500, dev loss: 0.6585\n",
            "epoch11 3736.0000 train acc: 0.7924,train loss: 0.6535, dev acc: 0.7500, dev loss: 0.6585\n",
            "epoch11 3737.0000 train acc: 0.7924,train loss: 0.6535, dev acc: 0.7500, dev loss: 0.6584\n",
            "epoch11 3738.0000 train acc: 0.7924,train loss: 0.6535, dev acc: 0.7500, dev loss: 0.6584\n",
            "epoch11 3739.0000 train acc: 0.7924,train loss: 0.6535, dev acc: 0.7500, dev loss: 0.6584\n",
            "epoch11 3740.0000 train acc: 0.7924,train loss: 0.6534, dev acc: 0.7500, dev loss: 0.6584\n",
            "epoch11 3741.0000 train acc: 0.7924,train loss: 0.6534, dev acc: 0.7500, dev loss: 0.6584\n",
            "epoch11 3742.0000 train acc: 0.7924,train loss: 0.6534, dev acc: 0.7500, dev loss: 0.6583\n",
            "epoch11 3743.0000 train acc: 0.7924,train loss: 0.6534, dev acc: 0.7500, dev loss: 0.6583\n",
            "epoch11 3744.0000 train acc: 0.7924,train loss: 0.6533, dev acc: 0.7500, dev loss: 0.6583\n",
            "epoch11 3745.0000 train acc: 0.7924,train loss: 0.6533, dev acc: 0.7500, dev loss: 0.6583\n",
            "epoch11 3746.0000 train acc: 0.7924,train loss: 0.6533, dev acc: 0.7500, dev loss: 0.6583\n",
            "epoch11 3747.0000 train acc: 0.7924,train loss: 0.6533, dev acc: 0.7500, dev loss: 0.6582\n",
            "epoch11 3748.0000 train acc: 0.7924,train loss: 0.6532, dev acc: 0.7500, dev loss: 0.6582\n",
            "epoch11 3749.0000 train acc: 0.7924,train loss: 0.6532, dev acc: 0.7500, dev loss: 0.6582\n",
            "epoch11 3750.0000 train acc: 0.7924,train loss: 0.6532, dev acc: 0.7500, dev loss: 0.6582\n",
            "epoch11 3751.0000 train acc: 0.7924,train loss: 0.6532, dev acc: 0.7500, dev loss: 0.6581\n",
            "epoch11 3752.0000 train acc: 0.7924,train loss: 0.6531, dev acc: 0.7500, dev loss: 0.6581\n",
            "epoch11 3753.0000 train acc: 0.7924,train loss: 0.6531, dev acc: 0.7500, dev loss: 0.6581\n",
            "epoch11 3754.0000 train acc: 0.7924,train loss: 0.6531, dev acc: 0.7500, dev loss: 0.6581\n",
            "epoch11 3755.0000 train acc: 0.7924,train loss: 0.6531, dev acc: 0.7500, dev loss: 0.6581\n",
            "epoch11 3756.0000 train acc: 0.7924,train loss: 0.6531, dev acc: 0.7500, dev loss: 0.6580\n",
            "epoch11 3757.0000 train acc: 0.7924,train loss: 0.6530, dev acc: 0.7500, dev loss: 0.6580\n",
            "epoch11 3758.0000 train acc: 0.7924,train loss: 0.6530, dev acc: 0.7500, dev loss: 0.6580\n",
            "epoch11 3759.0000 train acc: 0.7924,train loss: 0.6530, dev acc: 0.7500, dev loss: 0.6580\n",
            "epoch11 3760.0000 train acc: 0.7924,train loss: 0.6530, dev acc: 0.7500, dev loss: 0.6579\n",
            "epoch11 3761.0000 train acc: 0.7924,train loss: 0.6529, dev acc: 0.7500, dev loss: 0.6579\n",
            "epoch11 3762.0000 train acc: 0.7924,train loss: 0.6529, dev acc: 0.7500, dev loss: 0.6579\n",
            "epoch11 3763.0000 train acc: 0.7924,train loss: 0.6529, dev acc: 0.7500, dev loss: 0.6579\n",
            "epoch11 3764.0000 train acc: 0.7924,train loss: 0.6529, dev acc: 0.7500, dev loss: 0.6579\n",
            "epoch11 3765.0000 train acc: 0.7924,train loss: 0.6528, dev acc: 0.7500, dev loss: 0.6578\n",
            "epoch11 3766.0000 train acc: 0.7924,train loss: 0.6528, dev acc: 0.7500, dev loss: 0.6578\n",
            "epoch11 3767.0000 train acc: 0.7924,train loss: 0.6528, dev acc: 0.7500, dev loss: 0.6578\n",
            "epoch11 3768.0000 train acc: 0.7924,train loss: 0.6528, dev acc: 0.7500, dev loss: 0.6578\n",
            "epoch11 3769.0000 train acc: 0.7924,train loss: 0.6527, dev acc: 0.7500, dev loss: 0.6577\n",
            "epoch11 3770.0000 train acc: 0.7924,train loss: 0.6527, dev acc: 0.7500, dev loss: 0.6577\n",
            "epoch11 3771.0000 train acc: 0.7924,train loss: 0.6527, dev acc: 0.7500, dev loss: 0.6577\n",
            "epoch11 3772.0000 train acc: 0.7924,train loss: 0.6527, dev acc: 0.7500, dev loss: 0.6577\n",
            "epoch11 3773.0000 train acc: 0.7924,train loss: 0.6526, dev acc: 0.7500, dev loss: 0.6577\n",
            "epoch11 3774.0000 train acc: 0.7924,train loss: 0.6526, dev acc: 0.7500, dev loss: 0.6576\n",
            "epoch11 3775.0000 train acc: 0.7924,train loss: 0.6526, dev acc: 0.7500, dev loss: 0.6576\n",
            "epoch11 3776.0000 train acc: 0.7924,train loss: 0.6526, dev acc: 0.7500, dev loss: 0.6576\n",
            "epoch11 3777.0000 train acc: 0.7924,train loss: 0.6525, dev acc: 0.7500, dev loss: 0.6576\n",
            "epoch11 3778.0000 train acc: 0.7924,train loss: 0.6525, dev acc: 0.7500, dev loss: 0.6575\n",
            "epoch11 3779.0000 train acc: 0.7924,train loss: 0.6525, dev acc: 0.7500, dev loss: 0.6575\n",
            "epoch11 3780.0000 train acc: 0.7924,train loss: 0.6525, dev acc: 0.7500, dev loss: 0.6575\n",
            "epoch11 3781.0000 train acc: 0.7924,train loss: 0.6524, dev acc: 0.7500, dev loss: 0.6575\n",
            "epoch11 3782.0000 train acc: 0.7924,train loss: 0.6524, dev acc: 0.7500, dev loss: 0.6574\n",
            "epoch11 3783.0000 train acc: 0.7924,train loss: 0.6524, dev acc: 0.7500, dev loss: 0.6574\n",
            "epoch11 3784.0000 train acc: 0.7924,train loss: 0.6524, dev acc: 0.7500, dev loss: 0.6574\n",
            "epoch11 3785.0000 train acc: 0.7924,train loss: 0.6523, dev acc: 0.7500, dev loss: 0.6574\n",
            "epoch11 3786.0000 train acc: 0.7924,train loss: 0.6523, dev acc: 0.7500, dev loss: 0.6574\n",
            "epoch11 3787.0000 train acc: 0.7924,train loss: 0.6523, dev acc: 0.7500, dev loss: 0.6573\n",
            "epoch11 3788.0000 train acc: 0.7924,train loss: 0.6523, dev acc: 0.7500, dev loss: 0.6573\n",
            "epoch11 3789.0000 train acc: 0.7924,train loss: 0.6522, dev acc: 0.7500, dev loss: 0.6573\n",
            "epoch11 3790.0000 train acc: 0.7924,train loss: 0.6522, dev acc: 0.7500, dev loss: 0.6573\n",
            "epoch11 3791.0000 train acc: 0.7924,train loss: 0.6522, dev acc: 0.7500, dev loss: 0.6572\n",
            "epoch11 3792.0000 train acc: 0.7924,train loss: 0.6522, dev acc: 0.7500, dev loss: 0.6572\n",
            "epoch11 3793.0000 train acc: 0.7924,train loss: 0.6521, dev acc: 0.7500, dev loss: 0.6572\n",
            "epoch11 3794.0000 train acc: 0.7924,train loss: 0.6521, dev acc: 0.7500, dev loss: 0.6572\n",
            "epoch11 3795.0000 train acc: 0.7924,train loss: 0.6521, dev acc: 0.7500, dev loss: 0.6571\n",
            "epoch11 3796.0000 train acc: 0.7924,train loss: 0.6521, dev acc: 0.7500, dev loss: 0.6571\n",
            "epoch11 3797.0000 train acc: 0.7924,train loss: 0.6521, dev acc: 0.7500, dev loss: 0.6571\n",
            "epoch11 3798.0000 train acc: 0.7924,train loss: 0.6520, dev acc: 0.7500, dev loss: 0.6571\n",
            "epoch11 3799.0000 train acc: 0.7924,train loss: 0.6520, dev acc: 0.7500, dev loss: 0.6571\n",
            "epoch11 3800.0000 train acc: 0.7924,train loss: 0.6520, dev acc: 0.7500, dev loss: 0.6570\n",
            "epoch11 3801.0000 train acc: 0.7924,train loss: 0.6520, dev acc: 0.7500, dev loss: 0.6570\n",
            "epoch11 3802.0000 train acc: 0.7924,train loss: 0.6519, dev acc: 0.7500, dev loss: 0.6570\n",
            "epoch11 3803.0000 train acc: 0.7924,train loss: 0.6519, dev acc: 0.7500, dev loss: 0.6570\n",
            "epoch11 3804.0000 train acc: 0.7924,train loss: 0.6519, dev acc: 0.7500, dev loss: 0.6569\n",
            "epoch11 3805.0000 train acc: 0.7924,train loss: 0.6519, dev acc: 0.7500, dev loss: 0.6569\n",
            "epoch11 3806.0000 train acc: 0.7924,train loss: 0.6518, dev acc: 0.7500, dev loss: 0.6569\n",
            "epoch11 3807.0000 train acc: 0.7924,train loss: 0.6518, dev acc: 0.7500, dev loss: 0.6569\n",
            "epoch11 3808.0000 train acc: 0.7924,train loss: 0.6518, dev acc: 0.7500, dev loss: 0.6568\n",
            "epoch11 3809.0000 train acc: 0.7924,train loss: 0.6518, dev acc: 0.7500, dev loss: 0.6568\n",
            "epoch11 3810.0000 train acc: 0.7924,train loss: 0.6517, dev acc: 0.7500, dev loss: 0.6568\n",
            "epoch11 3811.0000 train acc: 0.7924,train loss: 0.6517, dev acc: 0.7500, dev loss: 0.6568\n",
            "epoch11 3812.0000 train acc: 0.7924,train loss: 0.6517, dev acc: 0.7500, dev loss: 0.6568\n",
            "epoch11 3813.0000 train acc: 0.7924,train loss: 0.6517, dev acc: 0.7500, dev loss: 0.6567\n",
            "epoch11 3814.0000 train acc: 0.7924,train loss: 0.6516, dev acc: 0.7500, dev loss: 0.6567\n",
            "epoch11 3815.0000 train acc: 0.7924,train loss: 0.6516, dev acc: 0.7500, dev loss: 0.6567\n",
            "epoch11 3816.0000 train acc: 0.7924,train loss: 0.6516, dev acc: 0.7500, dev loss: 0.6567\n",
            "epoch11 3817.0000 train acc: 0.7946,train loss: 0.6516, dev acc: 0.7500, dev loss: 0.6566\n",
            "epoch11 3818.0000 train acc: 0.7946,train loss: 0.6515, dev acc: 0.7500, dev loss: 0.6566\n",
            "epoch11 3819.0000 train acc: 0.7946,train loss: 0.6515, dev acc: 0.7500, dev loss: 0.6566\n",
            "epoch11 3820.0000 train acc: 0.7946,train loss: 0.6515, dev acc: 0.7500, dev loss: 0.6566\n",
            "epoch11 3821.0000 train acc: 0.7946,train loss: 0.6515, dev acc: 0.7500, dev loss: 0.6565\n",
            "epoch11 3822.0000 train acc: 0.7946,train loss: 0.6514, dev acc: 0.7500, dev loss: 0.6565\n",
            "epoch11 3823.0000 train acc: 0.7946,train loss: 0.6514, dev acc: 0.7500, dev loss: 0.6565\n",
            "epoch11 3824.0000 train acc: 0.7946,train loss: 0.6514, dev acc: 0.7500, dev loss: 0.6565\n",
            "epoch11 3825.0000 train acc: 0.7946,train loss: 0.6514, dev acc: 0.7500, dev loss: 0.6564\n",
            "epoch11 3826.0000 train acc: 0.7946,train loss: 0.6513, dev acc: 0.7500, dev loss: 0.6564\n",
            "epoch11 3827.0000 train acc: 0.7946,train loss: 0.6513, dev acc: 0.7500, dev loss: 0.6564\n",
            "epoch11 3828.0000 train acc: 0.7946,train loss: 0.6513, dev acc: 0.7500, dev loss: 0.6564\n",
            "epoch11 3829.0000 train acc: 0.7946,train loss: 0.6513, dev acc: 0.7500, dev loss: 0.6564\n",
            "epoch11 3830.0000 train acc: 0.7946,train loss: 0.6512, dev acc: 0.7500, dev loss: 0.6563\n",
            "epoch11 3831.0000 train acc: 0.7946,train loss: 0.6512, dev acc: 0.7500, dev loss: 0.6563\n",
            "epoch11 3832.0000 train acc: 0.7946,train loss: 0.6512, dev acc: 0.7500, dev loss: 0.6563\n",
            "epoch11 3833.0000 train acc: 0.7946,train loss: 0.6512, dev acc: 0.7500, dev loss: 0.6563\n",
            "epoch11 3834.0000 train acc: 0.7946,train loss: 0.6511, dev acc: 0.7500, dev loss: 0.6562\n",
            "epoch11 3835.0000 train acc: 0.7946,train loss: 0.6511, dev acc: 0.7500, dev loss: 0.6562\n",
            "epoch11 3836.0000 train acc: 0.7946,train loss: 0.6511, dev acc: 0.7500, dev loss: 0.6562\n",
            "epoch11 3837.0000 train acc: 0.7946,train loss: 0.6511, dev acc: 0.7500, dev loss: 0.6562\n",
            "epoch11 3838.0000 train acc: 0.7946,train loss: 0.6510, dev acc: 0.7500, dev loss: 0.6561\n",
            "epoch11 3839.0000 train acc: 0.7946,train loss: 0.6510, dev acc: 0.7500, dev loss: 0.6561\n",
            "epoch11 3840.0000 train acc: 0.7946,train loss: 0.6510, dev acc: 0.7500, dev loss: 0.6561\n",
            "epoch11 3841.0000 train acc: 0.7946,train loss: 0.6510, dev acc: 0.7500, dev loss: 0.6561\n",
            "epoch11 3842.0000 train acc: 0.7946,train loss: 0.6509, dev acc: 0.7500, dev loss: 0.6560\n",
            "epoch11 3843.0000 train acc: 0.7946,train loss: 0.6509, dev acc: 0.7500, dev loss: 0.6560\n",
            "epoch11 3844.0000 train acc: 0.7946,train loss: 0.6509, dev acc: 0.7500, dev loss: 0.6560\n",
            "epoch11 3845.0000 train acc: 0.7946,train loss: 0.6509, dev acc: 0.7500, dev loss: 0.6560\n",
            "epoch11 3846.0000 train acc: 0.7946,train loss: 0.6508, dev acc: 0.7500, dev loss: 0.6560\n",
            "epoch11 3847.0000 train acc: 0.7946,train loss: 0.6508, dev acc: 0.7500, dev loss: 0.6559\n",
            "epoch11 3848.0000 train acc: 0.7946,train loss: 0.6508, dev acc: 0.7500, dev loss: 0.6559\n",
            "epoch11 3849.0000 train acc: 0.7946,train loss: 0.6507, dev acc: 0.7500, dev loss: 0.6559\n",
            "epoch11 3850.0000 train acc: 0.7946,train loss: 0.6507, dev acc: 0.7500, dev loss: 0.6559\n",
            "epoch11 3851.0000 train acc: 0.7946,train loss: 0.6507, dev acc: 0.7500, dev loss: 0.6558\n",
            "epoch11 3852.0000 train acc: 0.7946,train loss: 0.6507, dev acc: 0.7500, dev loss: 0.6558\n",
            "epoch11 3853.0000 train acc: 0.7946,train loss: 0.6506, dev acc: 0.7500, dev loss: 0.6558\n",
            "epoch11 3854.0000 train acc: 0.7946,train loss: 0.6506, dev acc: 0.7500, dev loss: 0.6558\n",
            "epoch11 3855.0000 train acc: 0.7946,train loss: 0.6506, dev acc: 0.7500, dev loss: 0.6557\n",
            "epoch11 3856.0000 train acc: 0.7946,train loss: 0.6506, dev acc: 0.7500, dev loss: 0.6557\n",
            "epoch11 3857.0000 train acc: 0.7946,train loss: 0.6505, dev acc: 0.7500, dev loss: 0.6557\n",
            "epoch11 3858.0000 train acc: 0.7946,train loss: 0.6505, dev acc: 0.7500, dev loss: 0.6557\n",
            "epoch11 3859.0000 train acc: 0.7946,train loss: 0.6505, dev acc: 0.7500, dev loss: 0.6556\n",
            "epoch11 3860.0000 train acc: 0.7946,train loss: 0.6505, dev acc: 0.7500, dev loss: 0.6556\n",
            "epoch11 3861.0000 train acc: 0.7946,train loss: 0.6504, dev acc: 0.7500, dev loss: 0.6556\n",
            "epoch11 3862.0000 train acc: 0.7946,train loss: 0.6504, dev acc: 0.7500, dev loss: 0.6556\n",
            "epoch11 3863.0000 train acc: 0.7946,train loss: 0.6504, dev acc: 0.7500, dev loss: 0.6555\n",
            "epoch11 3864.0000 train acc: 0.7946,train loss: 0.6504, dev acc: 0.7500, dev loss: 0.6555\n",
            "epoch11 3865.0000 train acc: 0.7946,train loss: 0.6503, dev acc: 0.7500, dev loss: 0.6555\n",
            "epoch11 3866.0000 train acc: 0.7946,train loss: 0.6503, dev acc: 0.7500, dev loss: 0.6555\n",
            "epoch11 3867.0000 train acc: 0.7946,train loss: 0.6503, dev acc: 0.7500, dev loss: 0.6555\n",
            "epoch11 3868.0000 train acc: 0.7946,train loss: 0.6503, dev acc: 0.7500, dev loss: 0.6554\n",
            "epoch11 3869.0000 train acc: 0.7946,train loss: 0.6502, dev acc: 0.7500, dev loss: 0.6554\n",
            "epoch11 3870.0000 train acc: 0.7946,train loss: 0.6502, dev acc: 0.7500, dev loss: 0.6554\n",
            "epoch11 3871.0000 train acc: 0.7946,train loss: 0.6502, dev acc: 0.7500, dev loss: 0.6554\n",
            "epoch11 3872.0000 train acc: 0.7946,train loss: 0.6502, dev acc: 0.7500, dev loss: 0.6553\n",
            "epoch11 3873.0000 train acc: 0.7946,train loss: 0.6501, dev acc: 0.7500, dev loss: 0.6553\n",
            "epoch11 3874.0000 train acc: 0.7946,train loss: 0.6501, dev acc: 0.7500, dev loss: 0.6553\n",
            "epoch11 3875.0000 train acc: 0.7946,train loss: 0.6501, dev acc: 0.7500, dev loss: 0.6553\n",
            "epoch11 3876.0000 train acc: 0.7946,train loss: 0.6501, dev acc: 0.7500, dev loss: 0.6552\n",
            "epoch11 3877.0000 train acc: 0.7946,train loss: 0.6500, dev acc: 0.7500, dev loss: 0.6552\n",
            "epoch11 3878.0000 train acc: 0.7946,train loss: 0.6500, dev acc: 0.7500, dev loss: 0.6552\n",
            "epoch11 3879.0000 train acc: 0.7946,train loss: 0.6500, dev acc: 0.7500, dev loss: 0.6552\n",
            "epoch11 3880.0000 train acc: 0.7946,train loss: 0.6500, dev acc: 0.7500, dev loss: 0.6551\n",
            "epoch11 3881.0000 train acc: 0.7946,train loss: 0.6499, dev acc: 0.7500, dev loss: 0.6551\n",
            "epoch11 3882.0000 train acc: 0.7946,train loss: 0.6499, dev acc: 0.7500, dev loss: 0.6551\n",
            "epoch11 3883.0000 train acc: 0.7946,train loss: 0.6499, dev acc: 0.7500, dev loss: 0.6551\n",
            "epoch11 3884.0000 train acc: 0.7946,train loss: 0.6499, dev acc: 0.7500, dev loss: 0.6550\n",
            "epoch11 3885.0000 train acc: 0.7946,train loss: 0.6498, dev acc: 0.7500, dev loss: 0.6550\n",
            "epoch11 3886.0000 train acc: 0.7946,train loss: 0.6498, dev acc: 0.7500, dev loss: 0.6550\n",
            "epoch11 3887.0000 train acc: 0.7946,train loss: 0.6498, dev acc: 0.7500, dev loss: 0.6550\n",
            "epoch11 3888.0000 train acc: 0.7946,train loss: 0.6498, dev acc: 0.7500, dev loss: 0.6549\n",
            "epoch11 3889.0000 train acc: 0.7946,train loss: 0.6497, dev acc: 0.7500, dev loss: 0.6549\n",
            "epoch11 3890.0000 train acc: 0.7946,train loss: 0.6497, dev acc: 0.7500, dev loss: 0.6549\n",
            "epoch11 3891.0000 train acc: 0.7946,train loss: 0.6497, dev acc: 0.7500, dev loss: 0.6549\n",
            "epoch11 3892.0000 train acc: 0.7946,train loss: 0.6496, dev acc: 0.7500, dev loss: 0.6548\n",
            "epoch11 3893.0000 train acc: 0.7946,train loss: 0.6496, dev acc: 0.7500, dev loss: 0.6548\n",
            "epoch11 3894.0000 train acc: 0.7946,train loss: 0.6496, dev acc: 0.7500, dev loss: 0.6548\n",
            "epoch11 3895.0000 train acc: 0.7946,train loss: 0.6496, dev acc: 0.7500, dev loss: 0.6548\n",
            "epoch11 3896.0000 train acc: 0.7946,train loss: 0.6495, dev acc: 0.7500, dev loss: 0.6548\n",
            "epoch11 3897.0000 train acc: 0.7946,train loss: 0.6495, dev acc: 0.7500, dev loss: 0.6547\n",
            "epoch11 3898.0000 train acc: 0.7946,train loss: 0.6495, dev acc: 0.7500, dev loss: 0.6547\n",
            "epoch11 3899.0000 train acc: 0.7946,train loss: 0.6495, dev acc: 0.7500, dev loss: 0.6547\n",
            "epoch11 3900.0000 train acc: 0.7946,train loss: 0.6494, dev acc: 0.7500, dev loss: 0.6547\n",
            "epoch11 3901.0000 train acc: 0.7946,train loss: 0.6494, dev acc: 0.7500, dev loss: 0.6546\n",
            "epoch11 3902.0000 train acc: 0.7946,train loss: 0.6494, dev acc: 0.7500, dev loss: 0.6546\n",
            "epoch11 3903.0000 train acc: 0.7946,train loss: 0.6494, dev acc: 0.7500, dev loss: 0.6546\n",
            "epoch11 3904.0000 train acc: 0.7946,train loss: 0.6493, dev acc: 0.7500, dev loss: 0.6546\n",
            "epoch11 3905.0000 train acc: 0.7946,train loss: 0.6493, dev acc: 0.7500, dev loss: 0.6545\n",
            "epoch11 3906.0000 train acc: 0.7946,train loss: 0.6493, dev acc: 0.7500, dev loss: 0.6545\n",
            "epoch11 3907.0000 train acc: 0.7946,train loss: 0.6493, dev acc: 0.7500, dev loss: 0.6545\n",
            "epoch11 3908.0000 train acc: 0.7946,train loss: 0.6492, dev acc: 0.7500, dev loss: 0.6545\n",
            "epoch11 3909.0000 train acc: 0.7946,train loss: 0.6492, dev acc: 0.7500, dev loss: 0.6544\n",
            "epoch11 3910.0000 train acc: 0.7946,train loss: 0.6492, dev acc: 0.7500, dev loss: 0.6544\n",
            "epoch11 3911.0000 train acc: 0.7946,train loss: 0.6492, dev acc: 0.7500, dev loss: 0.6544\n",
            "epoch11 3912.0000 train acc: 0.7946,train loss: 0.6491, dev acc: 0.7500, dev loss: 0.6544\n",
            "epoch11 3913.0000 train acc: 0.7946,train loss: 0.6491, dev acc: 0.7500, dev loss: 0.6543\n",
            "epoch11 3914.0000 train acc: 0.7946,train loss: 0.6491, dev acc: 0.7500, dev loss: 0.6543\n",
            "epoch11 3915.0000 train acc: 0.7946,train loss: 0.6491, dev acc: 0.7500, dev loss: 0.6543\n",
            "epoch11 3916.0000 train acc: 0.7946,train loss: 0.6490, dev acc: 0.7500, dev loss: 0.6543\n",
            "epoch11 3917.0000 train acc: 0.7946,train loss: 0.6490, dev acc: 0.7500, dev loss: 0.6542\n",
            "epoch11 3918.0000 train acc: 0.7946,train loss: 0.6490, dev acc: 0.7500, dev loss: 0.6542\n",
            "epoch11 3919.0000 train acc: 0.7946,train loss: 0.6489, dev acc: 0.7500, dev loss: 0.6542\n",
            "epoch11 3920.0000 train acc: 0.7946,train loss: 0.6489, dev acc: 0.7500, dev loss: 0.6542\n",
            "epoch11 3921.0000 train acc: 0.7946,train loss: 0.6489, dev acc: 0.7500, dev loss: 0.6541\n",
            "epoch11 3922.0000 train acc: 0.7946,train loss: 0.6489, dev acc: 0.7500, dev loss: 0.6541\n",
            "epoch11 3923.0000 train acc: 0.7946,train loss: 0.6488, dev acc: 0.7500, dev loss: 0.6541\n",
            "epoch11 3924.0000 train acc: 0.7946,train loss: 0.6488, dev acc: 0.7500, dev loss: 0.6541\n",
            "epoch11 3925.0000 train acc: 0.7946,train loss: 0.6488, dev acc: 0.7500, dev loss: 0.6540\n",
            "epoch11 3926.0000 train acc: 0.7946,train loss: 0.6488, dev acc: 0.7500, dev loss: 0.6540\n",
            "epoch11 3927.0000 train acc: 0.7946,train loss: 0.6487, dev acc: 0.7500, dev loss: 0.6540\n",
            "epoch11 3928.0000 train acc: 0.7946,train loss: 0.6487, dev acc: 0.7500, dev loss: 0.6540\n",
            "epoch11 3929.0000 train acc: 0.7946,train loss: 0.6487, dev acc: 0.7500, dev loss: 0.6539\n",
            "epoch11 3930.0000 train acc: 0.7946,train loss: 0.6487, dev acc: 0.7500, dev loss: 0.6539\n",
            "epoch11 3931.0000 train acc: 0.7946,train loss: 0.6486, dev acc: 0.7500, dev loss: 0.6539\n",
            "epoch11 3932.0000 train acc: 0.7946,train loss: 0.6486, dev acc: 0.7500, dev loss: 0.6539\n",
            "epoch11 3933.0000 train acc: 0.7946,train loss: 0.6486, dev acc: 0.7500, dev loss: 0.6539\n",
            "epoch11 3934.0000 train acc: 0.7946,train loss: 0.6486, dev acc: 0.7500, dev loss: 0.6538\n",
            "epoch11 3935.0000 train acc: 0.7946,train loss: 0.6485, dev acc: 0.7500, dev loss: 0.6538\n",
            "epoch11 3936.0000 train acc: 0.7946,train loss: 0.6485, dev acc: 0.7500, dev loss: 0.6538\n",
            "epoch11 3937.0000 train acc: 0.7946,train loss: 0.6485, dev acc: 0.7500, dev loss: 0.6538\n",
            "epoch11 3938.0000 train acc: 0.7946,train loss: 0.6484, dev acc: 0.7500, dev loss: 0.6537\n",
            "epoch11 3939.0000 train acc: 0.7946,train loss: 0.6484, dev acc: 0.7500, dev loss: 0.6537\n",
            "epoch11 3940.0000 train acc: 0.7946,train loss: 0.6484, dev acc: 0.7500, dev loss: 0.6537\n",
            "epoch11 3941.0000 train acc: 0.7946,train loss: 0.6484, dev acc: 0.7500, dev loss: 0.6537\n",
            "epoch11 3942.0000 train acc: 0.7946,train loss: 0.6483, dev acc: 0.7500, dev loss: 0.6536\n",
            "epoch11 3943.0000 train acc: 0.7946,train loss: 0.6483, dev acc: 0.7500, dev loss: 0.6536\n",
            "epoch11 3944.0000 train acc: 0.7946,train loss: 0.6483, dev acc: 0.7500, dev loss: 0.6536\n",
            "epoch11 3945.0000 train acc: 0.7946,train loss: 0.6483, dev acc: 0.7500, dev loss: 0.6536\n",
            "epoch11 3946.0000 train acc: 0.7946,train loss: 0.6482, dev acc: 0.7500, dev loss: 0.6535\n",
            "epoch11 3947.0000 train acc: 0.7946,train loss: 0.6482, dev acc: 0.7500, dev loss: 0.6535\n",
            "epoch11 3948.0000 train acc: 0.7946,train loss: 0.6482, dev acc: 0.7500, dev loss: 0.6535\n",
            "epoch11 3949.0000 train acc: 0.7946,train loss: 0.6482, dev acc: 0.7500, dev loss: 0.6535\n",
            "epoch11 3950.0000 train acc: 0.7946,train loss: 0.6481, dev acc: 0.7500, dev loss: 0.6534\n",
            "epoch11 3951.0000 train acc: 0.7946,train loss: 0.6481, dev acc: 0.7500, dev loss: 0.6534\n",
            "epoch11 3952.0000 train acc: 0.7946,train loss: 0.6481, dev acc: 0.7500, dev loss: 0.6534\n",
            "epoch11 3953.0000 train acc: 0.7946,train loss: 0.6480, dev acc: 0.7500, dev loss: 0.6534\n",
            "epoch11 3954.0000 train acc: 0.7946,train loss: 0.6480, dev acc: 0.7500, dev loss: 0.6533\n",
            "epoch11 3955.0000 train acc: 0.7946,train loss: 0.6480, dev acc: 0.7500, dev loss: 0.6533\n",
            "epoch11 3956.0000 train acc: 0.7946,train loss: 0.6480, dev acc: 0.7500, dev loss: 0.6533\n",
            "epoch11 3957.0000 train acc: 0.7946,train loss: 0.6479, dev acc: 0.7500, dev loss: 0.6533\n",
            "epoch11 3958.0000 train acc: 0.7946,train loss: 0.6479, dev acc: 0.7500, dev loss: 0.6532\n",
            "epoch11 3959.0000 train acc: 0.7946,train loss: 0.6479, dev acc: 0.7500, dev loss: 0.6532\n",
            "epoch11 3960.0000 train acc: 0.7946,train loss: 0.6479, dev acc: 0.7500, dev loss: 0.6532\n",
            "epoch11 3961.0000 train acc: 0.7946,train loss: 0.6478, dev acc: 0.7500, dev loss: 0.6532\n",
            "epoch11 3962.0000 train acc: 0.7946,train loss: 0.6478, dev acc: 0.7500, dev loss: 0.6531\n",
            "epoch11 3963.0000 train acc: 0.7946,train loss: 0.6478, dev acc: 0.7500, dev loss: 0.6531\n",
            "epoch11 3964.0000 train acc: 0.7946,train loss: 0.6478, dev acc: 0.7500, dev loss: 0.6531\n",
            "epoch11 3965.0000 train acc: 0.7946,train loss: 0.6477, dev acc: 0.7500, dev loss: 0.6531\n",
            "epoch11 3966.0000 train acc: 0.7946,train loss: 0.6477, dev acc: 0.7500, dev loss: 0.6530\n",
            "epoch11 3967.0000 train acc: 0.7946,train loss: 0.6477, dev acc: 0.7500, dev loss: 0.6530\n",
            "epoch11 3968.0000 train acc: 0.7946,train loss: 0.6476, dev acc: 0.7500, dev loss: 0.6530\n",
            "epoch11 3969.0000 train acc: 0.7946,train loss: 0.6476, dev acc: 0.7500, dev loss: 0.6530\n",
            "epoch11 3970.0000 train acc: 0.7946,train loss: 0.6476, dev acc: 0.7500, dev loss: 0.6529\n",
            "epoch11 3971.0000 train acc: 0.7946,train loss: 0.6476, dev acc: 0.7500, dev loss: 0.6529\n",
            "epoch11 3972.0000 train acc: 0.7946,train loss: 0.6475, dev acc: 0.7500, dev loss: 0.6529\n",
            "epoch11 3973.0000 train acc: 0.7946,train loss: 0.6475, dev acc: 0.7500, dev loss: 0.6529\n",
            "epoch11 3974.0000 train acc: 0.7946,train loss: 0.6475, dev acc: 0.7500, dev loss: 0.6528\n",
            "epoch11 3975.0000 train acc: 0.7946,train loss: 0.6475, dev acc: 0.7500, dev loss: 0.6528\n",
            "epoch11 3976.0000 train acc: 0.7946,train loss: 0.6474, dev acc: 0.7500, dev loss: 0.6528\n",
            "epoch11 3977.0000 train acc: 0.7946,train loss: 0.6474, dev acc: 0.7500, dev loss: 0.6528\n",
            "epoch11 3978.0000 train acc: 0.7946,train loss: 0.6474, dev acc: 0.7500, dev loss: 0.6527\n",
            "epoch11 3979.0000 train acc: 0.7946,train loss: 0.6473, dev acc: 0.7500, dev loss: 0.6527\n",
            "epoch11 3980.0000 train acc: 0.7946,train loss: 0.6473, dev acc: 0.7500, dev loss: 0.6527\n",
            "epoch11 3981.0000 train acc: 0.7946,train loss: 0.6473, dev acc: 0.7500, dev loss: 0.6527\n",
            "epoch11 3982.0000 train acc: 0.7946,train loss: 0.6473, dev acc: 0.7500, dev loss: 0.6526\n",
            "epoch11 3983.0000 train acc: 0.7946,train loss: 0.6472, dev acc: 0.7500, dev loss: 0.6526\n",
            "epoch11 3984.0000 train acc: 0.7946,train loss: 0.6472, dev acc: 0.7500, dev loss: 0.6526\n",
            "epoch11 3985.0000 train acc: 0.7946,train loss: 0.6472, dev acc: 0.7500, dev loss: 0.6526\n",
            "epoch11 3986.0000 train acc: 0.7946,train loss: 0.6472, dev acc: 0.7500, dev loss: 0.6525\n",
            "epoch11 3987.0000 train acc: 0.7946,train loss: 0.6471, dev acc: 0.7500, dev loss: 0.6525\n",
            "epoch11 3988.0000 train acc: 0.7946,train loss: 0.6471, dev acc: 0.7500, dev loss: 0.6525\n",
            "epoch11 3989.0000 train acc: 0.7946,train loss: 0.6471, dev acc: 0.7500, dev loss: 0.6525\n",
            "epoch11 3990.0000 train acc: 0.7946,train loss: 0.6470, dev acc: 0.7500, dev loss: 0.6524\n",
            "epoch11 3991.0000 train acc: 0.7946,train loss: 0.6470, dev acc: 0.7500, dev loss: 0.6524\n",
            "epoch11 3992.0000 train acc: 0.7946,train loss: 0.6470, dev acc: 0.7500, dev loss: 0.6524\n",
            "epoch11 3993.0000 train acc: 0.7946,train loss: 0.6470, dev acc: 0.7500, dev loss: 0.6524\n",
            "epoch11 3994.0000 train acc: 0.7946,train loss: 0.6469, dev acc: 0.7500, dev loss: 0.6523\n",
            "epoch11 3995.0000 train acc: 0.7946,train loss: 0.6469, dev acc: 0.7500, dev loss: 0.6523\n",
            "epoch11 3996.0000 train acc: 0.7946,train loss: 0.6469, dev acc: 0.7500, dev loss: 0.6523\n",
            "epoch11 3997.0000 train acc: 0.7946,train loss: 0.6469, dev acc: 0.7500, dev loss: 0.6523\n",
            "epoch11 3998.0000 train acc: 0.7946,train loss: 0.6468, dev acc: 0.7500, dev loss: 0.6522\n",
            "epoch11 3999.0000 train acc: 0.7946,train loss: 0.6468, dev acc: 0.7500, dev loss: 0.6522\n",
            "epoch11 4000.0000 train acc: 0.7946,train loss: 0.6468, dev acc: 0.7500, dev loss: 0.6522\n",
            "epoch11 4001.0000 train acc: 0.7946,train loss: 0.6467, dev acc: 0.7500, dev loss: 0.6522\n",
            "epoch11 4002.0000 train acc: 0.7946,train loss: 0.6467, dev acc: 0.7500, dev loss: 0.6521\n",
            "epoch11 4003.0000 train acc: 0.7946,train loss: 0.6467, dev acc: 0.7500, dev loss: 0.6521\n",
            "epoch11 4004.0000 train acc: 0.7946,train loss: 0.6467, dev acc: 0.7500, dev loss: 0.6521\n",
            "epoch11 4005.0000 train acc: 0.7946,train loss: 0.6466, dev acc: 0.7500, dev loss: 0.6521\n",
            "epoch11 4006.0000 train acc: 0.7946,train loss: 0.6466, dev acc: 0.7500, dev loss: 0.6520\n",
            "epoch11 4007.0000 train acc: 0.7946,train loss: 0.6466, dev acc: 0.7500, dev loss: 0.6520\n",
            "epoch11 4008.0000 train acc: 0.7946,train loss: 0.6466, dev acc: 0.7500, dev loss: 0.6520\n",
            "epoch11 4009.0000 train acc: 0.7946,train loss: 0.6465, dev acc: 0.7500, dev loss: 0.6520\n",
            "epoch11 4010.0000 train acc: 0.7946,train loss: 0.6465, dev acc: 0.7500, dev loss: 0.6519\n",
            "epoch11 4011.0000 train acc: 0.7946,train loss: 0.6465, dev acc: 0.7500, dev loss: 0.6519\n",
            "epoch11 4012.0000 train acc: 0.7946,train loss: 0.6464, dev acc: 0.7500, dev loss: 0.6519\n",
            "epoch11 4013.0000 train acc: 0.7946,train loss: 0.6464, dev acc: 0.7500, dev loss: 0.6519\n",
            "epoch11 4014.0000 train acc: 0.7946,train loss: 0.6464, dev acc: 0.7500, dev loss: 0.6518\n",
            "epoch11 4015.0000 train acc: 0.7946,train loss: 0.6464, dev acc: 0.7500, dev loss: 0.6518\n",
            "epoch11 4016.0000 train acc: 0.7946,train loss: 0.6463, dev acc: 0.7500, dev loss: 0.6518\n",
            "epoch11 4017.0000 train acc: 0.7946,train loss: 0.6463, dev acc: 0.7500, dev loss: 0.6518\n",
            "epoch11 4018.0000 train acc: 0.7946,train loss: 0.6463, dev acc: 0.7500, dev loss: 0.6517\n",
            "epoch11 4019.0000 train acc: 0.7946,train loss: 0.6462, dev acc: 0.7500, dev loss: 0.6517\n",
            "epoch11 4020.0000 train acc: 0.7946,train loss: 0.6462, dev acc: 0.7500, dev loss: 0.6517\n",
            "epoch11 4021.0000 train acc: 0.7946,train loss: 0.6462, dev acc: 0.7500, dev loss: 0.6517\n",
            "epoch11 4022.0000 train acc: 0.7946,train loss: 0.6462, dev acc: 0.7500, dev loss: 0.6516\n",
            "epoch11 4023.0000 train acc: 0.7946,train loss: 0.6461, dev acc: 0.7500, dev loss: 0.6516\n",
            "epoch11 4024.0000 train acc: 0.7946,train loss: 0.6461, dev acc: 0.7500, dev loss: 0.6516\n",
            "epoch11 4025.0000 train acc: 0.7946,train loss: 0.6461, dev acc: 0.7500, dev loss: 0.6516\n",
            "epoch11 4026.0000 train acc: 0.7946,train loss: 0.6461, dev acc: 0.7500, dev loss: 0.6515\n",
            "epoch11 4027.0000 train acc: 0.7946,train loss: 0.6460, dev acc: 0.7500, dev loss: 0.6515\n",
            "epoch11 4028.0000 train acc: 0.7946,train loss: 0.6460, dev acc: 0.7500, dev loss: 0.6515\n",
            "epoch11 4029.0000 train acc: 0.7946,train loss: 0.6460, dev acc: 0.7500, dev loss: 0.6515\n",
            "epoch11 4030.0000 train acc: 0.7946,train loss: 0.6459, dev acc: 0.7500, dev loss: 0.6514\n",
            "epoch11 4031.0000 train acc: 0.7946,train loss: 0.6459, dev acc: 0.7500, dev loss: 0.6514\n",
            "epoch11 4032.0000 train acc: 0.7946,train loss: 0.6459, dev acc: 0.7500, dev loss: 0.6514\n",
            "epoch11 4033.0000 train acc: 0.7946,train loss: 0.6459, dev acc: 0.7500, dev loss: 0.6514\n",
            "epoch11 4034.0000 train acc: 0.7946,train loss: 0.6458, dev acc: 0.7500, dev loss: 0.6513\n",
            "epoch11 4035.0000 train acc: 0.7946,train loss: 0.6458, dev acc: 0.7500, dev loss: 0.6513\n",
            "epoch11 4036.0000 train acc: 0.7946,train loss: 0.6458, dev acc: 0.7500, dev loss: 0.6513\n",
            "epoch11 4037.0000 train acc: 0.7946,train loss: 0.6457, dev acc: 0.7500, dev loss: 0.6513\n",
            "epoch11 4038.0000 train acc: 0.7946,train loss: 0.6457, dev acc: 0.7500, dev loss: 0.6512\n",
            "epoch11 4039.0000 train acc: 0.7946,train loss: 0.6457, dev acc: 0.7500, dev loss: 0.6512\n",
            "epoch11 4040.0000 train acc: 0.7946,train loss: 0.6457, dev acc: 0.7500, dev loss: 0.6512\n",
            "epoch11 4041.0000 train acc: 0.7946,train loss: 0.6456, dev acc: 0.7500, dev loss: 0.6511\n",
            "epoch11 4042.0000 train acc: 0.7946,train loss: 0.6456, dev acc: 0.7500, dev loss: 0.6511\n",
            "epoch11 4043.0000 train acc: 0.7946,train loss: 0.6456, dev acc: 0.7500, dev loss: 0.6511\n",
            "epoch11 4044.0000 train acc: 0.7946,train loss: 0.6455, dev acc: 0.7500, dev loss: 0.6511\n",
            "epoch11 4045.0000 train acc: 0.7946,train loss: 0.6455, dev acc: 0.7500, dev loss: 0.6510\n",
            "epoch11 4046.0000 train acc: 0.7946,train loss: 0.6455, dev acc: 0.7500, dev loss: 0.6510\n",
            "epoch11 4047.0000 train acc: 0.7946,train loss: 0.6455, dev acc: 0.7500, dev loss: 0.6510\n",
            "epoch11 4048.0000 train acc: 0.7946,train loss: 0.6454, dev acc: 0.7500, dev loss: 0.6510\n",
            "epoch11 4049.0000 train acc: 0.7946,train loss: 0.6454, dev acc: 0.7500, dev loss: 0.6509\n",
            "epoch11 4050.0000 train acc: 0.7946,train loss: 0.6454, dev acc: 0.7500, dev loss: 0.6509\n",
            "epoch11 4051.0000 train acc: 0.7946,train loss: 0.6453, dev acc: 0.7500, dev loss: 0.6509\n",
            "epoch11 4052.0000 train acc: 0.7946,train loss: 0.6453, dev acc: 0.7500, dev loss: 0.6509\n",
            "epoch11 4053.0000 train acc: 0.7946,train loss: 0.6453, dev acc: 0.7656, dev loss: 0.6508\n",
            "epoch11 4054.0000 train acc: 0.7946,train loss: 0.6453, dev acc: 0.7656, dev loss: 0.6508\n",
            "epoch11 4055.0000 train acc: 0.7946,train loss: 0.6452, dev acc: 0.7656, dev loss: 0.6508\n",
            "epoch11 4056.0000 train acc: 0.7946,train loss: 0.6452, dev acc: 0.7656, dev loss: 0.6508\n",
            "epoch11 4057.0000 train acc: 0.7946,train loss: 0.6452, dev acc: 0.7656, dev loss: 0.6507\n",
            "epoch11 4058.0000 train acc: 0.7946,train loss: 0.6451, dev acc: 0.7656, dev loss: 0.6507\n",
            "epoch11 4059.0000 train acc: 0.7946,train loss: 0.6451, dev acc: 0.7656, dev loss: 0.6507\n",
            "epoch11 4060.0000 train acc: 0.7946,train loss: 0.6451, dev acc: 0.7656, dev loss: 0.6507\n",
            "epoch11 4061.0000 train acc: 0.7946,train loss: 0.6451, dev acc: 0.7656, dev loss: 0.6506\n",
            "epoch11 4062.0000 train acc: 0.7946,train loss: 0.6450, dev acc: 0.7656, dev loss: 0.6506\n",
            "epoch11 4063.0000 train acc: 0.7946,train loss: 0.6450, dev acc: 0.7656, dev loss: 0.6506\n",
            "epoch11 4064.0000 train acc: 0.7946,train loss: 0.6450, dev acc: 0.7656, dev loss: 0.6505\n",
            "epoch11 4065.0000 train acc: 0.7946,train loss: 0.6449, dev acc: 0.7656, dev loss: 0.6505\n",
            "epoch11 4066.0000 train acc: 0.7946,train loss: 0.6449, dev acc: 0.7656, dev loss: 0.6505\n",
            "epoch11 4067.0000 train acc: 0.7946,train loss: 0.6449, dev acc: 0.7656, dev loss: 0.6505\n",
            "epoch11 4068.0000 train acc: 0.7946,train loss: 0.6449, dev acc: 0.7656, dev loss: 0.6504\n",
            "epoch11 4069.0000 train acc: 0.7946,train loss: 0.6448, dev acc: 0.7656, dev loss: 0.6504\n",
            "epoch11 4070.0000 train acc: 0.7946,train loss: 0.6448, dev acc: 0.7656, dev loss: 0.6504\n",
            "epoch11 4071.0000 train acc: 0.7946,train loss: 0.6448, dev acc: 0.7656, dev loss: 0.6504\n",
            "epoch11 4072.0000 train acc: 0.7946,train loss: 0.6447, dev acc: 0.7656, dev loss: 0.6503\n",
            "epoch11 4073.0000 train acc: 0.7946,train loss: 0.6447, dev acc: 0.7656, dev loss: 0.6503\n",
            "epoch11 4074.0000 train acc: 0.7946,train loss: 0.6447, dev acc: 0.7656, dev loss: 0.6503\n",
            "epoch11 4075.0000 train acc: 0.7946,train loss: 0.6447, dev acc: 0.7656, dev loss: 0.6503\n",
            "epoch11 4076.0000 train acc: 0.7946,train loss: 0.6446, dev acc: 0.7656, dev loss: 0.6502\n",
            "epoch11 4077.0000 train acc: 0.7946,train loss: 0.6446, dev acc: 0.7656, dev loss: 0.6502\n",
            "epoch11 4078.0000 train acc: 0.7946,train loss: 0.6446, dev acc: 0.7656, dev loss: 0.6502\n",
            "epoch11 4079.0000 train acc: 0.7946,train loss: 0.6445, dev acc: 0.7656, dev loss: 0.6502\n",
            "epoch11 4080.0000 train acc: 0.7946,train loss: 0.6445, dev acc: 0.7656, dev loss: 0.6501\n",
            "epoch11 4081.0000 train acc: 0.7946,train loss: 0.6445, dev acc: 0.7656, dev loss: 0.6501\n",
            "epoch11 4082.0000 train acc: 0.7946,train loss: 0.6445, dev acc: 0.7656, dev loss: 0.6501\n",
            "epoch11 4083.0000 train acc: 0.7946,train loss: 0.6444, dev acc: 0.7656, dev loss: 0.6500\n",
            "epoch11 4084.0000 train acc: 0.7946,train loss: 0.6444, dev acc: 0.7656, dev loss: 0.6500\n",
            "epoch11 4085.0000 train acc: 0.7946,train loss: 0.6444, dev acc: 0.7656, dev loss: 0.6500\n",
            "epoch11 4086.0000 train acc: 0.7946,train loss: 0.6443, dev acc: 0.7656, dev loss: 0.6500\n",
            "epoch11 4087.0000 train acc: 0.7946,train loss: 0.6443, dev acc: 0.7656, dev loss: 0.6499\n",
            "epoch11 4088.0000 train acc: 0.7946,train loss: 0.6443, dev acc: 0.7656, dev loss: 0.6499\n",
            "epoch11 4089.0000 train acc: 0.7946,train loss: 0.6442, dev acc: 0.7656, dev loss: 0.6499\n",
            "epoch11 4090.0000 train acc: 0.7946,train loss: 0.6442, dev acc: 0.7656, dev loss: 0.6499\n",
            "epoch11 4091.0000 train acc: 0.7946,train loss: 0.6442, dev acc: 0.7656, dev loss: 0.6498\n",
            "epoch11 4092.0000 train acc: 0.7946,train loss: 0.6442, dev acc: 0.7656, dev loss: 0.6498\n",
            "epoch11 4093.0000 train acc: 0.7946,train loss: 0.6441, dev acc: 0.7656, dev loss: 0.6498\n",
            "epoch11 4094.0000 train acc: 0.7946,train loss: 0.6441, dev acc: 0.7656, dev loss: 0.6498\n",
            "epoch11 4095.0000 train acc: 0.7946,train loss: 0.6441, dev acc: 0.7656, dev loss: 0.6497\n",
            "epoch11 4096.0000 train acc: 0.7946,train loss: 0.6440, dev acc: 0.7656, dev loss: 0.6497\n",
            "epoch11 4097.0000 train acc: 0.7946,train loss: 0.6440, dev acc: 0.7656, dev loss: 0.6497\n",
            "epoch11 4098.0000 train acc: 0.7946,train loss: 0.6440, dev acc: 0.7656, dev loss: 0.6497\n",
            "epoch11 4099.0000 train acc: 0.7946,train loss: 0.6440, dev acc: 0.7656, dev loss: 0.6496\n",
            "epoch11 4100.0000 train acc: 0.7946,train loss: 0.6439, dev acc: 0.7656, dev loss: 0.6496\n",
            "epoch11 4101.0000 train acc: 0.7946,train loss: 0.6439, dev acc: 0.7656, dev loss: 0.6496\n",
            "epoch11 4102.0000 train acc: 0.7946,train loss: 0.6439, dev acc: 0.7656, dev loss: 0.6496\n",
            "epoch11 4103.0000 train acc: 0.7946,train loss: 0.6438, dev acc: 0.7656, dev loss: 0.6495\n",
            "epoch11 4104.0000 train acc: 0.7946,train loss: 0.6438, dev acc: 0.7656, dev loss: 0.6495\n",
            "epoch11 4105.0000 train acc: 0.7946,train loss: 0.6438, dev acc: 0.7656, dev loss: 0.6495\n",
            "epoch11 4106.0000 train acc: 0.7946,train loss: 0.6438, dev acc: 0.7656, dev loss: 0.6494\n",
            "epoch11 4107.0000 train acc: 0.7946,train loss: 0.6437, dev acc: 0.7656, dev loss: 0.6494\n",
            "epoch11 4108.0000 train acc: 0.7946,train loss: 0.6437, dev acc: 0.7656, dev loss: 0.6494\n",
            "epoch11 4109.0000 train acc: 0.7946,train loss: 0.6437, dev acc: 0.7656, dev loss: 0.6494\n",
            "epoch11 4110.0000 train acc: 0.7946,train loss: 0.6436, dev acc: 0.7656, dev loss: 0.6493\n",
            "epoch11 4111.0000 train acc: 0.7946,train loss: 0.6436, dev acc: 0.7656, dev loss: 0.6493\n",
            "epoch11 4112.0000 train acc: 0.7946,train loss: 0.6436, dev acc: 0.7656, dev loss: 0.6493\n",
            "epoch11 4113.0000 train acc: 0.7946,train loss: 0.6436, dev acc: 0.7656, dev loss: 0.6493\n",
            "epoch11 4114.0000 train acc: 0.7946,train loss: 0.6435, dev acc: 0.7656, dev loss: 0.6492\n",
            "epoch11 4115.0000 train acc: 0.7946,train loss: 0.6435, dev acc: 0.7656, dev loss: 0.6492\n",
            "epoch11 4116.0000 train acc: 0.7946,train loss: 0.6435, dev acc: 0.7656, dev loss: 0.6492\n",
            "epoch11 4117.0000 train acc: 0.7946,train loss: 0.6434, dev acc: 0.7656, dev loss: 0.6492\n",
            "epoch11 4118.0000 train acc: 0.7946,train loss: 0.6434, dev acc: 0.7656, dev loss: 0.6491\n",
            "epoch11 4119.0000 train acc: 0.7946,train loss: 0.6434, dev acc: 0.7656, dev loss: 0.6491\n",
            "epoch11 4120.0000 train acc: 0.7946,train loss: 0.6433, dev acc: 0.7656, dev loss: 0.6491\n",
            "epoch11 4121.0000 train acc: 0.7946,train loss: 0.6433, dev acc: 0.7656, dev loss: 0.6491\n",
            "epoch11 4122.0000 train acc: 0.7946,train loss: 0.6433, dev acc: 0.7656, dev loss: 0.6490\n",
            "epoch11 4123.0000 train acc: 0.7946,train loss: 0.6433, dev acc: 0.7656, dev loss: 0.6490\n",
            "epoch11 4124.0000 train acc: 0.7946,train loss: 0.6432, dev acc: 0.7656, dev loss: 0.6490\n",
            "epoch11 4125.0000 train acc: 0.7946,train loss: 0.6432, dev acc: 0.7656, dev loss: 0.6489\n",
            "epoch11 4126.0000 train acc: 0.7946,train loss: 0.6432, dev acc: 0.7656, dev loss: 0.6489\n",
            "epoch11 4127.0000 train acc: 0.7946,train loss: 0.6431, dev acc: 0.7656, dev loss: 0.6489\n",
            "epoch11 4128.0000 train acc: 0.7946,train loss: 0.6431, dev acc: 0.7656, dev loss: 0.6489\n",
            "epoch11 4129.0000 train acc: 0.7946,train loss: 0.6431, dev acc: 0.7656, dev loss: 0.6488\n",
            "epoch11 4130.0000 train acc: 0.7946,train loss: 0.6431, dev acc: 0.7656, dev loss: 0.6488\n",
            "epoch11 4131.0000 train acc: 0.7946,train loss: 0.6430, dev acc: 0.7656, dev loss: 0.6488\n",
            "epoch11 4132.0000 train acc: 0.7969,train loss: 0.6430, dev acc: 0.7656, dev loss: 0.6488\n",
            "epoch11 4133.0000 train acc: 0.7969,train loss: 0.6430, dev acc: 0.7656, dev loss: 0.6487\n",
            "epoch11 4134.0000 train acc: 0.7969,train loss: 0.6429, dev acc: 0.7656, dev loss: 0.6487\n",
            "epoch11 4135.0000 train acc: 0.7969,train loss: 0.6429, dev acc: 0.7656, dev loss: 0.6487\n",
            "epoch11 4136.0000 train acc: 0.7969,train loss: 0.6429, dev acc: 0.7656, dev loss: 0.6487\n",
            "epoch11 4137.0000 train acc: 0.7969,train loss: 0.6428, dev acc: 0.7656, dev loss: 0.6486\n",
            "epoch11 4138.0000 train acc: 0.7969,train loss: 0.6428, dev acc: 0.7656, dev loss: 0.6486\n",
            "epoch11 4139.0000 train acc: 0.7969,train loss: 0.6428, dev acc: 0.7656, dev loss: 0.6486\n",
            "epoch11 4140.0000 train acc: 0.7969,train loss: 0.6428, dev acc: 0.7656, dev loss: 0.6485\n",
            "epoch11 4141.0000 train acc: 0.7969,train loss: 0.6427, dev acc: 0.7656, dev loss: 0.6485\n",
            "epoch11 4142.0000 train acc: 0.7969,train loss: 0.6427, dev acc: 0.7656, dev loss: 0.6485\n",
            "epoch11 4143.0000 train acc: 0.7969,train loss: 0.6427, dev acc: 0.7656, dev loss: 0.6485\n",
            "epoch11 4144.0000 train acc: 0.7969,train loss: 0.6426, dev acc: 0.7656, dev loss: 0.6484\n",
            "epoch11 4145.0000 train acc: 0.7969,train loss: 0.6426, dev acc: 0.7656, dev loss: 0.6484\n",
            "epoch11 4146.0000 train acc: 0.7969,train loss: 0.6426, dev acc: 0.7656, dev loss: 0.6484\n",
            "epoch11 4147.0000 train acc: 0.7969,train loss: 0.6425, dev acc: 0.7656, dev loss: 0.6484\n",
            "epoch11 4148.0000 train acc: 0.7969,train loss: 0.6425, dev acc: 0.7656, dev loss: 0.6483\n",
            "epoch11 4149.0000 train acc: 0.7969,train loss: 0.6425, dev acc: 0.7656, dev loss: 0.6483\n",
            "epoch11 4150.0000 train acc: 0.7969,train loss: 0.6425, dev acc: 0.7656, dev loss: 0.6483\n",
            "epoch11 4151.0000 train acc: 0.7969,train loss: 0.6424, dev acc: 0.7656, dev loss: 0.6482\n",
            "epoch11 4152.0000 train acc: 0.7969,train loss: 0.6424, dev acc: 0.7656, dev loss: 0.6482\n",
            "epoch11 4153.0000 train acc: 0.7969,train loss: 0.6424, dev acc: 0.7656, dev loss: 0.6482\n",
            "epoch11 4154.0000 train acc: 0.7969,train loss: 0.6423, dev acc: 0.7656, dev loss: 0.6482\n",
            "epoch11 4155.0000 train acc: 0.7969,train loss: 0.6423, dev acc: 0.7656, dev loss: 0.6481\n",
            "epoch11 4156.0000 train acc: 0.7969,train loss: 0.6423, dev acc: 0.7656, dev loss: 0.6481\n",
            "epoch11 4157.0000 train acc: 0.7969,train loss: 0.6423, dev acc: 0.7656, dev loss: 0.6481\n",
            "epoch11 4158.0000 train acc: 0.7969,train loss: 0.6422, dev acc: 0.7656, dev loss: 0.6481\n",
            "epoch11 4159.0000 train acc: 0.7969,train loss: 0.6422, dev acc: 0.7656, dev loss: 0.6480\n",
            "epoch11 4160.0000 train acc: 0.7969,train loss: 0.6422, dev acc: 0.7656, dev loss: 0.6480\n",
            "epoch11 4161.0000 train acc: 0.7969,train loss: 0.6421, dev acc: 0.7656, dev loss: 0.6480\n",
            "epoch11 4162.0000 train acc: 0.7969,train loss: 0.6421, dev acc: 0.7656, dev loss: 0.6480\n",
            "epoch11 4163.0000 train acc: 0.7969,train loss: 0.6421, dev acc: 0.7656, dev loss: 0.6479\n",
            "epoch11 4164.0000 train acc: 0.7969,train loss: 0.6420, dev acc: 0.7656, dev loss: 0.6479\n",
            "epoch11 4165.0000 train acc: 0.7946,train loss: 0.6420, dev acc: 0.7656, dev loss: 0.6479\n",
            "epoch11 4166.0000 train acc: 0.7946,train loss: 0.6420, dev acc: 0.7656, dev loss: 0.6478\n",
            "epoch11 4167.0000 train acc: 0.7946,train loss: 0.6420, dev acc: 0.7656, dev loss: 0.6478\n",
            "epoch11 4168.0000 train acc: 0.7946,train loss: 0.6419, dev acc: 0.7656, dev loss: 0.6478\n",
            "epoch11 4169.0000 train acc: 0.7946,train loss: 0.6419, dev acc: 0.7656, dev loss: 0.6478\n",
            "epoch11 4170.0000 train acc: 0.7946,train loss: 0.6419, dev acc: 0.7656, dev loss: 0.6477\n",
            "epoch11 4171.0000 train acc: 0.7946,train loss: 0.6418, dev acc: 0.7656, dev loss: 0.6477\n",
            "epoch11 4172.0000 train acc: 0.7946,train loss: 0.6418, dev acc: 0.7656, dev loss: 0.6477\n",
            "epoch11 4173.0000 train acc: 0.7946,train loss: 0.6418, dev acc: 0.7656, dev loss: 0.6477\n",
            "epoch11 4174.0000 train acc: 0.7946,train loss: 0.6417, dev acc: 0.7656, dev loss: 0.6476\n",
            "epoch11 4175.0000 train acc: 0.7946,train loss: 0.6417, dev acc: 0.7656, dev loss: 0.6476\n",
            "epoch11 4176.0000 train acc: 0.7946,train loss: 0.6417, dev acc: 0.7656, dev loss: 0.6476\n",
            "epoch11 4177.0000 train acc: 0.7946,train loss: 0.6416, dev acc: 0.7656, dev loss: 0.6475\n",
            "epoch11 4178.0000 train acc: 0.7946,train loss: 0.6416, dev acc: 0.7656, dev loss: 0.6475\n",
            "epoch11 4179.0000 train acc: 0.7946,train loss: 0.6416, dev acc: 0.7656, dev loss: 0.6475\n",
            "epoch11 4180.0000 train acc: 0.7946,train loss: 0.6416, dev acc: 0.7656, dev loss: 0.6475\n",
            "epoch11 4181.0000 train acc: 0.7946,train loss: 0.6415, dev acc: 0.7656, dev loss: 0.6474\n",
            "epoch11 4182.0000 train acc: 0.7946,train loss: 0.6415, dev acc: 0.7656, dev loss: 0.6474\n",
            "epoch11 4183.0000 train acc: 0.7946,train loss: 0.6415, dev acc: 0.7656, dev loss: 0.6474\n",
            "epoch11 4184.0000 train acc: 0.7946,train loss: 0.6414, dev acc: 0.7656, dev loss: 0.6474\n",
            "epoch11 4185.0000 train acc: 0.7946,train loss: 0.6414, dev acc: 0.7656, dev loss: 0.6473\n",
            "epoch11 4186.0000 train acc: 0.7946,train loss: 0.6414, dev acc: 0.7656, dev loss: 0.6473\n",
            "epoch11 4187.0000 train acc: 0.7946,train loss: 0.6413, dev acc: 0.7656, dev loss: 0.6473\n",
            "epoch11 4188.0000 train acc: 0.7946,train loss: 0.6413, dev acc: 0.7656, dev loss: 0.6472\n",
            "epoch11 4189.0000 train acc: 0.7946,train loss: 0.6413, dev acc: 0.7656, dev loss: 0.6472\n",
            "epoch11 4190.0000 train acc: 0.7946,train loss: 0.6413, dev acc: 0.7656, dev loss: 0.6472\n",
            "epoch11 4191.0000 train acc: 0.7946,train loss: 0.6412, dev acc: 0.7656, dev loss: 0.6472\n",
            "epoch11 4192.0000 train acc: 0.7946,train loss: 0.6412, dev acc: 0.7656, dev loss: 0.6471\n",
            "epoch11 4193.0000 train acc: 0.7946,train loss: 0.6412, dev acc: 0.7656, dev loss: 0.6471\n",
            "epoch11 4194.0000 train acc: 0.7946,train loss: 0.6411, dev acc: 0.7656, dev loss: 0.6471\n",
            "epoch11 4195.0000 train acc: 0.7946,train loss: 0.6411, dev acc: 0.7656, dev loss: 0.6471\n",
            "epoch11 4196.0000 train acc: 0.7946,train loss: 0.6411, dev acc: 0.7656, dev loss: 0.6470\n",
            "epoch11 4197.0000 train acc: 0.7946,train loss: 0.6410, dev acc: 0.7656, dev loss: 0.6470\n",
            "epoch11 4198.0000 train acc: 0.7946,train loss: 0.6410, dev acc: 0.7656, dev loss: 0.6470\n",
            "epoch11 4199.0000 train acc: 0.7946,train loss: 0.6410, dev acc: 0.7656, dev loss: 0.6469\n",
            "epoch11 4200.0000 train acc: 0.7946,train loss: 0.6409, dev acc: 0.7656, dev loss: 0.6469\n",
            "epoch11 4201.0000 train acc: 0.7946,train loss: 0.6409, dev acc: 0.7656, dev loss: 0.6469\n",
            "epoch11 4202.0000 train acc: 0.7946,train loss: 0.6409, dev acc: 0.7656, dev loss: 0.6469\n",
            "epoch11 4203.0000 train acc: 0.7946,train loss: 0.6409, dev acc: 0.7656, dev loss: 0.6468\n",
            "epoch11 4204.0000 train acc: 0.7946,train loss: 0.6408, dev acc: 0.7656, dev loss: 0.6468\n",
            "epoch11 4205.0000 train acc: 0.7946,train loss: 0.6408, dev acc: 0.7656, dev loss: 0.6468\n",
            "epoch11 4206.0000 train acc: 0.7946,train loss: 0.6408, dev acc: 0.7656, dev loss: 0.6467\n",
            "epoch11 4207.0000 train acc: 0.7946,train loss: 0.6407, dev acc: 0.7656, dev loss: 0.6467\n",
            "epoch11 4208.0000 train acc: 0.7946,train loss: 0.6407, dev acc: 0.7656, dev loss: 0.6467\n",
            "epoch11 4209.0000 train acc: 0.7946,train loss: 0.6407, dev acc: 0.7656, dev loss: 0.6467\n",
            "epoch11 4210.0000 train acc: 0.7946,train loss: 0.6406, dev acc: 0.7656, dev loss: 0.6466\n",
            "epoch11 4211.0000 train acc: 0.7946,train loss: 0.6406, dev acc: 0.7656, dev loss: 0.6466\n",
            "epoch11 4212.0000 train acc: 0.7946,train loss: 0.6406, dev acc: 0.7656, dev loss: 0.6466\n",
            "epoch11 4213.0000 train acc: 0.7946,train loss: 0.6406, dev acc: 0.7656, dev loss: 0.6466\n",
            "epoch11 4214.0000 train acc: 0.7946,train loss: 0.6405, dev acc: 0.7656, dev loss: 0.6465\n",
            "epoch11 4215.0000 train acc: 0.7946,train loss: 0.6405, dev acc: 0.7656, dev loss: 0.6465\n",
            "epoch11 4216.0000 train acc: 0.7946,train loss: 0.6405, dev acc: 0.7656, dev loss: 0.6465\n",
            "epoch11 4217.0000 train acc: 0.7946,train loss: 0.6404, dev acc: 0.7656, dev loss: 0.6464\n",
            "epoch11 4218.0000 train acc: 0.7946,train loss: 0.6404, dev acc: 0.7656, dev loss: 0.6464\n",
            "epoch11 4219.0000 train acc: 0.7946,train loss: 0.6404, dev acc: 0.7656, dev loss: 0.6464\n",
            "epoch11 4220.0000 train acc: 0.7946,train loss: 0.6403, dev acc: 0.7656, dev loss: 0.6464\n",
            "epoch11 4221.0000 train acc: 0.7946,train loss: 0.6403, dev acc: 0.7656, dev loss: 0.6463\n",
            "epoch11 4222.0000 train acc: 0.7946,train loss: 0.6403, dev acc: 0.7656, dev loss: 0.6463\n",
            "epoch11 4223.0000 train acc: 0.7946,train loss: 0.6402, dev acc: 0.7656, dev loss: 0.6463\n",
            "epoch11 4224.0000 train acc: 0.7946,train loss: 0.6402, dev acc: 0.7656, dev loss: 0.6462\n",
            "epoch11 4225.0000 train acc: 0.7946,train loss: 0.6402, dev acc: 0.7656, dev loss: 0.6462\n",
            "epoch11 4226.0000 train acc: 0.7946,train loss: 0.6401, dev acc: 0.7656, dev loss: 0.6462\n",
            "epoch11 4227.0000 train acc: 0.7946,train loss: 0.6401, dev acc: 0.7656, dev loss: 0.6462\n",
            "epoch11 4228.0000 train acc: 0.7946,train loss: 0.6401, dev acc: 0.7656, dev loss: 0.6461\n",
            "epoch11 4229.0000 train acc: 0.7946,train loss: 0.6401, dev acc: 0.7656, dev loss: 0.6461\n",
            "epoch11 4230.0000 train acc: 0.7946,train loss: 0.6400, dev acc: 0.7656, dev loss: 0.6461\n",
            "epoch11 4231.0000 train acc: 0.7946,train loss: 0.6400, dev acc: 0.7656, dev loss: 0.6461\n",
            "epoch11 4232.0000 train acc: 0.7946,train loss: 0.6400, dev acc: 0.7656, dev loss: 0.6460\n",
            "epoch11 4233.0000 train acc: 0.7946,train loss: 0.6399, dev acc: 0.7656, dev loss: 0.6460\n",
            "epoch11 4234.0000 train acc: 0.7946,train loss: 0.6399, dev acc: 0.7656, dev loss: 0.6460\n",
            "epoch11 4235.0000 train acc: 0.7946,train loss: 0.6399, dev acc: 0.7656, dev loss: 0.6459\n",
            "epoch11 4236.0000 train acc: 0.7969,train loss: 0.6398, dev acc: 0.7656, dev loss: 0.6459\n",
            "epoch11 4237.0000 train acc: 0.7969,train loss: 0.6398, dev acc: 0.7656, dev loss: 0.6459\n",
            "epoch11 4238.0000 train acc: 0.7969,train loss: 0.6398, dev acc: 0.7656, dev loss: 0.6459\n",
            "epoch11 4239.0000 train acc: 0.7969,train loss: 0.6397, dev acc: 0.7656, dev loss: 0.6458\n",
            "epoch11 4240.0000 train acc: 0.7969,train loss: 0.6397, dev acc: 0.7656, dev loss: 0.6458\n",
            "epoch11 4241.0000 train acc: 0.7969,train loss: 0.6397, dev acc: 0.7656, dev loss: 0.6458\n",
            "epoch11 4242.0000 train acc: 0.7969,train loss: 0.6396, dev acc: 0.7656, dev loss: 0.6457\n",
            "epoch11 4243.0000 train acc: 0.7969,train loss: 0.6396, dev acc: 0.7656, dev loss: 0.6457\n",
            "epoch11 4244.0000 train acc: 0.7969,train loss: 0.6396, dev acc: 0.7656, dev loss: 0.6457\n",
            "epoch11 4245.0000 train acc: 0.7969,train loss: 0.6396, dev acc: 0.7656, dev loss: 0.6457\n",
            "epoch11 4246.0000 train acc: 0.7969,train loss: 0.6395, dev acc: 0.7656, dev loss: 0.6456\n",
            "epoch11 4247.0000 train acc: 0.7991,train loss: 0.6395, dev acc: 0.7656, dev loss: 0.6456\n",
            "epoch11 4248.0000 train acc: 0.7991,train loss: 0.6395, dev acc: 0.7656, dev loss: 0.6456\n",
            "epoch11 4249.0000 train acc: 0.7991,train loss: 0.6394, dev acc: 0.7656, dev loss: 0.6455\n",
            "epoch11 4250.0000 train acc: 0.7991,train loss: 0.6394, dev acc: 0.7656, dev loss: 0.6455\n",
            "epoch11 4251.0000 train acc: 0.7991,train loss: 0.6394, dev acc: 0.7656, dev loss: 0.6455\n",
            "epoch11 4252.0000 train acc: 0.7991,train loss: 0.6393, dev acc: 0.7656, dev loss: 0.6455\n",
            "epoch11 4253.0000 train acc: 0.7991,train loss: 0.6393, dev acc: 0.7656, dev loss: 0.6454\n",
            "epoch11 4254.0000 train acc: 0.8013,train loss: 0.6393, dev acc: 0.7656, dev loss: 0.6454\n",
            "epoch11 4255.0000 train acc: 0.8013,train loss: 0.6392, dev acc: 0.7656, dev loss: 0.6454\n",
            "epoch11 4256.0000 train acc: 0.8013,train loss: 0.6392, dev acc: 0.7656, dev loss: 0.6453\n",
            "epoch11 4257.0000 train acc: 0.8013,train loss: 0.6392, dev acc: 0.7656, dev loss: 0.6453\n",
            "epoch11 4258.0000 train acc: 0.8013,train loss: 0.6391, dev acc: 0.7656, dev loss: 0.6453\n",
            "epoch11 4259.0000 train acc: 0.8013,train loss: 0.6391, dev acc: 0.7656, dev loss: 0.6453\n",
            "epoch11 4260.0000 train acc: 0.8013,train loss: 0.6391, dev acc: 0.7656, dev loss: 0.6452\n",
            "epoch11 4261.0000 train acc: 0.8013,train loss: 0.6390, dev acc: 0.7656, dev loss: 0.6452\n",
            "epoch11 4262.0000 train acc: 0.8013,train loss: 0.6390, dev acc: 0.7656, dev loss: 0.6452\n",
            "epoch11 4263.0000 train acc: 0.8013,train loss: 0.6390, dev acc: 0.7656, dev loss: 0.6451\n",
            "epoch11 4264.0000 train acc: 0.8013,train loss: 0.6390, dev acc: 0.7656, dev loss: 0.6451\n",
            "epoch11 4265.0000 train acc: 0.8013,train loss: 0.6389, dev acc: 0.7656, dev loss: 0.6451\n",
            "epoch11 4266.0000 train acc: 0.8013,train loss: 0.6389, dev acc: 0.7656, dev loss: 0.6451\n",
            "epoch11 4267.0000 train acc: 0.8013,train loss: 0.6389, dev acc: 0.7656, dev loss: 0.6450\n",
            "epoch11 4268.0000 train acc: 0.8013,train loss: 0.6388, dev acc: 0.7656, dev loss: 0.6450\n",
            "epoch11 4269.0000 train acc: 0.8013,train loss: 0.6388, dev acc: 0.7656, dev loss: 0.6450\n",
            "epoch11 4270.0000 train acc: 0.8013,train loss: 0.6388, dev acc: 0.7656, dev loss: 0.6449\n",
            "epoch11 4271.0000 train acc: 0.8013,train loss: 0.6387, dev acc: 0.7656, dev loss: 0.6449\n",
            "epoch11 4272.0000 train acc: 0.8013,train loss: 0.6387, dev acc: 0.7656, dev loss: 0.6449\n",
            "epoch11 4273.0000 train acc: 0.8013,train loss: 0.6387, dev acc: 0.7656, dev loss: 0.6449\n",
            "epoch11 4274.0000 train acc: 0.8013,train loss: 0.6386, dev acc: 0.7656, dev loss: 0.6448\n",
            "epoch11 4275.0000 train acc: 0.8013,train loss: 0.6386, dev acc: 0.7656, dev loss: 0.6448\n",
            "epoch11 4276.0000 train acc: 0.8013,train loss: 0.6386, dev acc: 0.7656, dev loss: 0.6448\n",
            "epoch11 4277.0000 train acc: 0.8013,train loss: 0.6385, dev acc: 0.7656, dev loss: 0.6447\n",
            "epoch11 4278.0000 train acc: 0.8013,train loss: 0.6385, dev acc: 0.7656, dev loss: 0.6447\n",
            "epoch11 4279.0000 train acc: 0.8013,train loss: 0.6385, dev acc: 0.7656, dev loss: 0.6447\n",
            "epoch11 4280.0000 train acc: 0.8013,train loss: 0.6384, dev acc: 0.7656, dev loss: 0.6447\n",
            "epoch11 4281.0000 train acc: 0.8013,train loss: 0.6384, dev acc: 0.7656, dev loss: 0.6446\n",
            "epoch11 4282.0000 train acc: 0.8013,train loss: 0.6384, dev acc: 0.7656, dev loss: 0.6446\n",
            "epoch11 4283.0000 train acc: 0.8013,train loss: 0.6384, dev acc: 0.7656, dev loss: 0.6446\n",
            "epoch11 4284.0000 train acc: 0.8013,train loss: 0.6383, dev acc: 0.7656, dev loss: 0.6445\n",
            "epoch11 4285.0000 train acc: 0.8013,train loss: 0.6383, dev acc: 0.7656, dev loss: 0.6445\n",
            "epoch11 4286.0000 train acc: 0.8013,train loss: 0.6383, dev acc: 0.7656, dev loss: 0.6445\n",
            "epoch11 4287.0000 train acc: 0.8013,train loss: 0.6382, dev acc: 0.7656, dev loss: 0.6445\n",
            "epoch11 4288.0000 train acc: 0.8013,train loss: 0.6382, dev acc: 0.7656, dev loss: 0.6444\n",
            "epoch11 4289.0000 train acc: 0.8013,train loss: 0.6382, dev acc: 0.7656, dev loss: 0.6444\n",
            "epoch11 4290.0000 train acc: 0.8013,train loss: 0.6381, dev acc: 0.7656, dev loss: 0.6444\n",
            "epoch11 4291.0000 train acc: 0.8013,train loss: 0.6381, dev acc: 0.7656, dev loss: 0.6443\n",
            "epoch11 4292.0000 train acc: 0.8013,train loss: 0.6381, dev acc: 0.7656, dev loss: 0.6443\n",
            "epoch11 4293.0000 train acc: 0.8013,train loss: 0.6380, dev acc: 0.7656, dev loss: 0.6443\n",
            "epoch11 4294.0000 train acc: 0.8013,train loss: 0.6380, dev acc: 0.7656, dev loss: 0.6443\n",
            "epoch11 4295.0000 train acc: 0.8013,train loss: 0.6380, dev acc: 0.7656, dev loss: 0.6442\n",
            "epoch11 4296.0000 train acc: 0.8013,train loss: 0.6379, dev acc: 0.7656, dev loss: 0.6442\n",
            "epoch11 4297.0000 train acc: 0.8013,train loss: 0.6379, dev acc: 0.7656, dev loss: 0.6442\n",
            "epoch11 4298.0000 train acc: 0.8013,train loss: 0.6379, dev acc: 0.7656, dev loss: 0.6441\n",
            "epoch11 4299.0000 train acc: 0.8013,train loss: 0.6378, dev acc: 0.7656, dev loss: 0.6441\n",
            "epoch11 4300.0000 train acc: 0.8013,train loss: 0.6378, dev acc: 0.7656, dev loss: 0.6441\n",
            "epoch11 4301.0000 train acc: 0.8013,train loss: 0.6378, dev acc: 0.7656, dev loss: 0.6440\n",
            "epoch11 4302.0000 train acc: 0.8013,train loss: 0.6377, dev acc: 0.7656, dev loss: 0.6440\n",
            "epoch11 4303.0000 train acc: 0.8013,train loss: 0.6377, dev acc: 0.7656, dev loss: 0.6440\n",
            "epoch11 4304.0000 train acc: 0.8013,train loss: 0.6377, dev acc: 0.7656, dev loss: 0.6440\n",
            "epoch11 4305.0000 train acc: 0.8013,train loss: 0.6376, dev acc: 0.7656, dev loss: 0.6439\n",
            "epoch11 4306.0000 train acc: 0.8013,train loss: 0.6376, dev acc: 0.7656, dev loss: 0.6439\n",
            "epoch11 4307.0000 train acc: 0.8013,train loss: 0.6376, dev acc: 0.7656, dev loss: 0.6439\n",
            "epoch11 4308.0000 train acc: 0.8013,train loss: 0.6376, dev acc: 0.7656, dev loss: 0.6438\n",
            "epoch11 4309.0000 train acc: 0.8013,train loss: 0.6375, dev acc: 0.7656, dev loss: 0.6438\n",
            "epoch11 4310.0000 train acc: 0.8013,train loss: 0.6375, dev acc: 0.7656, dev loss: 0.6438\n",
            "epoch11 4311.0000 train acc: 0.8013,train loss: 0.6375, dev acc: 0.7656, dev loss: 0.6438\n",
            "epoch11 4312.0000 train acc: 0.8013,train loss: 0.6374, dev acc: 0.7656, dev loss: 0.6437\n",
            "epoch11 4313.0000 train acc: 0.8013,train loss: 0.6374, dev acc: 0.7656, dev loss: 0.6437\n",
            "epoch11 4314.0000 train acc: 0.8013,train loss: 0.6374, dev acc: 0.7656, dev loss: 0.6437\n",
            "epoch11 4315.0000 train acc: 0.8013,train loss: 0.6373, dev acc: 0.7656, dev loss: 0.6436\n",
            "epoch11 4316.0000 train acc: 0.8013,train loss: 0.6373, dev acc: 0.7656, dev loss: 0.6436\n",
            "epoch11 4317.0000 train acc: 0.8013,train loss: 0.6373, dev acc: 0.7656, dev loss: 0.6436\n",
            "epoch11 4318.0000 train acc: 0.8013,train loss: 0.6372, dev acc: 0.7656, dev loss: 0.6436\n",
            "epoch11 4319.0000 train acc: 0.8013,train loss: 0.6372, dev acc: 0.7656, dev loss: 0.6435\n",
            "epoch11 4320.0000 train acc: 0.8013,train loss: 0.6372, dev acc: 0.7656, dev loss: 0.6435\n",
            "epoch11 4321.0000 train acc: 0.8013,train loss: 0.6371, dev acc: 0.7656, dev loss: 0.6435\n",
            "epoch11 4322.0000 train acc: 0.8013,train loss: 0.6371, dev acc: 0.7656, dev loss: 0.6434\n",
            "epoch11 4323.0000 train acc: 0.8013,train loss: 0.6371, dev acc: 0.7656, dev loss: 0.6434\n",
            "epoch11 4324.0000 train acc: 0.8013,train loss: 0.6370, dev acc: 0.7656, dev loss: 0.6434\n",
            "epoch11 4325.0000 train acc: 0.8013,train loss: 0.6370, dev acc: 0.7656, dev loss: 0.6433\n",
            "epoch11 4326.0000 train acc: 0.8013,train loss: 0.6370, dev acc: 0.7656, dev loss: 0.6433\n",
            "epoch11 4327.0000 train acc: 0.8013,train loss: 0.6369, dev acc: 0.7656, dev loss: 0.6433\n",
            "epoch11 4328.0000 train acc: 0.8013,train loss: 0.6369, dev acc: 0.7656, dev loss: 0.6433\n",
            "epoch11 4329.0000 train acc: 0.8013,train loss: 0.6369, dev acc: 0.7656, dev loss: 0.6432\n",
            "epoch11 4330.0000 train acc: 0.8013,train loss: 0.6368, dev acc: 0.7656, dev loss: 0.6432\n",
            "epoch11 4331.0000 train acc: 0.8013,train loss: 0.6368, dev acc: 0.7656, dev loss: 0.6432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_pred.T)\n",
        "print(label.numpy().T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKCZcniZgQtn",
        "outputId": "3a239e76-d4ec-4e67-cadd-aad1e734eb0f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1\n",
            "  0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0]]\n",
            "[[1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            "  1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            "  1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WueBeZ04ZIHp",
        "outputId": "ee8eaf99-e63d-4ac8-8e1d-a5b5e7b0bc9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['年龄', '性别', '脑出血前mRS评分', '高血压病史', '卒中病史', '糖尿病史', '房颤史', '冠心病史', '吸烟史', '饮酒史', '发病到首次影像检查时间间隔', '脑室引流', '止血治疗', '降颅压治疗', '降压治疗', '镇静、镇痛治疗', '止吐护胃', '营养神经', 'HM_volume', 'HM_ACA_R_Ratio', 'HM_MCA_R_Ratio', 'HM_PCA_R_Ratio', 'HM_Pons_Medulla_R_Ratio', 'HM_Cerebellum_R_Ratio', 'HM_ACA_L_Ratio', 'HM_MCA_L_Ratio', 'HM_PCA_L_Ratio', 'HM_Pons_Medulla_L_Ratio', 'HM_Cerebellum_L_Ratio', 'ED_volume', 'ED_ACA_R_Ratio', 'ED_MCA_R_Ratio', 'ED_PCA_R_Ratio', 'ED_Pons_Medulla_R_Ratio', 'ED_Cerebellum_R_Ratio', 'ED_ACA_L_Ratio', 'ED_MCA_L_Ratio', 'ED_PCA_L_Ratio', 'ED_Pons_Medulla_L_Ratio', 'ED_Cerebellum_L_Ratio', '高压', '低压']\n"
          ]
        }
      ],
      "source": [
        "data[['高压', '低压']] = data['血压'].str.split('/', expand=True).astype(int)\n",
        "data.head()  #展示数据集前5个\n",
        "data['性别'] = data['性别'].replace({'男': 1, '女': 0})\n",
        "feats = [f for f in data if f not in [ \"ID\",\"90天mRS\",\"血压\",\"数据集划分\"]]#选择特征\n",
        "print(feats)\n",
        "\n",
        "# 创建MinMaxScaler对象\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# 对特征进行最小-最大归一化\n",
        "data[feats] = scaler.fit_transform(data[feats])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "TF7t8u_AZJKN",
        "outputId": "fe576e45-22ba-45fc-c1a4-b881aeff9e39"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e51ab33-f5ae-423c-b6dd-34843937b79f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>90天mRS</th>\n",
              "      <th>数据集划分</th>\n",
              "      <th>年龄</th>\n",
              "      <th>性别</th>\n",
              "      <th>脑出血前mRS评分</th>\n",
              "      <th>高血压病史</th>\n",
              "      <th>卒中病史</th>\n",
              "      <th>糖尿病史</th>\n",
              "      <th>房颤史</th>\n",
              "      <th>...</th>\n",
              "      <th>ED_PCA_R_Ratio</th>\n",
              "      <th>ED_Pons_Medulla_R_Ratio</th>\n",
              "      <th>ED_Cerebellum_R_Ratio</th>\n",
              "      <th>ED_ACA_L_Ratio</th>\n",
              "      <th>ED_MCA_L_Ratio</th>\n",
              "      <th>ED_PCA_L_Ratio</th>\n",
              "      <th>ED_Pons_Medulla_L_Ratio</th>\n",
              "      <th>ED_Cerebellum_L_Ratio</th>\n",
              "      <th>高压</th>\n",
              "      <th>低压</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>sub101</td>\n",
              "      <td>NaN</td>\n",
              "      <td>测试1</td>\n",
              "      <td>0.712121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.173469</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.871429</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>sub102</td>\n",
              "      <td>NaN</td>\n",
              "      <td>测试1</td>\n",
              "      <td>0.606061</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.488889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>sub103</td>\n",
              "      <td>NaN</td>\n",
              "      <td>测试1</td>\n",
              "      <td>0.515152</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032967</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.511111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>sub104</td>\n",
              "      <td>NaN</td>\n",
              "      <td>测试1</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.224490</td>\n",
              "      <td>0.017857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.307143</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>sub105</td>\n",
              "      <td>NaN</td>\n",
              "      <td>测试1</td>\n",
              "      <td>0.318182</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.879121</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.364286</td>\n",
              "      <td>0.455556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e51ab33-f5ae-423c-b6dd-34843937b79f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e51ab33-f5ae-423c-b6dd-34843937b79f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e51ab33-f5ae-423c-b6dd-34843937b79f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8efb0aca-55de-4cfe-be87-6d2e84985cfc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8efb0aca-55de-4cfe-be87-6d2e84985cfc')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8efb0aca-55de-4cfe-be87-6d2e84985cfc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         ID  90天mRS 数据集划分        年龄   性别  脑出血前mRS评分  高血压病史  卒中病史  糖尿病史  房颤史  \\\n",
              "100  sub101     NaN   测试1  0.712121  0.0   0.000000    1.0   1.0   1.0  0.0   \n",
              "101  sub102     NaN   测试1  0.606061  1.0   0.333333    1.0   1.0   0.0  0.0   \n",
              "102  sub103     NaN   测试1  0.515152  1.0   1.000000    1.0   1.0   0.0  0.0   \n",
              "103  sub104     NaN   测试1  0.181818  1.0   0.000000    1.0   0.0   0.0  0.0   \n",
              "104  sub105     NaN   测试1  0.318182  1.0   0.000000    1.0   1.0   0.0  0.0   \n",
              "\n",
              "     ...  ED_PCA_R_Ratio  ED_Pons_Medulla_R_Ratio  ED_Cerebellum_R_Ratio  \\\n",
              "100  ...        0.173469                 0.000000                    0.0   \n",
              "101  ...        0.122449                 0.000000                    0.0   \n",
              "102  ...        0.000000                 0.000000                    0.0   \n",
              "103  ...        0.224490                 0.017857                    0.0   \n",
              "104  ...        0.000000                 0.000000                    0.0   \n",
              "\n",
              "     ED_ACA_L_Ratio ED_MCA_L_Ratio  ED_PCA_L_Ratio  ED_Pons_Medulla_L_Ratio  \\\n",
              "100        0.000000           0.00        0.000000                      0.0   \n",
              "101        0.000000           0.00        0.000000                      0.0   \n",
              "102        0.032967           0.94        0.047619                      0.0   \n",
              "103        0.000000           0.00        0.000000                      0.0   \n",
              "104        0.879121           0.20        0.000000                      0.0   \n",
              "\n",
              "     ED_Cerebellum_L_Ratio        高压        低压  \n",
              "100                    0.0  0.871429  0.777778  \n",
              "101                    0.0  0.400000  0.488889  \n",
              "102                    0.0  0.300000  0.511111  \n",
              "103                    0.0  0.307143  0.600000  \n",
              "104                    0.0  0.364286  0.455556  \n",
              "\n",
              "[5 rows x 46 columns]"
            ]
          },
          "execution_count": 221,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 使用条件索引划分数据\n",
        "df_train = data[data['数据集划分'] == '训练']\n",
        "df_test = data[data['数据集划分'] == '测试1']\n",
        "# df_train.head()\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YII5aulLZNDP",
        "outputId": "15662b51-db6a-4ad5-9e8e-ff49c2b69fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "83    1.0\n",
            "53    3.0\n",
            "70    1.0\n",
            "45    2.0\n",
            "44    1.0\n",
            "39    1.0\n",
            "22    1.0\n",
            "80    3.0\n",
            "10    1.0\n",
            "0     4.0\n",
            "18    1.0\n",
            "30    4.0\n",
            "73    0.0\n",
            "33    4.0\n",
            "90    2.0\n",
            "4     3.0\n",
            "76    6.0\n",
            "77    1.0\n",
            "12    1.0\n",
            "31    0.0\n",
            "Name: 90天mRS, dtype: float64\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "# 提取特征列（排除目标列）\n",
        "X = df_train .drop(columns=[\"ID\",\"90天mRS\",\"血压\",\"数据集划分\"])\n",
        "\n",
        "# 提取目标列\n",
        "y = df_train[\"90天mRS\"]\n",
        "\n",
        "# 将数据集分为训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(y_test)\n",
        "print(y_test.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV4OiPAu23Ge",
        "outputId": "28189c4e-d6fb-4af9-9da3-b854841eacac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([80, 1, 42])\n",
            "torch.Size([20, 1, 42])\n"
          ]
        }
      ],
      "source": [
        "t = list(range(1, num_epochs + 1, step))\n",
        "# print(len(t))\n",
        "# print(X)\n",
        "\n",
        "\n",
        "# 划分数据集为训练集和测试集\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
        "\n",
        "# 将数据转换为PyTorch张量\n",
        "X_train = torch.Tensor(X_train.values)\n",
        "y_train = torch.Tensor(y_train.values).view(-1, 1)  # 将目标数据调整为列向量\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "y_test = torch.Tensor(y_test.values).view(-1, 1)  # 将目标数据调整为列向量\n",
        "\n",
        "X_train=torch.reshape(X_train,(X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test=torch.reshape(X_test,(X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# X_train=torch.reshape(X_train,(1,X_train.shape[0], X_train.shape[1]))\n",
        "# X_test=torch.reshape(X_test,(1,X_test.shape[0],  X_test.shape[1]))\n",
        "\n",
        "print(X_train.size())\n",
        "print(X_test.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shedqbBaNl1A",
        "outputId": "dd3047cf-f913-47dd-f9f0-117ac96580e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0.1515, 1.0000, 0.0000,  ..., 0.0000, 0.5714, 0.7889]],\n",
            "\n",
            "        [[0.4091, 1.0000, 0.0000,  ..., 0.0000, 0.3714, 0.5556]],\n",
            "\n",
            "        [[0.7879, 0.0000, 0.0000,  ..., 1.0000, 0.3714, 0.3444]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.7273, 0.0000, 0.0000,  ..., 0.0000, 0.1500, 0.2778]],\n",
            "\n",
            "        [[0.1667, 1.0000, 0.0000,  ..., 0.0000, 0.5714, 0.5778]],\n",
            "\n",
            "        [[0.3182, 1.0000, 0.0000,  ..., 0.0000, 0.1929, 0.4667]]])\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bQl4fDw4BiTb",
        "outputId": "a0104922-efa9-45c6-9971-5a810b2ff294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "Epoch [5001/10000], train_Loss: 0.0003887911734636873,test_Loss:21.977039337158203, r2_store:-0.3559820472824524\n",
            "Epoch [5002/10000], train_Loss: 0.00038885511457920074,test_Loss:21.964218139648438, r2_store:-0.35505813572451306\n",
            "Epoch [5003/10000], train_Loss: 0.00038938195211812854,test_Loss:21.976675033569336, r2_store:-0.3560033716670272\n",
            "Epoch [5004/10000], train_Loss: 0.00039052829379215837,test_Loss:21.965417861938477, r2_store:-0.354879935972644\n",
            "Epoch [5005/10000], train_Loss: 0.0003921288007404655,test_Loss:21.980939865112305, r2_store:-0.35601155081690194\n",
            "Epoch [5006/10000], train_Loss: 0.000394180096918717,test_Loss:21.96817398071289, r2_store:-0.35466517691842303\n",
            "Epoch [5007/10000], train_Loss: 0.0003987882810179144,test_Loss:21.985828399658203, r2_store:-0.3561418830624634\n",
            "Epoch [5008/10000], train_Loss: 0.0004055732861161232,test_Loss:21.96488380432129, r2_store:-0.35447684527230106\n",
            "Epoch [5009/10000], train_Loss: 0.000414711277699098,test_Loss:21.985626220703125, r2_store:-0.3564191990358576\n",
            "Epoch [5010/10000], train_Loss: 0.0004268816264811903,test_Loss:21.958072662353516, r2_store:-0.35420007739861026\n",
            "Epoch [5011/10000], train_Loss: 0.00044483403326012194,test_Loss:21.98728370666504, r2_store:-0.3567114807533007\n",
            "Epoch [5012/10000], train_Loss: 0.00047011557035148144,test_Loss:21.951631546020508, r2_store:-0.3537224493480249\n",
            "Epoch [5013/10000], train_Loss: 0.0005048700841143727,test_Loss:21.99458122253418, r2_store:-0.3570950108756026\n",
            "Epoch [5014/10000], train_Loss: 0.0005529236514121294,test_Loss:21.948135375976562, r2_store:-0.3530449474298869\n",
            "Epoch [5015/10000], train_Loss: 0.0006219349452294409,test_Loss:22.00459098815918, r2_store:-0.3577305468840424\n",
            "Epoch [5016/10000], train_Loss: 0.0007211383199319243,test_Loss:21.93783950805664, r2_store:-0.352154587530342\n",
            "Epoch [5017/10000], train_Loss: 0.000864966947119683,test_Loss:22.013700485229492, r2_store:-0.35880749994169525\n",
            "Epoch [5018/10000], train_Loss: 0.0010722618317231536,test_Loss:21.91729164123535, r2_store:-0.3509407920071632\n",
            "Epoch [5019/10000], train_Loss: 0.0013767881318926811,test_Loss:22.030487060546875, r2_store:-0.360373928143809\n",
            "Epoch [5020/10000], train_Loss: 0.0018110513919964433,test_Loss:21.895715713500977, r2_store:-0.34910407929595944\n",
            "Epoch [5021/10000], train_Loss: 0.002452809363603592,test_Loss:22.06336212158203, r2_store:-0.3626748910694444\n",
            "Epoch [5022/10000], train_Loss: 0.003393135964870453,test_Loss:21.872140884399414, r2_store:-0.3462396123018645\n",
            "Epoch [5023/10000], train_Loss: 0.0048085772432386875,test_Loss:22.10896110534668, r2_store:-0.36619655921986927\n",
            "Epoch [5024/10000], train_Loss: 0.006882697343826294,test_Loss:21.81399917602539, r2_store:-0.34237522452228353\n",
            "Epoch [5025/10000], train_Loss: 0.009987521916627884,test_Loss:22.16860580444336, r2_store:-0.3718530934705424\n",
            "Epoch [5026/10000], train_Loss: 0.014495907351374626,test_Loss:21.756542205810547, r2_store:-0.3365880651134827\n",
            "Epoch [5027/10000], train_Loss: 0.021246979013085365,test_Loss:22.274097442626953, r2_store:-0.3800042188965205\n",
            "Epoch [5028/10000], train_Loss: 0.030734583735466003,test_Loss:21.650774002075195, r2_store:-0.3293602633957451\n",
            "Epoch [5029/10000], train_Loss: 0.044351544231176376,test_Loss:22.399473190307617, r2_store:-0.3922529220516908\n",
            "Epoch [5030/10000], train_Loss: 0.062168508768081665,test_Loss:21.56668472290039, r2_store:-0.3208173961741887\n",
            "Epoch [5031/10000], train_Loss: 0.08504833281040192,test_Loss:22.570415496826172, r2_store:-0.4062608531097509\n",
            "Epoch [5032/10000], train_Loss: 0.10738722234964371,test_Loss:21.476882934570312, r2_store:-0.3155790032011905\n",
            "Epoch [5033/10000], train_Loss: 0.1260974109172821,test_Loss:22.62977409362793, r2_store:-0.4115990949972703\n",
            "Epoch [5034/10000], train_Loss: 0.12638090550899506,test_Loss:21.533720016479492, r2_store:-0.3182398283832153\n",
            "Epoch [5035/10000], train_Loss: 0.10690611600875854,test_Loss:22.431407928466797, r2_store:-0.3943917170581581\n",
            "Epoch [5036/10000], train_Loss: 0.06622637063264847,test_Loss:21.732372283935547, r2_store:-0.33630294858437493\n",
            "Epoch [5037/10000], train_Loss: 0.025119949132204056,test_Loss:22.05522918701172, r2_store:-0.3607746160270613\n",
            "Epoch [5038/10000], train_Loss: 0.002254127524793148,test_Loss:22.153615951538086, r2_store:-0.36496011592259925\n",
            "Epoch [5039/10000], train_Loss: 0.006023246794939041,test_Loss:21.823354721069336, r2_store:-0.3346856838970196\n",
            "Epoch [5040/10000], train_Loss: 0.02642396092414856,test_Loss:22.43532943725586, r2_store:-0.38516069024362665\n",
            "Epoch [5041/10000], train_Loss: 0.04404788091778755,test_Loss:21.78237533569336, r2_store:-0.32907622279909887\n",
            "Epoch [5042/10000], train_Loss: 0.0452398955821991,test_Loss:22.367168426513672, r2_store:-0.3793120606795375\n",
            "Epoch [5043/10000], train_Loss: 0.0287180058658123,test_Loss:21.912471771240234, r2_store:-0.344091661070399\n",
            "Epoch [5044/10000], train_Loss: 0.009078973904252052,test_Loss:22.0472354888916, r2_store:-0.35658312350409016\n",
            "Epoch [5045/10000], train_Loss: 0.0007416815496981144,test_Loss:22.195049285888672, r2_store:-0.3675723143647627\n",
            "Epoch [5046/10000], train_Loss: 0.007058098912239075,test_Loss:21.881664276123047, r2_store:-0.33950662898849315\n",
            "Epoch [5047/10000], train_Loss: 0.018747389316558838,test_Loss:22.336488723754883, r2_store:-0.3781013014764478\n",
            "Epoch [5048/10000], train_Loss: 0.02356853522360325,test_Loss:21.88008689880371, r2_store:-0.33957887794268204\n",
            "Epoch [5049/10000], train_Loss: 0.017858430743217468,test_Loss:22.20250701904297, r2_store:-0.36699376201837985\n",
            "Epoch [5050/10000], train_Loss: 0.007199454121291637,test_Loss:22.054981231689453, r2_store:-0.3531503043000328\n",
            "Epoch [5051/10000], train_Loss: 0.0009587209788151085,test_Loss:22.00448989868164, r2_store:-0.34877921041727444\n",
            "Epoch [5052/10000], train_Loss: 0.0028709755279123783,test_Loss:22.21174430847168, r2_store:-0.3675836821122056\n",
            "Epoch [5053/10000], train_Loss: 0.008990908041596413,test_Loss:21.889028549194336, r2_store:-0.3410382192860608\n",
            "Epoch [5054/10000], train_Loss: 0.01258140243589878,test_Loss:22.20828628540039, r2_store:-0.368774037314175\n",
            "Epoch [5055/10000], train_Loss: 0.01027468778192997,test_Loss:21.94004249572754, r2_store:-0.3468492427352612\n",
            "Epoch [5056/10000], train_Loss: 0.0047654761001467705,test_Loss:22.052352905273438, r2_store:-0.35774897868004785\n",
            "Epoch [5057/10000], train_Loss: 0.0009605870582163334,test_Loss:22.061519622802734, r2_store:-0.35927947229128443\n",
            "Epoch [5058/10000], train_Loss: 0.0014761340571567416,test_Loss:21.92060661315918, r2_store:-0.346846666059355\n",
            "Epoch [5059/10000], train_Loss: 0.0046484582126140594,test_Loss:22.149412155151367, r2_store:-0.3658378235822055\n",
            "Epoch [5060/10000], train_Loss: 0.0068845199421048164,test_Loss:21.903173446655273, r2_store:-0.34498664178306027\n",
            "Epoch [5061/10000], train_Loss: 0.006149261258542538,test_Loss:22.100826263427734, r2_store:-0.36147668386772924\n",
            "Epoch [5062/10000], train_Loss: 0.003310050815343857,test_Loss:22.004343032836914, r2_store:-0.35139179895703765\n",
            "Epoch [5063/10000], train_Loss: 0.0009815958328545094,test_Loss:22.017166137695312, r2_store:-0.3520397381163669\n",
            "Epoch [5064/10000], train_Loss: 0.0007886482635512948,test_Loss:22.094276428222656, r2_store:-0.35976234473728397\n",
            "Epoch [5065/10000], train_Loss: 0.0022832024842500687,test_Loss:21.93502426147461, r2_store:-0.34705029382605224\n",
            "Epoch [5066/10000], train_Loss: 0.0037347592879086733,test_Loss:22.110702514648438, r2_store:-0.36245939336370814\n",
            "Epoch [5067/10000], train_Loss: 0.003805282060056925,test_Loss:21.94430160522461, r2_store:-0.34898413173243115\n",
            "Epoch [5068/10000], train_Loss: 0.0025710477493703365,test_Loss:22.038143157958984, r2_store:-0.3584808525345189\n",
            "Epoch [5069/10000], train_Loss: 0.00112742162309587,test_Loss:21.993938446044922, r2_store:-0.35543640882389793\n",
            "Epoch [5070/10000], train_Loss: 0.000542067748028785,test_Loss:21.96811294555664, r2_store:-0.35258984159141993\n",
            "Epoch [5071/10000], train_Loss: 0.0010018219472840428,test_Loss:22.06913185119629, r2_store:-0.3604359815459528\n",
            "Epoch [5072/10000], train_Loss: 0.0018695058533921838,test_Loss:21.946521759033203, r2_store:-0.34979930889149835\n",
            "Epoch [5073/10000], train_Loss: 0.002332741394639015,test_Loss:22.071773529052734, r2_store:-0.36075191960016295\n",
            "Epoch [5074/10000], train_Loss: 0.002041471656411886,test_Loss:21.972320556640625, r2_store:-0.3515782684557005\n",
            "Epoch [5075/10000], train_Loss: 0.0012995635624974966,test_Loss:22.035619735717773, r2_store:-0.356996760954174\n",
            "Epoch [5076/10000], train_Loss: 0.00066336989402771,test_Loss:22.015411376953125, r2_store:-0.3559888796974944\n",
            "Epoch [5077/10000], train_Loss: 0.0005165348993614316,test_Loss:21.97784423828125, r2_store:-0.35315436353888274\n",
            "Epoch [5078/10000], train_Loss: 0.000823061796836555,test_Loss:22.0528564453125, r2_store:-0.35933484746704236\n",
            "Epoch [5079/10000], train_Loss: 0.001235650503076613,test_Loss:21.962722778320312, r2_store:-0.3516319317663643\n",
            "Epoch [5080/10000], train_Loss: 0.0014074587961658835,test_Loss:22.04556655883789, r2_store:-0.35944010516241653\n",
            "Epoch [5081/10000], train_Loss: 0.0012303786352276802,test_Loss:21.967601776123047, r2_store:-0.3530448413333942\n",
            "Epoch [5082/10000], train_Loss: 0.0008605752373114228,test_Loss:22.012853622436523, r2_store:-0.35675144504083245\n",
            "Epoch [5083/10000], train_Loss: 0.0005518539110198617,test_Loss:22.00499725341797, r2_store:-0.35570963808292255\n",
            "Epoch [5084/10000], train_Loss: 0.0004716042894870043,test_Loss:21.985267639160156, r2_store:-0.35372718479392007\n",
            "Epoch [5085/10000], train_Loss: 0.0006046522757969797,test_Loss:22.037214279174805, r2_store:-0.3578051822923709\n",
            "Epoch [5086/10000], train_Loss: 0.000806135474704206,test_Loss:21.97715950012207, r2_store:-0.352407035125478\n",
            "Epoch [5087/10000], train_Loss: 0.0009165749070234597,test_Loss:22.0447998046875, r2_store:-0.3580856553692997\n",
            "Epoch [5088/10000], train_Loss: 0.0008683625492267311,test_Loss:21.98371124267578, r2_store:-0.3532461320947926\n",
            "Epoch [5089/10000], train_Loss: 0.0007065082900226116,test_Loss:22.020397186279297, r2_store:-0.35678734957279423\n",
            "Epoch [5090/10000], train_Loss: 0.0005366414552554488,test_Loss:21.999927520751953, r2_store:-0.3552016655680852\n",
            "Epoch [5091/10000], train_Loss: 0.00044565313146449625,test_Loss:21.99712371826172, r2_store:-0.3548665684240442\n",
            "Epoch [5092/10000], train_Loss: 0.0004591030883602798,test_Loss:22.02211570739746, r2_store:-0.35685310175866647\n",
            "Epoch [5093/10000], train_Loss: 0.0005391801241785288,test_Loss:21.985645294189453, r2_store:-0.3535953104232099\n",
            "Epoch [5094/10000], train_Loss: 0.0006193793378770351,test_Loss:22.03327178955078, r2_store:-0.35740508874154675\n",
            "Epoch [5095/10000], train_Loss: 0.0006490146624855697,test_Loss:21.988990783691406, r2_store:-0.35355450849059844\n",
            "Epoch [5096/10000], train_Loss: 0.0006134624709375203,test_Loss:22.026569366455078, r2_store:-0.35685636504767526\n",
            "Epoch [5097/10000], train_Loss: 0.0005381917580962181,test_Loss:21.996801376342773, r2_store:-0.35457402754322676\n",
            "Epoch [5098/10000], train_Loss: 0.0004625412984751165,test_Loss:22.009326934814453, r2_store:-0.3557100891959195\n",
            "Epoch [5099/10000], train_Loss: 0.00042066964670084417,test_Loss:22.01126480102539, r2_store:-0.3557953665981515\n",
            "Epoch [5100/10000], train_Loss: 0.00042197201400995255,test_Loss:21.995807647705078, r2_store:-0.3545868964912191\n",
            "Epoch [5101/10000], train_Loss: 0.00045277824392542243,test_Loss:22.02033042907715, r2_store:-0.3566056794983512\n",
            "Epoch [5102/10000], train_Loss: 0.0004879047046415508,test_Loss:21.992002487182617, r2_store:-0.35405121546531815\n",
            "Epoch [5103/10000], train_Loss: 0.0005070821498520672,test_Loss:22.025054931640625, r2_store:-0.35666419288363094\n",
            "Epoch [5104/10000], train_Loss: 0.000502547831274569,test_Loss:21.994468688964844, r2_store:-0.35418619550389074\n",
            "Epoch [5105/10000], train_Loss: 0.0004771447856910527,test_Loss:22.01700210571289, r2_store:-0.3561869122185195\n",
            "Epoch [5106/10000], train_Loss: 0.0004436087911017239,test_Loss:22.000267028808594, r2_store:-0.3547929983472906\n",
            "Epoch [5107/10000], train_Loss: 0.00041424520895816386,test_Loss:22.010114669799805, r2_store:-0.35538708029063715\n",
            "Epoch [5108/10000], train_Loss: 0.00039923895383253694,test_Loss:22.01097869873047, r2_store:-0.35548390140805686\n",
            "Epoch [5109/10000], train_Loss: 0.00039939829730428755,test_Loss:22.00082778930664, r2_store:-0.35476171256922084\n",
            "Epoch [5110/10000], train_Loss: 0.00040985335363075137,test_Loss:22.018980026245117, r2_store:-0.35597926745991093\n",
            "Epoch [5111/10000], train_Loss: 0.00042208004742860794,test_Loss:22.001508712768555, r2_store:-0.35439542078230324\n",
            "Epoch [5112/10000], train_Loss: 0.00043105846270918846,test_Loss:22.02098846435547, r2_store:-0.35613468326568\n",
            "Epoch [5113/10000], train_Loss: 0.0004328872018959373,test_Loss:22.00309944152832, r2_store:-0.35437613225853615\n",
            "Epoch [5114/10000], train_Loss: 0.0004255800449755043,test_Loss:22.020679473876953, r2_store:-0.3558938648449197\n",
            "Epoch [5115/10000], train_Loss: 0.00041399471228942275,test_Loss:22.00262451171875, r2_store:-0.3546561024956836\n",
            "Epoch [5116/10000], train_Loss: 0.000401005323510617,test_Loss:22.01307487487793, r2_store:-0.35553190510496324\n",
            "Epoch [5117/10000], train_Loss: 0.0003893117536790669,test_Loss:22.008895874023438, r2_store:-0.3550321488710608\n",
            "Epoch [5118/10000], train_Loss: 0.0003819938865490258,test_Loss:22.008167266845703, r2_store:-0.3551158267878798\n",
            "Epoch [5119/10000], train_Loss: 0.00037975257146172225,test_Loss:22.01015853881836, r2_store:-0.35548552514872256\n",
            "Epoch [5120/10000], train_Loss: 0.000382125930627808,test_Loss:22.005550384521484, r2_store:-0.3547911238310766\n",
            "Epoch [5121/10000], train_Loss: 0.00038607377791777253,test_Loss:22.01708984375, r2_store:-0.3556885020908147\n",
            "Epoch [5122/10000], train_Loss: 0.0003896449925377965,test_Loss:22.003219604492188, r2_store:-0.3545836923449732\n",
            "Epoch [5123/10000], train_Loss: 0.00039232714334502816,test_Loss:22.017192840576172, r2_store:-0.35573800539832146\n",
            "Epoch [5124/10000], train_Loss: 0.00039265089435502887,test_Loss:22.00442123413086, r2_store:-0.35454014249408683\n",
            "Epoch [5125/10000], train_Loss: 0.00039013888454064727,test_Loss:22.016141891479492, r2_store:-0.3556742449764254\n",
            "Epoch [5126/10000], train_Loss: 0.0003849531931336969,test_Loss:22.00288963317871, r2_store:-0.3547212574822065\n",
            "Epoch [5127/10000], train_Loss: 0.00037914124550297856,test_Loss:22.012601852416992, r2_store:-0.3554817724295689\n",
            "Epoch [5128/10000], train_Loss: 0.00037350592901930213,test_Loss:22.007511138916016, r2_store:-0.35483318082128057\n",
            "Epoch [5129/10000], train_Loss: 0.0003685130795929581,test_Loss:22.012758255004883, r2_store:-0.35513674209434276\n",
            "Epoch [5130/10000], train_Loss: 0.000364644278306514,test_Loss:22.012004852294922, r2_store:-0.35499046897638653\n",
            "Epoch [5131/10000], train_Loss: 0.0003626731631811708,test_Loss:22.012928009033203, r2_store:-0.35483638362480985\n",
            "Epoch [5132/10000], train_Loss: 0.0003619170456659049,test_Loss:22.015901565551758, r2_store:-0.3551142808603265\n",
            "Epoch [5133/10000], train_Loss: 0.0003621422511059791,test_Loss:22.007099151611328, r2_store:-0.3546603443083889\n",
            "Epoch [5134/10000], train_Loss: 0.0003628244739957154,test_Loss:22.01265525817871, r2_store:-0.3552573321103598\n",
            "Epoch [5135/10000], train_Loss: 0.0003636001201812178,test_Loss:22.00480079650879, r2_store:-0.35452762701668505\n",
            "Epoch [5136/10000], train_Loss: 0.00036406292929314077,test_Loss:22.013591766357422, r2_store:-0.35529253816054474\n",
            "Epoch [5137/10000], train_Loss: 0.0003635491884779185,test_Loss:22.00474739074707, r2_store:-0.35450113283607076\n",
            "Epoch [5138/10000], train_Loss: 0.0003624610835686326,test_Loss:22.014606475830078, r2_store:-0.35532044598065693\n",
            "Epoch [5139/10000], train_Loss: 0.0003610679123084992,test_Loss:22.006343841552734, r2_store:-0.35455064101176514\n",
            "Epoch [5140/10000], train_Loss: 0.00035912165185436606,test_Loss:22.01499366760254, r2_store:-0.3552802970000726\n",
            "Epoch [5141/10000], train_Loss: 0.0003569326945580542,test_Loss:22.007970809936523, r2_store:-0.354556608750231\n",
            "Epoch [5142/10000], train_Loss: 0.0003549781977199018,test_Loss:22.015682220458984, r2_store:-0.3551753394020123\n",
            "Epoch [5143/10000], train_Loss: 0.00035280812880955637,test_Loss:22.00741195678711, r2_store:-0.35457740035173413\n",
            "Epoch [5144/10000], train_Loss: 0.0003507086948957294,test_Loss:22.013050079345703, r2_store:-0.3551033019700256\n",
            "Epoch [5145/10000], train_Loss: 0.00034883004263974726,test_Loss:22.006977081298828, r2_store:-0.3546119387881934\n",
            "Epoch [5146/10000], train_Loss: 0.00034688677988015115,test_Loss:22.011409759521484, r2_store:-0.3550620482267177\n",
            "Epoch [5147/10000], train_Loss: 0.00034536171006038785,test_Loss:22.006690979003906, r2_store:-0.3546283020806358\n",
            "Epoch [5148/10000], train_Loss: 0.00034398524439893663,test_Loss:22.011510848999023, r2_store:-0.354976680290928\n",
            "Epoch [5149/10000], train_Loss: 0.00034243572736158967,test_Loss:22.00696563720703, r2_store:-0.3545929102864269\n",
            "Epoch [5150/10000], train_Loss: 0.0003409035853110254,test_Loss:22.009492874145508, r2_store:-0.3549040519786819\n",
            "Epoch [5151/10000], train_Loss: 0.00033977109706029296,test_Loss:22.00786018371582, r2_store:-0.3545246097596808\n",
            "Epoch [5152/10000], train_Loss: 0.00033868729951791465,test_Loss:22.01119613647461, r2_store:-0.3548339700811465\n",
            "Epoch [5153/10000], train_Loss: 0.00033737116609700024,test_Loss:22.00577163696289, r2_store:-0.354560304541933\n",
            "Epoch [5154/10000], train_Loss: 0.0003362173156347126,test_Loss:22.010604858398438, r2_store:-0.35487820142316817\n",
            "Epoch [5155/10000], train_Loss: 0.0003351901541464031,test_Loss:22.007123947143555, r2_store:-0.3545799273184007\n",
            "Epoch [5156/10000], train_Loss: 0.00033409983734600246,test_Loss:22.008785247802734, r2_store:-0.35488794983783234\n",
            "Epoch [5157/10000], train_Loss: 0.0003328285238239914,test_Loss:22.003419876098633, r2_store:-0.35457366257532885\n",
            "Epoch [5158/10000], train_Loss: 0.0003318077069707215,test_Loss:22.008203506469727, r2_store:-0.35481298465122957\n",
            "Epoch [5159/10000], train_Loss: 0.00033058488043025136,test_Loss:22.005435943603516, r2_store:-0.35446601709862513\n",
            "Epoch [5160/10000], train_Loss: 0.0003298449155408889,test_Loss:22.008398056030273, r2_store:-0.35478837919556727\n",
            "Epoch [5161/10000], train_Loss: 0.00032908652792684734,test_Loss:22.004390716552734, r2_store:-0.354421844461029\n",
            "Epoch [5162/10000], train_Loss: 0.0003281317767687142,test_Loss:22.00969886779785, r2_store:-0.35483001287971994\n",
            "Epoch [5163/10000], train_Loss: 0.0003280871897004545,test_Loss:22.003049850463867, r2_store:-0.35434038837899684\n",
            "Epoch [5164/10000], train_Loss: 0.0003285098937340081,test_Loss:22.008197784423828, r2_store:-0.3549170298345614\n",
            "Epoch [5165/10000], train_Loss: 0.0003291941247880459,test_Loss:22.00015640258789, r2_store:-0.3541535330414245\n",
            "Epoch [5166/10000], train_Loss: 0.0003308283048681915,test_Loss:22.01097869873047, r2_store:-0.3549586794105193\n",
            "Epoch [5167/10000], train_Loss: 0.00033394384081475437,test_Loss:21.998355865478516, r2_store:-0.353883206892438\n",
            "Epoch [5168/10000], train_Loss: 0.00033845347934402525,test_Loss:22.012495040893555, r2_store:-0.3551273511543458\n",
            "Epoch [5169/10000], train_Loss: 0.00034462238545529544,test_Loss:21.99388313293457, r2_store:-0.35368098841592976\n",
            "Epoch [5170/10000], train_Loss: 0.0003542016202118248,test_Loss:22.014270782470703, r2_store:-0.3554579175408381\n",
            "Epoch [5171/10000], train_Loss: 0.000368939945474267,test_Loss:21.990053176879883, r2_store:-0.35331451364612887\n",
            "Epoch [5172/10000], train_Loss: 0.0003907606878783554,test_Loss:22.020587921142578, r2_store:-0.35584884228150493\n",
            "Epoch [5173/10000], train_Loss: 0.0004238944093231112,test_Loss:21.984115600585938, r2_store:-0.3527237820825484\n",
            "Epoch [5174/10000], train_Loss: 0.0004730379150714725,test_Loss:22.029176712036133, r2_store:-0.35643726168908874\n",
            "Epoch [5175/10000], train_Loss: 0.0005480417748913169,test_Loss:21.97612953186035, r2_store:-0.3518438201230163\n",
            "Epoch [5176/10000], train_Loss: 0.0006613606819882989,test_Loss:22.041868209838867, r2_store:-0.3574032326587775\n",
            "Epoch [5177/10000], train_Loss: 0.0008337022736668587,test_Loss:21.957611083984375, r2_store:-0.35058915704153737\n",
            "Epoch [5178/10000], train_Loss: 0.001095338724553585,test_Loss:22.059520721435547, r2_store:-0.3589252107547998\n",
            "Epoch [5179/10000], train_Loss: 0.0014942241832613945,test_Loss:21.93948745727539, r2_store:-0.34858801286682883\n",
            "Epoch [5180/10000], train_Loss: 0.0021025489550083876,test_Loss:22.088634490966797, r2_store:-0.3613039626363814\n",
            "Epoch [5181/10000], train_Loss: 0.0030324417166411877,test_Loss:21.89586639404297, r2_store:-0.34575913413256454\n",
            "Epoch [5182/10000], train_Loss: 0.00447808438912034,test_Loss:22.133962631225586, r2_store:-0.3651758206197373\n",
            "Epoch [5183/10000], train_Loss: 0.006696989294141531,test_Loss:21.856782913208008, r2_store:-0.3411726640752488\n",
            "Epoch [5184/10000], train_Loss: 0.010200484655797482,test_Loss:22.215740203857422, r2_store:-0.37131748153165156\n",
            "Epoch [5185/10000], train_Loss: 0.015534904785454273,test_Loss:21.763822555541992, r2_store:-0.3348684020595969\n",
            "Epoch [5186/10000], train_Loss: 0.023861652240157127,test_Loss:22.32805061340332, r2_store:-0.38152888683175723\n",
            "Epoch [5187/10000], train_Loss: 0.03611807897686958,test_Loss:21.688541412353516, r2_store:-0.3258506974721316\n",
            "Epoch [5188/10000], train_Loss: 0.05452234670519829,test_Loss:22.51629066467285, r2_store:-0.396600892743022\n",
            "Epoch [5189/10000], train_Loss: 0.07962344586849213,test_Loss:21.536561965942383, r2_store:-0.31601970495128184\n",
            "Epoch [5190/10000], train_Loss: 0.11264654248952866,test_Loss:22.6816349029541, r2_store:-0.4143978508159296\n",
            "Epoch [5191/10000], train_Loss: 0.14440496265888214,test_Loss:21.49415397644043, r2_store:-0.3091448428922179\n",
            "Epoch [5192/10000], train_Loss: 0.16887086629867554,test_Loss:22.807106018066406, r2_store:-0.4181656623947376\n",
            "Epoch [5193/10000], train_Loss: 0.161843940615654,test_Loss:21.536962509155273, r2_store:-0.3152128473031506\n",
            "Epoch [5194/10000], train_Loss: 0.1222076267004013,test_Loss:22.392597198486328, r2_store:-0.3904421824326598\n",
            "Epoch [5195/10000], train_Loss: 0.05829820781946182,test_Loss:21.87080192565918, r2_store:-0.3416161982471344\n",
            "Epoch [5196/10000], train_Loss: 0.010260211303830147,test_Loss:21.97718048095703, r2_store:-0.3467793069912526\n",
            "Epoch [5197/10000], train_Loss: 0.003513490315526724,test_Loss:22.364490509033203, r2_store:-0.37844887179641984\n",
            "Epoch [5198/10000], train_Loss: 0.03111448511481285,test_Loss:21.767789840698242, r2_store:-0.32450663626015896\n",
            "Epoch [5199/10000], train_Loss: 0.06119497865438461,test_Loss:22.624576568603516, r2_store:-0.39061271166329803\n",
            "Epoch [5200/10000], train_Loss: 0.06338135898113251,test_Loss:21.90239715576172, r2_store:-0.33036054340399046\n",
            "Epoch [5201/10000], train_Loss: 0.03768331557512283,test_Loss:22.27741050720215, r2_store:-0.3662802072605569\n",
            "Epoch [5202/10000], train_Loss: 0.008232241496443748,test_Loss:22.167255401611328, r2_store:-0.35923612468484545\n",
            "Epoch [5203/10000], train_Loss: 0.0019414646085351706,test_Loss:21.929340362548828, r2_store:-0.3383820761995686\n",
            "Epoch [5204/10000], train_Loss: 0.018087157979607582,test_Loss:22.444143295288086, r2_store:-0.38128311573401596\n",
            "Epoch [5205/10000], train_Loss: 0.033470578491687775,test_Loss:21.874080657958984, r2_store:-0.3344784647434418\n",
            "Epoch [5206/10000], train_Loss: 0.03040401265025139,test_Loss:22.319332122802734, r2_store:-0.3712812008335926\n",
            "Epoch [5207/10000], train_Loss: 0.013099057599902153,test_Loss:22.145963668823242, r2_store:-0.3523649360766645\n",
            "Epoch [5208/10000], train_Loss: 0.0013398672454059124,test_Loss:22.086292266845703, r2_store:-0.3464917473694513\n",
            "Epoch [5209/10000], train_Loss: 0.005064855329692364,test_Loss:22.36002540588379, r2_store:-0.3720010570689736\n",
            "Epoch [5210/10000], train_Loss: 0.015824712812900543,test_Loss:21.95633316040039, r2_store:-0.33724828232715676\n",
            "Epoch [5211/10000], train_Loss: 0.01935691572725773,test_Loss:22.32937240600586, r2_store:-0.368538528777568\n",
            "Epoch [5212/10000], train_Loss: 0.011805148795247078,test_Loss:22.059812545776367, r2_store:-0.3483588879332893\n",
            "Epoch [5213/10000], train_Loss: 0.002645416185259819,test_Loss:22.062454223632812, r2_store:-0.3508310334238436\n",
            "Epoch [5214/10000], train_Loss: 0.0014273643027991056,test_Loss:22.23941421508789, r2_store:-0.3655082678781987\n",
            "Epoch [5215/10000], train_Loss: 0.0071605802513659,test_Loss:21.973018646240234, r2_store:-0.3410697959811828\n",
            "Epoch [5216/10000], train_Loss: 0.011460860259830952,test_Loss:22.262250900268555, r2_store:-0.36713091525168484\n",
            "Epoch [5217/10000], train_Loss: 0.00906287133693695,test_Loss:22.006927490234375, r2_store:-0.34763753070446723\n",
            "Epoch [5218/10000], train_Loss: 0.0033473658841103315,test_Loss:22.0725040435791, r2_store:-0.3541051134768096\n",
            "Epoch [5219/10000], train_Loss: 0.0006879196153022349,test_Loss:22.1621036529541, r2_store:-0.3602561673308824\n",
            "Epoch [5220/10000], train_Loss: 0.0029131327755749226,test_Loss:21.97884178161621, r2_store:-0.3438408754306508\n",
            "Epoch [5221/10000], train_Loss: 0.006215170491486788,test_Loss:22.212757110595703, r2_store:-0.36380717753430813\n",
            "Epoch [5222/10000], train_Loss: 0.006385978311300278,test_Loss:22.009946823120117, r2_store:-0.3463346044373068\n",
            "Epoch [5223/10000], train_Loss: 0.0034988471306860447,test_Loss:22.122859954833984, r2_store:-0.35558652495397514\n",
            "Epoch [5224/10000], train_Loss: 0.0009061078308150172,test_Loss:22.124526977539062, r2_store:-0.3563903912151767\n",
            "Epoch [5225/10000], train_Loss: 0.001074297120794654,test_Loss:22.001100540161133, r2_store:-0.3472568030435157\n",
            "Epoch [5226/10000], train_Loss: 0.0030451857019215822,test_Loss:22.160480499267578, r2_store:-0.36200789982059645\n",
            "Epoch [5227/10000], train_Loss: 0.004158597439527512,test_Loss:21.989009857177734, r2_store:-0.3470835579721592\n",
            "Epoch [5228/10000], train_Loss: 0.003225246910005808,test_Loss:22.106834411621094, r2_store:-0.3577210991290447\n",
            "Epoch [5229/10000], train_Loss: 0.0013943591620773077,test_Loss:22.050861358642578, r2_store:-0.3539901780093915\n",
            "Epoch [5230/10000], train_Loss: 0.0005664503551088274,test_Loss:22.01217269897461, r2_store:-0.3506054699508774\n",
            "Epoch [5231/10000], train_Loss: 0.0012319430243223906,test_Loss:22.127010345458984, r2_store:-0.35973921362913486\n",
            "Epoch [5232/10000], train_Loss: 0.0023001034278422594,test_Loss:21.99560546875, r2_store:-0.34825909568389024\n",
            "Epoch [5233/10000], train_Loss: 0.002521814312785864,test_Loss:22.113210678100586, r2_store:-0.3589033240846671\n",
            "Epoch [5234/10000], train_Loss: 0.0017205039039254189,test_Loss:22.031431198120117, r2_store:-0.3522358501303857\n",
            "Epoch [5235/10000], train_Loss: 0.000780455011408776,test_Loss:22.052824020385742, r2_store:-0.35372915543111905\n",
            "Epoch [5236/10000], train_Loss: 0.0005420192028395832,test_Loss:22.09994888305664, r2_store:-0.3574962633172143\n",
            "Epoch [5237/10000], train_Loss: 0.0010215644724667072,test_Loss:22.011396408081055, r2_store:-0.3502914104330823\n",
            "Epoch [5238/10000], train_Loss: 0.001553137437440455,test_Loss:22.106849670410156, r2_store:-0.3591176785276615\n",
            "Epoch [5239/10000], train_Loss: 0.0015609592664986849,test_Loss:22.018299102783203, r2_store:-0.35154872862029696\n",
            "Epoch [5240/10000], train_Loss: 0.001082586939446628,test_Loss:22.07100486755371, r2_store:-0.35622158853542274\n",
            "Epoch [5241/10000], train_Loss: 0.0005996573599986732,test_Loss:22.058055877685547, r2_store:-0.355460778792404\n",
            "Epoch [5242/10000], train_Loss: 0.0005054453504271805,test_Loss:22.025814056396484, r2_store:-0.35251879578009016\n",
            "Epoch [5243/10000], train_Loss: 0.0007694490486755967,test_Loss:22.096752166748047, r2_store:-0.35789100530910556\n",
            "Epoch [5244/10000], train_Loss: 0.0010443374048918486,test_Loss:22.02413558959961, r2_store:-0.35135324412984414\n",
            "Epoch [5245/10000], train_Loss: 0.0010509334970265627,test_Loss:22.087116241455078, r2_store:-0.3569639473398427\n",
            "Epoch [5246/10000], train_Loss: 0.0008029494201764464,test_Loss:22.041881561279297, r2_store:-0.3532473863708605\n",
            "Epoch [5247/10000], train_Loss: 0.0005382398376241326,test_Loss:22.056232452392578, r2_store:-0.35412346817593554\n",
            "Epoch [5248/10000], train_Loss: 0.00045904068974778056,test_Loss:22.079435348510742, r2_store:-0.3558656476090587\n",
            "Epoch [5249/10000], train_Loss: 0.0005755076999776065,test_Loss:22.03446388244629, r2_store:-0.35217812094100953\n",
            "Epoch [5250/10000], train_Loss: 0.0007322408491745591,test_Loss:22.088884353637695, r2_store:-0.35690219563320413\n",
            "Epoch [5251/10000], train_Loss: 0.0007747040363028646,test_Loss:22.040699005126953, r2_store:-0.3523702986877213\n",
            "Epoch [5252/10000], train_Loss: 0.0006711868336424232,test_Loss:22.080366134643555, r2_store:-0.3555772794917125\n",
            "Epoch [5253/10000], train_Loss: 0.0005182384047657251,test_Loss:22.05986785888672, r2_store:-0.3541889747452225\n",
            "Epoch [5254/10000], train_Loss: 0.00043414291576482356,test_Loss:22.0502986907959, r2_store:-0.3536842348577063\n",
            "Epoch [5255/10000], train_Loss: 0.00046105970977805555,test_Loss:22.07808494567871, r2_store:-0.35592828742226557\n",
            "Epoch [5256/10000], train_Loss: 0.0005433823098428547,test_Loss:22.043407440185547, r2_store:-0.35273052574313946\n",
            "Epoch [5257/10000], train_Loss: 0.0005959884729236364,test_Loss:22.084184646606445, r2_store:-0.3562153026679149\n",
            "Epoch [5258/10000], train_Loss: 0.0005747684626840055,test_Loss:22.048442840576172, r2_store:-0.3533198515109677\n",
            "Epoch [5259/10000], train_Loss: 0.000501189089845866,test_Loss:22.070459365844727, r2_store:-0.35514577655936685\n",
            "Epoch [5260/10000], train_Loss: 0.00043173786252737045,test_Loss:22.065752029418945, r2_store:-0.35456333935241746\n",
            "Epoch [5261/10000], train_Loss: 0.00040838279528543353,test_Loss:22.056293487548828, r2_store:-0.353694054663221\n",
            "Epoch [5262/10000], train_Loss: 0.0004328638897277415,test_Loss:22.07589340209961, r2_store:-0.35548694814948223\n",
            "Epoch [5263/10000], train_Loss: 0.00047133566113188863,test_Loss:22.047027587890625, r2_store:-0.3531108275712991\n",
            "Epoch [5264/10000], train_Loss: 0.0004877018800470978,test_Loss:22.076265335083008, r2_store:-0.3555255404016333\n",
            "Epoch [5265/10000], train_Loss: 0.00046923226909711957,test_Loss:22.05233383178711, r2_store:-0.3536086098554847\n",
            "Epoch [5266/10000], train_Loss: 0.00043126390664838254,test_Loss:22.068025588989258, r2_store:-0.35480307929121757\n",
            "Epoch [5267/10000], train_Loss: 0.0003988028911408037,test_Loss:22.067325592041016, r2_store:-0.3545365767536892\n",
            "Epoch [5268/10000], train_Loss: 0.0003891916712746024,test_Loss:22.060333251953125, r2_store:-0.35393144332023185\n",
            "Epoch [5269/10000], train_Loss: 0.00040126527892425656,test_Loss:22.075366973876953, r2_store:-0.3552519460715251\n",
            "Epoch [5270/10000], train_Loss: 0.000419434072682634,test_Loss:22.055740356445312, r2_store:-0.3535327398170609\n",
            "Epoch [5271/10000], train_Loss: 0.00042904214933514595,test_Loss:22.077394485473633, r2_store:-0.3553079963340626\n",
            "Epoch [5272/10000], train_Loss: 0.0004224017611704767,test_Loss:22.058738708496094, r2_store:-0.3537441032647928\n",
            "Epoch [5273/10000], train_Loss: 0.000404396269004792,test_Loss:22.071399688720703, r2_store:-0.35484051833761976\n",
            "Epoch [5274/10000], train_Loss: 0.00038507053977809846,test_Loss:22.066410064697266, r2_store:-0.3543699090718766\n",
            "Epoch [5275/10000], train_Loss: 0.00037422426976263523,test_Loss:22.06543731689453, r2_store:-0.354233662817959\n",
            "Epoch [5276/10000], train_Loss: 0.00037473608972504735,test_Loss:22.073486328125, r2_store:-0.3549474965344219\n",
            "Epoch [5277/10000], train_Loss: 0.0003820843412540853,test_Loss:22.06193733215332, r2_store:-0.35387584860882293\n",
            "Epoch [5278/10000], train_Loss: 0.0003889656509272754,test_Loss:22.074663162231445, r2_store:-0.3551449445157633\n",
            "Epoch [5279/10000], train_Loss: 0.00039045323501341045,test_Loss:22.05971908569336, r2_store:-0.3538970902307106\n",
            "Epoch [5280/10000], train_Loss: 0.0003846564213745296,test_Loss:22.071002960205078, r2_store:-0.35494636247476286\n",
            "Epoch [5281/10000], train_Loss: 0.00037567762774415314,test_Loss:22.062984466552734, r2_store:-0.3541764634357294\n",
            "Epoch [5282/10000], train_Loss: 0.00036693192669190466,test_Loss:22.068143844604492, r2_store:-0.3545185730250269\n",
            "Epoch [5283/10000], train_Loss: 0.000361207639798522,test_Loss:22.06992530822754, r2_store:-0.35451709489423044\n",
            "Epoch [5284/10000], train_Loss: 0.00035985297290608287,test_Loss:22.065387725830078, r2_store:-0.3541341746245297\n",
            "Epoch [5285/10000], train_Loss: 0.0003615652385633439,test_Loss:22.074583053588867, r2_store:-0.35473028099965576\n",
            "Epoch [5286/10000], train_Loss: 0.0003636137116700411,test_Loss:22.065486907958984, r2_store:-0.3539164286923939\n",
            "Epoch [5287/10000], train_Loss: 0.0003639703500084579,test_Loss:22.07360076904297, r2_store:-0.3547377595730534\n",
            "Epoch [5288/10000], train_Loss: 0.0003622816293500364,test_Loss:22.066953659057617, r2_store:-0.35394766762011187\n",
            "Epoch [5289/10000], train_Loss: 0.00035861184005625546,test_Loss:22.07541847229004, r2_store:-0.35451192119324726\n",
            "Epoch [5290/10000], train_Loss: 0.0003540191682986915,test_Loss:22.070274353027344, r2_store:-0.35411660664863875\n",
            "Epoch [5291/10000], train_Loss: 0.00034984847297891974,test_Loss:22.07168197631836, r2_store:-0.3542433922991848\n",
            "Epoch [5292/10000], train_Loss: 0.0003475286066532135,test_Loss:22.073564529418945, r2_store:-0.3542867098823528\n",
            "Epoch [5293/10000], train_Loss: 0.0003469097428023815,test_Loss:22.069765090942383, r2_store:-0.35396094198097905\n",
            "Epoch [5294/10000], train_Loss: 0.00034686378785409033,test_Loss:22.072811126708984, r2_store:-0.3543707418034485\n",
            "Epoch [5295/10000], train_Loss: 0.0003469150688033551,test_Loss:22.06525230407715, r2_store:-0.3538379650415495\n",
            "Epoch [5296/10000], train_Loss: 0.00034663715632632375,test_Loss:22.072460174560547, r2_store:-0.35435364198289276\n",
            "Epoch [5297/10000], train_Loss: 0.0003451828961260617,test_Loss:22.06852912902832, r2_store:-0.3538261043776505\n",
            "Epoch [5298/10000], train_Loss: 0.0003428676282055676,test_Loss:22.073760986328125, r2_store:-0.35422664017975136\n",
            "Epoch [5299/10000], train_Loss: 0.00034017013967968524,test_Loss:22.07126235961914, r2_store:-0.35388543522131743\n",
            "Epoch [5300/10000], train_Loss: 0.0003381310380063951,test_Loss:22.074565887451172, r2_store:-0.3540588814914545\n",
            "Epoch [5301/10000], train_Loss: 0.0003362534916959703,test_Loss:22.071603775024414, r2_store:-0.35400819960943597\n",
            "Epoch [5302/10000], train_Loss: 0.000334839744027704,test_Loss:22.068662643432617, r2_store:-0.35397410589332545\n",
            "Epoch [5303/10000], train_Loss: 0.0003337315283715725,test_Loss:22.069839477539062, r2_store:-0.35408512511168455\n",
            "Epoch [5304/10000], train_Loss: 0.0003328214806970209,test_Loss:22.068218231201172, r2_store:-0.3538057032208246\n",
            "Epoch [5305/10000], train_Loss: 0.0003321468539070338,test_Loss:22.071683883666992, r2_store:-0.35406347503533153\n",
            "Epoch [5306/10000], train_Loss: 0.0003315682988613844,test_Loss:22.068622589111328, r2_store:-0.35371250872336457\n",
            "Epoch [5307/10000], train_Loss: 0.0003305886057205498,test_Loss:22.073902130126953, r2_store:-0.3540212363129378\n",
            "Epoch [5308/10000], train_Loss: 0.0003290174645371735,test_Loss:22.070301055908203, r2_store:-0.35373575708017957\n",
            "Epoch [5309/10000], train_Loss: 0.00032733476837165654,test_Loss:22.071208953857422, r2_store:-0.3540112299815048\n",
            "Epoch [5310/10000], train_Loss: 0.0003258989017922431,test_Loss:22.06745719909668, r2_store:-0.3538064250960238\n",
            "Epoch [5311/10000], train_Loss: 0.00032458535861223936,test_Loss:22.069713592529297, r2_store:-0.3539167537725043\n",
            "Epoch [5312/10000], train_Loss: 0.0003231189912185073,test_Loss:22.069900512695312, r2_store:-0.3537483141151734\n",
            "Epoch [5313/10000], train_Loss: 0.0003217197663616389,test_Loss:22.070722579956055, r2_store:-0.3537872347803763\n",
            "Epoch [5314/10000], train_Loss: 0.000320317194564268,test_Loss:22.07115936279297, r2_store:-0.353718555028423\n",
            "Epoch [5315/10000], train_Loss: 0.0003191996947862208,test_Loss:22.072662353515625, r2_store:-0.35372659374093063\n",
            "Epoch [5316/10000], train_Loss: 0.00031791700166650116,test_Loss:22.071945190429688, r2_store:-0.35376239485581173\n",
            "Epoch [5317/10000], train_Loss: 0.00031691795447841287,test_Loss:22.069183349609375, r2_store:-0.35374567758758\n",
            "Epoch [5318/10000], train_Loss: 0.00031601189402863383,test_Loss:22.070436477661133, r2_store:-0.3537817285482425\n",
            "Epoch [5319/10000], train_Loss: 0.0003148124669678509,test_Loss:22.069271087646484, r2_store:-0.3537094565775425\n",
            "Epoch [5320/10000], train_Loss: 0.00031343166483566165,test_Loss:22.070528030395508, r2_store:-0.35377282504482044\n",
            "Epoch [5321/10000], train_Loss: 0.00031235135975293815,test_Loss:22.069875717163086, r2_store:-0.3536518504144095\n",
            "Epoch [5322/10000], train_Loss: 0.00031138345366343856,test_Loss:22.070636749267578, r2_store:-0.35374545765855925\n",
            "Epoch [5323/10000], train_Loss: 0.00031015017884783447,test_Loss:22.06745719909668, r2_store:-0.35364213294183644\n",
            "Epoch [5324/10000], train_Loss: 0.0003091392572969198,test_Loss:22.068540573120117, r2_store:-0.35378761824143434\n",
            "Epoch [5325/10000], train_Loss: 0.0003083365736529231,test_Loss:22.067447662353516, r2_store:-0.35359616785874004\n",
            "Epoch [5326/10000], train_Loss: 0.00030745044932700694,test_Loss:22.06965446472168, r2_store:-0.35376717855179796\n",
            "Epoch [5327/10000], train_Loss: 0.0003062857431359589,test_Loss:22.066709518432617, r2_store:-0.35350107311891454\n",
            "Epoch [5328/10000], train_Loss: 0.0003054840490221977,test_Loss:22.070266723632812, r2_store:-0.35372000436296425\n",
            "Epoch [5329/10000], train_Loss: 0.000304659188259393,test_Loss:22.067319869995117, r2_store:-0.35340668517575713\n",
            "Epoch [5330/10000], train_Loss: 0.00030370650347322226,test_Loss:22.069381713867188, r2_store:-0.35375114353604076\n",
            "Epoch [5331/10000], train_Loss: 0.0003031785017810762,test_Loss:22.064422607421875, r2_store:-0.3534029794389737\n",
            "Epoch [5332/10000], train_Loss: 0.0003027678176295012,test_Loss:22.0694580078125, r2_store:-0.35378713108330095\n",
            "Epoch [5333/10000], train_Loss: 0.0003020856820512563,test_Loss:22.06501579284668, r2_store:-0.3533273862653705\n",
            "Epoch [5334/10000], train_Loss: 0.00030119516304694116,test_Loss:22.069766998291016, r2_store:-0.3537615445102362\n",
            "Epoch [5335/10000], train_Loss: 0.0003004662285093218,test_Loss:22.065425872802734, r2_store:-0.35325699923106035\n",
            "Epoch [5336/10000], train_Loss: 0.0002998580748680979,test_Loss:22.07204818725586, r2_store:-0.35377164338439027\n",
            "Epoch [5337/10000], train_Loss: 0.0002990863868035376,test_Loss:22.06488037109375, r2_store:-0.3532860306847181\n",
            "Epoch [5338/10000], train_Loss: 0.0002983461890835315,test_Loss:22.07036781311035, r2_store:-0.3538580393866728\n",
            "Epoch [5339/10000], train_Loss: 0.0002977366966661066,test_Loss:22.06324577331543, r2_store:-0.3532659143109107\n",
            "Epoch [5340/10000], train_Loss: 0.00029758113669231534,test_Loss:22.069551467895508, r2_store:-0.353864575192937\n",
            "Epoch [5341/10000], train_Loss: 0.0002973104710690677,test_Loss:22.060977935791016, r2_store:-0.3531346901273096\n",
            "Epoch [5342/10000], train_Loss: 0.00029737906879745424,test_Loss:22.070438385009766, r2_store:-0.3538169316983639\n",
            "Epoch [5343/10000], train_Loss: 0.00029732464463450015,test_Loss:22.062610626220703, r2_store:-0.3529765993880676\n",
            "Epoch [5344/10000], train_Loss: 0.0002984243619721383,test_Loss:22.072063446044922, r2_store:-0.3538618525037902\n",
            "Epoch [5345/10000], train_Loss: 0.00029914872720837593,test_Loss:22.059770584106445, r2_store:-0.3529302528560816\n",
            "Epoch [5346/10000], train_Loss: 0.00030036215321160853,test_Loss:22.07065773010254, r2_store:-0.35401235251019436\n",
            "Epoch [5347/10000], train_Loss: 0.0003029405779670924,test_Loss:22.056625366210938, r2_store:-0.3528218753707113\n",
            "Epoch [5348/10000], train_Loss: 0.00030626310035586357,test_Loss:22.071533203125, r2_store:-0.3541027050506238\n",
            "Epoch [5349/10000], train_Loss: 0.00031029185629449785,test_Loss:22.054676055908203, r2_store:-0.35259998613783283\n",
            "Epoch [5350/10000], train_Loss: 0.00031549963750876486,test_Loss:22.074440002441406, r2_store:-0.3541749613634271\n",
            "Epoch [5351/10000], train_Loss: 0.000322401465382427,test_Loss:22.05495834350586, r2_store:-0.3523380201992725\n",
            "Epoch [5352/10000], train_Loss: 0.0003319121606182307,test_Loss:22.078712463378906, r2_store:-0.35437918584033\n",
            "Epoch [5353/10000], train_Loss: 0.0003453426470514387,test_Loss:22.05075454711914, r2_store:-0.3520860803164234\n",
            "Epoch [5354/10000], train_Loss: 0.0003644338867161423,test_Loss:22.080760955810547, r2_store:-0.35475402319493865\n",
            "Epoch [5355/10000], train_Loss: 0.00039040722185745835,test_Loss:22.04469871520996, r2_store:-0.3517052449486413\n",
            "Epoch [5356/10000], train_Loss: 0.00042664367356337607,test_Loss:22.085315704345703, r2_store:-0.3552196531143199\n",
            "Epoch [5357/10000], train_Loss: 0.0004769586957991123,test_Loss:22.036327362060547, r2_store:-0.3511054066940531\n",
            "Epoch [5358/10000], train_Loss: 0.0005469887400977314,test_Loss:22.09217071533203, r2_store:-0.3558470911127769\n",
            "Epoch [5359/10000], train_Loss: 0.0006452439120039344,test_Loss:22.027074813842773, r2_store:-0.35024446028769773\n",
            "Epoch [5360/10000], train_Loss: 0.0007818291196599603,test_Loss:22.103988647460938, r2_store:-0.3567836352149827\n",
            "Epoch [5361/10000], train_Loss: 0.0009756988729350269,test_Loss:22.011884689331055, r2_store:-0.3490395557304784\n",
            "Epoch [5362/10000], train_Loss: 0.0012543502962216735,test_Loss:22.120861053466797, r2_store:-0.35815474383119317\n",
            "Epoch [5363/10000], train_Loss: 0.0016537534538656473,test_Loss:21.99132537841797, r2_store:-0.3473393461650245\n",
            "Epoch [5364/10000], train_Loss: 0.0022202269174158573,test_Loss:22.147218704223633, r2_store:-0.3602698480240254\n",
            "Epoch [5365/10000], train_Loss: 0.00303988647647202,test_Loss:21.96570587158203, r2_store:-0.3448296782251776\n",
            "Epoch [5366/10000], train_Loss: 0.004247128032147884,test_Loss:22.185083389282227, r2_store:-0.3633997958188211\n",
            "Epoch [5367/10000], train_Loss: 0.0059920684434473515,test_Loss:21.91657257080078, r2_store:-0.3413021704296342\n",
            "Epoch [5368/10000], train_Loss: 0.008572148159146309,test_Loss:22.245174407958984, r2_store:-0.36817936269594\n",
            "Epoch [5369/10000], train_Loss: 0.012282198294997215,test_Loss:21.87424659729004, r2_store:-0.3361101717383135\n",
            "Epoch [5370/10000], train_Loss: 0.017787612974643707,test_Loss:22.338233947753906, r2_store:-0.3754369903177486\n",
            "Epoch [5371/10000], train_Loss: 0.025482892990112305,test_Loss:21.770618438720703, r2_store:-0.3297995670756708\n",
            "Epoch [5372/10000], train_Loss: 0.036497071385383606,test_Loss:22.43992042541504, r2_store:-0.3862103461817059\n",
            "Epoch [5373/10000], train_Loss: 0.051072560250759125,test_Loss:21.687976837158203, r2_store:-0.3217620408974824\n",
            "Epoch [5374/10000], train_Loss: 0.07035736739635468,test_Loss:22.592655181884766, r2_store:-0.39881604671927584\n",
            "Epoch [5375/10000], train_Loss: 0.09105618298053741,test_Loss:21.59783172607422, r2_store:-0.31519593756049846\n",
            "Epoch [5376/10000], train_Loss: 0.11157591640949249,test_Loss:22.694000244140625, r2_store:-0.40652118977305185\n",
            "Epoch [5377/10000], train_Loss: 0.11996680498123169,test_Loss:21.653560638427734, r2_store:-0.31453220511464064\n",
            "Epoch [5378/10000], train_Loss: 0.11375226080417633,test_Loss:22.59910011291504, r2_store:-0.39707381659558116\n",
            "Epoch [5379/10000], train_Loss: 0.08446351438760757,test_Loss:21.775821685791016, r2_store:-0.32779576191160453\n",
            "Epoch [5380/10000], train_Loss: 0.04549573361873627,test_Loss:22.261428833007812, r2_store:-0.36862709090190626\n",
            "Epoch [5381/10000], train_Loss: 0.012119848281145096,test_Loss:22.10086441040039, r2_store:-0.35397250146406023\n",
            "Epoch [5382/10000], train_Loss: 0.0005668110679835081,test_Loss:21.953245162963867, r2_store:-0.340017554590907\n",
            "Epoch [5383/10000], train_Loss: 0.011359116062521935,test_Loss:22.426618576049805, r2_store:-0.3781595233360291\n",
            "Epoch [5384/10000], train_Loss: 0.030998622998595238,test_Loss:21.865943908691406, r2_store:-0.328059169759922\n",
            "Epoch [5385/10000], train_Loss: 0.043076496571302414,test_Loss:22.505495071411133, r2_store:-0.38081337177564456\n",
            "Epoch [5386/10000], train_Loss: 0.037566766142845154,test_Loss:21.966856002807617, r2_store:-0.3354538741048845\n",
            "Epoch [5387/10000], train_Loss: 0.020430857315659523,test_Loss:22.262378692626953, r2_store:-0.361926304487624\n",
            "Epoch [5388/10000], train_Loss: 0.004590123891830444,test_Loss:22.184499740600586, r2_store:-0.35619618485756854\n",
            "Epoch [5389/10000], train_Loss: 0.0009990099351853132,test_Loss:22.013813018798828, r2_store:-0.3418901065002289\n",
            "Epoch [5390/10000], train_Loss: 0.00893489085137844,test_Loss:22.370655059814453, r2_store:-0.3724660419602168\n",
            "Epoch [5391/10000], train_Loss: 0.018583031371235847,test_Loss:21.942846298217773, r2_store:-0.33552593915555784\n",
            "Epoch [5392/10000], train_Loss: 0.020948518067598343,test_Loss:22.343801498413086, r2_store:-0.36930262528988655\n",
            "Epoch [5393/10000], train_Loss: 0.014165895991027355,test_Loss:22.068809509277344, r2_store:-0.3441095462410708\n",
            "Epoch [5394/10000], train_Loss: 0.004965081810951233,test_Loss:22.170129776000977, r2_store:-0.35332523448557485\n",
            "Epoch [5395/10000], train_Loss: 0.0005970386555418372,test_Loss:22.226749420166016, r2_store:-0.3597745722950949\n",
            "Epoch [5396/10000], train_Loss: 0.0031802826561033726,test_Loss:22.011228561401367, r2_store:-0.34134537729004566\n",
            "Epoch [5397/10000], train_Loss: 0.008622834458947182,test_Loss:22.321969985961914, r2_store:-0.3670773386283024\n",
            "Epoch [5398/10000], train_Loss: 0.011216792277991772,test_Loss:22.004793167114258, r2_store:-0.34111369959509696\n",
            "Epoch [5399/10000], train_Loss: 0.008857106789946556,test_Loss:22.221954345703125, r2_store:-0.36081134055792163\n",
            "Epoch [5400/10000], train_Loss: 0.003947067074477673,test_Loss:22.10672378540039, r2_store:-0.3507746389769131\n",
            "Epoch [5401/10000], train_Loss: 0.0007581764948554337,test_Loss:22.091938018798828, r2_store:-0.3491093248108179\n",
            "Epoch [5402/10000], train_Loss: 0.0012678485363721848,test_Loss:22.22258949279785, r2_store:-0.36074798958735554\n",
            "Epoch [5403/10000], train_Loss: 0.004004302900284529,test_Loss:22.012432098388672, r2_store:-0.34305211010427006\n",
            "Epoch [5404/10000], train_Loss: 0.006003150250762701,test_Loss:22.238285064697266, r2_store:-0.3621662353501802\n",
            "Epoch [5405/10000], train_Loss: 0.0054486715234816074,test_Loss:22.046100616455078, r2_store:-0.34572307149908243\n",
            "Epoch [5406/10000], train_Loss: 0.0030869869515299797,test_Loss:22.161184310913086, r2_store:-0.3551393049568434\n",
            "Epoch [5407/10000], train_Loss: 0.0009479827131144702,test_Loss:22.141613006591797, r2_store:-0.35336574126909315\n",
            "Epoch [5408/10000], train_Loss: 0.0005540737183764577,test_Loss:22.0693416595459, r2_store:-0.34751915933590727\n",
            "Epoch [5409/10000], train_Loss: 0.0017141757998615503,test_Loss:22.20099639892578, r2_store:-0.3592920844426313\n",
            "Epoch [5410/10000], train_Loss: 0.0030495808459818363,test_Loss:22.03774642944336, r2_store:-0.3455838351063518\n",
            "Epoch [5411/10000], train_Loss: 0.0033575687557458878,test_Loss:22.18606185913086, r2_store:-0.3589834019492104\n",
            "Epoch [5412/10000], train_Loss: 0.002463038545101881,test_Loss:22.067035675048828, r2_store:-0.34947122375453255\n",
            "Epoch [5413/10000], train_Loss: 0.0011829733848571777,test_Loss:22.121013641357422, r2_store:-0.3539082684075463\n",
            "Epoch [5414/10000], train_Loss: 0.0004584914131555706,test_Loss:22.13898277282715, r2_store:-0.35512028926051853\n",
            "Epoch [5415/10000], train_Loss: 0.0006431947113014758,test_Loss:22.064369201660156, r2_store:-0.3490860365830235\n",
            "Epoch [5416/10000], train_Loss: 0.0013444868382066488,test_Loss:22.168582916259766, r2_store:-0.3582725038133636\n",
            "Epoch [5417/10000], train_Loss: 0.0018817596137523651,test_Loss:22.05173110961914, r2_store:-0.34806010095147233\n",
            "Epoch [5418/10000], train_Loss: 0.0018428679322823882,test_Loss:22.161319732666016, r2_store:-0.35707466155498\n",
            "Epoch [5419/10000], train_Loss: 0.0013042362406849861,test_Loss:22.084430694580078, r2_store:-0.35081595183933145\n",
            "Epoch [5420/10000], train_Loss: 0.0006907473434694111,test_Loss:22.113788604736328, r2_store:-0.35345082332330624\n",
            "Epoch [5421/10000], train_Loss: 0.0003967397497035563,test_Loss:22.130224227905273, r2_store:-0.35469750632799335\n",
            "Epoch [5422/10000], train_Loss: 0.0005214244592934847,test_Loss:22.076854705810547, r2_store:-0.35026405330850197\n",
            "Epoch [5423/10000], train_Loss: 0.0008646643836982548,test_Loss:22.14985466003418, r2_store:-0.356872515306907\n",
            "Epoch [5424/10000], train_Loss: 0.0011236199643462896,test_Loss:22.05712890625, r2_store:-0.34963738540496303\n",
            "Epoch [5425/10000], train_Loss: 0.0011162698501721025,test_Loss:22.13584327697754, r2_store:-0.3561791415269251\n",
            "Epoch [5426/10000], train_Loss: 0.0008718346362002194,test_Loss:22.087196350097656, r2_store:-0.3512170018949512\n",
            "Epoch [5427/10000], train_Loss: 0.0005671402905136347,test_Loss:22.119264602661133, r2_store:-0.35360038758858137\n",
            "Epoch [5428/10000], train_Loss: 0.0003826553584076464,test_Loss:22.119693756103516, r2_store:-0.3538033455376419\n",
            "Epoch [5429/10000], train_Loss: 0.0003928543592337519,test_Loss:22.090219497680664, r2_store:-0.35130930178886755\n",
            "Epoch [5430/10000], train_Loss: 0.0005365315591916442,test_Loss:22.143339157104492, r2_store:-0.35546891125870705\n",
            "Epoch [5431/10000], train_Loss: 0.0006875923718325794,test_Loss:22.082748413085938, r2_store:-0.35040468170579175\n",
            "Epoch [5432/10000], train_Loss: 0.0007433835999108851,test_Loss:22.1378173828125, r2_store:-0.35544751120728546\n",
            "Epoch [5433/10000], train_Loss: 0.0006765348371118307,test_Loss:22.085933685302734, r2_store:-0.3512116006610515\n",
            "Epoch [5434/10000], train_Loss: 0.0005370029248297215,test_Loss:22.123403549194336, r2_store:-0.3540352090848724\n",
            "Epoch [5435/10000], train_Loss: 0.0004069010610692203,test_Loss:22.111024856567383, r2_store:-0.35277774497160075\n",
            "Epoch [5436/10000], train_Loss: 0.0003456442500464618,test_Loss:22.103422164916992, r2_store:-0.3523221275076731\n",
            "Epoch [5437/10000], train_Loss: 0.00036358574288897216,test_Loss:22.12381362915039, r2_store:-0.35422415419649567\n",
            "Epoch [5438/10000], train_Loss: 0.00042928894981741905,test_Loss:22.09048843383789, r2_store:-0.3512900411938795\n",
            "Epoch [5439/10000], train_Loss: 0.0004913141019642353,test_Loss:22.13144874572754, r2_store:-0.3547286434833965\n",
            "Epoch [5440/10000], train_Loss: 0.0005125285242684186,test_Loss:22.085947036743164, r2_store:-0.35134192210198045\n",
            "Epoch [5441/10000], train_Loss: 0.0004846980737056583,test_Loss:22.122711181640625, r2_store:-0.3542504956246877\n",
            "Epoch [5442/10000], train_Loss: 0.0004260242567397654,test_Loss:22.104042053222656, r2_store:-0.35201104596521593\n",
            "Epoch [5443/10000], train_Loss: 0.00036742660449817777,test_Loss:22.11751937866211, r2_store:-0.35308954233645506\n",
            "Epoch [5444/10000], train_Loss: 0.00033121492015197873,test_Loss:22.111724853515625, r2_store:-0.3530150600910895\n",
            "Epoch [5445/10000], train_Loss: 0.0003272125031799078,test_Loss:22.10186004638672, r2_store:-0.35211871732054223\n",
            "Epoch [5446/10000], train_Loss: 0.00034639472141861916,test_Loss:22.12468719482422, r2_store:-0.3536898556729937\n",
            "Epoch [5447/10000], train_Loss: 0.0003741334076039493,test_Loss:22.097835540771484, r2_store:-0.35157520964873124\n",
            "Epoch [5448/10000], train_Loss: 0.0003937604487873614,test_Loss:22.121379852294922, r2_store:-0.35394935761824153\n",
            "Epoch [5449/10000], train_Loss: 0.00039692610152997077,test_Loss:22.093891143798828, r2_store:-0.3516593944337343\n",
            "Epoch [5450/10000], train_Loss: 0.00038227729965001345,test_Loss:22.120777130126953, r2_store:-0.3535731300893472\n",
            "Epoch [5451/10000], train_Loss: 0.0003574623551685363,test_Loss:22.104412078857422, r2_store:-0.35206297036530576\n",
            "Epoch [5452/10000], train_Loss: 0.0003324734279885888,test_Loss:22.113218307495117, r2_store:-0.3529479177114252\n",
            "Epoch [5453/10000], train_Loss: 0.00031516444869339466,test_Loss:22.111099243164062, r2_store:-0.3527229135406167\n",
            "Epoch [5454/10000], train_Loss: 0.0003096396685577929,test_Loss:22.10977554321289, r2_store:-0.3523710944836034\n",
            "Epoch [5455/10000], train_Loss: 0.0003140555345453322,test_Loss:22.1201114654541, r2_store:-0.3532723373037907\n",
            "Epoch [5456/10000], train_Loss: 0.00032387563260272145,test_Loss:22.10324478149414, r2_store:-0.3520219697766036\n",
            "Epoch [5457/10000], train_Loss: 0.0003341115079820156,test_Loss:22.121538162231445, r2_store:-0.3535305387639085\n",
            "Epoch [5458/10000], train_Loss: 0.00034089238033629954,test_Loss:22.104230880737305, r2_store:-0.3518782460167751\n",
            "Epoch [5459/10000], train_Loss: 0.00034098862670361996,test_Loss:22.12312126159668, r2_store:-0.35344985604896517\n",
            "Epoch [5460/10000], train_Loss: 0.00033508409978821874,test_Loss:22.104963302612305, r2_store:-0.3520276903700701\n",
            "Epoch [5461/10000], train_Loss: 0.0003248948196414858,test_Loss:22.120676040649414, r2_store:-0.35313500189537406\n",
            "Epoch [5462/10000], train_Loss: 0.0003136096056550741,test_Loss:22.114660263061523, r2_store:-0.3522656294405484\n",
            "Epoch [5463/10000], train_Loss: 0.00030421605333685875,test_Loss:22.11941146850586, r2_store:-0.35271209647889523\n",
            "Epoch [5464/10000], train_Loss: 0.0002980521821882576,test_Loss:22.11526107788086, r2_store:-0.35266795377368276\n",
            "Epoch [5465/10000], train_Loss: 0.0002964169252663851,test_Loss:22.113834381103516, r2_store:-0.3523847903603139\n",
            "Epoch [5466/10000], train_Loss: 0.0002974282833747566,test_Loss:22.1221981048584, r2_store:-0.35294624732227775\n",
            "Epoch [5467/10000], train_Loss: 0.00030083919409662485,test_Loss:22.109996795654297, r2_store:-0.3521808271243192\n",
            "Epoch [5468/10000], train_Loss: 0.0003041336021851748,test_Loss:22.120044708251953, r2_store:-0.35318321178814305\n",
            "Epoch [5469/10000], train_Loss: 0.00030711834551766515,test_Loss:22.11018180847168, r2_store:-0.35204429776980173\n",
            "Epoch [5470/10000], train_Loss: 0.0003079003363382071,test_Loss:22.12436294555664, r2_store:-0.35312228440908\n",
            "Epoch [5471/10000], train_Loss: 0.00030721878283657134,test_Loss:22.109214782714844, r2_store:-0.35200291534720773\n",
            "Epoch [5472/10000], train_Loss: 0.0003042082244064659,test_Loss:22.120563507080078, r2_store:-0.3530004022896396\n",
            "Epoch [5473/10000], train_Loss: 0.0003004876780323684,test_Loss:22.112077713012695, r2_store:-0.35206260556298274\n",
            "Epoch [5474/10000], train_Loss: 0.00029572745552286506,test_Loss:22.12154197692871, r2_store:-0.3528196567518347\n",
            "Epoch [5475/10000], train_Loss: 0.0002913330099545419,test_Loss:22.11271095275879, r2_store:-0.3522597373427778\n",
            "Epoch [5476/10000], train_Loss: 0.00028741577989421785,test_Loss:22.117897033691406, r2_store:-0.3526985315892113\n",
            "Epoch [5477/10000], train_Loss: 0.0002844099944923073,test_Loss:22.1163387298584, r2_store:-0.35242386721636065\n",
            "Epoch [5478/10000], train_Loss: 0.0002821706875693053,test_Loss:22.11722183227539, r2_store:-0.35248736993211227\n",
            "Epoch [5479/10000], train_Loss: 0.0002808314166031778,test_Loss:22.115970611572266, r2_store:-0.3525158598381508\n",
            "Epoch [5480/10000], train_Loss: 0.00028004805790260434,test_Loss:22.113182067871094, r2_store:-0.3522851057510017\n",
            "Epoch [5481/10000], train_Loss: 0.00027955009136348963,test_Loss:22.118074417114258, r2_store:-0.3525473118690281\n",
            "Epoch [5482/10000], train_Loss: 0.00027963658794760704,test_Loss:22.11396598815918, r2_store:-0.35213758370665293\n",
            "Epoch [5483/10000], train_Loss: 0.000279505446087569,test_Loss:22.118839263916016, r2_store:-0.35260798070667176\n",
            "Epoch [5484/10000], train_Loss: 0.0002794319880194962,test_Loss:22.112337112426758, r2_store:-0.35208609698006854\n",
            "Epoch [5485/10000], train_Loss: 0.0002792432496789843,test_Loss:22.120094299316406, r2_store:-0.3526385869991977\n",
            "Epoch [5486/10000], train_Loss: 0.00027869504992850125,test_Loss:22.113704681396484, r2_store:-0.3520462222190841\n",
            "Epoch [5487/10000], train_Loss: 0.0002779119531624019,test_Loss:22.119304656982422, r2_store:-0.3526299471286023\n",
            "Epoch [5488/10000], train_Loss: 0.0002766708785202354,test_Loss:22.1114501953125, r2_store:-0.3520532440176687\n",
            "Epoch [5489/10000], train_Loss: 0.00027564913034439087,test_Loss:22.11859130859375, r2_store:-0.3525854514338218\n",
            "Epoch [5490/10000], train_Loss: 0.0002745073870755732,test_Loss:22.113069534301758, r2_store:-0.35204635817705987\n",
            "Epoch [5491/10000], train_Loss: 0.0002731561253312975,test_Loss:22.117847442626953, r2_store:-0.35255927505094586\n",
            "Epoch [5492/10000], train_Loss: 0.0002718430187087506,test_Loss:22.11189842224121, r2_store:-0.3520783470768136\n",
            "Epoch [5493/10000], train_Loss: 0.0002705639344640076,test_Loss:22.11844253540039, r2_store:-0.35249536986893304\n",
            "Epoch [5494/10000], train_Loss: 0.00026933944900520146,test_Loss:22.112979888916016, r2_store:-0.35203599551212794\n",
            "Epoch [5495/10000], train_Loss: 0.0002679931349121034,test_Loss:22.117263793945312, r2_store:-0.3524285207882736\n",
            "Epoch [5496/10000], train_Loss: 0.0002668210945557803,test_Loss:22.11393928527832, r2_store:-0.35200148902569417\n",
            "Epoch [5497/10000], train_Loss: 0.0002661175967659801,test_Loss:22.11908531188965, r2_store:-0.35242103865790453\n",
            "Epoch [5498/10000], train_Loss: 0.0002653765259310603,test_Loss:22.113300323486328, r2_store:-0.35201888672487325\n",
            "Epoch [5499/10000], train_Loss: 0.000264572212472558,test_Loss:22.11732292175293, r2_store:-0.3524775083149734\n",
            "Epoch [5500/10000], train_Loss: 0.0002638334408402443,test_Loss:22.110994338989258, r2_store:-0.3519863133955843\n",
            "Epoch [5501/10000], train_Loss: 0.0002634936827234924,test_Loss:22.116655349731445, r2_store:-0.3524829033331218\n",
            "Epoch [5502/10000], train_Loss: 0.0002630861126817763,test_Loss:22.10967254638672, r2_store:-0.35189166598298693\n",
            "Epoch [5503/10000], train_Loss: 0.00026295267161913216,test_Loss:22.11722183227539, r2_store:-0.3524913628170898\n",
            "Epoch [5504/10000], train_Loss: 0.000263121968600899,test_Loss:22.109760284423828, r2_store:-0.3517911973508263\n",
            "Epoch [5505/10000], train_Loss: 0.0002638227306306362,test_Loss:22.118371963500977, r2_store:-0.3525830288573264\n",
            "Epoch [5506/10000], train_Loss: 0.0002650412789080292,test_Loss:22.107685089111328, r2_store:-0.3516850339155748\n",
            "Epoch [5507/10000], train_Loss: 0.00026740101748146117,test_Loss:22.119741439819336, r2_store:-0.3527028632490723\n",
            "Epoch [5508/10000], train_Loss: 0.000271364493528381,test_Loss:22.105224609375, r2_store:-0.3514806275228013\n",
            "Epoch [5509/10000], train_Loss: 0.0002766086836345494,test_Loss:22.120784759521484, r2_store:-0.3528849782456567\n",
            "Epoch [5510/10000], train_Loss: 0.0002837949723470956,test_Loss:22.100650787353516, r2_store:-0.35125403795485055\n",
            "Epoch [5511/10000], train_Loss: 0.00029470951994881034,test_Loss:22.122880935668945, r2_store:-0.3531631005376916\n",
            "Epoch [5512/10000], train_Loss: 0.00031075836159288883,test_Loss:22.096839904785156, r2_store:-0.35087576400257636\n",
            "Epoch [5513/10000], train_Loss: 0.00033444049768149853,test_Loss:22.12940216064453, r2_store:-0.3535420262628477\n",
            "Epoch [5514/10000], train_Loss: 0.00036811421159654856,test_Loss:22.092041015625, r2_store:-0.3503470876700432\n",
            "Epoch [5515/10000], train_Loss: 0.0004176083893980831,test_Loss:22.13663673400879, r2_store:-0.35416169395316244\n",
            "Epoch [5516/10000], train_Loss: 0.000491592101752758,test_Loss:22.08175277709961, r2_store:-0.3495500949705077\n",
            "Epoch [5517/10000], train_Loss: 0.0006011867080815136,test_Loss:22.14778709411621, r2_store:-0.35506077967972516\n",
            "Epoch [5518/10000], train_Loss: 0.0007652718923054636,test_Loss:22.067813873291016, r2_store:-0.34831811639261057\n",
            "Epoch [5519/10000], train_Loss: 0.0010108171263709664,test_Loss:22.164859771728516, r2_store:-0.3564800453937875\n",
            "Epoch [5520/10000], train_Loss: 0.0013800340238958597,test_Loss:22.046350479125977, r2_store:-0.3465533484001331\n",
            "Epoch [5521/10000], train_Loss: 0.0019398210570216179,test_Loss:22.192001342773438, r2_store:-0.3588022174229881\n",
            "Epoch [5522/10000], train_Loss: 0.0027909427881240845,test_Loss:22.013744354248047, r2_store:-0.34388349470025403\n",
            "Epoch [5523/10000], train_Loss: 0.0040992433205246925,test_Loss:22.236263275146484, r2_store:-0.3623925974447004\n",
            "Epoch [5524/10000], train_Loss: 0.006099803373217583,test_Loss:21.963516235351562, r2_store:-0.33979011457821096\n",
            "Epoch [5525/10000], train_Loss: 0.009219760075211525,test_Loss:22.309141159057617, r2_store:-0.3681377169578117\n",
            "Epoch [5526/10000], train_Loss: 0.013961275108158588,test_Loss:21.903724670410156, r2_store:-0.3335710324594996\n",
            "Epoch [5527/10000], train_Loss: 0.02135436423122883,test_Loss:22.42198944091797, r2_store:-0.37740069386830344\n",
            "Epoch [5528/10000], train_Loss: 0.03243114799261093,test_Loss:21.77946662902832, r2_store:-0.32552720556351344\n",
            "Epoch [5529/10000], train_Loss: 0.04896421357989311,test_Loss:22.57485580444336, r2_store:-0.3918828498637619\n",
            "Epoch [5530/10000], train_Loss: 0.07109709084033966,test_Loss:21.683347702026367, r2_store:-0.3160044662403987\n",
            "Epoch [5531/10000], train_Loss: 0.10063090175390244,test_Loss:22.766016006469727, r2_store:-0.4088404521926885\n",
            "Epoch [5532/10000], train_Loss: 0.13138779997825623,test_Loss:21.60202980041504, r2_store:-0.3093204242108052\n",
            "Epoch [5533/10000], train_Loss: 0.1577787697315216,test_Loss:22.866321563720703, r2_store:-0.4167351702394293\n",
            "Epoch [5534/10000], train_Loss: 0.15723909437656403,test_Loss:21.65744400024414, r2_store:-0.3145682706762811\n",
            "Epoch [5535/10000], train_Loss: 0.12654848396778107,test_Loss:22.569793701171875, r2_store:-0.3937952437283567\n",
            "Epoch [5536/10000], train_Loss: 0.06703703850507736,test_Loss:21.91275978088379, r2_store:-0.33937283660903383\n",
            "Epoch [5537/10000], train_Loss: 0.016033563762903214,test_Loss:22.055164337158203, r2_store:-0.35169205717134133\n",
            "Epoch [5538/10000], train_Loss: 0.0012375388760119677,test_Loss:22.36545181274414, r2_store:-0.3752172348302327\n",
            "Epoch [5539/10000], train_Loss: 0.023008249700069427,test_Loss:21.839778900146484, r2_store:-0.32622542656503883\n",
            "Epoch [5540/10000], train_Loss: 0.05398232489824295,test_Loss:22.638240814208984, r2_store:-0.390186753430126\n",
            "Epoch [5541/10000], train_Loss: 0.06255462765693665,test_Loss:21.958349227905273, r2_store:-0.32846488802541174\n",
            "Epoch [5542/10000], train_Loss: 0.04271533340215683,test_Loss:22.419391632080078, r2_store:-0.36854673519504555\n",
            "Epoch [5543/10000], train_Loss: 0.012605465948581696,test_Loss:22.204723358154297, r2_store:-0.35487299366860325\n",
            "Epoch [5544/10000], train_Loss: 0.0008382187224924564,test_Loss:21.99956512451172, r2_store:-0.3399891691655741\n",
            "Epoch [5545/10000], train_Loss: 0.013037538155913353,test_Loss:22.452922821044922, r2_store:-0.378161357257512\n",
            "Epoch [5546/10000], train_Loss: 0.029956990852952003,test_Loss:21.962867736816406, r2_store:-0.33200232711405375\n",
            "Epoch [5547/10000], train_Loss: 0.03184686601161957,test_Loss:22.42673110961914, r2_store:-0.3711318163230355\n",
            "Epoch [5548/10000], train_Loss: 0.016919709742069244,test_Loss:22.150663375854492, r2_store:-0.3473755456410672\n",
            "Epoch [5549/10000], train_Loss: 0.0027589290402829647,test_Loss:22.155485153198242, r2_store:-0.3474928848086234\n",
            "Epoch [5550/10000], train_Loss: 0.0026687851641327143,test_Loss:22.41994857788086, r2_store:-0.36804114575314495\n",
            "Epoch [5551/10000], train_Loss: 0.012574365362524986,test_Loss:22.059707641601562, r2_store:-0.33567818350600986\n",
            "Epoch [5552/10000], train_Loss: 0.01878407970070839,test_Loss:22.411834716796875, r2_store:-0.36864007824180756\n",
            "Epoch [5553/10000], train_Loss: 0.01397568266838789,test_Loss:22.08805274963379, r2_store:-0.34476486513125604\n",
            "Epoch [5554/10000], train_Loss: 0.004575041122734547,test_Loss:22.160083770751953, r2_store:-0.35216726907042406\n",
            "Epoch [5555/10000], train_Loss: 0.0007252943469211459,test_Loss:22.293380737304688, r2_store:-0.3615322903674485\n",
            "Epoch [5556/10000], train_Loss: 0.004803468473255634,test_Loss:22.066295623779297, r2_store:-0.34008787084431513\n",
            "Epoch [5557/10000], train_Loss: 0.010149193927645683,test_Loss:22.35007095336914, r2_store:-0.3659626780988974\n",
            "Epoch [5558/10000], train_Loss: 0.009883184917271137,test_Loss:22.082035064697266, r2_store:-0.3442237821120713\n",
            "Epoch [5559/10000], train_Loss: 0.004856362007558346,test_Loss:22.189449310302734, r2_store:-0.35478218980693454\n",
            "Epoch [5560/10000], train_Loss: 0.0008886553114280105,test_Loss:22.20282554626465, r2_store:-0.3566596014994783\n",
            "Epoch [5561/10000], train_Loss: 0.0016483021900057793,test_Loss:22.050004959106445, r2_store:-0.34337871572803613\n",
            "Epoch [5562/10000], train_Loss: 0.004988313652575016,test_Loss:22.277151107788086, r2_store:-0.36212406620075654\n",
            "Epoch [5563/10000], train_Loss: 0.006433422211557627,test_Loss:22.07007598876953, r2_store:-0.34341186801432433\n",
            "Epoch [5564/10000], train_Loss: 0.00449412502348423,test_Loss:22.20758056640625, r2_store:-0.3558774512620373\n",
            "Epoch [5565/10000], train_Loss: 0.0015282463282346725,test_Loss:22.163515090942383, r2_store:-0.3528132814480549\n",
            "Epoch [5566/10000], train_Loss: 0.000589036731980741,test_Loss:22.09385871887207, r2_store:-0.3470303468848037\n",
            "Epoch [5567/10000], train_Loss: 0.0020345300436019897,test_Loss:22.238956451416016, r2_store:-0.3599527894089869\n",
            "Epoch [5568/10000], train_Loss: 0.0036856227088719606,test_Loss:22.052513122558594, r2_store:-0.3452527613934151\n",
            "Epoch [5569/10000], train_Loss: 0.0036245272494852543,test_Loss:22.192337036132812, r2_store:-0.35782331418944757\n",
            "Epoch [5570/10000], train_Loss: 0.002034636912867427,test_Loss:22.11800193786621, r2_store:-0.3507067727778759\n",
            "Epoch [5571/10000], train_Loss: 0.000663045619148761,test_Loss:22.127042770385742, r2_store:-0.3505761852152922\n",
            "Epoch [5572/10000], train_Loss: 0.0006749846506863832,test_Loss:22.204715728759766, r2_store:-0.35715795709266396\n",
            "Epoch [5573/10000], train_Loss: 0.0016545320395380259,test_Loss:22.081729888916016, r2_store:-0.34708582890268214\n",
            "Epoch [5574/10000], train_Loss: 0.0023455959744751453,test_Loss:22.213153839111328, r2_store:-0.35826615591908695\n",
            "Epoch [5575/10000], train_Loss: 0.002028031973168254,test_Loss:22.113758087158203, r2_store:-0.3495933869959098\n",
            "Epoch [5576/10000], train_Loss: 0.0011076226364821196,test_Loss:22.161893844604492, r2_store:-0.3538683770041158\n",
            "Epoch [5577/10000], train_Loss: 0.0004777141730301082,test_Loss:22.167179107666016, r2_store:-0.354868364991191\n",
            "Epoch [5578/10000], train_Loss: 0.0005968721816316247,test_Loss:22.101184844970703, r2_store:-0.3497267304570748\n",
            "Epoch [5579/10000], train_Loss: 0.0011440099915489554,test_Loss:22.192075729370117, r2_store:-0.3576991848176667\n",
            "Epoch [5580/10000], train_Loss: 0.001471694209612906,test_Loss:22.097599029541016, r2_store:-0.34953322228228334\n",
            "Epoch [5581/10000], train_Loss: 0.001269375323317945,test_Loss:22.16816520690918, r2_store:-0.3559992929757094\n",
            "Epoch [5582/10000], train_Loss: 0.0007709591300226748,test_Loss:22.130353927612305, r2_store:-0.35281291253221214\n",
            "Epoch [5583/10000], train_Loss: 0.00043187616392970085,test_Loss:22.130983352661133, r2_store:-0.35228015249725164\n",
            "Epoch [5584/10000], train_Loss: 0.0004767683276440948,test_Loss:22.180879592895508, r2_store:-0.35583126286447153\n",
            "Epoch [5585/10000], train_Loss: 0.0007559556979686022,test_Loss:22.117544174194336, r2_store:-0.3499531923077859\n",
            "Epoch [5586/10000], train_Loss: 0.0009535728022456169,test_Loss:22.19190788269043, r2_store:-0.35591594695883466\n",
            "Epoch [5587/10000], train_Loss: 0.0008889363380149007,test_Loss:22.13510513305664, r2_store:-0.3507215966145434\n",
            "Epoch [5588/10000], train_Loss: 0.000638105848338455,test_Loss:22.167339324951172, r2_store:-0.35374816205531645\n",
            "Epoch [5589/10000], train_Loss: 0.0004207430756650865,test_Loss:22.158296585083008, r2_store:-0.3533987596075474\n",
            "Epoch [5590/10000], train_Loss: 0.0003852037771139294,test_Loss:22.13599967956543, r2_store:-0.35142509714602177\n",
            "Epoch [5591/10000], train_Loss: 0.0005067583988420665,test_Loss:22.183448791503906, r2_store:-0.3551898225607495\n",
            "Epoch [5592/10000], train_Loss: 0.0006407223991118371,test_Loss:22.13057518005371, r2_store:-0.3506714821880701\n",
            "Epoch [5593/10000], train_Loss: 0.0006620950298383832,test_Loss:22.176109313964844, r2_store:-0.3548484623540462\n",
            "Epoch [5594/10000], train_Loss: 0.0005602192250080407,test_Loss:22.135818481445312, r2_store:-0.35184634786081337\n",
            "Epoch [5595/10000], train_Loss: 0.00042468076571822166,test_Loss:22.14815902709961, r2_store:-0.35307844516415665\n",
            "Epoch [5596/10000], train_Loss: 0.0003541613114066422,test_Loss:22.15408706665039, r2_store:-0.35363871219170284\n",
            "Epoch [5597/10000], train_Loss: 0.00037945358781144023,test_Loss:22.12872886657715, r2_store:-0.3515591461429177\n",
            "Epoch [5598/10000], train_Loss: 0.0004526962002273649,test_Loss:22.165369033813477, r2_store:-0.3545992127187205\n",
            "Epoch [5599/10000], train_Loss: 0.0005010339664295316,test_Loss:22.130084991455078, r2_store:-0.35127129095713694\n",
            "Epoch [5600/10000], train_Loss: 0.00048615288687869906,test_Loss:22.16765594482422, r2_store:-0.35404764401873456\n",
            "Epoch [5601/10000], train_Loss: 0.0004247354227118194,test_Loss:22.14602279663086, r2_store:-0.35206129850017076\n",
            "Epoch [5602/10000], train_Loss: 0.0003600280615501106,test_Loss:22.15167808532715, r2_store:-0.35270978770307404\n",
            "Epoch [5603/10000], train_Loss: 0.00033142304164357483,test_Loss:22.155162811279297, r2_store:-0.35320645509239235\n",
            "Epoch [5604/10000], train_Loss: 0.00034643200342543423,test_Loss:22.136554718017578, r2_store:-0.3516307595429795\n",
            "Epoch [5605/10000], train_Loss: 0.0003815953677985817,test_Loss:22.1629695892334, r2_store:-0.35378517295434797\n",
            "Epoch [5606/10000], train_Loss: 0.000403999729314819,test_Loss:22.13541030883789, r2_store:-0.35144499902760185\n",
            "Epoch [5607/10000], train_Loss: 0.00039834348717704415,test_Loss:22.160541534423828, r2_store:-0.35356432099805013\n",
            "Epoch [5608/10000], train_Loss: 0.0003687284770421684,test_Loss:22.144330978393555, r2_store:-0.35206014440515676\n",
            "Epoch [5609/10000], train_Loss: 0.00033555133268237114,test_Loss:22.154552459716797, r2_store:-0.35275056793570525\n",
            "Epoch [5610/10000], train_Loss: 0.0003161242639180273,test_Loss:22.156436920166016, r2_store:-0.35284010480562156\n",
            "Epoch [5611/10000], train_Loss: 0.00031662851688452065,test_Loss:22.146047592163086, r2_store:-0.3520086307242416\n",
            "Epoch [5612/10000], train_Loss: 0.0003296585928183049,test_Loss:22.161359786987305, r2_store:-0.3533681411684013\n",
            "Epoch [5613/10000], train_Loss: 0.0003425366012379527,test_Loss:22.14366912841797, r2_store:-0.3517613112561193\n",
            "Epoch [5614/10000], train_Loss: 0.00034567940747365355,test_Loss:22.163930892944336, r2_store:-0.35333344683129364\n",
            "Epoch [5615/10000], train_Loss: 0.0003368159232195467,test_Loss:22.148683547973633, r2_store:-0.3520348542092846\n",
            "Epoch [5616/10000], train_Loss: 0.00032122342963702977,test_Loss:22.161306381225586, r2_store:-0.3529239815110796\n",
            "Epoch [5617/10000], train_Loss: 0.0003070131642743945,test_Loss:22.158723831176758, r2_store:-0.3525451316275501\n",
            "Epoch [5618/10000], train_Loss: 0.0002995542890857905,test_Loss:22.15785026550293, r2_store:-0.35240617547696496\n",
            "Epoch [5619/10000], train_Loss: 0.0002995218092110008,test_Loss:22.16562843322754, r2_store:-0.3529867560286981\n",
            "Epoch [5620/10000], train_Loss: 0.00030482019064947963,test_Loss:22.156291961669922, r2_store:-0.35206035832126936\n",
            "Epoch [5621/10000], train_Loss: 0.0003093927225563675,test_Loss:22.170454025268555, r2_store:-0.35308899762458656\n",
            "Epoch [5622/10000], train_Loss: 0.00031033530831336975,test_Loss:22.157682418823242, r2_store:-0.35200963182510336\n",
            "Epoch [5623/10000], train_Loss: 0.0003062580362893641,test_Loss:22.16862678527832, r2_store:-0.3529629665259735\n",
            "Epoch [5624/10000], train_Loss: 0.0002994263486471027,test_Loss:22.163034439086914, r2_store:-0.3522928293020817\n",
            "Epoch [5625/10000], train_Loss: 0.00029221756267361343,test_Loss:22.16614532470703, r2_store:-0.3526864941400698\n",
            "Epoch [5626/10000], train_Loss: 0.00028719782130792737,test_Loss:22.163602828979492, r2_store:-0.3527027026442131\n",
            "Epoch [5627/10000], train_Loss: 0.0002854632039088756,test_Loss:22.160844802856445, r2_store:-0.352420887011329\n",
            "Epoch [5628/10000], train_Loss: 0.0002859636442735791,test_Loss:22.168045043945312, r2_store:-0.35294458263279327\n",
            "Epoch [5629/10000], train_Loss: 0.00028768324409611523,test_Loss:22.159805297851562, r2_store:-0.35227103415889793\n",
            "Epoch [5630/10000], train_Loss: 0.0002883332490455359,test_Loss:22.168550491333008, r2_store:-0.3530131439014892\n",
            "Epoch [5631/10000], train_Loss: 0.0002875749487429857,test_Loss:22.162330627441406, r2_store:-0.35225663697599496\n",
            "Epoch [5632/10000], train_Loss: 0.0002851057215593755,test_Loss:22.16958236694336, r2_store:-0.35284963724094287\n",
            "Epoch [5633/10000], train_Loss: 0.0002818283101078123,test_Loss:22.16219711303711, r2_store:-0.352383660821294\n",
            "Epoch [5634/10000], train_Loss: 0.0002782140509225428,test_Loss:22.164182662963867, r2_store:-0.3526732824729413\n",
            "Epoch [5635/10000], train_Loss: 0.0002752787549979985,test_Loss:22.163326263427734, r2_store:-0.3525734409585748\n",
            "Epoch [5636/10000], train_Loss: 0.0002736237074714154,test_Loss:22.162336349487305, r2_store:-0.3524644043012597\n",
            "Epoch [5637/10000], train_Loss: 0.0002727615355979651,test_Loss:22.16574478149414, r2_store:-0.3526781069240561\n",
            "Epoch [5638/10000], train_Loss: 0.00027255353052169085,test_Loss:22.164867401123047, r2_store:-0.3522636915820516\n",
            "Epoch [5639/10000], train_Loss: 0.00027208015671931207,test_Loss:22.169755935668945, r2_store:-0.3526562809214775\n",
            "Epoch [5640/10000], train_Loss: 0.0002714057045523077,test_Loss:22.163707733154297, r2_store:-0.3521836606327402\n",
            "Epoch [5641/10000], train_Loss: 0.0002708412939682603,test_Loss:22.169265747070312, r2_store:-0.3526150463489597\n",
            "Epoch [5642/10000], train_Loss: 0.00026948435697704554,test_Loss:22.164628982543945, r2_store:-0.35217372430265814\n",
            "Epoch [5643/10000], train_Loss: 0.0002674671122804284,test_Loss:22.167978286743164, r2_store:-0.35247829001418673\n",
            "Epoch [5644/10000], train_Loss: 0.00026535370852798223,test_Loss:22.164531707763672, r2_store:-0.3522373163286754\n",
            "Epoch [5645/10000], train_Loss: 0.000263602240011096,test_Loss:22.166423797607422, r2_store:-0.35235592746339695\n",
            "Epoch [5646/10000], train_Loss: 0.00026230671210214496,test_Loss:22.167200088500977, r2_store:-0.3523241996122801\n",
            "Epoch [5647/10000], train_Loss: 0.00026111240731552243,test_Loss:22.16666030883789, r2_store:-0.35223222566667345\n",
            "Epoch [5648/10000], train_Loss: 0.0002601614105515182,test_Loss:22.1682186126709, r2_store:-0.3523491833657122\n",
            "Epoch [5649/10000], train_Loss: 0.0002594313700683415,test_Loss:22.165754318237305, r2_store:-0.3521128897198349\n",
            "Epoch [5650/10000], train_Loss: 0.00025880770408548415,test_Loss:22.167888641357422, r2_store:-0.35231370723519073\n",
            "Epoch [5651/10000], train_Loss: 0.00025788103812374175,test_Loss:22.164457321166992, r2_store:-0.35203719936219335\n",
            "Epoch [5652/10000], train_Loss: 0.00025692000053822994,test_Loss:22.167255401611328, r2_store:-0.3523041446365609\n",
            "Epoch [5653/10000], train_Loss: 0.0002559222630225122,test_Loss:22.16424560546875, r2_store:-0.3520233711839216\n",
            "Epoch [5654/10000], train_Loss: 0.00025504775112494826,test_Loss:22.168975830078125, r2_store:-0.3522607887614313\n",
            "Epoch [5655/10000], train_Loss: 0.0002538017288316041,test_Loss:22.167434692382812, r2_store:-0.3519969790751978\n",
            "Epoch [5656/10000], train_Loss: 0.0002526137395761907,test_Loss:22.16963768005371, r2_store:-0.35217843072886446\n",
            "Epoch [5657/10000], train_Loss: 0.0002515479864086956,test_Loss:22.16691017150879, r2_store:-0.3520354285545104\n",
            "Epoch [5658/10000], train_Loss: 0.00025035670842044055,test_Loss:22.16688346862793, r2_store:-0.3521360112739049\n",
            "Epoch [5659/10000], train_Loss: 0.0002492044004611671,test_Loss:22.16562271118164, r2_store:-0.3520655180688588\n",
            "Epoch [5660/10000], train_Loss: 0.0002482891140971333,test_Loss:22.165876388549805, r2_store:-0.35202397775440253\n",
            "Epoch [5661/10000], train_Loss: 0.00024734294856898487,test_Loss:22.16650390625, r2_store:-0.35204799318406454\n",
            "Epoch [5662/10000], train_Loss: 0.000246499344939366,test_Loss:22.166135787963867, r2_store:-0.3519465030058979\n",
            "Epoch [5663/10000], train_Loss: 0.00024541630409657955,test_Loss:22.169448852539062, r2_store:-0.3520533506597512\n",
            "Epoch [5664/10000], train_Loss: 0.00024470503558404744,test_Loss:22.16785430908203, r2_store:-0.3519003174162878\n",
            "Epoch [5665/10000], train_Loss: 0.00024409576144535094,test_Loss:22.169384002685547, r2_store:-0.3520772201173552\n",
            "Epoch [5666/10000], train_Loss: 0.00024325773119926453,test_Loss:22.166696548461914, r2_store:-0.35185448353865256\n",
            "Epoch [5667/10000], train_Loss: 0.00024234017473645508,test_Loss:22.16879653930664, r2_store:-0.35205161273635666\n",
            "Epoch [5668/10000], train_Loss: 0.0002414905757177621,test_Loss:22.165119171142578, r2_store:-0.35177497704489924\n",
            "Epoch [5669/10000], train_Loss: 0.00024101915187202394,test_Loss:22.167421340942383, r2_store:-0.3520418909887679\n",
            "Epoch [5670/10000], train_Loss: 0.00024022939032875001,test_Loss:22.16518211364746, r2_store:-0.35172497246459633\n",
            "Epoch [5671/10000], train_Loss: 0.0002393545873928815,test_Loss:22.170635223388672, r2_store:-0.35201954325268336\n",
            "Epoch [5672/10000], train_Loss: 0.00023868485004641116,test_Loss:22.166336059570312, r2_store:-0.35169610020808384\n",
            "Epoch [5673/10000], train_Loss: 0.00023778753529768437,test_Loss:22.17007064819336, r2_store:-0.3519924716867202\n",
            "Epoch [5674/10000], train_Loss: 0.00023705282364971936,test_Loss:22.167823791503906, r2_store:-0.35163179251416943\n",
            "Epoch [5675/10000], train_Loss: 0.00023627564951311797,test_Loss:22.171157836914062, r2_store:-0.3519642051539369\n",
            "Epoch [5676/10000], train_Loss: 0.00023553389473818243,test_Loss:22.16500473022461, r2_store:-0.351616250539434\n",
            "Epoch [5677/10000], train_Loss: 0.0002347931294934824,test_Loss:22.16823387145996, r2_store:-0.3519838150572776\n",
            "Epoch [5678/10000], train_Loss: 0.00023448315914720297,test_Loss:22.164499282836914, r2_store:-0.35153427705650286\n",
            "Epoch [5679/10000], train_Loss: 0.00023401060025207698,test_Loss:22.171138763427734, r2_store:-0.35195137711182545\n",
            "Epoch [5680/10000], train_Loss: 0.00023361074272543192,test_Loss:22.16555404663086, r2_store:-0.3514695795137561\n",
            "Epoch [5681/10000], train_Loss: 0.00023328322276938707,test_Loss:22.172176361083984, r2_store:-0.3519937333704204\n",
            "Epoch [5682/10000], train_Loss: 0.00023302661429625005,test_Loss:22.16543960571289, r2_store:-0.35142477741080547\n",
            "Epoch [5683/10000], train_Loss: 0.00023335334844887257,test_Loss:22.171117782592773, r2_store:-0.3520738237999288\n",
            "Epoch [5684/10000], train_Loss: 0.00023387416149489582,test_Loss:22.161924362182617, r2_store:-0.35134480651424393\n",
            "Epoch [5685/10000], train_Loss: 0.00023486357531510293,test_Loss:22.172035217285156, r2_store:-0.35211741830069454\n",
            "Epoch [5686/10000], train_Loss: 0.00023647949274163693,test_Loss:22.162248611450195, r2_store:-0.351138758070902\n",
            "Epoch [5687/10000], train_Loss: 0.0002387582353549078,test_Loss:22.17434310913086, r2_store:-0.35215721814547507\n",
            "Epoch [5688/10000], train_Loss: 0.0002420364908175543,test_Loss:22.16067886352539, r2_store:-0.35095006916423976\n",
            "Epoch [5689/10000], train_Loss: 0.0002464857534505427,test_Loss:22.176687240600586, r2_store:-0.35232177075505255\n",
            "Epoch [5690/10000], train_Loss: 0.0002526271273382008,test_Loss:22.1580867767334, r2_store:-0.35077287394467094\n",
            "Epoch [5691/10000], train_Loss: 0.00026141892885789275,test_Loss:22.17817497253418, r2_store:-0.35257504907746573\n",
            "Epoch [5692/10000], train_Loss: 0.0002739122719503939,test_Loss:22.153779983520508, r2_store:-0.3504703897248165\n",
            "Epoch [5693/10000], train_Loss: 0.00029118580278009176,test_Loss:22.18280792236328, r2_store:-0.3528460323729017\n",
            "Epoch [5694/10000], train_Loss: 0.00031537801260128617,test_Loss:22.150543212890625, r2_store:-0.3499831364145749\n",
            "Epoch [5695/10000], train_Loss: 0.00034921467886306345,test_Loss:22.189414978027344, r2_store:-0.3532411964864497\n",
            "Epoch [5696/10000], train_Loss: 0.0003966875374317169,test_Loss:22.144001007080078, r2_store:-0.34938804241077914\n",
            "Epoch [5697/10000], train_Loss: 0.00046295725042000413,test_Loss:22.19696617126465, r2_store:-0.3539325917573015\n",
            "Epoch [5698/10000], train_Loss: 0.0005574822425842285,test_Loss:22.133312225341797, r2_store:-0.34860394600728206\n",
            "Epoch [5699/10000], train_Loss: 0.0006908956565894186,test_Loss:22.208240509033203, r2_store:-0.3549125704061251\n",
            "Epoch [5700/10000], train_Loss: 0.0008786249090917408,test_Loss:22.120420455932617, r2_store:-0.34741772671235727\n",
            "Epoch [5701/10000], train_Loss: 0.0011488578747957945,test_Loss:22.226776123046875, r2_store:-0.35628773676210845\n",
            "Epoch [5702/10000], train_Loss: 0.001542431302368641,test_Loss:22.09914779663086, r2_store:-0.345713466975373\n",
            "Epoch [5703/10000], train_Loss: 0.0021134247072041035,test_Loss:22.25350570678711, r2_store:-0.3584434549003723\n",
            "Epoch [5704/10000], train_Loss: 0.0029509509913623333,test_Loss:22.075260162353516, r2_store:-0.3431477576026507\n",
            "Epoch [5705/10000], train_Loss: 0.004196471534669399,test_Loss:22.29441261291504, r2_store:-0.3617051131785707\n",
            "Epoch [5706/10000], train_Loss: 0.0060279895551502705,test_Loss:22.02811050415039, r2_store:-0.3394109953724389\n",
            "Epoch [5707/10000], train_Loss: 0.008797119371592999,test_Loss:22.35592269897461, r2_store:-0.36674306491815245\n",
            "Epoch [5708/10000], train_Loss: 0.012851402163505554,test_Loss:21.967390060424805, r2_store:-0.33407578798363\n",
            "Epoch [5709/10000], train_Loss: 0.01891581527888775,test_Loss:22.45475959777832, r2_store:-0.37454682065460343\n",
            "Epoch [5710/10000], train_Loss: 0.02752869203686714,test_Loss:21.89373207092285, r2_store:-0.3268045498061103\n",
            "Epoch [5711/10000], train_Loss: 0.04012864828109741,test_Loss:22.584049224853516, r2_store:-0.3858984351136614\n",
            "Epoch [5712/10000], train_Loss: 0.057072483003139496,test_Loss:21.760915756225586, r2_store:-0.3187044057699808\n",
            "Epoch [5713/10000], train_Loss: 0.07928260415792465,test_Loss:22.742671966552734, r2_store:-0.39993361874389177\n",
            "Epoch [5714/10000], train_Loss: 0.10184433311223984,test_Loss:21.74806022644043, r2_store:-0.31219471573081536\n",
            "Epoch [5715/10000], train_Loss: 0.12293169647455215,test_Loss:22.844730377197266, r2_store:-0.4072571959191811\n",
            "Epoch [5716/10000], train_Loss: 0.1276053935289383,test_Loss:21.742382049560547, r2_store:-0.3145140334952423\n",
            "Epoch [5717/10000], train_Loss: 0.11345014721155167,test_Loss:22.658161163330078, r2_store:-0.39340932252811167\n",
            "Epoch [5718/10000], train_Loss: 0.07415281236171722,test_Loss:21.917285919189453, r2_store:-0.3316242524057873\n",
            "Epoch [5719/10000], train_Loss: 0.03086375631392002,test_Loss:22.231355667114258, r2_store:-0.360574238708812\n",
            "Epoch [5720/10000], train_Loss: 0.0036234292201697826,test_Loss:22.25895118713379, r2_store:-0.36128793972938644\n",
            "Epoch [5721/10000], train_Loss: 0.004459390416741371,test_Loss:21.98493003845215, r2_store:-0.3332453931110695\n",
            "Epoch [5722/10000], train_Loss: 0.024747446179389954,test_Loss:22.607450485229492, r2_store:-0.381811335671131\n",
            "Epoch [5723/10000], train_Loss: 0.04355328157544136,test_Loss:21.968975067138672, r2_store:-0.3264082377671793\n",
            "Epoch [5724/10000], train_Loss: 0.045540180057287216,test_Loss:22.536157608032227, r2_store:-0.37548078843368016\n",
            "Epoch [5725/10000], train_Loss: 0.028636986389756203,test_Loss:22.14264678955078, r2_store:-0.34021020925057743\n",
            "Epoch [5726/10000], train_Loss: 0.008571655489504337,test_Loss:22.264095306396484, r2_store:-0.3511893257981282\n",
            "Epoch [5727/10000], train_Loss: 0.0006427596090361476,test_Loss:22.37582015991211, r2_store:-0.36356020059834093\n",
            "Epoch [5728/10000], train_Loss: 0.007930943742394447,test_Loss:22.040138244628906, r2_store:-0.33474314070408395\n",
            "Epoch [5729/10000], train_Loss: 0.019908064976334572,test_Loss:22.500104904174805, r2_store:-0.37306128976231157\n",
            "Epoch [5730/10000], train_Loss: 0.02358456514775753,test_Loss:22.10638999938965, r2_store:-0.33569735330496964\n",
            "Epoch [5731/10000], train_Loss: 0.01634247601032257,test_Loss:22.380605697631836, r2_store:-0.36057944612081716\n",
            "Epoch [5732/10000], train_Loss: 0.005360725335776806,test_Loss:22.244321823120117, r2_store:-0.3511130198658441\n",
            "Epoch [5733/10000], train_Loss: 0.0006229910650290549,test_Loss:22.150007247924805, r2_store:-0.3430698894299673\n",
            "Epoch [5734/10000], train_Loss: 0.00439505185931921,test_Loss:22.405115127563477, r2_store:-0.3649465840224937\n",
            "Epoch [5735/10000], train_Loss: 0.010828250087797642,test_Loss:22.06930160522461, r2_store:-0.33713844070323185\n",
            "Epoch [5736/10000], train_Loss: 0.012818698771297932,test_Loss:22.350601196289062, r2_store:-0.363646196097827\n",
            "Epoch [5737/10000], train_Loss: 0.008558242581784725,test_Loss:22.141094207763672, r2_store:-0.34539751483677716\n",
            "Epoch [5738/10000], train_Loss: 0.0027583071496337652,test_Loss:22.21440887451172, r2_store:-0.3512195037962953\n",
            "Epoch [5739/10000], train_Loss: 0.0005441457033157349,test_Loss:22.304548263549805, r2_store:-0.35822645087612015\n",
            "Epoch [5740/10000], train_Loss: 0.0028329924680292606,test_Loss:22.12411880493164, r2_store:-0.3418694352810716\n",
            "Epoch [5741/10000], train_Loss: 0.006256327033042908,test_Loss:22.35868263244629, r2_store:-0.3626235388635073\n",
            "Epoch [5742/10000], train_Loss: 0.007027211599051952,test_Loss:22.12032127380371, r2_store:-0.3429184529145788\n",
            "Epoch [5743/10000], train_Loss: 0.004700041376054287,test_Loss:22.26664161682129, r2_store:-0.3555529596929716\n",
            "Epoch [5744/10000], train_Loss: 0.001620759954676032,test_Loss:22.2242431640625, r2_store:-0.3510315612413777\n",
            "Epoch [5745/10000], train_Loss: 0.00046809669584035873,test_Loss:22.16387176513672, r2_store:-0.34609327804891743\n",
            "Epoch [5746/10000], train_Loss: 0.0016535241156816483,test_Loss:22.296260833740234, r2_store:-0.3582281597582544\n",
            "Epoch [5747/10000], train_Loss: 0.003475309582427144,test_Loss:22.12383270263672, r2_store:-0.3431888844726634\n",
            "Epoch [5748/10000], train_Loss: 0.004048657603561878,test_Loss:22.288127899169922, r2_store:-0.3579374254209937\n",
            "Epoch [5749/10000], train_Loss: 0.0029296106658875942,test_Loss:22.149072647094727, r2_store:-0.3476042037035121\n",
            "Epoch [5750/10000], train_Loss: 0.0012554178247228265,test_Loss:22.192386627197266, r2_store:-0.35192654720790517\n",
            "Epoch [5751/10000], train_Loss: 0.00041443613008596003,test_Loss:22.22916603088379, r2_store:-0.354302510394253\n",
            "Epoch [5752/10000], train_Loss: 0.0008309983531944454,test_Loss:22.145408630371094, r2_store:-0.346570845534965\n",
            "Epoch [5753/10000], train_Loss: 0.0018156589940190315,test_Loss:22.265544891357422, r2_store:-0.35754372435019866\n",
            "Epoch [5754/10000], train_Loss: 0.002346249297261238,test_Loss:22.13467025756836, r2_store:-0.34634363929212686\n",
            "Epoch [5755/10000], train_Loss: 0.0020095226354897022,test_Loss:22.247051239013672, r2_store:-0.35541172136505406\n",
            "Epoch [5756/10000], train_Loss: 0.0011471410980448127,test_Loss:22.18915367126465, r2_store:-0.35032918938376634\n",
            "Epoch [5757/10000], train_Loss: 0.0004768533108290285,test_Loss:22.189544677734375, r2_store:-0.35087301247203606\n",
            "Epoch [5758/10000], train_Loss: 0.0004101682861801237,test_Loss:22.229694366455078, r2_store:-0.35486706906720245\n",
            "Epoch [5759/10000], train_Loss: 0.0008298169705085456,test_Loss:22.153852462768555, r2_store:-0.34800306200739595\n",
            "Epoch [5760/10000], train_Loss: 0.0012795677175745368,test_Loss:22.24709129333496, r2_store:-0.3564310839168767\n",
            "Epoch [5761/10000], train_Loss: 0.0013683401048183441,test_Loss:22.14274787902832, r2_store:-0.34872057408192947\n",
            "Epoch [5762/10000], train_Loss: 0.0010599499801173806,test_Loss:22.206310272216797, r2_store:-0.3545040491121143\n",
            "Epoch [5763/10000], train_Loss: 0.000617806741502136,test_Loss:22.184818267822266, r2_store:-0.35156323412972235\n",
            "Epoch [5764/10000], train_Loss: 0.00035268592182546854,test_Loss:22.184123992919922, r2_store:-0.3510861362336253\n",
            "Epoch [5765/10000], train_Loss: 0.00038633166695944965,test_Loss:22.217540740966797, r2_store:-0.3543073113746218\n",
            "Epoch [5766/10000], train_Loss: 0.0006079248851165175,test_Loss:22.161436080932617, r2_store:-0.3490881695233212\n",
            "Epoch [5767/10000], train_Loss: 0.0008099933038465679,test_Loss:22.241104125976562, r2_store:-0.3549275514754662\n",
            "Epoch [5768/10000], train_Loss: 0.0008365205721929669,test_Loss:22.177663803100586, r2_store:-0.34924581307022584\n",
            "Epoch [5769/10000], train_Loss: 0.000685474369674921,test_Loss:22.221874237060547, r2_store:-0.35343971573121147\n",
            "Epoch [5770/10000], train_Loss: 0.00047061435179784894,test_Loss:22.19460678100586, r2_store:-0.35116307035466554\n",
            "Epoch [5771/10000], train_Loss: 0.00032767796074040234,test_Loss:22.19957733154297, r2_store:-0.3512746244484024\n",
            "Epoch [5772/10000], train_Loss: 0.0003176193858962506,test_Loss:22.222774505615234, r2_store:-0.35312777638269854\n",
            "Epoch [5773/10000], train_Loss: 0.00040644066757522523,test_Loss:22.18313980102539, r2_store:-0.3498671371511781\n",
            "Epoch [5774/10000], train_Loss: 0.0005089082405902445,test_Loss:22.230525970458984, r2_store:-0.35391586551475585\n",
            "Epoch [5775/10000], train_Loss: 0.000550704135093838,test_Loss:22.185983657836914, r2_store:-0.3498352371985294\n",
            "Epoch [5776/10000], train_Loss: 0.0005082187708467245,test_Loss:22.224157333374023, r2_store:-0.35323085349578154\n",
            "Epoch [5777/10000], train_Loss: 0.00041381100891157985,test_Loss:22.192365646362305, r2_store:-0.35091747628533887\n",
            "Epoch [5778/10000], train_Loss: 0.00032591898343525827,test_Loss:22.202533721923828, r2_store:-0.35176372426199\n",
            "Epoch [5779/10000], train_Loss: 0.00028651085449382663,test_Loss:22.21209144592285, r2_store:-0.352177953826448\n",
            "Epoch [5780/10000], train_Loss: 0.00030202706693671644,test_Loss:22.193567276000977, r2_store:-0.35047426973710816\n",
            "Epoch [5781/10000], train_Loss: 0.0003481759922578931,test_Loss:22.219806671142578, r2_store:-0.35291960024546065\n",
            "Epoch [5782/10000], train_Loss: 0.0003873175592161715,test_Loss:22.186843872070312, r2_store:-0.35003812611088714\n",
            "Epoch [5783/10000], train_Loss: 0.0003964644856750965,test_Loss:22.2238712310791, r2_store:-0.35274513357187587\n",
            "Epoch [5784/10000], train_Loss: 0.00037337298272177577,test_Loss:22.19744110107422, r2_store:-0.35040884649744264\n",
            "Epoch [5785/10000], train_Loss: 0.0003320458345115185,test_Loss:22.21369171142578, r2_store:-0.3520652254507377\n",
            "Epoch [5786/10000], train_Loss: 0.00029269413789734244,test_Loss:22.202804565429688, r2_store:-0.3512832155348533\n",
            "Epoch [5787/10000], train_Loss: 0.0002712986315600574,test_Loss:22.205121994018555, r2_store:-0.35119340635280216\n",
            "Epoch [5788/10000], train_Loss: 0.00027132025570608675,test_Loss:22.214853286743164, r2_store:-0.3520291120221044\n",
            "Epoch [5789/10000], train_Loss: 0.00028619024669751525,test_Loss:22.196205139160156, r2_store:-0.350622369310158\n",
            "Epoch [5790/10000], train_Loss: 0.0003040614537894726,test_Loss:22.218936920166016, r2_store:-0.3524044507633226\n",
            "Epoch [5791/10000], train_Loss: 0.0003142340574413538,test_Loss:22.201732635498047, r2_store:-0.3505118219338239\n",
            "Epoch [5792/10000], train_Loss: 0.00031235103961080313,test_Loss:22.223407745361328, r2_store:-0.35231967770191397\n",
            "Epoch [5793/10000], train_Loss: 0.00029984937282279134,test_Loss:22.20420265197754, r2_store:-0.35086542688000044\n",
            "Epoch [5794/10000], train_Loss: 0.0002822156238835305,test_Loss:22.217147827148438, r2_store:-0.35192089321382913\n",
            "Epoch [5795/10000], train_Loss: 0.00026624667225405574,test_Loss:22.214326858520508, r2_store:-0.35133841570632995\n",
            "Epoch [5796/10000], train_Loss: 0.0002564066671766341,test_Loss:22.21644401550293, r2_store:-0.3513580706000101\n",
            "Epoch [5797/10000], train_Loss: 0.00025460499455221,test_Loss:22.220325469970703, r2_store:-0.3517998798208162\n",
            "Epoch [5798/10000], train_Loss: 0.0002583576715551317,test_Loss:22.210603713989258, r2_store:-0.35100059255076177\n",
            "Epoch [5799/10000], train_Loss: 0.0002650069654919207,test_Loss:22.225496292114258, r2_store:-0.35210958059088093\n",
            "Epoch [5800/10000], train_Loss: 0.00027021864661946893,test_Loss:22.213077545166016, r2_store:-0.35085962334908505\n",
            "Epoch [5801/10000], train_Loss: 0.00027193728601559997,test_Loss:22.227590560913086, r2_store:-0.35212659947699687\n",
            "Epoch [5802/10000], train_Loss: 0.0002688164822757244,test_Loss:22.213359832763672, r2_store:-0.35095319275396886\n",
            "Epoch [5803/10000], train_Loss: 0.0002622891333885491,test_Loss:22.225967407226562, r2_store:-0.3519004621952706\n",
            "Epoch [5804/10000], train_Loss: 0.00025420921156182885,test_Loss:22.219480514526367, r2_store:-0.3511840303327065\n",
            "Epoch [5805/10000], train_Loss: 0.0002472786291036755,test_Loss:22.22395896911621, r2_store:-0.3516029189113432\n",
            "Epoch [5806/10000], train_Loss: 0.0002424200501991436,test_Loss:22.222408294677734, r2_store:-0.35147642731763074\n",
            "Epoch [5807/10000], train_Loss: 0.00024030436179600656,test_Loss:22.222299575805664, r2_store:-0.3513062224753054\n",
            "Epoch [5808/10000], train_Loss: 0.00024020431737881154,test_Loss:22.22804069519043, r2_store:-0.3516695889519723\n",
            "Epoch [5809/10000], train_Loss: 0.00024140675668604672,test_Loss:22.220264434814453, r2_store:-0.35109260985154855\n",
            "Epoch [5810/10000], train_Loss: 0.00024262125953100622,test_Loss:22.22654151916504, r2_store:-0.3517726001433812\n",
            "Epoch [5811/10000], train_Loss: 0.0002436675422359258,test_Loss:22.219135284423828, r2_store:-0.3509636477935496\n",
            "Epoch [5812/10000], train_Loss: 0.0002436242939438671,test_Loss:22.228734970092773, r2_store:-0.3517204247564425\n",
            "Epoch [5813/10000], train_Loss: 0.0002423943515168503,test_Loss:22.219314575195312, r2_store:-0.3509404667616396\n",
            "Epoch [5814/10000], train_Loss: 0.00024019643024075776,test_Loss:22.228797912597656, r2_store:-0.3516094183202012\n",
            "Epoch [5815/10000], train_Loss: 0.00023769417020957917,test_Loss:22.22344398498535, r2_store:-0.35097065807131433\n",
            "Epoch [5816/10000], train_Loss: 0.00023485471319872886,test_Loss:22.228281021118164, r2_store:-0.35143384005808764\n",
            "Epoch [5817/10000], train_Loss: 0.00023205287288874388,test_Loss:22.22361183166504, r2_store:-0.3510316270879965\n",
            "Epoch [5818/10000], train_Loss: 0.00022983601957093924,test_Loss:22.227436065673828, r2_store:-0.35125108249804216\n",
            "Epoch [5819/10000], train_Loss: 0.000227960612392053,test_Loss:22.226083755493164, r2_store:-0.3511455140510573\n",
            "Epoch [5820/10000], train_Loss: 0.00022665029973722994,test_Loss:22.225467681884766, r2_store:-0.35113573313327096\n",
            "Epoch [5821/10000], train_Loss: 0.0002257637243019417,test_Loss:22.22702407836914, r2_store:-0.3512696704356695\n",
            "Epoch [5822/10000], train_Loss: 0.00022525030362885445,test_Loss:22.224994659423828, r2_store:-0.3509824332243927\n",
            "Epoch [5823/10000], train_Loss: 0.0002251844562124461,test_Loss:22.230159759521484, r2_store:-0.3512837336132837\n",
            "Epoch [5824/10000], train_Loss: 0.00022523605730384588,test_Loss:22.22559928894043, r2_store:-0.35082650447152797\n",
            "Epoch [5825/10000], train_Loss: 0.00022502313368022442,test_Loss:22.230470657348633, r2_store:-0.3512880828963083\n",
            "Epoch [5826/10000], train_Loss: 0.00022451812401413918,test_Loss:22.2246150970459, r2_store:-0.35076210238968697\n",
            "Epoch [5827/10000], train_Loss: 0.00022414613340515643,test_Loss:22.231510162353516, r2_store:-0.35128200355522643\n",
            "Epoch [5828/10000], train_Loss: 0.00022354480461217463,test_Loss:22.226016998291016, r2_store:-0.3507219024233874\n",
            "Epoch [5829/10000], train_Loss: 0.00022264037397690117,test_Loss:22.23287582397461, r2_store:-0.35127767760662887\n",
            "Epoch [5830/10000], train_Loss: 0.0002221566828666255,test_Loss:22.22662925720215, r2_store:-0.35070315636771454\n",
            "Epoch [5831/10000], train_Loss: 0.000221334514208138,test_Loss:22.233057022094727, r2_store:-0.35125714101426997\n",
            "Epoch [5832/10000], train_Loss: 0.00022042312775738537,test_Loss:22.225955963134766, r2_store:-0.350670433307108\n",
            "Epoch [5833/10000], train_Loss: 0.0002195571141783148,test_Loss:22.232547760009766, r2_store:-0.3512237948495116\n",
            "Epoch [5834/10000], train_Loss: 0.00021882946020923555,test_Loss:22.225929260253906, r2_store:-0.350635301181883\n",
            "Epoch [5835/10000], train_Loss: 0.00021792505867779255,test_Loss:22.232608795166016, r2_store:-0.3511941695888834\n",
            "Epoch [5836/10000], train_Loss: 0.00021710680448450148,test_Loss:22.225797653198242, r2_store:-0.35061372823223125\n",
            "Epoch [5837/10000], train_Loss: 0.0002162756136385724,test_Loss:22.232410430908203, r2_store:-0.35116930509914623\n",
            "Epoch [5838/10000], train_Loss: 0.00021556434512604028,test_Loss:22.227235794067383, r2_store:-0.3505774523660039\n",
            "Epoch [5839/10000], train_Loss: 0.00021483420277945697,test_Loss:22.2344970703125, r2_store:-0.3511464851158579\n",
            "Epoch [5840/10000], train_Loss: 0.0002143865858670324,test_Loss:22.227277755737305, r2_store:-0.3505087070796262\n",
            "Epoch [5841/10000], train_Loss: 0.00021390951587818563,test_Loss:22.23436737060547, r2_store:-0.3511143320899188\n",
            "Epoch [5842/10000], train_Loss: 0.00021377179655246437,test_Loss:22.227357864379883, r2_store:-0.3504182438377983\n",
            "Epoch [5843/10000], train_Loss: 0.00021361303515732288,test_Loss:22.235673904418945, r2_store:-0.35112005336326146\n",
            "Epoch [5844/10000], train_Loss: 0.00021374973584897816,test_Loss:22.226421356201172, r2_store:-0.35035863791971744\n",
            "Epoch [5845/10000], train_Loss: 0.0002143551828339696,test_Loss:22.235742568969727, r2_store:-0.35117767285635915\n",
            "Epoch [5846/10000], train_Loss: 0.00021528848446905613,test_Loss:22.226200103759766, r2_store:-0.35024238892099246\n",
            "Epoch [5847/10000], train_Loss: 0.00021689145069103688,test_Loss:22.238679885864258, r2_store:-0.3512314282468416\n",
            "Epoch [5848/10000], train_Loss: 0.00021930623915977776,test_Loss:22.225177764892578, r2_store:-0.3501111898920952\n",
            "Epoch [5849/10000], train_Loss: 0.0002225324569735676,test_Loss:22.23857879638672, r2_store:-0.35137822543903807\n",
            "Epoch [5850/10000], train_Loss: 0.0002271459234179929,test_Loss:22.22201919555664, r2_store:-0.34993364372820945\n",
            "Epoch [5851/10000], train_Loss: 0.00023335851437877864,test_Loss:22.242551803588867, r2_store:-0.35149037095973457\n",
            "Epoch [5852/10000], train_Loss: 0.00024150013632606715,test_Loss:22.221412658691406, r2_store:-0.3496366382231082\n",
            "Epoch [5853/10000], train_Loss: 0.0002526557364035398,test_Loss:22.24485206604004, r2_store:-0.35169093106102545\n",
            "Epoch [5854/10000], train_Loss: 0.00026842125225812197,test_Loss:22.216835021972656, r2_store:-0.3493218497750259\n",
            "Epoch [5855/10000], train_Loss: 0.000290432246401906,test_Loss:22.249622344970703, r2_store:-0.35205981936346054\n",
            "Epoch [5856/10000], train_Loss: 0.00032111830660142004,test_Loss:22.211881637573242, r2_store:-0.34885840302862725\n",
            "Epoch [5857/10000], train_Loss: 0.00036404779530130327,test_Loss:22.255577087402344, r2_store:-0.3525471987424251\n",
            "Epoch [5858/10000], train_Loss: 0.00042515588575042784,test_Loss:22.20407485961914, r2_store:-0.34815548737784785\n",
            "Epoch [5859/10000], train_Loss: 0.0005106962053105235,test_Loss:22.265525817871094, r2_store:-0.3532351395727289\n",
            "Epoch [5860/10000], train_Loss: 0.0006332602351903915,test_Loss:22.19271469116211, r2_store:-0.3471692150773551\n",
            "Epoch [5861/10000], train_Loss: 0.0008057333761826158,test_Loss:22.280094146728516, r2_store:-0.3542924098568858\n",
            "Epoch [5862/10000], train_Loss: 0.0010553221218287945,test_Loss:22.18111228942871, r2_store:-0.3457897296522092\n",
            "Epoch [5863/10000], train_Loss: 0.0014144142623990774,test_Loss:22.299917221069336, r2_store:-0.3559962358052875\n",
            "Epoch [5864/10000], train_Loss: 0.0019400917226448655,test_Loss:22.152299880981445, r2_store:-0.34386604020426703\n",
            "Epoch [5865/10000], train_Loss: 0.0027114208787679672,test_Loss:22.328210830688477, r2_store:-0.35852056639873053\n",
            "Epoch [5866/10000], train_Loss: 0.0038440220523625612,test_Loss:22.122610092163086, r2_store:-0.34085356575994763\n",
            "Epoch [5867/10000], train_Loss: 0.005527526140213013,test_Loss:22.380075454711914, r2_store:-0.3622596018416506\n",
            "Epoch [5868/10000], train_Loss: 0.007999286986887455,test_Loss:22.06831932067871, r2_store:-0.3366482776344224\n",
            "Epoch [5869/10000], train_Loss: 0.011667603626847267,test_Loss:22.452983856201172, r2_store:-0.36824083947262287\n",
            "Epoch [5870/10000], train_Loss: 0.016992691904306412,test_Loss:22.01380729675293, r2_store:-0.330663416607184\n",
            "Epoch [5871/10000], train_Loss: 0.02495807781815529,test_Loss:22.555782318115234, r2_store:-0.37722367398616696\n",
            "Epoch [5872/10000], train_Loss: 0.03626244515180588,test_Loss:21.893400192260742, r2_store:-0.3230343323409941\n",
            "Epoch [5873/10000], train_Loss: 0.05225575715303421,test_Loss:22.695926666259766, r2_store:-0.390002394244932\n",
            "Epoch [5874/10000], train_Loss: 0.07226209342479706,test_Loss:21.84108543395996, r2_store:-0.3148733331904834\n",
            "Epoch [5875/10000], train_Loss: 0.09667475521564484,test_Loss:22.85636329650879, r2_store:-0.4036436423749272\n",
            "Epoch [5876/10000], train_Loss: 0.11698122322559357,test_Loss:21.768095016479492, r2_store:-0.31173435587750675\n",
            "Epoch [5877/10000], train_Loss: 0.12899085879325867,test_Loss:22.88078498840332, r2_store:-0.4044022634054041\n",
            "Epoch [5878/10000], train_Loss: 0.11617299169301987,test_Loss:21.832509994506836, r2_store:-0.31925308618542014\n",
            "Epoch [5879/10000], train_Loss: 0.08310309052467346,test_Loss:22.49393653869629, r2_store:-0.3809218944588282\n",
            "Epoch [5880/10000], train_Loss: 0.03826514631509781,test_Loss:22.08534812927246, r2_store:-0.3423422508541878\n",
            "Epoch [5881/10000], train_Loss: 0.006801257375627756,test_Loss:22.1934871673584, r2_store:-0.3464901562794611\n",
            "Epoch [5882/10000], train_Loss: 0.002188832499086857,test_Loss:22.500560760498047, r2_store:-0.37041703571175333\n",
            "Epoch [5883/10000], train_Loss: 0.0196301881223917,test_Loss:22.005008697509766, r2_store:-0.3268765896361219\n",
            "Epoch [5884/10000], train_Loss: 0.04070444777607918,test_Loss:22.67790412902832, r2_store:-0.3809829204504893\n",
            "Epoch [5885/10000], train_Loss: 0.045625947415828705,test_Loss:22.14323616027832, r2_store:-0.32821390564024977\n",
            "Epoch [5886/10000], train_Loss: 0.0324951633810997,test_Loss:22.541879653930664, r2_store:-0.3642478129618085\n",
            "Epoch [5887/10000], train_Loss: 0.011509090662002563,test_Loss:22.268802642822266, r2_store:-0.34901108987659724\n",
            "Epoch [5888/10000], train_Loss: 0.0008183217723853886,test_Loss:22.164974212646484, r2_store:-0.342045861043051\n",
            "Epoch [5889/10000], train_Loss: 0.005928955972194672,test_Loss:22.541133880615234, r2_store:-0.3693869508028369\n",
            "Epoch [5890/10000], train_Loss: 0.01784401759505272,test_Loss:22.16303062438965, r2_store:-0.3320712182824428\n",
            "Epoch [5891/10000], train_Loss: 0.02395334281027317,test_Loss:22.556652069091797, r2_store:-0.36883278089519766\n",
            "Epoch [5892/10000], train_Loss: 0.017844270914793015,test_Loss:22.194581985473633, r2_store:-0.34046582066425035\n",
            "Epoch [5893/10000], train_Loss: 0.00685186218470335,test_Loss:22.327171325683594, r2_store:-0.35153235090821755\n",
            "Epoch [5894/10000], train_Loss: 0.0007234417134895921,test_Loss:22.426713943481445, r2_store:-0.35697245719316206\n",
            "Epoch [5895/10000], train_Loss: 0.0035479036159813404,test_Loss:22.191875457763672, r2_store:-0.33720840925666784\n",
            "Epoch [5896/10000], train_Loss: 0.010096062906086445,test_Loss:22.47458839416504, r2_store:-0.36470345346551625\n",
            "Epoch [5897/10000], train_Loss: 0.012714698910713196,test_Loss:22.161928176879883, r2_store:-0.3380869659771035\n",
            "Epoch [5898/10000], train_Loss: 0.009119660593569279,test_Loss:22.38540267944336, r2_store:-0.3568601690796014\n",
            "Epoch [5899/10000], train_Loss: 0.0032300655730068684,test_Loss:22.300294876098633, r2_store:-0.34979422756988043\n",
            "Epoch [5900/10000], train_Loss: 0.0005408464930951595,test_Loss:22.219913482666016, r2_store:-0.344226500221952\n",
            "Epoch [5901/10000], train_Loss: 0.002532282378524542,test_Loss:22.392236709594727, r2_store:-0.36019542864588017\n",
            "Epoch [5902/10000], train_Loss: 0.005962449125945568,test_Loss:22.16201400756836, r2_store:-0.33983507223072973\n",
            "Epoch [5903/10000], train_Loss: 0.007077958434820175,test_Loss:22.383792877197266, r2_store:-0.3589521113809142\n",
            "Epoch [5904/10000], train_Loss: 0.004858851432800293,test_Loss:22.218233108520508, r2_store:-0.3450647200501942\n",
            "Epoch [5905/10000], train_Loss: 0.0017359296325594187,test_Loss:22.27376937866211, r2_store:-0.34936794051523923\n",
            "Epoch [5906/10000], train_Loss: 0.0004632662166841328,test_Loss:22.34104347229004, r2_store:-0.3539267329905451\n",
            "Epoch [5907/10000], train_Loss: 0.001563545665703714,test_Loss:22.203126907348633, r2_store:-0.342583066592115\n",
            "Epoch [5908/10000], train_Loss: 0.00341598829254508,test_Loss:22.36316680908203, r2_store:-0.3578718192306414\n",
            "Epoch [5909/10000], train_Loss: 0.003970267251133919,test_Loss:22.185848236083984, r2_store:-0.3435779879550076\n",
            "Epoch [5910/10000], train_Loss: 0.0028832205571234226,test_Loss:22.305931091308594, r2_store:-0.3539506806744299\n",
            "Epoch [5911/10000], train_Loss: 0.0012122346088290215,test_Loss:22.261503219604492, r2_store:-0.3500011559763072\n",
            "Epoch [5912/10000], train_Loss: 0.0003975906874984503,test_Loss:22.22661590576172, r2_store:-0.34776442187756995\n",
            "Epoch [5913/10000], train_Loss: 0.0008312026038765907,test_Loss:22.314285278320312, r2_store:-0.3556410567790129\n",
            "Epoch [5914/10000], train_Loss: 0.0018052527448162436,test_Loss:22.19662857055664, r2_store:-0.34484423700452527\n",
            "Epoch [5915/10000], train_Loss: 0.002323001157492399,test_Loss:22.332561492919922, r2_store:-0.3559587736204961\n",
            "Epoch [5916/10000], train_Loss: 0.001962534850463271,test_Loss:22.218584060668945, r2_store:-0.34714607331123815\n",
            "Epoch [5917/10000], train_Loss: 0.0011091458145529032,test_Loss:22.268863677978516, r2_store:-0.3521725808362033\n",
            "Epoch [5918/10000], train_Loss: 0.00045337146730162203,test_Loss:22.271385192871094, r2_store:-0.35181355691833427\n",
            "Epoch [5919/10000], train_Loss: 0.00039615435525774956,test_Loss:22.236488342285156, r2_store:-0.34799548253999335\n",
            "Epoch [5920/10000], train_Loss: 0.0008194258552975953,test_Loss:22.31357192993164, r2_store:-0.3551182907830004\n",
            "Epoch [5921/10000], train_Loss: 0.0012588653480634093,test_Loss:22.20806884765625, r2_store:-0.34704141693503465\n",
            "Epoch [5922/10000], train_Loss: 0.0013471969868987799,test_Loss:22.29493522644043, r2_store:-0.3548450096418001\n",
            "Epoch [5923/10000], train_Loss: 0.0010420710314065218,test_Loss:22.233789443969727, r2_store:-0.34896002430737694\n",
            "Epoch [5924/10000], train_Loss: 0.0006045064656063914,test_Loss:22.269392013549805, r2_store:-0.3517484483465647\n",
            "Epoch [5925/10000], train_Loss: 0.0003368673787917942,test_Loss:22.266094207763672, r2_store:-0.35206174706498516\n",
            "Epoch [5926/10000], train_Loss: 0.00036085062311030924,test_Loss:22.228801727294922, r2_store:-0.3488586688504709\n",
            "Epoch [5927/10000], train_Loss: 0.0005842623650096357,test_Loss:22.296924591064453, r2_store:-0.3538786384592385\n",
            "Epoch [5928/10000], train_Loss: 0.0007878791657276452,test_Loss:22.235496520996094, r2_store:-0.3478770699001781\n",
            "Epoch [5929/10000], train_Loss: 0.0008229374652728438,test_Loss:22.296794891357422, r2_store:-0.35352298273458116\n",
            "Epoch [5930/10000], train_Loss: 0.0006730534369125962,test_Loss:22.23783302307129, r2_store:-0.3493145126115331\n",
            "Epoch [5931/10000], train_Loss: 0.0004592136829160154,test_Loss:22.267169952392578, r2_store:-0.3516480869090959\n",
            "Epoch [5932/10000], train_Loss: 0.00031099451007321477,test_Loss:22.273717880249023, r2_store:-0.35140058498624316\n",
            "Epoch [5933/10000], train_Loss: 0.00029770840774290264,test_Loss:22.250459671020508, r2_store:-0.34959164557863587\n",
            "Epoch [5934/10000], train_Loss: 0.0003852054360322654,test_Loss:22.28214454650879, r2_store:-0.3529029688436831\n",
            "Epoch [5935/10000], train_Loss: 0.0004923483356833458,test_Loss:22.235904693603516, r2_store:-0.3488499548051047\n",
            "Epoch [5936/10000], train_Loss: 0.0005372783052735031,test_Loss:22.288015365600586, r2_store:-0.3529608254645269\n",
            "Epoch [5937/10000], train_Loss: 0.0005002854159101844,test_Loss:22.242170333862305, r2_store:-0.3494347531244222\n",
            "Epoch [5938/10000], train_Loss: 0.00040619922219775617,test_Loss:22.266616821289062, r2_store:-0.35188325459067005\n",
            "Epoch [5939/10000], train_Loss: 0.0003148939576931298,test_Loss:22.258373260498047, r2_store:-0.35077928442372697\n",
            "Epoch [5940/10000], train_Loss: 0.0002670325920917094,test_Loss:22.257314682006836, r2_store:-0.35041841262091955\n",
            "Epoch [5941/10000], train_Loss: 0.0002776283654384315,test_Loss:22.27294921875, r2_store:-0.35192591715556243\n",
            "Epoch [5942/10000], train_Loss: 0.0003224832471460104,test_Loss:22.24405288696289, r2_store:-0.34948007862957753\n",
            "Epoch [5943/10000], train_Loss: 0.0003680442168843001,test_Loss:22.279769897460938, r2_store:-0.35234677786497004\n",
            "Epoch [5944/10000], train_Loss: 0.0003851645451504737,test_Loss:22.244340896606445, r2_store:-0.3494392627835232\n",
            "Epoch [5945/10000], train_Loss: 0.00036689918488264084,test_Loss:22.271955490112305, r2_store:-0.35194661938633875\n",
            "Epoch [5946/10000], train_Loss: 0.00032556147198192775,test_Loss:22.252552032470703, r2_store:-0.3500026994848833\n",
            "Epoch [5947/10000], train_Loss: 0.0002813918690662831,test_Loss:22.2657527923584, r2_store:-0.35098988748965\n",
            "Epoch [5948/10000], train_Loss: 0.00025304986047558486,test_Loss:22.26259994506836, r2_store:-0.35084224290091526\n",
            "Epoch [5949/10000], train_Loss: 0.00024734967155382037,test_Loss:22.256128311157227, r2_store:-0.35015141564539265\n",
            "Epoch [5950/10000], train_Loss: 0.00026029322179965675,test_Loss:22.272829055786133, r2_store:-0.3514892442771511\n",
            "Epoch [5951/10000], train_Loss: 0.0002801820228341967,test_Loss:22.25151824951172, r2_store:-0.349698323067428\n",
            "Epoch [5952/10000], train_Loss: 0.000294997327728197,test_Loss:22.276103973388672, r2_store:-0.35170453132780355\n",
            "Epoch [5953/10000], train_Loss: 0.00029730674577876925,test_Loss:22.255613327026367, r2_store:-0.34977279875760625\n",
            "Epoch [5954/10000], train_Loss: 0.00028671554173342884,test_Loss:22.275550842285156, r2_store:-0.3514761471091048\n",
            "Epoch [5955/10000], train_Loss: 0.00026801772764883935,test_Loss:22.259660720825195, r2_store:-0.3502204600978447\n",
            "Epoch [5956/10000], train_Loss: 0.00024908187333494425,test_Loss:22.27000617980957, r2_store:-0.35099018046787966\n",
            "Epoch [5957/10000], train_Loss: 0.00023572135251015425,test_Loss:22.269153594970703, r2_store:-0.35079948290160257\n",
            "Epoch [5958/10000], train_Loss: 0.0002310570125700906,test_Loss:22.265865325927734, r2_store:-0.35052745018547204\n",
            "Epoch [5959/10000], train_Loss: 0.00023378714104183018,test_Loss:22.274812698364258, r2_store:-0.3512878540792228\n",
            "Epoch [5960/10000], train_Loss: 0.00024064297031145543,test_Loss:22.26480484008789, r2_store:-0.3502158193870437\n",
            "Epoch [5961/10000], train_Loss: 0.00024748346186243,test_Loss:22.281967163085938, r2_store:-0.35149355012156014\n",
            "Epoch [5962/10000], train_Loss: 0.00025141792139038444,test_Loss:22.2662353515625, r2_store:-0.3501532519478816\n",
            "Epoch [5963/10000], train_Loss: 0.0002504827862139791,test_Loss:22.280122756958008, r2_store:-0.3514632384681311\n",
            "Epoch [5964/10000], train_Loss: 0.0002449649036861956,test_Loss:22.266605377197266, r2_store:-0.3503167852013003\n",
            "Epoch [5965/10000], train_Loss: 0.00023687095381319523,test_Loss:22.278453826904297, r2_store:-0.3511919920501685\n",
            "Epoch [5966/10000], train_Loss: 0.0002283811627421528,test_Loss:22.272926330566406, r2_store:-0.3505704944366608\n",
            "Epoch [5967/10000], train_Loss: 0.00022179566440172493,test_Loss:22.276689529418945, r2_store:-0.3508462446278213\n",
            "Epoch [5968/10000], train_Loss: 0.00021806833683513105,test_Loss:22.2773380279541, r2_store:-0.35086643148736507\n",
            "Epoch [5969/10000], train_Loss: 0.00021711965382564813,test_Loss:22.275466918945312, r2_store:-0.3505455605079233\n",
            "Epoch [5970/10000], train_Loss: 0.00021798055968247354,test_Loss:22.282833099365234, r2_store:-0.3510804941844319\n",
            "Epoch [5971/10000], train_Loss: 0.00022011759574525058,test_Loss:22.2740535736084, r2_store:-0.3503517558933775\n",
            "Epoch [5972/10000], train_Loss: 0.0002219879097538069,test_Loss:22.283756256103516, r2_store:-0.3511689180969091\n",
            "Epoch [5973/10000], train_Loss: 0.00022266276937443763,test_Loss:22.27468490600586, r2_store:-0.35027336475577187\n",
            "Epoch [5974/10000], train_Loss: 0.00022194173652678728,test_Loss:22.28510284423828, r2_store:-0.3511327492054337\n",
            "Epoch [5975/10000], train_Loss: 0.0002201116003561765,test_Loss:22.27553939819336, r2_store:-0.3503020509636052\n",
            "Epoch [5976/10000], train_Loss: 0.00021712618763558567,test_Loss:22.284093856811523, r2_store:-0.35101513711642895\n",
            "Epoch [5977/10000], train_Loss: 0.00021390349138528109,test_Loss:22.27883529663086, r2_store:-0.35039818296543657\n",
            "Epoch [5978/10000], train_Loss: 0.00021072484378237277,test_Loss:22.285917282104492, r2_store:-0.35083471518007103\n",
            "Epoch [5979/10000], train_Loss: 0.00020780197519343346,test_Loss:22.283496856689453, r2_store:-0.3504788157237124\n",
            "Epoch [5980/10000], train_Loss: 0.00020559348922688514,test_Loss:22.28636360168457, r2_store:-0.35062075525726777\n",
            "Epoch [5981/10000], train_Loss: 0.00020377263717819005,test_Loss:22.286317825317383, r2_store:-0.3505311488494036\n",
            "Epoch [5982/10000], train_Loss: 0.00020278205920476466,test_Loss:22.284679412841797, r2_store:-0.3504411132582632\n",
            "Epoch [5983/10000], train_Loss: 0.0002021166292252019,test_Loss:22.286699295043945, r2_store:-0.3506061425694271\n",
            "Epoch [5984/10000], train_Loss: 0.0002015808568103239,test_Loss:22.28360939025879, r2_store:-0.350334936362489\n",
            "Epoch [5985/10000], train_Loss: 0.0002012118638958782,test_Loss:22.286535263061523, r2_store:-0.3506756739761312\n",
            "Epoch [5986/10000], train_Loss: 0.00020097759261261672,test_Loss:22.28235626220703, r2_store:-0.35028753758109277\n",
            "Epoch [5987/10000], train_Loss: 0.00020040820527356118,test_Loss:22.289260864257812, r2_store:-0.35064979575869426\n",
            "Epoch [5988/10000], train_Loss: 0.00019980568322353065,test_Loss:22.286602020263672, r2_store:-0.3501999219526053\n",
            "Epoch [5989/10000], train_Loss: 0.0001992439792957157,test_Loss:22.291336059570312, r2_store:-0.3506210421010374\n",
            "Epoch [5990/10000], train_Loss: 0.00019843722111545503,test_Loss:22.28574562072754, r2_store:-0.35018162649259166\n",
            "Epoch [5991/10000], train_Loss: 0.0001974502083612606,test_Loss:22.290966033935547, r2_store:-0.3505824986210073\n",
            "Epoch [5992/10000], train_Loss: 0.00019654123752843589,test_Loss:22.286052703857422, r2_store:-0.3501494404473453\n",
            "Epoch [5993/10000], train_Loss: 0.0001955190673470497,test_Loss:22.290874481201172, r2_store:-0.35052608434435917\n",
            "Epoch [5994/10000], train_Loss: 0.00019448336388450116,test_Loss:22.287593841552734, r2_store:-0.3501551641724081\n",
            "Epoch [5995/10000], train_Loss: 0.00019346608314663172,test_Loss:22.292694091796875, r2_store:-0.35050792881817827\n",
            "Epoch [5996/10000], train_Loss: 0.00019262255227658898,test_Loss:22.289615631103516, r2_store:-0.35015847609494766\n",
            "Epoch [5997/10000], train_Loss: 0.00019174008048139513,test_Loss:22.29344940185547, r2_store:-0.35048388100130645\n",
            "Epoch [5998/10000], train_Loss: 0.00019100467034149915,test_Loss:22.2891788482666, r2_store:-0.3500985726683845\n",
            "Epoch [5999/10000], train_Loss: 0.00019053138385061175,test_Loss:22.2940616607666, r2_store:-0.35046170563188084\n",
            "Epoch [6000/10000], train_Loss: 0.00019015934958588332,test_Loss:22.288867950439453, r2_store:-0.35004366618109395\n",
            "Epoch [6001/10000], train_Loss: 0.0001896274770842865,test_Loss:22.29405403137207, r2_store:-0.3504854886579645\n",
            "Epoch [6002/10000], train_Loss: 0.00018935144180431962,test_Loss:22.289304733276367, r2_store:-0.3500047283638297\n",
            "Epoch [6003/10000], train_Loss: 0.00018900424765888602,test_Loss:22.295629501342773, r2_store:-0.35048409963805516\n",
            "Epoch [6004/10000], train_Loss: 0.00018888924387283623,test_Loss:22.289236068725586, r2_store:-0.3498830327179421\n",
            "Epoch [6005/10000], train_Loss: 0.00018915887631010264,test_Loss:22.29670524597168, r2_store:-0.35047999556936626\n",
            "Epoch [6006/10000], train_Loss: 0.00018962877220474184,test_Loss:22.28887176513672, r2_store:-0.3497744486407013\n",
            "Epoch [6007/10000], train_Loss: 0.00019051649724133313,test_Loss:22.298694610595703, r2_store:-0.350559296986503\n",
            "Epoch [6008/10000], train_Loss: 0.00019197426445316523,test_Loss:22.288433074951172, r2_store:-0.34965743645063063\n",
            "Epoch [6009/10000], train_Loss: 0.00019420977332629263,test_Loss:22.299480438232422, r2_store:-0.3506629282937095\n",
            "Epoch [6010/10000], train_Loss: 0.0001974736078409478,test_Loss:22.28563690185547, r2_store:-0.34946391902334506\n",
            "Epoch [6011/10000], train_Loss: 0.00020236133423168212,test_Loss:22.30234718322754, r2_store:-0.3507691341370007\n",
            "Epoch [6012/10000], train_Loss: 0.00020877264614682645,test_Loss:22.284656524658203, r2_store:-0.3492073158877753\n",
            "Epoch [6013/10000], train_Loss: 0.00021747832943219692,test_Loss:22.304954528808594, r2_store:-0.3509769391823203\n",
            "Epoch [6014/10000], train_Loss: 0.00022916945454198867,test_Loss:22.28072166442871, r2_store:-0.34892730240683956\n",
            "Epoch [6015/10000], train_Loss: 0.0002459554234519601,test_Loss:22.30996322631836, r2_store:-0.3512842072470428\n",
            "Epoch [6016/10000], train_Loss: 0.0002697406162042171,test_Loss:22.27825355529785, r2_store:-0.34848679756680023\n",
            "Epoch [6017/10000], train_Loss: 0.0003041406744159758,test_Loss:22.31683349609375, r2_store:-0.3517283497635908\n",
            "Epoch [6018/10000], train_Loss: 0.00035266499617137015,test_Loss:22.26974105834961, r2_store:-0.3479088764718061\n",
            "Epoch [6019/10000], train_Loss: 0.0004214010259602219,test_Loss:22.32452392578125, r2_store:-0.35243762360153963\n",
            "Epoch [6020/10000], train_Loss: 0.0005205207853578031,test_Loss:22.261478424072266, r2_store:-0.3470193877369647\n",
            "Epoch [6021/10000], train_Loss: 0.0006646662950515747,test_Loss:22.337158203125, r2_store:-0.35342810867678853\n",
            "Epoch [6022/10000], train_Loss: 0.0008754816954024136,test_Loss:22.243667602539062, r2_store:-0.34569673311736726\n",
            "Epoch [6023/10000], train_Loss: 0.0011842636158689857,test_Loss:22.355159759521484, r2_store:-0.354934489626227\n",
            "Epoch [6024/10000], train_Loss: 0.0016392471734434366,test_Loss:22.2254695892334, r2_store:-0.3437377239134023\n",
            "Epoch [6025/10000], train_Loss: 0.0023131384514272213,test_Loss:22.38797378540039, r2_store:-0.35727367384359376\n",
            "Epoch [6026/10000], train_Loss: 0.0033135470002889633,test_Loss:22.189212799072266, r2_store:-0.3409625073030982\n",
            "Epoch [6027/10000], train_Loss: 0.004807346500456333,test_Loss:22.433895111083984, r2_store:-0.3609801037977418\n",
            "Epoch [6028/10000], train_Loss: 0.007034345529973507,test_Loss:22.150880813598633, r2_store:-0.3368129307790828\n",
            "Epoch [6029/10000], train_Loss: 0.01040244847536087,test_Loss:22.500301361083984, r2_store:-0.36682112632833697\n",
            "Epoch [6030/10000], train_Loss: 0.015469176694750786,test_Loss:22.058490753173828, r2_store:-0.33103602078872907\n",
            "Epoch [6031/10000], train_Loss: 0.023096106946468353,test_Loss:22.602901458740234, r2_store:-0.3759213644571844\n",
            "Epoch [6032/10000], train_Loss: 0.03386753052473068,test_Loss:21.992183685302734, r2_store:-0.32311997156810457\n",
            "Epoch [6033/10000], train_Loss: 0.049486804753541946,test_Loss:22.74899673461914, r2_store:-0.3886421512111866\n",
            "Epoch [6034/10000], train_Loss: 0.06958331167697906,test_Loss:21.887470245361328, r2_store:-0.3147317842299999\n",
            "Epoch [6035/10000], train_Loss: 0.09479551017284393,test_Loss:22.90436553955078, r2_store:-0.40191512820344566\n",
            "Epoch [6036/10000], train_Loss: 0.11636266857385635,test_Loss:21.857589721679688, r2_store:-0.3096050458447044\n",
            "Epoch [6037/10000], train_Loss: 0.13133499026298523,test_Loss:22.94673728942871, r2_store:-0.40311566370715424\n",
            "Epoch [6038/10000], train_Loss: 0.12146822363138199,test_Loss:21.912181854248047, r2_store:-0.3153785047625475\n",
            "Epoch [6039/10000], train_Loss: 0.09052075445652008,test_Loss:22.651941299438477, r2_store:-0.3796327706806013\n",
            "Epoch [6040/10000], train_Loss: 0.04337746277451515,test_Loss:22.144210815429688, r2_store:-0.33874989005660594\n",
            "Epoch [6041/10000], train_Loss: 0.008384090848267078,test_Loss:22.210010528564453, r2_store:-0.34532934162599127\n",
            "Epoch [6042/10000], train_Loss: 0.001889710663817823,test_Loss:22.533435821533203, r2_store:-0.3692151549885381\n",
            "Epoch [6043/10000], train_Loss: 0.020189082249999046,test_Loss:22.092260360717773, r2_store:-0.3251961831662469\n",
            "Epoch [6044/10000], train_Loss: 0.042742349207401276,test_Loss:22.779293060302734, r2_store:-0.38050128945471706\n",
            "Epoch [6045/10000], train_Loss: 0.04758810997009277,test_Loss:22.154621124267578, r2_store:-0.3280610951923779\n",
            "Epoch [6046/10000], train_Loss: 0.03249993920326233,test_Loss:22.560226440429688, r2_store:-0.3629211801594141\n",
            "Epoch [6047/10000], train_Loss: 0.01027324516326189,test_Loss:22.440990447998047, r2_store:-0.3494159795443048\n",
            "Epoch [6048/10000], train_Loss: 0.0006595743470825255,test_Loss:22.309768676757812, r2_store:-0.3388166876658536\n",
            "Epoch [6049/10000], train_Loss: 0.008197616785764694,test_Loss:22.627262115478516, r2_store:-0.36981751518428574\n",
            "Epoch [6050/10000], train_Loss: 0.020945778116583824,test_Loss:22.18478775024414, r2_store:-0.3310451656975226\n",
            "Epoch [6051/10000], train_Loss: 0.024974027648568153,test_Loss:22.628889083862305, r2_store:-0.3669146445268816\n",
            "Epoch [6052/10000], train_Loss: 0.016123056411743164,test_Loss:22.36159896850586, r2_store:-0.3414184507224012\n",
            "Epoch [6053/10000], train_Loss: 0.004542218521237373,test_Loss:22.40591049194336, r2_store:-0.34777169458445334\n",
            "Epoch [6054/10000], train_Loss: 0.0007720749126747251,test_Loss:22.500572204589844, r2_store:-0.3595680381488471\n",
            "Epoch [6055/10000], train_Loss: 0.006239256821572781,test_Loss:22.225698471069336, r2_store:-0.3356906131313664\n",
            "Epoch [6056/10000], train_Loss: 0.012870773673057556,test_Loss:22.567861557006836, r2_store:-0.36452636184694054\n",
            "Epoch [6057/10000], train_Loss: 0.012994550168514252,test_Loss:22.25481605529785, r2_store:-0.33907034062219066\n",
            "Epoch [6058/10000], train_Loss: 0.006974831223487854,test_Loss:22.398778915405273, r2_store:-0.35291107455581283\n",
            "Epoch [6059/10000], train_Loss: 0.0014088333118706942,test_Loss:22.405128479003906, r2_store:-0.35236655275983164\n",
            "Epoch [6060/10000], train_Loss: 0.0011972698848694563,test_Loss:22.287811279296875, r2_store:-0.34050749588983\n",
            "Epoch [6061/10000], train_Loss: 0.005027798004448414,test_Loss:22.516845703125, r2_store:-0.36065324899324924\n",
            "Epoch [6062/10000], train_Loss: 0.007776777260005474,test_Loss:22.242156982421875, r2_store:-0.339353269993637\n",
            "Epoch [6063/10000], train_Loss: 0.006579585373401642,test_Loss:22.42853546142578, r2_store:-0.35584787258494055\n",
            "Epoch [6064/10000], train_Loss: 0.002920849248766899,test_Loss:22.35720443725586, r2_store:-0.34795063479556876\n",
            "Epoch [6065/10000], train_Loss: 0.0005711867706850171,test_Loss:22.333145141601562, r2_store:-0.34563293609132906\n",
            "Epoch [6066/10000], train_Loss: 0.001248920918442309,test_Loss:22.44199562072754, r2_store:-0.3567119883712715\n",
            "Epoch [6067/10000], train_Loss: 0.0034391842782497406,test_Loss:22.254043579101562, r2_store:-0.3413710295274086\n",
            "Epoch [6068/10000], train_Loss: 0.004534720443189144,test_Loss:22.4365177154541, r2_store:-0.3571166102687613\n",
            "Epoch [6069/10000], train_Loss: 0.0034390888176858425,test_Loss:22.30086898803711, r2_store:-0.34572640886591244\n",
            "Epoch [6070/10000], train_Loss: 0.0014602921437472105,test_Loss:22.336767196655273, r2_store:-0.3505138409089472\n",
            "Epoch [6071/10000], train_Loss: 0.0004082326195202768,test_Loss:22.35727310180664, r2_store:-0.3532654352529576\n",
            "Epoch [6072/10000], train_Loss: 0.000950539018958807,test_Loss:22.26898193359375, r2_store:-0.34474010420023493\n",
            "Epoch [6073/10000], train_Loss: 0.0021252199076116085,test_Loss:22.418123245239258, r2_store:-0.3565020690538623\n",
            "Epoch [6074/10000], train_Loss: 0.0026542055420577526,test_Loss:22.279624938964844, r2_store:-0.34476577404379527\n",
            "Epoch [6075/10000], train_Loss: 0.002061527455225587,test_Loss:22.36935043334961, r2_store:-0.3534674592963596\n",
            "Epoch [6076/10000], train_Loss: 0.0009889344219118357,test_Loss:22.3234920501709, r2_store:-0.34961459438821296\n",
            "Epoch [6077/10000], train_Loss: 0.00036966483457945287,test_Loss:22.3154354095459, r2_store:-0.3483279222677902\n",
            "Epoch [6078/10000], train_Loss: 0.0005751827266067266,test_Loss:22.382394790649414, r2_store:-0.35431982856473243\n",
            "Epoch [6079/10000], train_Loss: 0.0011970176128670573,test_Loss:22.27165985107422, r2_store:-0.3459407951717812\n",
            "Epoch [6080/10000], train_Loss: 0.0015820153057575226,test_Loss:22.37274932861328, r2_store:-0.35491421426541714\n",
            "Epoch [6081/10000], train_Loss: 0.0013967363629490137,test_Loss:22.295793533325195, r2_store:-0.34760552849258985\n",
            "Epoch [6082/10000], train_Loss: 0.0008500302210450172,test_Loss:22.338111877441406, r2_store:-0.35183449904008746\n",
            "Epoch [6083/10000], train_Loss: 0.0004013989237137139,test_Loss:22.31521224975586, r2_store:-0.35146862946967805\n",
            "Epoch [6084/10000], train_Loss: 0.0003486551286187023,test_Loss:22.27817153930664, r2_store:-0.34840885882256933\n",
            "Epoch [6085/10000], train_Loss: 0.0006220533396117389,test_Loss:22.356311798095703, r2_store:-0.3538374442056669\n",
            "Epoch [6086/10000], train_Loss: 0.0009043354657478631,test_Loss:22.2899112701416, r2_store:-0.34711871542342587\n",
            "Epoch [6087/10000], train_Loss: 0.0009656964684836566,test_Loss:22.355710983276367, r2_store:-0.3532514689729407\n",
            "Epoch [6088/10000], train_Loss: 0.0007611258188262582,test_Loss:22.297338485717773, r2_store:-0.348581603806946\n",
            "Epoch [6089/10000], train_Loss: 0.0004803999327123165,test_Loss:22.32973861694336, r2_store:-0.3507691363258745\n",
            "Epoch [6090/10000], train_Loss: 0.00030270800925791264,test_Loss:22.340871810913086, r2_store:-0.35105414963833903\n",
            "Epoch [6091/10000], train_Loss: 0.00032673831447027624,test_Loss:22.304658889770508, r2_store:-0.34851943771803984\n",
            "Epoch [6092/10000], train_Loss: 0.00046771610504947603,test_Loss:22.344257354736328, r2_store:-0.35271539451179756\n",
            "Epoch [6093/10000], train_Loss: 0.0006000819848850369,test_Loss:22.29453468322754, r2_store:-0.3479529776893646\n",
            "Epoch [6094/10000], train_Loss: 0.0006164763472042978,test_Loss:22.352989196777344, r2_store:-0.3524205067865167\n",
            "Epoch [6095/10000], train_Loss: 0.0005196536658331752,test_Loss:22.307458877563477, r2_store:-0.3490175102870494\n",
            "Epoch [6096/10000], train_Loss: 0.000376114621758461,test_Loss:22.321964263916016, r2_store:-0.3508553290197851\n",
            "Epoch [6097/10000], train_Loss: 0.0002828201395459473,test_Loss:22.325756072998047, r2_store:-0.35077927381837526\n",
            "Epoch [6098/10000], train_Loss: 0.00027402304112911224,test_Loss:22.31380271911621, r2_store:-0.3492585124566516\n",
            "Epoch [6099/10000], train_Loss: 0.0003349715261720121,test_Loss:22.34396743774414, r2_store:-0.35195398264285527\n",
            "Epoch [6100/10000], train_Loss: 0.00040109516703523695,test_Loss:22.30093002319336, r2_store:-0.3486716813313928\n",
            "Epoch [6101/10000], train_Loss: 0.00042835570638999343,test_Loss:22.342693328857422, r2_store:-0.35194040251608794\n",
            "Epoch [6102/10000], train_Loss: 0.0003981796617154032,test_Loss:22.319440841674805, r2_store:-0.3490879816426231\n",
            "Epoch [6103/10000], train_Loss: 0.0003379403206054121,test_Loss:22.340391159057617, r2_store:-0.3509431705722592\n",
            "Epoch [6104/10000], train_Loss: 0.0002765841200016439,test_Loss:22.324125289916992, r2_store:-0.3501207699273716\n",
            "Epoch [6105/10000], train_Loss: 0.000249018456088379,test_Loss:22.32312774658203, r2_store:-0.34977040326389575\n",
            "Epoch [6106/10000], train_Loss: 0.00025496489251963794,test_Loss:22.34536361694336, r2_store:-0.3509793278055271\n",
            "Epoch [6107/10000], train_Loss: 0.0002846407296601683,test_Loss:22.31887435913086, r2_store:-0.34907670969751936\n",
            "Epoch [6108/10000], train_Loss: 0.0003089260426349938,test_Loss:22.337425231933594, r2_store:-0.35138456627755743\n",
            "Epoch [6109/10000], train_Loss: 0.00031909113749861717,test_Loss:22.314727783203125, r2_store:-0.34914036296927153\n",
            "Epoch [6110/10000], train_Loss: 0.0003040968149434775,test_Loss:22.34233856201172, r2_store:-0.3510854928239504\n",
            "Epoch [6111/10000], train_Loss: 0.00027817668160423636,test_Loss:22.322813034057617, r2_store:-0.34971536506162404\n",
            "Epoch [6112/10000], train_Loss: 0.0002488447935320437,test_Loss:22.32977294921875, r2_store:-0.3504214785414701\n",
            "Epoch [6113/10000], train_Loss: 0.00023296024301089346,test_Loss:22.335901260375977, r2_store:-0.3503911842681182\n",
            "Epoch [6114/10000], train_Loss: 0.00022993302263785154,test_Loss:22.3328914642334, r2_store:-0.3497528905738456\n",
            "Epoch [6115/10000], train_Loss: 0.00023915960628073663,test_Loss:22.342918395996094, r2_store:-0.3508984185053514\n",
            "Epoch [6116/10000], train_Loss: 0.00024953577667474747,test_Loss:22.323076248168945, r2_store:-0.34952312197992863\n",
            "Epoch [6117/10000], train_Loss: 0.00025669459137134254,test_Loss:22.34343719482422, r2_store:-0.3510845898120456\n",
            "Epoch [6118/10000], train_Loss: 0.0002551485667936504,test_Loss:22.329214096069336, r2_store:-0.3496444019860927\n",
            "Epoch [6119/10000], train_Loss: 0.0002469600294716656,test_Loss:22.342185974121094, r2_store:-0.3508940361937627\n",
            "Epoch [6120/10000], train_Loss: 0.00023406569380313158,test_Loss:22.330472946166992, r2_store:-0.35003500177685476\n",
            "Epoch [6121/10000], train_Loss: 0.0002230285608675331,test_Loss:22.340059280395508, r2_store:-0.3504719397273941\n",
            "Epoch [6122/10000], train_Loss: 0.00021549539815168828,test_Loss:22.342552185058594, r2_store:-0.350441822185235\n",
            "Epoch [6123/10000], train_Loss: 0.00021396760712377727,test_Loss:22.336856842041016, r2_store:-0.35009753017745515\n",
            "Epoch [6124/10000], train_Loss: 0.00021584084606729448,test_Loss:22.343311309814453, r2_store:-0.3507998132931962\n",
            "Epoch [6125/10000], train_Loss: 0.00021974330593366176,test_Loss:22.337038040161133, r2_store:-0.34990937847804227\n",
            "Epoch [6126/10000], train_Loss: 0.0002228247030870989,test_Loss:22.349912643432617, r2_store:-0.35092560645587034\n",
            "Epoch [6127/10000], train_Loss: 0.00022340654686558992,test_Loss:22.33574676513672, r2_store:-0.34990821999407284\n",
            "Epoch [6128/10000], train_Loss: 0.00022111910220701247,test_Loss:22.347103118896484, r2_store:-0.35087431176450323\n",
            "Epoch [6129/10000], train_Loss: 0.00021677033510059118,test_Loss:22.3396053314209, r2_store:-0.3500273364919708\n",
            "Epoch [6130/10000], train_Loss: 0.00021150463726371527,test_Loss:22.347848892211914, r2_store:-0.3506645115540119\n",
            "Epoch [6131/10000], train_Loss: 0.00020635270630009472,test_Loss:22.34125328063965, r2_store:-0.3502564914888284\n",
            "Epoch [6132/10000], train_Loss: 0.00020209865760989487,test_Loss:22.342504501342773, r2_store:-0.3504513272579597\n",
            "Epoch [6133/10000], train_Loss: 0.00019974834867753088,test_Loss:22.345012664794922, r2_store:-0.35049901245467674\n",
            "Epoch [6134/10000], train_Loss: 0.00019889287068508565,test_Loss:22.34438705444336, r2_store:-0.35024355928940554\n",
            "Epoch [6135/10000], train_Loss: 0.00019892517593689263,test_Loss:22.349397659301758, r2_store:-0.35063823301312036\n",
            "Epoch [6136/10000], train_Loss: 0.00019930725102312863,test_Loss:22.343271255493164, r2_store:-0.3501172725464661\n",
            "Epoch [6137/10000], train_Loss: 0.00019969348795711994,test_Loss:22.351945877075195, r2_store:-0.35070426965816326\n",
            "Epoch [6138/10000], train_Loss: 0.00019937034812755883,test_Loss:22.346019744873047, r2_store:-0.3500596671851346\n",
            "Epoch [6139/10000], train_Loss: 0.00019836195860989392,test_Loss:22.35354232788086, r2_store:-0.35064631536941104\n",
            "Epoch [6140/10000], train_Loss: 0.00019667830201797187,test_Loss:22.347959518432617, r2_store:-0.3500669099155147\n",
            "Epoch [6141/10000], train_Loss: 0.00019476341549307108,test_Loss:22.355560302734375, r2_store:-0.3505589126770716\n",
            "Epoch [6142/10000], train_Loss: 0.00019248417811468244,test_Loss:22.35181427001953, r2_store:-0.35015958348572873\n",
            "Epoch [6143/10000], train_Loss: 0.00019024092762265354,test_Loss:22.355443954467773, r2_store:-0.3504732988801551\n",
            "Epoch [6144/10000], train_Loss: 0.00018833290960174054,test_Loss:22.35361099243164, r2_store:-0.3502428644672748\n",
            "Epoch [6145/10000], train_Loss: 0.00018682483641896397,test_Loss:22.35662078857422, r2_store:-0.3503201383353929\n",
            "Epoch [6146/10000], train_Loss: 0.00018548095249570906,test_Loss:22.35755157470703, r2_store:-0.3502644400746413\n",
            "Epoch [6147/10000], train_Loss: 0.00018440537678543478,test_Loss:22.35649871826172, r2_store:-0.35016800046572905\n",
            "Epoch [6148/10000], train_Loss: 0.00018359199748374522,test_Loss:22.357994079589844, r2_store:-0.35029375825810183\n",
            "Epoch [6149/10000], train_Loss: 0.000183008101885207,test_Loss:22.35643196105957, r2_store:-0.3500669620046013\n",
            "Epoch [6150/10000], train_Loss: 0.000182355273864232,test_Loss:22.3608455657959, r2_store:-0.35033582501214977\n",
            "Epoch [6151/10000], train_Loss: 0.00018199006444774568,test_Loss:22.357465744018555, r2_store:-0.3499929562751223\n",
            "Epoch [6152/10000], train_Loss: 0.00018164807988796383,test_Loss:22.36227798461914, r2_store:-0.3503625941492361\n",
            "Epoch [6153/10000], train_Loss: 0.00018115906277671456,test_Loss:22.358654022216797, r2_store:-0.34992509407931793\n",
            "Epoch [6154/10000], train_Loss: 0.00018059686408378184,test_Loss:22.36512565612793, r2_store:-0.35032105570749184\n",
            "Epoch [6155/10000], train_Loss: 0.00017996117821894586,test_Loss:22.36020851135254, r2_store:-0.3498433591847512\n",
            "Epoch [6156/10000], train_Loss: 0.00017919095989782363,test_Loss:22.365779876708984, r2_store:-0.350278812937572\n",
            "Epoch [6157/10000], train_Loss: 0.000178333226358518,test_Loss:22.361608505249023, r2_store:-0.34981921757955314\n",
            "Epoch [6158/10000], train_Loss: 0.00017757136083673686,test_Loss:22.366138458251953, r2_store:-0.35027537911267137\n",
            "Epoch [6159/10000], train_Loss: 0.00017668025975581259,test_Loss:22.359878540039062, r2_store:-0.3498315279868409\n",
            "Epoch [6160/10000], train_Loss: 0.00017598623526282609,test_Loss:22.364803314208984, r2_store:-0.35030473589288436\n",
            "Epoch [6161/10000], train_Loss: 0.00017533711798023432,test_Loss:22.3601131439209, r2_store:-0.3498159950638653\n",
            "Epoch [6162/10000], train_Loss: 0.00017476909852121025,test_Loss:22.36672592163086, r2_store:-0.3502801148709289\n",
            "Epoch [6163/10000], train_Loss: 0.00017427110287826508,test_Loss:22.361587524414062, r2_store:-0.3497264574046208\n",
            "Epoch [6164/10000], train_Loss: 0.00017376133473590016,test_Loss:22.368568420410156, r2_store:-0.35023423657310193\n",
            "Epoch [6165/10000], train_Loss: 0.00017335484153591096,test_Loss:22.362428665161133, r2_store:-0.34965259679674454\n",
            "Epoch [6166/10000], train_Loss: 0.00017286707588937134,test_Loss:22.368968963623047, r2_store:-0.35022404345387437\n",
            "Epoch [6167/10000], train_Loss: 0.0001725056063150987,test_Loss:22.36237907409668, r2_store:-0.3496145781326092\n",
            "Epoch [6168/10000], train_Loss: 0.0001725085749058053,test_Loss:22.37145233154297, r2_store:-0.3502547422489173\n",
            "Epoch [6169/10000], train_Loss: 0.00017235506675206125,test_Loss:22.364429473876953, r2_store:-0.34959891931336506\n",
            "Epoch [6170/10000], train_Loss: 0.0001722066372167319,test_Loss:22.37228775024414, r2_store:-0.35032880000073874\n",
            "Epoch [6171/10000], train_Loss: 0.00017236327403225005,test_Loss:22.36322593688965, r2_store:-0.3495634699195118\n",
            "Epoch [6172/10000], train_Loss: 0.0001730874937493354,test_Loss:22.37302589416504, r2_store:-0.3503691618406142\n",
            "Epoch [6173/10000], train_Loss: 0.00017411858425475657,test_Loss:22.362598419189453, r2_store:-0.34942858140211963\n",
            "Epoch [6174/10000], train_Loss: 0.00017544403090141714,test_Loss:22.374225616455078, r2_store:-0.3503886357313122\n",
            "Epoch [6175/10000], train_Loss: 0.00017724145436659455,test_Loss:22.362071990966797, r2_store:-0.349272930976813\n",
            "Epoch [6176/10000], train_Loss: 0.0001801137550501153,test_Loss:22.376684188842773, r2_store:-0.35048371144848334\n",
            "Epoch [6177/10000], train_Loss: 0.0001844460202846676,test_Loss:22.36126708984375, r2_store:-0.34909843324680834\n",
            "Epoch [6178/10000], train_Loss: 0.00019087790860794485,test_Loss:22.3803653717041, r2_store:-0.3506721129738457\n",
            "Epoch [6179/10000], train_Loss: 0.0001998391526285559,test_Loss:22.35952377319336, r2_store:-0.3488499769465765\n",
            "Epoch [6180/10000], train_Loss: 0.0002123434387613088,test_Loss:22.38389015197754, r2_store:-0.35093623338675095\n",
            "Epoch [6181/10000], train_Loss: 0.00023127355962060392,test_Loss:22.355443954467773, r2_store:-0.3484642337019197\n",
            "Epoch [6182/10000], train_Loss: 0.0002571428776718676,test_Loss:22.38878059387207, r2_store:-0.35131440417495785\n",
            "Epoch [6183/10000], train_Loss: 0.000294730591122061,test_Loss:22.34889030456543, r2_store:-0.34790812126433335\n",
            "Epoch [6184/10000], train_Loss: 0.0003473688557278365,test_Loss:22.39607810974121, r2_store:-0.35186396406416476\n",
            "Epoch [6185/10000], train_Loss: 0.0004220237024128437,test_Loss:22.3408145904541, r2_store:-0.34715919832871345\n",
            "Epoch [6186/10000], train_Loss: 0.0005275497678667307,test_Loss:22.408159255981445, r2_store:-0.35274203336152854\n",
            "Epoch [6187/10000], train_Loss: 0.0006828730693086982,test_Loss:22.33108139038086, r2_store:-0.34607770950462124\n",
            "Epoch [6188/10000], train_Loss: 0.0009094517445191741,test_Loss:22.424957275390625, r2_store:-0.35406882010226015\n",
            "Epoch [6189/10000], train_Loss: 0.0012449317146092653,test_Loss:22.310649871826172, r2_store:-0.34444724100503077\n",
            "Epoch [6190/10000], train_Loss: 0.0017424514517188072,test_Loss:22.448612213134766, r2_store:-0.3560888960810824\n",
            "Epoch [6191/10000], train_Loss: 0.0024854247458279133,test_Loss:22.28426170349121, r2_store:-0.3420112810748426\n",
            "Epoch [6192/10000], train_Loss: 0.003601031843572855,test_Loss:22.48454475402832, r2_store:-0.359350217274943\n",
            "Epoch [6193/10000], train_Loss: 0.005303878337144852,test_Loss:22.22955322265625, r2_store:-0.33847865783490416\n",
            "Epoch [6194/10000], train_Loss: 0.00787422340363264,test_Loss:22.540380477905273, r2_store:-0.36444977397447764\n",
            "Epoch [6195/10000], train_Loss: 0.011682329699397087,test_Loss:22.180770874023438, r2_store:-0.33314025416825666\n",
            "Epoch [6196/10000], train_Loss: 0.01747383549809456,test_Loss:22.633399963378906, r2_store:-0.3721687045855988\n",
            "Epoch [6197/10000], train_Loss: 0.025960152968764305,test_Loss:22.075773239135742, r2_store:-0.32602325535712207\n",
            "Epoch [6198/10000], train_Loss: 0.03848040848970413,test_Loss:22.766845703125, r2_store:-0.38341307027892824\n",
            "Epoch [6199/10000], train_Loss: 0.054413266479969025,test_Loss:22.02334213256836, r2_store:-0.31739860591951286\n",
            "Epoch [6200/10000], train_Loss: 0.0760270208120346,test_Loss:22.922998428344727, r2_store:-0.39652991794171344\n",
            "Epoch [6201/10000], train_Loss: 0.09845093637704849,test_Loss:21.92600440979004, r2_store:-0.3109832755795763\n",
            "Epoch [6202/10000], train_Loss: 0.1200876384973526,test_Loss:23.017742156982422, r2_store:-0.40380710846789314\n",
            "Epoch [6203/10000], train_Loss: 0.12429604679346085,test_Loss:21.94588851928711, r2_store:-0.31274804113326815\n",
            "Epoch [6204/10000], train_Loss: 0.11001388728618622,test_Loss:22.803470611572266, r2_store:-0.38906384626218893\n",
            "Epoch [6205/10000], train_Loss: 0.07010633498430252,test_Loss:22.11759376525879, r2_store:-0.33048712890345433\n",
            "Epoch [6206/10000], train_Loss: 0.027135303243994713,test_Loss:22.416337966918945, r2_store:-0.3558671795416457\n",
            "Epoch [6207/10000], train_Loss: 0.0022924127988517284,test_Loss:22.492891311645508, r2_store:-0.360856708878843\n",
            "Epoch [6208/10000], train_Loss: 0.006630646530538797,test_Loss:22.171737670898438, r2_store:-0.3297618218117577\n",
            "Epoch [6209/10000], train_Loss: 0.028824811801314354,test_Loss:22.824560165405273, r2_store:-0.3799273157427445\n",
            "Epoch [6210/10000], train_Loss: 0.04606308415532112,test_Loss:22.23158073425293, r2_store:-0.3242367383849072\n",
            "Epoch [6211/10000], train_Loss: 0.044430844485759735,test_Loss:22.79400062561035, r2_store:-0.3701601987215526\n",
            "Epoch [6212/10000], train_Loss: 0.02448098547756672,test_Loss:22.411209106445312, r2_store:-0.34013605238673605\n",
            "Epoch [6213/10000], train_Loss: 0.0052358307875692844,test_Loss:22.454553604125977, r2_store:-0.34517774468923124\n",
            "Epoch [6214/10000], train_Loss: 0.0014029385056346655,test_Loss:22.68060302734375, r2_store:-0.3632794998083346\n",
            "Epoch [6215/10000], train_Loss: 0.01199538353830576,test_Loss:22.303829193115234, r2_store:-0.33072228490853384\n",
            "Epoch [6216/10000], train_Loss: 0.02324218675494194,test_Loss:22.751432418823242, r2_store:-0.3698810550948135\n",
            "Epoch [6217/10000], train_Loss: 0.022865530103445053,test_Loss:22.34925651550293, r2_store:-0.3357120978311243\n",
            "Epoch [6218/10000], train_Loss: 0.012485687620937824,test_Loss:22.560636520385742, r2_store:-0.35489881133372014\n",
            "Epoch [6219/10000], train_Loss: 0.0024104751646518707,test_Loss:22.53809928894043, r2_store:-0.35323901559347437\n",
            "Epoch [6220/10000], train_Loss: 0.0014824951067566872,test_Loss:22.357378005981445, r2_store:-0.3385036663235548\n",
            "Epoch [6221/10000], train_Loss: 0.007990432903170586,test_Loss:22.646028518676758, r2_store:-0.364833085483675\n",
            "Epoch [6222/10000], train_Loss: 0.013292623683810234,test_Loss:22.303024291992188, r2_store:-0.33627618233489964\n",
            "Epoch [6223/10000], train_Loss: 0.011770963668823242,test_Loss:22.57571029663086, r2_store:-0.3588160685062658\n",
            "Epoch [6224/10000], train_Loss: 0.005420250818133354,test_Loss:22.440366744995117, r2_store:-0.3470642786616942\n",
            "Epoch [6225/10000], train_Loss: 0.0008587888441979885,test_Loss:22.416011810302734, r2_store:-0.3452455035834421\n",
            "Epoch [6226/10000], train_Loss: 0.0016389176016673446,test_Loss:22.5744686126709, r2_store:-0.35926525284259214\n",
            "Epoch [6227/10000], train_Loss: 0.005482400301843882,test_Loss:22.337703704833984, r2_store:-0.3392652290797882\n",
            "Epoch [6228/10000], train_Loss: 0.00767448078840971,test_Loss:22.577320098876953, r2_store:-0.36007761685870876\n",
            "Epoch [6229/10000], train_Loss: 0.005967295728623867,test_Loss:22.38235092163086, r2_store:-0.3443440348784439\n",
            "Epoch [6230/10000], train_Loss: 0.002439141273498535,test_Loss:22.46128273010254, r2_store:-0.35068397803664486\n",
            "Epoch [6231/10000], train_Loss: 0.0004585430142469704,test_Loss:22.511432647705078, r2_store:-0.35369841148549575\n",
            "Epoch [6232/10000], train_Loss: 0.0013405203353613615,test_Loss:22.38309669494629, r2_store:-0.34246631938121874\n",
            "Epoch [6233/10000], train_Loss: 0.0034681367687880993,test_Loss:22.547536849975586, r2_store:-0.3580071900212032\n",
            "Epoch [6234/10000], train_Loss: 0.004375723656266928,test_Loss:22.35038185119629, r2_store:-0.3427280960402952\n",
            "Epoch [6235/10000], train_Loss: 0.003315332578495145,test_Loss:22.473957061767578, r2_store:-0.3539967892311484\n",
            "Epoch [6236/10000], train_Loss: 0.0014144936576485634,test_Loss:22.418975830078125, r2_store:-0.34923240453505855\n",
            "Epoch [6237/10000], train_Loss: 0.0003850351495202631,test_Loss:22.388944625854492, r2_store:-0.34704110021999357\n",
            "Epoch [6238/10000], train_Loss: 0.000826922885607928,test_Loss:22.481416702270508, r2_store:-0.355272325059794\n",
            "Epoch [6239/10000], train_Loss: 0.001949479803442955,test_Loss:22.353391647338867, r2_store:-0.3439771790639079\n",
            "Epoch [6240/10000], train_Loss: 0.0025215973146259785,test_Loss:22.49302101135254, r2_store:-0.3555171414224221\n",
            "Epoch [6241/10000], train_Loss: 0.0020439783111214638,test_Loss:22.388397216796875, r2_store:-0.3465251511676508\n",
            "Epoch [6242/10000], train_Loss: 0.0010406303917989135,test_Loss:22.43608856201172, r2_store:-0.35103289393622283\n",
            "Epoch [6243/10000], train_Loss: 0.0003708260483108461,test_Loss:22.443016052246094, r2_store:-0.35167501923408406\n",
            "Epoch [6244/10000], train_Loss: 0.0004477103357203305,test_Loss:22.390092849731445, r2_store:-0.34676945572394735\n",
            "Epoch [6245/10000], train_Loss: 0.0010010212427005172,test_Loss:22.481563568115234, r2_store:-0.35480084577156124\n",
            "Epoch [6246/10000], train_Loss: 0.0014326799428090453,test_Loss:22.36808204650879, r2_store:-0.34619600481074153\n",
            "Epoch [6247/10000], train_Loss: 0.0013712585205212235,test_Loss:22.449403762817383, r2_store:-0.35386565869236497\n",
            "Epoch [6248/10000], train_Loss: 0.000906977045815438,test_Loss:22.39209747314453, r2_store:-0.349022826150986\n",
            "Epoch [6249/10000], train_Loss: 0.0004393972922116518,test_Loss:22.406509399414062, r2_store:-0.3504431713898519\n",
            "Epoch [6250/10000], train_Loss: 0.00028638471849262714,test_Loss:22.427196502685547, r2_store:-0.3523692162894747\n",
            "Epoch [6251/10000], train_Loss: 0.00046634124009869993,test_Loss:22.37801742553711, r2_store:-0.3475616687205454\n",
            "Epoch [6252/10000], train_Loss: 0.000752987980376929,test_Loss:22.46052360534668, r2_store:-0.3535243172743576\n",
            "Epoch [6253/10000], train_Loss: 0.0008879750967025757,test_Loss:22.396142959594727, r2_store:-0.3471226932991607\n",
            "Epoch [6254/10000], train_Loss: 0.0007801701431162655,test_Loss:22.45431137084961, r2_store:-0.3521200142257719\n",
            "Epoch [6255/10000], train_Loss: 0.0005253122071735561,test_Loss:22.416133880615234, r2_store:-0.34901872946450063\n",
            "Epoch [6256/10000], train_Loss: 0.000313495344016701,test_Loss:22.425748825073242, r2_store:-0.34973949843834307\n",
            "Epoch [6257/10000], train_Loss: 0.0002621158491820097,test_Loss:22.447853088378906, r2_store:-0.35144223765305993\n",
            "Epoch [6258/10000], train_Loss: 0.00035778069286607206,test_Loss:22.40854835510254, r2_store:-0.348188018897857\n",
            "Epoch [6259/10000], train_Loss: 0.00049120734911412,test_Loss:22.455108642578125, r2_store:-0.3526263087557413\n",
            "Epoch [6260/10000], train_Loss: 0.0005557709373533726,test_Loss:22.404464721679688, r2_store:-0.34824178727505295\n",
            "Epoch [6261/10000], train_Loss: 0.0005081024137325585,test_Loss:22.449373245239258, r2_store:-0.3519496359102132\n",
            "Epoch [6262/10000], train_Loss: 0.0003903907199855894,test_Loss:22.418338775634766, r2_store:-0.3494502769467933\n",
            "Epoch [6263/10000], train_Loss: 0.0002803268434945494,test_Loss:22.425334930419922, r2_store:-0.35018857268134096\n",
            "Epoch [6264/10000], train_Loss: 0.00023770410916768014,test_Loss:22.43419647216797, r2_store:-0.3508184671549004\n",
            "Epoch [6265/10000], train_Loss: 0.0002675530849955976,test_Loss:22.41384506225586, r2_store:-0.3487064752183089\n",
            "Epoch [6266/10000], train_Loss: 0.0003300083917565644,test_Loss:22.44956398010254, r2_store:-0.35156020751574113\n",
            "Epoch [6267/10000], train_Loss: 0.0003758086822926998,test_Loss:22.41265296936035, r2_store:-0.3483875624479935\n",
            "Epoch [6268/10000], train_Loss: 0.0003744063142221421,test_Loss:22.447467803955078, r2_store:-0.3513592154402332\n",
            "Epoch [6269/10000], train_Loss: 0.00033297803020104766,test_Loss:22.42218017578125, r2_store:-0.34908559262743544\n",
            "Epoch [6270/10000], train_Loss: 0.00027548466459847987,test_Loss:22.437389373779297, r2_store:-0.35049813077709735\n",
            "Epoch [6271/10000], train_Loss: 0.00023231349769048393,test_Loss:22.430110931396484, r2_store:-0.350166328771649\n",
            "Epoch [6272/10000], train_Loss: 0.0002195782435592264,test_Loss:22.423328399658203, r2_store:-0.3495376232322005\n",
            "Epoch [6273/10000], train_Loss: 0.00023447822604794055,test_Loss:22.442808151245117, r2_store:-0.3509849931094131\n",
            "Epoch [6274/10000], train_Loss: 0.000260330067249015,test_Loss:22.418529510498047, r2_store:-0.3490885163348023\n",
            "Epoch [6275/10000], train_Loss: 0.0002783841628115624,test_Loss:22.442890167236328, r2_store:-0.35126856285846686\n",
            "Epoch [6276/10000], train_Loss: 0.000278591614915058,test_Loss:22.421812057495117, r2_store:-0.3492666698502651\n",
            "Epoch [6277/10000], train_Loss: 0.00026108039310202,test_Loss:22.44381332397461, r2_store:-0.3509070726281789\n",
            "Epoch [6278/10000], train_Loss: 0.00023584607697557658,test_Loss:22.430004119873047, r2_store:-0.3498310808636236\n",
            "Epoch [6279/10000], train_Loss: 0.00021423182624857873,test_Loss:22.43450355529785, r2_store:-0.3502384703824317\n",
            "Epoch [6280/10000], train_Loss: 0.0002042997657554224,test_Loss:22.440454483032227, r2_store:-0.35039183392951445\n",
            "Epoch [6281/10000], train_Loss: 0.00020612827211152762,test_Loss:22.4309024810791, r2_store:-0.34964623688879515\n",
            "Epoch [6282/10000], train_Loss: 0.0002145573089364916,test_Loss:22.44315528869629, r2_store:-0.3507979941250725\n",
            "Epoch [6283/10000], train_Loss: 0.00022332968364935368,test_Loss:22.428882598876953, r2_store:-0.34946737200177735\n",
            "Epoch [6284/10000], train_Loss: 0.0002278443134855479,test_Loss:22.44637680053711, r2_store:-0.3509537421253097\n",
            "Epoch [6285/10000], train_Loss: 0.00022610451560467482,test_Loss:22.42950439453125, r2_store:-0.3496402683939701\n",
            "Epoch [6286/10000], train_Loss: 0.00021811462647747248,test_Loss:22.44574737548828, r2_store:-0.35075240640401173\n",
            "Epoch [6287/10000], train_Loss: 0.0002072302595479414,test_Loss:22.43784523010254, r2_store:-0.3499642423243441\n",
            "Epoch [6288/10000], train_Loss: 0.00019756541587412357,test_Loss:22.44144058227539, r2_store:-0.3503632944956898\n",
            "Epoch [6289/10000], train_Loss: 0.00019183047697879374,test_Loss:22.441864013671875, r2_store:-0.3503480942256596\n",
            "Epoch [6290/10000], train_Loss: 0.00019039925246033818,test_Loss:22.440631866455078, r2_store:-0.35002211879961287\n",
            "Epoch [6291/10000], train_Loss: 0.0001926571858348325,test_Loss:22.447160720825195, r2_store:-0.35063900130884695\n",
            "Epoch [6292/10000], train_Loss: 0.00019607091962825507,test_Loss:22.437288284301758, r2_store:-0.3497956370597415\n",
            "Epoch [6293/10000], train_Loss: 0.00019890035036951303,test_Loss:22.451637268066406, r2_store:-0.3507015437852212\n",
            "Epoch [6294/10000], train_Loss: 0.00019918307953048497,test_Loss:22.44251823425293, r2_store:-0.34971486209489355\n",
            "Epoch [6295/10000], train_Loss: 0.0001973464386537671,test_Loss:22.45169448852539, r2_store:-0.35057731429541983\n",
            "Epoch [6296/10000], train_Loss: 0.0001936032494995743,test_Loss:22.441585540771484, r2_store:-0.34980865997161703\n",
            "Epoch [6297/10000], train_Loss: 0.00018925270705949515,test_Loss:22.4505558013916, r2_store:-0.35037939693498954\n",
            "Epoch [6298/10000], train_Loss: 0.00018482416635379195,test_Loss:22.447614669799805, r2_store:-0.34998488588885346\n",
            "Epoch [6299/10000], train_Loss: 0.0001814835995901376,test_Loss:22.449113845825195, r2_store:-0.3501692556817959\n",
            "Epoch [6300/10000], train_Loss: 0.0001794055278878659,test_Loss:22.449100494384766, r2_store:-0.3501590746851204\n",
            "Epoch [6301/10000], train_Loss: 0.00017838514759205282,test_Loss:22.449649810791016, r2_store:-0.35000496184751784\n",
            "Epoch [6302/10000], train_Loss: 0.00017811922589316964,test_Loss:22.45322036743164, r2_store:-0.35027304657154845\n",
            "Epoch [6303/10000], train_Loss: 0.00017805307288654149,test_Loss:22.44870376586914, r2_store:-0.34986244640195907\n",
            "Epoch [6304/10000], train_Loss: 0.0001782260078471154,test_Loss:22.455577850341797, r2_store:-0.35030971579162107\n",
            "Epoch [6305/10000], train_Loss: 0.00017815093451645225,test_Loss:22.451271057128906, r2_store:-0.3497849796293244\n",
            "Epoch [6306/10000], train_Loss: 0.000177697220351547,test_Loss:22.456607818603516, r2_store:-0.3503212409929892\n",
            "Epoch [6307/10000], train_Loss: 0.00017697244766168296,test_Loss:22.44968032836914, r2_store:-0.34977681224620283\n",
            "Epoch [6308/10000], train_Loss: 0.00017595160170458257,test_Loss:22.45768165588379, r2_store:-0.35027687593763224\n",
            "Epoch [6309/10000], train_Loss: 0.00017444048717152327,test_Loss:22.453542709350586, r2_store:-0.3497962042845306\n",
            "Epoch [6310/10000], train_Loss: 0.00017286791990045458,test_Loss:22.458139419555664, r2_store:-0.35018096644576446\n",
            "Epoch [6311/10000], train_Loss: 0.000171261141076684,test_Loss:22.454814910888672, r2_store:-0.34982611726330926\n",
            "Epoch [6312/10000], train_Loss: 0.00016978755593299866,test_Loss:22.459238052368164, r2_store:-0.3500883538878721\n",
            "Epoch [6313/10000], train_Loss: 0.00016854211571626365,test_Loss:22.457571029663086, r2_store:-0.34984136303862434\n",
            "Epoch [6314/10000], train_Loss: 0.00016739004058763385,test_Loss:22.460018157958984, r2_store:-0.3499899031288385\n",
            "Epoch [6315/10000], train_Loss: 0.00016622584371361881,test_Loss:22.459592819213867, r2_store:-0.34984915021257845\n",
            "Epoch [6316/10000], train_Loss: 0.00016533710004296154,test_Loss:22.462093353271484, r2_store:-0.34990954895900894\n",
            "Epoch [6317/10000], train_Loss: 0.00016436479927506298,test_Loss:22.462696075439453, r2_store:-0.3498789927400947\n",
            "Epoch [6318/10000], train_Loss: 0.0001635719381738454,test_Loss:22.462343215942383, r2_store:-0.34987601679817715\n",
            "Epoch [6319/10000], train_Loss: 0.00016285679885186255,test_Loss:22.462688446044922, r2_store:-0.3499205011502373\n",
            "Epoch [6320/10000], train_Loss: 0.00016225388390012085,test_Loss:22.462377548217773, r2_store:-0.3498240704057707\n",
            "Epoch [6321/10000], train_Loss: 0.0001615361834410578,test_Loss:22.464595794677734, r2_store:-0.3499146341548349\n",
            "Epoch [6322/10000], train_Loss: 0.0001608893071534112,test_Loss:22.463281631469727, r2_store:-0.34977658672938805\n",
            "Epoch [6323/10000], train_Loss: 0.00016024727665353566,test_Loss:22.464740753173828, r2_store:-0.34991902148519904\n",
            "Epoch [6324/10000], train_Loss: 0.0001597273221705109,test_Loss:22.46376609802246, r2_store:-0.3497016166113094\n",
            "Epoch [6325/10000], train_Loss: 0.00015931886446196586,test_Loss:22.46817398071289, r2_store:-0.3499011293323393\n",
            "Epoch [6326/10000], train_Loss: 0.00015890496433712542,test_Loss:22.465476989746094, r2_store:-0.34959918946095025\n",
            "Epoch [6327/10000], train_Loss: 0.00015858685947023332,test_Loss:22.468000411987305, r2_store:-0.3499133237277967\n",
            "Epoch [6328/10000], train_Loss: 0.0001583493867656216,test_Loss:22.463546752929688, r2_store:-0.3495208147559956\n",
            "Epoch [6329/10000], train_Loss: 0.000158346927491948,test_Loss:22.46955108642578, r2_store:-0.349906512464202\n",
            "Epoch [6330/10000], train_Loss: 0.00015830530901439488,test_Loss:22.465055465698242, r2_store:-0.3493967382165011\n",
            "Epoch [6331/10000], train_Loss: 0.00015836676175240427,test_Loss:22.471229553222656, r2_store:-0.34989347122189685\n",
            "Epoch [6332/10000], train_Loss: 0.00015854620141908526,test_Loss:22.465425491333008, r2_store:-0.3492922450957294\n",
            "Epoch [6333/10000], train_Loss: 0.00015887338668107986,test_Loss:22.474349975585938, r2_store:-0.3499157961714854\n",
            "Epoch [6334/10000], train_Loss: 0.00015958202129695565,test_Loss:22.466243743896484, r2_store:-0.34920071666445973\n",
            "Epoch [6335/10000], train_Loss: 0.00016032267012633383,test_Loss:22.4738826751709, r2_store:-0.34999596477797756\n",
            "Epoch [6336/10000], train_Loss: 0.00016166562272701412,test_Loss:22.462865829467773, r2_store:-0.3491096242619376\n",
            "Epoch [6337/10000], train_Loss: 0.00016357601271010935,test_Loss:22.4755802154541, r2_store:-0.35007150433426437\n",
            "Epoch [6338/10000], train_Loss: 0.0001659486733842641,test_Loss:22.464588165283203, r2_store:-0.34893986926077125\n",
            "Epoch [6339/10000], train_Loss: 0.00016914053412619978,test_Loss:22.479808807373047, r2_store:-0.35014213504994474\n",
            "Epoch [6340/10000], train_Loss: 0.00017358666809741408,test_Loss:22.464534759521484, r2_store:-0.3487415352820282\n",
            "Epoch [6341/10000], train_Loss: 0.0001800063473638147,test_Loss:22.483789443969727, r2_store:-0.3503173068778651\n",
            "Epoch [6342/10000], train_Loss: 0.00018897377594839782,test_Loss:22.463130950927734, r2_store:-0.34850586631135805\n",
            "Epoch [6343/10000], train_Loss: 0.00020116326049901545,test_Loss:22.48685073852539, r2_store:-0.3505796366588436\n",
            "Epoch [6344/10000], train_Loss: 0.00021847881725989282,test_Loss:22.458133697509766, r2_store:-0.348163277322626\n",
            "Epoch [6345/10000], train_Loss: 0.00024225008382927626,test_Loss:22.490156173706055, r2_store:-0.35094111675992434\n",
            "Epoch [6346/10000], train_Loss: 0.0002764363307505846,test_Loss:22.451934814453125, r2_store:-0.3476535911304175\n",
            "Epoch [6347/10000], train_Loss: 0.00032347944215871394,test_Loss:22.496862411499023, r2_store:-0.3514573957487428\n",
            "Epoch [6348/10000], train_Loss: 0.0003916786517947912,test_Loss:22.444072723388672, r2_store:-0.34695250751793427\n",
            "Epoch [6349/10000], train_Loss: 0.0004867085663136095,test_Loss:22.507408142089844, r2_store:-0.35226841001313636\n",
            "Epoch [6350/10000], train_Loss: 0.0006224674871191382,test_Loss:22.434188842773438, r2_store:-0.34598362516794245\n",
            "Epoch [6351/10000], train_Loss: 0.0008161747828125954,test_Loss:22.523035049438477, r2_store:-0.3534671595171446\n",
            "Epoch [6352/10000], train_Loss: 0.001099546323530376,test_Loss:22.418170928955078, r2_store:-0.3445283058815014\n",
            "Epoch [6353/10000], train_Loss: 0.0015122370095923543,test_Loss:22.543397903442383, r2_store:-0.355280045449881\n",
            "Epoch [6354/10000], train_Loss: 0.002131939632818103,test_Loss:22.39021873474121, r2_store:-0.34235422314616537\n",
            "Epoch [6355/10000], train_Loss: 0.0030450201593339443,test_Loss:22.572175979614258, r2_store:-0.3580325819523962\n",
            "Epoch [6356/10000], train_Loss: 0.004379098303616047,test_Loss:22.343952178955078, r2_store:-0.33927693082172317\n",
            "Epoch [6357/10000], train_Loss: 0.006342859007418156,test_Loss:22.616172790527344, r2_store:-0.3622183068842457\n",
            "Epoch [6358/10000], train_Loss: 0.009114129468798637,test_Loss:22.30011749267578, r2_store:-0.3348769037485464\n",
            "Epoch [6359/10000], train_Loss: 0.013266652822494507,test_Loss:22.688745498657227, r2_store:-0.36834139615075\n",
            "Epoch [6360/10000], train_Loss: 0.019122013822197914,test_Loss:22.216320037841797, r2_store:-0.3288564878322928\n",
            "Epoch [6361/10000], train_Loss: 0.027683114632964134,test_Loss:22.786949157714844, r2_store:-0.37699868152242666\n",
            "Epoch [6362/10000], train_Loss: 0.03872194141149521,test_Loss:22.151643753051758, r2_store:-0.3217157727321869\n",
            "Epoch [6363/10000], train_Loss: 0.05378621816635132,test_Loss:22.924671173095703, r2_store:-0.3881681147210374\n",
            "Epoch [6364/10000], train_Loss: 0.07064628601074219,test_Loss:22.053279876708984, r2_store:-0.31538315221669566\n",
            "Epoch [6365/10000], train_Loss: 0.08933217823505402,test_Loss:22.997472763061523, r2_store:-0.39668183028804727\n",
            "Epoch [6366/10000], train_Loss: 0.0994727686047554,test_Loss:22.056438446044922, r2_store:-0.3135739907497743\n",
            "Epoch [6367/10000], train_Loss: 0.10003358125686646,test_Loss:22.95387840270996, r2_store:-0.39107448559848645\n",
            "Epoch [6368/10000], train_Loss: 0.08086760342121124,test_Loss:22.13510513305664, r2_store:-0.3225799959379949\n",
            "Epoch [6369/10000], train_Loss: 0.050825200974941254,test_Loss:22.682188034057617, r2_store:-0.3678828957641709\n",
            "Epoch [6370/10000], train_Loss: 0.01913309469819069,test_Loss:22.436992645263672, r2_store:-0.34390157833628177\n",
            "Epoch [6371/10000], train_Loss: 0.0018210185226053,test_Loss:22.4283504486084, r2_store:-0.3410807086362868\n",
            "Epoch [6372/10000], train_Loss: 0.003826302010565996,test_Loss:22.751190185546875, r2_store:-0.3668930797222407\n",
            "Epoch [6373/10000], train_Loss: 0.018511250615119934,test_Loss:22.322635650634766, r2_store:-0.3267294768313236\n",
            "Epoch [6374/10000], train_Loss: 0.032889120280742645,test_Loss:22.924482345581055, r2_store:-0.374422055961372\n",
            "Epoch [6375/10000], train_Loss: 0.035427480936050415,test_Loss:22.39282989501953, r2_store:-0.3286372135729936\n",
            "Epoch [6376/10000], train_Loss: 0.025781292468309402,test_Loss:22.775760650634766, r2_store:-0.3614102937132275\n",
            "Epoch [6377/10000], train_Loss: 0.010595817118883133,test_Loss:22.557437896728516, r2_store:-0.3445891724818717\n",
            "Epoch [6378/10000], train_Loss: 0.0012069357326254249,test_Loss:22.516197204589844, r2_store:-0.3428170499686787\n",
            "Epoch [6379/10000], train_Loss: 0.002492826897650957,test_Loss:22.73249626159668, r2_store:-0.3624712850580356\n",
            "Epoch [6380/10000], train_Loss: 0.010470816865563393,test_Loss:22.380939483642578, r2_store:-0.33347261577131015\n",
            "Epoch [6381/10000], train_Loss: 0.016830291599035263,test_Loss:22.759172439575195, r2_store:-0.3662399233224807\n",
            "Epoch [6382/10000], train_Loss: 0.015850242227315903,test_Loss:22.434518814086914, r2_store:-0.33750140306587184\n",
            "Epoch [6383/10000], train_Loss: 0.009116090834140778,test_Loss:22.630756378173828, r2_store:-0.3547330001096134\n",
            "Epoch [6384/10000], train_Loss: 0.0023379973135888577,test_Loss:22.55968475341797, r2_store:-0.35045765083971214\n",
            "Epoch [6385/10000], train_Loss: 0.000584190827794373,test_Loss:22.452274322509766, r2_store:-0.3414426198296172\n",
            "Epoch [6386/10000], train_Loss: 0.0038403067737817764,test_Loss:22.693843841552734, r2_store:-0.36042045529864075\n",
            "Epoch [6387/10000], train_Loss: 0.007960593327879906,test_Loss:22.431751251220703, r2_store:-0.3371926572320312\n",
            "Epoch [6388/10000], train_Loss: 0.00906648300588131,test_Loss:22.687114715576172, r2_store:-0.35937392986169936\n",
            "Epoch [6389/10000], train_Loss: 0.006377847399562597,test_Loss:22.48780632019043, r2_store:-0.34342267160965756\n",
            "Epoch [6390/10000], train_Loss: 0.0025011515244841576,test_Loss:22.563570022583008, r2_store:-0.35050889523945616\n",
            "Epoch [6391/10000], train_Loss: 0.0004260946880094707,test_Loss:22.59922218322754, r2_store:-0.35373393375813134\n",
            "Epoch [6392/10000], train_Loss: 0.001224110135808587,test_Loss:22.464975357055664, r2_store:-0.3429245605010671\n",
            "Epoch [6393/10000], train_Loss: 0.003468857379630208,test_Loss:22.643840789794922, r2_store:-0.35912402804272725\n",
            "Epoch [6394/10000], train_Loss: 0.004875395447015762,test_Loss:22.444965362548828, r2_store:-0.3419374706495333\n",
            "Epoch [6395/10000], train_Loss: 0.004366527311503887,test_Loss:22.612152099609375, r2_store:-0.355987231213974\n",
            "Epoch [6396/10000], train_Loss: 0.002480312017723918,test_Loss:22.50429916381836, r2_store:-0.3468442189819494\n",
            "Epoch [6397/10000], train_Loss: 0.0007738517015241086,test_Loss:22.520275115966797, r2_store:-0.3487642589369908\n",
            "Epoch [6398/10000], train_Loss: 0.0003312115150038153,test_Loss:22.564273834228516, r2_store:-0.35318852696811986\n",
            "Epoch [6399/10000], train_Loss: 0.001110354671254754,test_Loss:22.449392318725586, r2_store:-0.34378632460497527\n",
            "Epoch [6400/10000], train_Loss: 0.0022012139670550823,test_Loss:22.586505889892578, r2_store:-0.3558859511044321\n",
            "Epoch [6401/10000], train_Loss: 0.002655310556292534,test_Loss:22.442941665649414, r2_store:-0.3438056052953504\n",
            "Epoch [6402/10000], train_Loss: 0.0021882206201553345,test_Loss:22.554235458374023, r2_store:-0.353546193955949\n",
            "Epoch [6403/10000], train_Loss: 0.0012205996317788959,test_Loss:22.48676872253418, r2_store:-0.3477952847905623\n",
            "Epoch [6404/10000], train_Loss: 0.00044235290260985494,test_Loss:22.498197555541992, r2_store:-0.3489769637658944\n",
            "Epoch [6405/10000], train_Loss: 0.00028152408776804805,test_Loss:22.533885955810547, r2_store:-0.35241249387361817\n",
            "Epoch [6406/10000], train_Loss: 0.0006724841659888625,test_Loss:22.454256057739258, r2_store:-0.34579516903713636\n",
            "Epoch [6407/10000], train_Loss: 0.0011996878311038017,test_Loss:22.554668426513672, r2_store:-0.35444392854758844\n",
            "Epoch [6408/10000], train_Loss: 0.0014452117029577494,test_Loss:22.45522689819336, r2_store:-0.3457473592959861\n",
            "Epoch [6409/10000], train_Loss: 0.001268492778763175,test_Loss:22.539020538330078, r2_store:-0.3531373958040105\n",
            "Epoch [6410/10000], train_Loss: 0.0008227621437981725,test_Loss:22.480518341064453, r2_store:-0.34826765838430807\n",
            "Epoch [6411/10000], train_Loss: 0.0004038193728774786,test_Loss:22.500019073486328, r2_store:-0.3500808570963603\n",
            "Epoch [6412/10000], train_Loss: 0.00023081080871634185,test_Loss:22.5132999420166, r2_store:-0.3513217889507745\n",
            "Epoch [6413/10000], train_Loss: 0.00033373889164067805,test_Loss:22.46831512451172, r2_store:-0.3475071915496408\n",
            "Epoch [6414/10000], train_Loss: 0.000575670157559216,test_Loss:22.533130645751953, r2_store:-0.3529378784647961\n",
            "Epoch [6415/10000], train_Loss: 0.0007693005609326065,test_Loss:22.465457916259766, r2_store:-0.34662330666876406\n",
            "Epoch [6416/10000], train_Loss: 0.0007977769710123539,test_Loss:22.53874969482422, r2_store:-0.35240398330488754\n",
            "Epoch [6417/10000], train_Loss: 0.0006602064240723848,test_Loss:22.4854679107666, r2_store:-0.3476005992042184\n",
            "Epoch [6418/10000], train_Loss: 0.00044699772843159735,test_Loss:22.518238067626953, r2_store:-0.35059146867669444\n",
            "Epoch [6419/10000], train_Loss: 0.000273407727945596,test_Loss:22.50307846069336, r2_store:-0.34961449357872487\n",
            "Epoch [6420/10000], train_Loss: 0.0002113260270562023,test_Loss:22.49241065979004, r2_store:-0.3487407924038295\n",
            "Epoch [6421/10000], train_Loss: 0.00025922947679646313,test_Loss:22.522205352783203, r2_store:-0.35135062770532466\n",
            "Epoch [6422/10000], train_Loss: 0.00036249321419745684,test_Loss:22.479595184326172, r2_store:-0.34773137986533564\n",
            "Epoch [6423/10000], train_Loss: 0.00044999615056440234,test_Loss:22.526987075805664, r2_store:-0.35196543910094724\n",
            "Epoch [6424/10000], train_Loss: 0.00047456155880354345,test_Loss:22.478679656982422, r2_store:-0.34784984472321456\n",
            "Epoch [6425/10000], train_Loss: 0.00042821397073566914,test_Loss:22.52159881591797, r2_store:-0.3513507743251594\n",
            "Epoch [6426/10000], train_Loss: 0.00034156886977143586,test_Loss:22.493175506591797, r2_store:-0.3487691984959389\n",
            "Epoch [6427/10000], train_Loss: 0.0002559018903411925,test_Loss:22.508010864257812, r2_store:-0.35006361172986034\n",
            "Epoch [6428/10000], train_Loss: 0.00020414397295098752,test_Loss:22.506715774536133, r2_store:-0.34991533629599236\n",
            "Epoch [6429/10000], train_Loss: 0.0001991165627259761,test_Loss:22.49953842163086, r2_store:-0.3488045883181534\n",
            "Epoch [6430/10000], train_Loss: 0.00022931226703803986,test_Loss:22.525819778442383, r2_store:-0.3507158833335873\n",
            "Epoch [6431/10000], train_Loss: 0.00027188312378712,test_Loss:22.49665069580078, r2_store:-0.34814799191219126\n",
            "Epoch [6432/10000], train_Loss: 0.0003029488434549421,test_Loss:22.529409408569336, r2_store:-0.3510036915081214\n",
            "Epoch [6433/10000], train_Loss: 0.0003114971914328635,test_Loss:22.499006271362305, r2_store:-0.34822507830398153\n",
            "Epoch [6434/10000], train_Loss: 0.0002960852289106697,test_Loss:22.527355194091797, r2_store:-0.3507930542890312\n",
            "Epoch [6435/10000], train_Loss: 0.00026449296274222434,test_Loss:22.500530242919922, r2_store:-0.34880000290506374\n",
            "Epoch [6436/10000], train_Loss: 0.00022824175539426506,test_Loss:22.516239166259766, r2_store:-0.35019674706667003\n",
            "Epoch [6437/10000], train_Loss: 0.00019891939882654697,test_Loss:22.512361526489258, r2_store:-0.3495006553423232\n",
            "Epoch [6438/10000], train_Loss: 0.00018323727999813855,test_Loss:22.51274299621582, r2_store:-0.34950691529183486\n",
            "Epoch [6439/10000], train_Loss: 0.0001813714625313878,test_Loss:22.519271850585938, r2_store:-0.3501332053634971\n",
            "Epoch [6440/10000], train_Loss: 0.0001899550115922466,test_Loss:22.50922203063965, r2_store:-0.3490203916211787\n",
            "Epoch [6441/10000], train_Loss: 0.00020313786808401346,test_Loss:22.529340744018555, r2_store:-0.3505255859126608\n",
            "Epoch [6442/10000], train_Loss: 0.00021574090351350605,test_Loss:22.510602951049805, r2_store:-0.3487817230419934\n",
            "Epoch [6443/10000], train_Loss: 0.00022228345915209502,test_Loss:22.531648635864258, r2_store:-0.3506176749631924\n",
            "Epoch [6444/10000], train_Loss: 0.00022264309518504888,test_Loss:22.51268196105957, r2_store:-0.34882490395250154\n",
            "Epoch [6445/10000], train_Loss: 0.00021601305343210697,test_Loss:22.53207778930664, r2_store:-0.35049401349219056\n",
            "Epoch [6446/10000], train_Loss: 0.00020496721845120192,test_Loss:22.515533447265625, r2_store:-0.34912166128920563\n",
            "Epoch [6447/10000], train_Loss: 0.00019180835806764662,test_Loss:22.528568267822266, r2_store:-0.3502287350610189\n",
            "Epoch [6448/10000], train_Loss: 0.00018009051564149559,test_Loss:22.523571014404297, r2_store:-0.3495226033053882\n",
            "Epoch [6449/10000], train_Loss: 0.0001711845543468371,test_Loss:22.529640197753906, r2_store:-0.3499066608657191\n",
            "Epoch [6450/10000], train_Loss: 0.00016619343659840524,test_Loss:22.52926254272461, r2_store:-0.3499079088584016\n",
            "Epoch [6451/10000], train_Loss: 0.00016528910782653838,test_Loss:22.52716827392578, r2_store:-0.3496048030628167\n",
            "Epoch [6452/10000], train_Loss: 0.00016681678243912756,test_Loss:22.534276962280273, r2_store:-0.3501620184533967\n",
            "Epoch [6453/10000], train_Loss: 0.00016959445201791823,test_Loss:22.525209426879883, r2_store:-0.3493600721043544\n",
            "Epoch [6454/10000], train_Loss: 0.00017282748012803495,test_Loss:22.537654876708984, r2_store:-0.350274853706283\n",
            "Epoch [6455/10000], train_Loss: 0.0001754046679707244,test_Loss:22.528074264526367, r2_store:-0.34923004957418313\n",
            "Epoch [6456/10000], train_Loss: 0.00017650757217779756,test_Loss:22.539714813232422, r2_store:-0.3503075669909774\n",
            "Epoch [6457/10000], train_Loss: 0.00017580778512638062,test_Loss:22.528263092041016, r2_store:-0.349255522623634\n",
            "Epoch [6458/10000], train_Loss: 0.0001738775463309139,test_Loss:22.541759490966797, r2_store:-0.3502548285370417\n",
            "Epoch [6459/10000], train_Loss: 0.00017071816546376795,test_Loss:22.53102684020996, r2_store:-0.34933322078773865\n",
            "Epoch [6460/10000], train_Loss: 0.00016699868137948215,test_Loss:22.539440155029297, r2_store:-0.35011051294288964\n",
            "Epoch [6461/10000], train_Loss: 0.00016344018513336778,test_Loss:22.534156799316406, r2_store:-0.349408356040255\n",
            "Epoch [6462/10000], train_Loss: 0.00015989110397640616,test_Loss:22.54140853881836, r2_store:-0.3499400007446827\n",
            "Epoch [6463/10000], train_Loss: 0.00015701455413363874,test_Loss:22.535804748535156, r2_store:-0.3495184209660698\n",
            "Epoch [6464/10000], train_Loss: 0.00015475515101570636,test_Loss:22.541685104370117, r2_store:-0.3497913783072981\n",
            "Epoch [6465/10000], train_Loss: 0.00015266495756804943,test_Loss:22.541776657104492, r2_store:-0.34961279694896463\n",
            "Epoch [6466/10000], train_Loss: 0.00015128552331589162,test_Loss:22.54134178161621, r2_store:-0.34966070873050037\n",
            "Epoch [6467/10000], train_Loss: 0.0001504190731793642,test_Loss:22.541412353515625, r2_store:-0.34968188838984604\n",
            "Epoch [6468/10000], train_Loss: 0.00014988488692324609,test_Loss:22.543270111083984, r2_store:-0.3495290712225274\n",
            "Epoch [6469/10000], train_Loss: 0.0001493629242759198,test_Loss:22.54731559753418, r2_store:-0.34969667550225525\n",
            "Epoch [6470/10000], train_Loss: 0.00014881810056976974,test_Loss:22.54399871826172, r2_store:-0.3494011078794963\n",
            "Epoch [6471/10000], train_Loss: 0.00014879327500239015,test_Loss:22.548397064208984, r2_store:-0.3497215779934839\n",
            "Epoch [6472/10000], train_Loss: 0.0001487394329160452,test_Loss:22.545543670654297, r2_store:-0.349330754509773\n",
            "Epoch [6473/10000], train_Loss: 0.00014854305482003838,test_Loss:22.550613403320312, r2_store:-0.34978859379070704\n",
            "Epoch [6474/10000], train_Loss: 0.00014865410048514605,test_Loss:22.543298721313477, r2_store:-0.34930196817495696\n",
            "Epoch [6475/10000], train_Loss: 0.00014874644693918526,test_Loss:22.551542282104492, r2_store:-0.3498696444693772\n",
            "Epoch [6476/10000], train_Loss: 0.0001486713590566069,test_Loss:22.54648208618164, r2_store:-0.34925401297166636\n",
            "Epoch [6477/10000], train_Loss: 0.00014876715431455523,test_Loss:22.554738998413086, r2_store:-0.3498833328015163\n",
            "Epoch [6478/10000], train_Loss: 0.00014893738261889666,test_Loss:22.547449111938477, r2_store:-0.34915070193161335\n",
            "Epoch [6479/10000], train_Loss: 0.00014952851051930338,test_Loss:22.557937622070312, r2_store:-0.349884914364895\n",
            "Epoch [6480/10000], train_Loss: 0.00015009177150204778,test_Loss:22.549747467041016, r2_store:-0.34905762819737984\n",
            "Epoch [6481/10000], train_Loss: 0.0001508067944087088,test_Loss:22.559871673583984, r2_store:-0.3499366972487281\n",
            "Epoch [6482/10000], train_Loss: 0.00015182787319645286,test_Loss:22.54891014099121, r2_store:-0.34898256985343923\n",
            "Epoch [6483/10000], train_Loss: 0.00015353321214206517,test_Loss:22.561460494995117, r2_store:-0.350049304961922\n",
            "Epoch [6484/10000], train_Loss: 0.00015687072300352156,test_Loss:22.547853469848633, r2_store:-0.34884077013861914\n",
            "Epoch [6485/10000], train_Loss: 0.00016138497448991984,test_Loss:22.562894821166992, r2_store:-0.3501757308951712\n",
            "Epoch [6486/10000], train_Loss: 0.00016736653924454004,test_Loss:22.54501724243164, r2_store:-0.3486036069872609\n",
            "Epoch [6487/10000], train_Loss: 0.00017548205505590886,test_Loss:22.566246032714844, r2_store:-0.3503293751383889\n",
            "Epoch [6488/10000], train_Loss: 0.00018706513219513,test_Loss:22.544191360473633, r2_store:-0.348298425475992\n",
            "Epoch [6489/10000], train_Loss: 0.00020225187472533435,test_Loss:22.571617126464844, r2_store:-0.3505910937227974\n",
            "Epoch [6490/10000], train_Loss: 0.00022359704598784447,test_Loss:22.541336059570312, r2_store:-0.34792388951306497\n",
            "Epoch [6491/10000], train_Loss: 0.00025196216301992536,test_Loss:22.57761001586914, r2_store:-0.35099950163500626\n",
            "Epoch [6492/10000], train_Loss: 0.0002927786554209888,test_Loss:22.535924911499023, r2_store:-0.3474137544733318\n",
            "Epoch [6493/10000], train_Loss: 0.0003480908926576376,test_Loss:22.584280014038086, r2_store:-0.35156140475514186\n",
            "Epoch [6494/10000], train_Loss: 0.0004238115216139704,test_Loss:22.52758026123047, r2_store:-0.34667869415899055\n",
            "Epoch [6495/10000], train_Loss: 0.0005284621147438884,test_Loss:22.595073699951172, r2_store:-0.35232652416506016\n",
            "Epoch [6496/10000], train_Loss: 0.0006775945657864213,test_Loss:22.518508911132812, r2_store:-0.3456175292462844\n",
            "Epoch [6497/10000], train_Loss: 0.000888957642018795,test_Loss:22.610950469970703, r2_store:-0.3535136699004491\n",
            "Epoch [6498/10000], train_Loss: 0.0012021027505397797,test_Loss:22.49737548828125, r2_store:-0.34415510803457816\n",
            "Epoch [6499/10000], train_Loss: 0.0016486675012856722,test_Loss:22.629154205322266, r2_store:-0.3554517872667333\n",
            "Epoch [6500/10000], train_Loss: 0.0023111046757549047,test_Loss:22.47190284729004, r2_store:-0.34205950482196057\n",
            "Epoch [6501/10000], train_Loss: 0.0032713438849896193,test_Loss:22.66197967529297, r2_store:-0.35832603056952594\n",
            "Epoch [6502/10000], train_Loss: 0.004642396233975887,test_Loss:22.432392120361328, r2_store:-0.3390176966239389\n",
            "Epoch [6503/10000], train_Loss: 0.00668138125911355,test_Loss:22.712095260620117, r2_store:-0.3625489954138572\n",
            "Epoch [6504/10000], train_Loss: 0.009617140516638756,test_Loss:22.386920928955078, r2_store:-0.33436885692881413\n",
            "Epoch [6505/10000], train_Loss: 0.01410685945302248,test_Loss:22.792449951171875, r2_store:-0.368947486926263\n",
            "Epoch [6506/10000], train_Loss: 0.020636294037103653,test_Loss:22.295963287353516, r2_store:-0.3279771241082474\n",
            "Epoch [6507/10000], train_Loss: 0.030302967876195908,test_Loss:22.88810920715332, r2_store:-0.3788637755614872\n",
            "Epoch [6508/10000], train_Loss: 0.04335331171751022,test_Loss:22.21853256225586, r2_store:-0.3202083002144165\n",
            "Epoch [6509/10000], train_Loss: 0.06140521168708801,test_Loss:23.033042907714844, r2_store:-0.3914359875502522\n",
            "Epoch [6510/10000], train_Loss: 0.0809498280286789,test_Loss:22.12206268310547, r2_store:-0.3135987305788337\n",
            "Epoch [6511/10000], train_Loss: 0.10214246809482574,test_Loss:23.146270751953125, r2_store:-0.4002457275458071\n",
            "Epoch [6512/10000], train_Loss: 0.11177690327167511,test_Loss:22.119525909423828, r2_store:-0.31317180817550505\n",
            "Epoch [6513/10000], train_Loss: 0.10663062334060669,test_Loss:23.042221069335938, r2_store:-0.3914217079211013\n",
            "Epoch [6514/10000], train_Loss: 0.07823792845010757,test_Loss:22.22638702392578, r2_store:-0.32717779534938574\n",
            "Epoch [6515/10000], train_Loss: 0.03940042853355408,test_Loss:22.634395599365234, r2_store:-0.3627888960247845\n",
            "Epoch [6516/10000], train_Loss: 0.008181197568774223,test_Loss:22.560400009155273, r2_store:-0.35467499719884055\n",
            "Epoch [6517/10000], train_Loss: 0.0014867413556203246,test_Loss:22.37112045288086, r2_store:-0.33519130401650443\n",
            "Epoch [6518/10000], train_Loss: 0.016549712046980858,test_Loss:22.928918838500977, r2_store:-0.37662910526950677\n",
            "Epoch [6519/10000], train_Loss: 0.035941991955041885,test_Loss:22.35287857055664, r2_store:-0.32550741918238635\n",
            "Epoch [6520/10000], train_Loss: 0.04310228303074837,test_Loss:22.987743377685547, r2_store:-0.37387282176999626\n",
            "Epoch [6521/10000], train_Loss: 0.030911926180124283,test_Loss:22.544803619384766, r2_store:-0.3364139553382741\n",
            "Epoch [6522/10000], train_Loss: 0.011828204616904259,test_Loss:22.706815719604492, r2_store:-0.3517195959418544\n",
            "Epoch [6523/10000], train_Loss: 0.0009539012680761516,test_Loss:22.757366180419922, r2_store:-0.358706143171051\n",
            "Epoch [6524/10000], train_Loss: 0.00513959676027298,test_Loss:22.461305618286133, r2_store:-0.3344996588653144\n",
            "Epoch [6525/10000], train_Loss: 0.01659059152007103,test_Loss:22.91098976135254, r2_store:-0.37021794948785147\n",
            "Epoch [6526/10000], train_Loss: 0.0222520399838686,test_Loss:22.472110748291016, r2_store:-0.33384081308261293\n",
            "Epoch [6527/10000], train_Loss: 0.0171959288418293,test_Loss:22.779804229736328, r2_store:-0.3597337585209537\n",
            "Epoch [6528/10000], train_Loss: 0.006683456711471081,test_Loss:22.647891998291016, r2_store:-0.3478990527197616\n",
            "Epoch [6529/10000], train_Loss: 0.0007765251793898642,test_Loss:22.584976196289062, r2_store:-0.3425720626694899\n",
            "Epoch [6530/10000], train_Loss: 0.0034291748888790607,test_Loss:22.807796478271484, r2_store:-0.3624071751039626\n",
            "Epoch [6531/10000], train_Loss: 0.009687801823019981,test_Loss:22.473033905029297, r2_store:-0.336060724663533\n",
            "Epoch [6532/10000], train_Loss: 0.012365918606519699,test_Loss:22.787586212158203, r2_store:-0.36156778342701945\n",
            "Epoch [6533/10000], train_Loss: 0.008795884437859058,test_Loss:22.556926727294922, r2_store:-0.3426542700414834\n",
            "Epoch [6534/10000], train_Loss: 0.003109643468633294,test_Loss:22.641328811645508, r2_store:-0.3490855498862009\n",
            "Epoch [6535/10000], train_Loss: 0.0005184477777220309,test_Loss:22.70565414428711, r2_store:-0.354626384010855\n",
            "Epoch [6536/10000], train_Loss: 0.002411325927823782,test_Loss:22.51752471923828, r2_store:-0.33981708163420765\n",
            "Epoch [6537/10000], train_Loss: 0.005770419258624315,test_Loss:22.741371154785156, r2_store:-0.36005426815019637\n",
            "Epoch [6538/10000], train_Loss: 0.006819073110818863,test_Loss:22.492189407348633, r2_store:-0.3413501920684934\n",
            "Epoch [6539/10000], train_Loss: 0.004813497886061668,test_Loss:22.643680572509766, r2_store:-0.3547030842610843\n",
            "Epoch [6540/10000], train_Loss: 0.0017647159984335303,test_Loss:22.59280014038086, r2_store:-0.3497217768668288\n",
            "Epoch [6541/10000], train_Loss: 0.0003844072052743286,test_Loss:22.557987213134766, r2_store:-0.34580678720983515\n",
            "Epoch [6542/10000], train_Loss: 0.0013666771119460464,test_Loss:22.693096160888672, r2_store:-0.3570661774247794\n",
            "Epoch [6543/10000], train_Loss: 0.003167300019413233,test_Loss:22.509136199951172, r2_store:-0.3426581844265477\n",
            "Epoch [6544/10000], train_Loss: 0.003888209816068411,test_Loss:22.67691421508789, r2_store:-0.35720453276586794\n",
            "Epoch [6545/10000], train_Loss: 0.0029269512742757797,test_Loss:22.539636611938477, r2_store:-0.34639161900963833\n",
            "Epoch [6546/10000], train_Loss: 0.0013195553328841925,test_Loss:22.6021671295166, r2_store:-0.35130164705973654\n",
            "Epoch [6547/10000], train_Loss: 0.00036151119275018573,test_Loss:22.619035720825195, r2_store:-0.35267121819941827\n",
            "Epoch [6548/10000], train_Loss: 0.0005910611944273114,test_Loss:22.530475616455078, r2_store:-0.34599813698831694\n",
            "Epoch [6549/10000], train_Loss: 0.0015001456486061215,test_Loss:22.649517059326172, r2_store:-0.3562480169045512\n",
            "Epoch [6550/10000], train_Loss: 0.0021409911569207907,test_Loss:22.51537322998047, r2_store:-0.34526690853879827\n",
            "Epoch [6551/10000], train_Loss: 0.0019919653423130512,test_Loss:22.622543334960938, r2_store:-0.35480400162833536\n",
            "Epoch [6552/10000], train_Loss: 0.0012333623599261045,test_Loss:22.53937339782715, r2_store:-0.34875160153923024\n",
            "Epoch [6553/10000], train_Loss: 0.0004981216625310481,test_Loss:22.555355072021484, r2_store:-0.3505232557179334\n",
            "Epoch [6554/10000], train_Loss: 0.00025951548013836145,test_Loss:22.59022331237793, r2_store:-0.3529184668804002\n",
            "Epoch [6555/10000], train_Loss: 0.0005345058743841946,test_Loss:22.53238296508789, r2_store:-0.347052154134319\n",
            "Epoch [6556/10000], train_Loss: 0.000990800210274756,test_Loss:22.627079010009766, r2_store:-0.35473718733643556\n",
            "Epoch [6557/10000], train_Loss: 0.0012326231226325035,test_Loss:22.52757453918457, r2_store:-0.3468025513756705\n",
            "Epoch [6558/10000], train_Loss: 0.0010952928569167852,test_Loss:22.60209083557129, r2_store:-0.35356048564288023\n",
            "Epoch [6559/10000], train_Loss: 0.0007178158266469836,test_Loss:22.5539608001709, r2_store:-0.34914617492932254\n",
            "Epoch [6560/10000], train_Loss: 0.0003640632494352758,test_Loss:22.57520294189453, r2_store:-0.35070356309226436\n",
            "Epoch [6561/10000], train_Loss: 0.00022367571364156902,test_Loss:22.588863372802734, r2_store:-0.35204961738356033\n",
            "Epoch [6562/10000], train_Loss: 0.00031948238029144704,test_Loss:22.544479370117188, r2_store:-0.3484589667396527\n",
            "Epoch [6563/10000], train_Loss: 0.0005301798228174448,test_Loss:22.606060028076172, r2_store:-0.3536175308310423\n",
            "Epoch [6564/10000], train_Loss: 0.0006803029682487249,test_Loss:22.542591094970703, r2_store:-0.34791086098478563\n",
            "Epoch [6565/10000], train_Loss: 0.0006728490116074681,test_Loss:22.601329803466797, r2_store:-0.35301847898967886\n",
            "Epoch [6566/10000], train_Loss: 0.000529422250110656,test_Loss:22.551475524902344, r2_store:-0.3490507369193927\n",
            "Epoch [6567/10000], train_Loss: 0.00034676663926802576,test_Loss:22.578413009643555, r2_store:-0.3511666848572541\n",
            "Epoch [6568/10000], train_Loss: 0.00022268299653660506,test_Loss:22.58147621154785, r2_store:-0.35085293380147475\n",
            "Epoch [6569/10000], train_Loss: 0.00020484032575041056,test_Loss:22.56753921508789, r2_store:-0.3493264586706286\n",
            "Epoch [6570/10000], train_Loss: 0.0002738213515840471,test_Loss:22.599626541137695, r2_store:-0.3522304284770532\n",
            "Epoch [6571/10000], train_Loss: 0.00036447803722694516,test_Loss:22.552841186523438, r2_store:-0.34865439383107266\n",
            "Epoch [6572/10000], train_Loss: 0.00041510374285280704,test_Loss:22.59729766845703, r2_store:-0.35259053329100554\n",
            "Epoch [6573/10000], train_Loss: 0.0004014736623503268,test_Loss:22.557437896728516, r2_store:-0.3490819363130917\n",
            "Epoch [6574/10000], train_Loss: 0.00033615698339417577,test_Loss:22.590801239013672, r2_store:-0.35173330771341926\n",
            "Epoch [6575/10000], train_Loss: 0.00025546239339746535,test_Loss:22.5739688873291, r2_store:-0.3500920855021934\n",
            "Epoch [6576/10000], train_Loss: 0.00019703875295817852,test_Loss:22.58121681213379, r2_store:-0.350478875414848\n",
            "Epoch [6577/10000], train_Loss: 0.00018170657858718187,test_Loss:22.59133529663086, r2_store:-0.3512010367591678\n",
            "Epoch [6578/10000], train_Loss: 0.00020283197227399796,test_Loss:22.571481704711914, r2_store:-0.34954706282132375\n",
            "Epoch [6579/10000], train_Loss: 0.000238946799072437,test_Loss:22.596853256225586, r2_store:-0.3518629144841887\n",
            "Epoch [6580/10000], train_Loss: 0.0002687951782718301,test_Loss:22.566360473632812, r2_store:-0.34933137689658733\n",
            "Epoch [6581/10000], train_Loss: 0.000275457336101681,test_Loss:22.597179412841797, r2_store:-0.3518840369510656\n",
            "Epoch [6582/10000], train_Loss: 0.0002580978616606444,test_Loss:22.572818756103516, r2_store:-0.349707011523654\n",
            "Epoch [6583/10000], train_Loss: 0.0002266929514007643,test_Loss:22.59238624572754, r2_store:-0.35132686085469644\n",
            "Epoch [6584/10000], train_Loss: 0.00019494647858664393,test_Loss:22.581295013427734, r2_store:-0.35039391379650753\n",
            "Epoch [6585/10000], train_Loss: 0.00017352828581351787,test_Loss:22.583393096923828, r2_store:-0.3506361653225245\n",
            "Epoch [6586/10000], train_Loss: 0.0001675263192737475,test_Loss:22.588653564453125, r2_store:-0.35107467302273676\n",
            "Epoch [6587/10000], train_Loss: 0.00017469338490627706,test_Loss:22.57852554321289, r2_store:-0.3500341003752405\n",
            "Epoch [6588/10000], train_Loss: 0.00018796890799421817,test_Loss:22.59793472290039, r2_store:-0.351433269972109\n",
            "Epoch [6589/10000], train_Loss: 0.00020035247143823653,test_Loss:22.58060073852539, r2_store:-0.3497904597544923\n",
            "Epoch [6590/10000], train_Loss: 0.00020605861209332943,test_Loss:22.600542068481445, r2_store:-0.35151593054922436\n",
            "Epoch [6591/10000], train_Loss: 0.00020315786241553724,test_Loss:22.581968307495117, r2_store:-0.34992872660639485\n",
            "Epoch [6592/10000], train_Loss: 0.00019369219080545008,test_Loss:22.597410202026367, r2_store:-0.35128453126250014\n",
            "Epoch [6593/10000], train_Loss: 0.00018097006250172853,test_Loss:22.58625602722168, r2_store:-0.3502512411216514\n",
            "Epoch [6594/10000], train_Loss: 0.0001690459030214697,test_Loss:22.594263076782227, r2_store:-0.3508990089659556\n",
            "Epoch [6595/10000], train_Loss: 0.00016038032481446862,test_Loss:22.59152603149414, r2_store:-0.3506462565215922\n",
            "Epoch [6596/10000], train_Loss: 0.0001565580751048401,test_Loss:22.590723037719727, r2_store:-0.3505332189623418\n",
            "Epoch [6597/10000], train_Loss: 0.00015690908185206354,test_Loss:22.596813201904297, r2_store:-0.35098908272000084\n",
            "Epoch [6598/10000], train_Loss: 0.00015981665637809783,test_Loss:22.588672637939453, r2_store:-0.3502822625455573\n",
            "Epoch [6599/10000], train_Loss: 0.00016373641847167164,test_Loss:22.59808921813965, r2_store:-0.3511704515903593\n",
            "Epoch [6600/10000], train_Loss: 0.00016645624418742955,test_Loss:22.587818145751953, r2_store:-0.3501453769086247\n",
            "Epoch [6601/10000], train_Loss: 0.0001671634236117825,test_Loss:22.602306365966797, r2_store:-0.3511333738917739\n",
            "Epoch [6602/10000], train_Loss: 0.0001659614354139194,test_Loss:22.593393325805664, r2_store:-0.3501435641714814\n",
            "Epoch [6603/10000], train_Loss: 0.00016290703206323087,test_Loss:22.603248596191406, r2_store:-0.3510179050669586\n",
            "Epoch [6604/10000], train_Loss: 0.0001583742123330012,test_Loss:22.59402084350586, r2_store:-0.35031623927730093\n",
            "Epoch [6605/10000], train_Loss: 0.00015398372488562018,test_Loss:22.60175132751465, r2_store:-0.35086695089061526\n",
            "Epoch [6606/10000], train_Loss: 0.00015019322745501995,test_Loss:22.599496841430664, r2_store:-0.3504859210332496\n",
            "Epoch [6607/10000], train_Loss: 0.00014757683675270528,test_Loss:22.600130081176758, r2_store:-0.3506613843155313\n",
            "Epoch [6608/10000], train_Loss: 0.00014545998419634998,test_Loss:22.599782943725586, r2_store:-0.35061304857040865\n",
            "Epoch [6609/10000], train_Loss: 0.0001443850196665153,test_Loss:22.60050392150879, r2_store:-0.3504668405747271\n",
            "Epoch [6610/10000], train_Loss: 0.00014392433513421565,test_Loss:22.604351043701172, r2_store:-0.35072688179489764\n",
            "Epoch [6611/10000], train_Loss: 0.00014398917846847326,test_Loss:22.598922729492188, r2_store:-0.3503807230533329\n",
            "Epoch [6612/10000], train_Loss: 0.00014410035510081798,test_Loss:22.604358673095703, r2_store:-0.3508505037490872\n",
            "Epoch [6613/10000], train_Loss: 0.00014407234266400337,test_Loss:22.60064125061035, r2_store:-0.3503553221941238\n",
            "Epoch [6614/10000], train_Loss: 0.00014383639791049063,test_Loss:22.60819435119629, r2_store:-0.35089720255690215\n",
            "Epoch [6615/10000], train_Loss: 0.0001434135192539543,test_Loss:22.600238800048828, r2_store:-0.35035531674164444\n",
            "Epoch [6616/10000], train_Loss: 0.00014255230780690908,test_Loss:22.606761932373047, r2_store:-0.3508983195656914\n",
            "Epoch [6617/10000], train_Loss: 0.00014135132369119674,test_Loss:22.603023529052734, r2_store:-0.35038369098753286\n",
            "Epoch [6618/10000], train_Loss: 0.00014010595623403788,test_Loss:22.608028411865234, r2_store:-0.35085327299062485\n",
            "Epoch [6619/10000], train_Loss: 0.00013867976667825133,test_Loss:22.602956771850586, r2_store:-0.350411247624282\n",
            "Epoch [6620/10000], train_Loss: 0.00013731306535191834,test_Loss:22.608291625976562, r2_store:-0.35078072940339733\n",
            "Epoch [6621/10000], train_Loss: 0.0001357954170089215,test_Loss:22.604169845581055, r2_store:-0.3504280567412439\n",
            "Epoch [6622/10000], train_Loss: 0.00013472032151184976,test_Loss:22.607908248901367, r2_store:-0.35067782904945144\n",
            "Epoch [6623/10000], train_Loss: 0.00013359737931750715,test_Loss:22.60659408569336, r2_store:-0.35041585772494366\n",
            "Epoch [6624/10000], train_Loss: 0.0001323799224337563,test_Loss:22.608734130859375, r2_store:-0.3505694923079401\n",
            "Epoch [6625/10000], train_Loss: 0.0001313364045927301,test_Loss:22.60740089416504, r2_store:-0.3504141914048855\n",
            "Epoch [6626/10000], train_Loss: 0.0001305890764342621,test_Loss:22.609500885009766, r2_store:-0.35050496527450137\n",
            "Epoch [6627/10000], train_Loss: 0.00013001382467336953,test_Loss:22.60660743713379, r2_store:-0.3504277324704528\n",
            "Epoch [6628/10000], train_Loss: 0.00012919891742058098,test_Loss:22.60578727722168, r2_store:-0.3504749811637715\n",
            "Epoch [6629/10000], train_Loss: 0.00012858814443461597,test_Loss:22.606765747070312, r2_store:-0.35043257761154645\n",
            "Epoch [6630/10000], train_Loss: 0.0001277298724744469,test_Loss:22.60808563232422, r2_store:-0.3504211651866993\n",
            "Epoch [6631/10000], train_Loss: 0.00012716089258901775,test_Loss:22.60812759399414, r2_store:-0.3504022950740324\n",
            "Epoch [6632/10000], train_Loss: 0.00012675259495154023,test_Loss:22.60919189453125, r2_store:-0.35033353607092277\n",
            "Epoch [6633/10000], train_Loss: 0.00012630588025785983,test_Loss:22.612491607666016, r2_store:-0.3503558522299999\n",
            "Epoch [6634/10000], train_Loss: 0.00012572338164318353,test_Loss:22.611873626708984, r2_store:-0.3502692059079051\n",
            "Epoch [6635/10000], train_Loss: 0.00012503299512900412,test_Loss:22.61190414428711, r2_store:-0.350361310651772\n",
            "Epoch [6636/10000], train_Loss: 0.00012438834528438747,test_Loss:22.6104736328125, r2_store:-0.3502338203056532\n",
            "Epoch [6637/10000], train_Loss: 0.0001240281417267397,test_Loss:22.613544464111328, r2_store:-0.3503326628623691\n",
            "Epoch [6638/10000], train_Loss: 0.00012349123426247388,test_Loss:22.611980438232422, r2_store:-0.3501595079405162\n",
            "Epoch [6639/10000], train_Loss: 0.00012298957153689116,test_Loss:22.612939834594727, r2_store:-0.3502901692076781\n",
            "Epoch [6640/10000], train_Loss: 0.0001227031898451969,test_Loss:22.612945556640625, r2_store:-0.35011279505277826\n",
            "Epoch [6641/10000], train_Loss: 0.00012213735317345709,test_Loss:22.616294860839844, r2_store:-0.3502898912843988\n",
            "Epoch [6642/10000], train_Loss: 0.00012167475506430492,test_Loss:22.612789154052734, r2_store:-0.3501035665757781\n",
            "Epoch [6643/10000], train_Loss: 0.00012118220183765516,test_Loss:22.61511993408203, r2_store:-0.3502983502014667\n",
            "Epoch [6644/10000], train_Loss: 0.0001207828609040007,test_Loss:22.614498138427734, r2_store:-0.3500773284105909\n",
            "Epoch [6645/10000], train_Loss: 0.00012029431672999635,test_Loss:22.617908477783203, r2_store:-0.35030545255309664\n",
            "Epoch [6646/10000], train_Loss: 0.00012010915816063061,test_Loss:22.61359977722168, r2_store:-0.35002052407868756\n",
            "Epoch [6647/10000], train_Loss: 0.00011998710397165269,test_Loss:22.616857528686523, r2_store:-0.35035009887241975\n",
            "Epoch [6648/10000], train_Loss: 0.00012020870053675026,test_Loss:22.61354637145996, r2_store:-0.34994029933830606\n",
            "Epoch [6649/10000], train_Loss: 0.00012048578355461359,test_Loss:22.620800018310547, r2_store:-0.35040153719509815\n",
            "Epoch [6650/10000], train_Loss: 0.00012116896687075496,test_Loss:22.61461067199707, r2_store:-0.3498052415961288\n",
            "Epoch [6651/10000], train_Loss: 0.00012256568879820406,test_Loss:22.622526168823242, r2_store:-0.3504781564485435\n",
            "Epoch [6652/10000], train_Loss: 0.00012466874613892287,test_Loss:22.61336898803711, r2_store:-0.34962288858235113\n",
            "Epoch [6653/10000], train_Loss: 0.00012802283163182437,test_Loss:22.625736236572266, r2_store:-0.3506098475816293\n",
            "Epoch [6654/10000], train_Loss: 0.0001332266692770645,test_Loss:22.610973358154297, r2_store:-0.3493713893454018\n",
            "Epoch [6655/10000], train_Loss: 0.0001411383127560839,test_Loss:22.62752342224121, r2_store:-0.3508552080704872\n",
            "Epoch [6656/10000], train_Loss: 0.00015341048128902912,test_Loss:22.60634422302246, r2_store:-0.3490329126279028\n",
            "Epoch [6657/10000], train_Loss: 0.00017262707115150988,test_Loss:22.633197784423828, r2_store:-0.3512592627502247\n",
            "Epoch [6658/10000], train_Loss: 0.0002028620074270293,test_Loss:22.60171127319336, r2_store:-0.3484658004125376\n",
            "Epoch [6659/10000], train_Loss: 0.00024876068346202374,test_Loss:22.642215728759766, r2_store:-0.351857048281466\n",
            "Epoch [6660/10000], train_Loss: 0.00032090279273688793,test_Loss:22.593400955200195, r2_store:-0.34759755523874847\n",
            "Epoch [6661/10000], train_Loss: 0.0004318700230214745,test_Loss:22.656280517578125, r2_store:-0.3528429329759182\n",
            "Epoch [6662/10000], train_Loss: 0.0006067336653359234,test_Loss:22.579524993896484, r2_store:-0.3462776628449742\n",
            "Epoch [6663/10000], train_Loss: 0.0008793454617261887,test_Loss:22.676475524902344, r2_store:-0.3544639862172376\n",
            "Epoch [6664/10000], train_Loss: 0.0013097638729959726,test_Loss:22.556730270385742, r2_store:-0.34425220326646655\n",
            "Epoch [6665/10000], train_Loss: 0.001991276629269123,test_Loss:22.70960807800293, r2_store:-0.35712115207182227\n",
            "Epoch [6666/10000], train_Loss: 0.00306915445253253,test_Loss:22.518047332763672, r2_store:-0.3410745318779438\n",
            "Epoch [6667/10000], train_Loss: 0.004800005815923214,test_Loss:22.760272979736328, r2_store:-0.3614799458851905\n",
            "Epoch [6668/10000], train_Loss: 0.0075426227413117886,test_Loss:22.470264434814453, r2_store:-0.3361590045663241\n",
            "Epoch [6669/10000], train_Loss: 0.01198828686028719,test_Loss:22.846954345703125, r2_store:-0.3689873329161202\n",
            "Epoch [6670/10000], train_Loss: 0.019052447751164436,test_Loss:22.360990524291992, r2_store:-0.32879366022099377\n",
            "Epoch [6671/10000], train_Loss: 0.030386528000235558,test_Loss:22.977611541748047, r2_store:-0.38122325000203805\n",
            "Epoch [6672/10000], train_Loss: 0.047524936497211456,test_Loss:22.24613380432129, r2_store:-0.31877916762154257\n",
            "Epoch [6673/10000], train_Loss: 0.07324643433094025,test_Loss:23.188600540161133, r2_store:-0.3984498618125558\n",
            "Epoch [6674/10000], train_Loss: 0.10466351360082626,test_Loss:22.15966796875, r2_store:-0.3088255723370654\n",
            "Epoch [6675/10000], train_Loss: 0.14203070104122162,test_Loss:23.411243438720703, r2_store:-0.41412609940585465\n",
            "Epoch [6676/10000], train_Loss: 0.16546286642551422,test_Loss:22.104393005371094, r2_store:-0.3080212972229377\n",
            "Epoch [6677/10000], train_Loss: 0.16184721887111664,test_Loss:23.18484115600586, r2_store:-0.40276044963421853\n",
            "Epoch [6678/10000], train_Loss: 0.11002647876739502,test_Loss:22.24415397644043, r2_store:-0.32845145419278676\n",
            "Epoch [6679/10000], train_Loss: 0.04356474429368973,test_Loss:22.57502555847168, r2_store:-0.3592244971927834\n",
            "Epoch [6680/10000], train_Loss: 0.0033457160461694,test_Loss:22.721481323242188, r2_store:-0.3674200558290881\n",
            "Epoch [6681/10000], train_Loss: 0.013106897473335266,test_Loss:22.343948364257812, r2_store:-0.3254910145325134\n",
            "Epoch [6682/10000], train_Loss: 0.049538783729076385,test_Loss:23.208866119384766, r2_store:-0.3875831311153921\n",
            "Epoch [6683/10000], train_Loss: 0.06743759661912918,test_Loss:22.521438598632812, r2_store:-0.3231276204104916\n",
            "Epoch [6684/10000], train_Loss: 0.04947241023182869,test_Loss:23.037639617919922, r2_store:-0.3639176202052665\n",
            "Epoch [6685/10000], train_Loss: 0.014383005909621716,test_Loss:22.889604568481445, r2_store:-0.3508068828413582\n",
            "Epoch [6686/10000], train_Loss: 0.0013372603571042418,test_Loss:22.65921401977539, r2_store:-0.3338239186128711\n",
            "Epoch [6687/10000], train_Loss: 0.017851997166872025,test_Loss:23.131723403930664, r2_store:-0.3762704665734169\n",
            "Epoch [6688/10000], train_Loss: 0.03660621866583824,test_Loss:22.566089630126953, r2_store:-0.32914549594375764\n",
            "Epoch [6689/10000], train_Loss: 0.03355135768651962,test_Loss:23.00860595703125, r2_store:-0.3654641561545453\n",
            "Epoch [6690/10000], train_Loss: 0.013067871332168579,test_Loss:22.822233200073242, r2_store:-0.34990186450910277\n",
            "Epoch [6691/10000], train_Loss: 0.0012012252118438482,test_Loss:22.670734405517578, r2_store:-0.34052191353089145\n",
            "Epoch [6692/10000], train_Loss: 0.008518646471202374,test_Loss:22.979076385498047, r2_store:-0.37062441532272605\n",
            "Epoch [6693/10000], train_Loss: 0.020416580140590668,test_Loss:22.556201934814453, r2_store:-0.3347973599522258\n",
            "Epoch [6694/10000], train_Loss: 0.01988977938890457,test_Loss:22.889442443847656, r2_store:-0.3629812455126127\n",
            "Epoch [6695/10000], train_Loss: 0.008345132693648338,test_Loss:22.73666000366211, r2_store:-0.3502022322490901\n",
            "Epoch [6696/10000], train_Loss: 0.000922488805372268,test_Loss:22.652210235595703, r2_store:-0.34299009571317063\n",
            "Epoch [6697/10000], train_Loss: 0.004927042871713638,test_Loss:22.934635162353516, r2_store:-0.3656837810248361\n",
            "Epoch [6698/10000], train_Loss: 0.012212683446705341,test_Loss:22.63235855102539, r2_store:-0.33798081441013794\n",
            "Epoch [6699/10000], train_Loss: 0.012299186550080776,test_Loss:22.894338607788086, r2_store:-0.3610414878197319\n",
            "Epoch [6700/10000], train_Loss: 0.005490999668836594,test_Loss:22.71727180480957, r2_store:-0.35081514519464974\n",
            "Epoch [6701/10000], train_Loss: 0.0007494821329601109,test_Loss:22.637035369873047, r2_store:-0.34673659893392905\n",
            "Epoch [6702/10000], train_Loss: 0.0027461641002446413,test_Loss:22.842565536499023, r2_store:-0.36369353461260445\n",
            "Epoch [6703/10000], train_Loss: 0.007110326085239649,test_Loss:22.598087310791016, r2_store:-0.3420156438870594\n",
            "Epoch [6704/10000], train_Loss: 0.007738667074590921,test_Loss:22.79427719116211, r2_store:-0.36043361285404174\n",
            "Epoch [6705/10000], train_Loss: 0.003969603683799505,test_Loss:22.648006439208984, r2_store:-0.35061846233785365\n",
            "Epoch [6706/10000], train_Loss: 0.0007468935800716281,test_Loss:22.613616943359375, r2_store:-0.34887978446651013\n",
            "Epoch [6707/10000], train_Loss: 0.0013387590879574418,test_Loss:22.75141716003418, r2_store:-0.36063685360510056\n",
            "Epoch [6708/10000], train_Loss: 0.003995147999376059,test_Loss:22.544403076171875, r2_store:-0.34408187791510425\n",
            "Epoch [6709/10000], train_Loss: 0.004928573500365019,test_Loss:22.71441650390625, r2_store:-0.3593163650771707\n",
            "Epoch [6710/10000], train_Loss: 0.0030575201380997896,test_Loss:22.596858978271484, r2_store:-0.3498286055050841\n",
            "Epoch [6711/10000], train_Loss: 0.0008126983302645385,test_Loss:22.613353729248047, r2_store:-0.35065373106655384\n",
            "Epoch [6712/10000], train_Loss: 0.0005960409180261195,test_Loss:22.70706558227539, r2_store:-0.35799929362951555\n",
            "Epoch [6713/10000], train_Loss: 0.0020436435006558895,test_Loss:22.56076431274414, r2_store:-0.34617239889425644\n",
            "Epoch [6714/10000], train_Loss: 0.0030337623320519924,test_Loss:22.700101852416992, r2_store:-0.35917591564054185\n",
            "Epoch [6715/10000], train_Loss: 0.002387147629633546,test_Loss:22.581130981445312, r2_store:-0.35015860398805043\n",
            "Epoch [6716/10000], train_Loss: 0.0009929091902449727,test_Loss:22.61578369140625, r2_store:-0.35365006294135726\n",
            "Epoch [6717/10000], train_Loss: 0.00033584790071472526,test_Loss:22.64852523803711, r2_store:-0.3567351362856732\n",
            "Epoch [6718/10000], train_Loss: 0.0008473112247884274,test_Loss:22.552875518798828, r2_store:-0.34888284095688293\n",
            "Epoch [6719/10000], train_Loss: 0.0016698457766324282,test_Loss:22.67148208618164, r2_store:-0.3587822659875879\n",
            "Epoch [6720/10000], train_Loss: 0.0017764947842806578,test_Loss:22.55915641784668, r2_store:-0.34999012997730006\n",
            "Epoch [6721/10000], train_Loss: 0.001110561192035675,test_Loss:22.613901138305664, r2_store:-0.35515304040900664\n",
            "Epoch [6722/10000], train_Loss: 0.00041744671761989594,test_Loss:22.608478546142578, r2_store:-0.35451890243697215\n",
            "Epoch [6723/10000], train_Loss: 0.0003362756106071174,test_Loss:22.570606231689453, r2_store:-0.35051233410237703\n",
            "Epoch [6724/10000], train_Loss: 0.0007665989687666297,test_Loss:22.659988403320312, r2_store:-0.35713766368706934\n",
            "Epoch [6725/10000], train_Loss: 0.001130345044657588,test_Loss:22.576322555541992, r2_store:-0.3494362827874058\n",
            "Epoch [6726/10000], train_Loss: 0.0010498026385903358,test_Loss:22.65506362915039, r2_store:-0.35544425403283464\n",
            "Epoch [6727/10000], train_Loss: 0.0006318982923403382,test_Loss:22.61981201171875, r2_store:-0.35204442242401734\n",
            "Epoch [6728/10000], train_Loss: 0.0002948559704236686,test_Loss:22.618364334106445, r2_store:-0.35194977482164314\n",
            "Epoch [6729/10000], train_Loss: 0.0003041201562155038,test_Loss:22.652978897094727, r2_store:-0.3554016745032038\n",
            "Epoch [6730/10000], train_Loss: 0.0005533931544050574,test_Loss:22.585865020751953, r2_store:-0.35035206691938314\n",
            "Epoch [6731/10000], train_Loss: 0.0007402373012155294,test_Loss:22.65496063232422, r2_store:-0.35613403026708856\n",
            "Epoch [6732/10000], train_Loss: 0.0006761409458704293,test_Loss:22.605045318603516, r2_store:-0.3514864860717719\n",
            "Epoch [6733/10000], train_Loss: 0.0004445277154445648,test_Loss:22.640119552612305, r2_store:-0.35410389254047403\n",
            "Epoch [6734/10000], train_Loss: 0.00025756063405424356,test_Loss:22.63375473022461, r2_store:-0.35397177055823903\n",
            "Epoch [6735/10000], train_Loss: 0.00024498283164575696,test_Loss:22.605602264404297, r2_store:-0.3517603791600781\n",
            "Epoch [6736/10000], train_Loss: 0.0003668515128083527,test_Loss:22.652751922607422, r2_store:-0.35533820432018737\n",
            "Epoch [6737/10000], train_Loss: 0.0004770310188177973,test_Loss:22.605825424194336, r2_store:-0.35094872142849676\n",
            "Epoch [6738/10000], train_Loss: 0.0004714734386652708,test_Loss:22.650806427001953, r2_store:-0.35450020608697974\n",
            "Epoch [6739/10000], train_Loss: 0.0003612381697166711,test_Loss:22.62380027770996, r2_store:-0.3519746219546025\n",
            "Epoch [6740/10000], train_Loss: 0.00024526932975277305,test_Loss:22.637218475341797, r2_store:-0.3525887339755387\n",
            "Epoch [6741/10000], train_Loss: 0.00020679595763795078,test_Loss:22.654447555541992, r2_store:-0.3535665897554596\n",
            "Epoch [6742/10000], train_Loss: 0.000250929850153625,test_Loss:22.627729415893555, r2_store:-0.3512643244236999\n",
            "Epoch [6743/10000], train_Loss: 0.0003175890014972538,test_Loss:22.66165542602539, r2_store:-0.35432138577424954\n",
            "Epoch [6744/10000], train_Loss: 0.00034219055669382215,test_Loss:22.625431060791016, r2_store:-0.35141579685950175\n",
            "Epoch [6745/10000], train_Loss: 0.00030602997867390513,test_Loss:22.654394149780273, r2_store:-0.35372694057310716\n",
            "Epoch [6746/10000], train_Loss: 0.00024101868621073663,test_Loss:22.642230987548828, r2_store:-0.3524752321378475\n",
            "Epoch [6747/10000], train_Loss: 0.00019532509031705558,test_Loss:22.643875122070312, r2_store:-0.35241822628549024\n",
            "Epoch [6748/10000], train_Loss: 0.0001939920912263915,test_Loss:22.658639907836914, r2_store:-0.35352796204698667\n",
            "Epoch [6749/10000], train_Loss: 0.00022396061103790998,test_Loss:22.637460708618164, r2_store:-0.3516414906934222\n",
            "Epoch [6750/10000], train_Loss: 0.0002529062912799418,test_Loss:22.66507911682129, r2_store:-0.3538605346040935\n",
            "Epoch [6751/10000], train_Loss: 0.00025597529020160437,test_Loss:22.641986846923828, r2_store:-0.3517662216147901\n",
            "Epoch [6752/10000], train_Loss: 0.0002318479382665828,test_Loss:22.662811279296875, r2_store:-0.3532771674545656\n",
            "Epoch [6753/10000], train_Loss: 0.00019840530876535922,test_Loss:22.656696319580078, r2_store:-0.3524968612181467\n",
            "Epoch [6754/10000], train_Loss: 0.0001776428980519995,test_Loss:22.657814025878906, r2_store:-0.35234303451756444\n",
            "Epoch [6755/10000], train_Loss: 0.00017841962107922882,test_Loss:22.669471740722656, r2_store:-0.35316313552337775\n",
            "Epoch [6756/10000], train_Loss: 0.00019335211254656315,test_Loss:22.65359878540039, r2_store:-0.35175100625718425\n",
            "Epoch [6757/10000], train_Loss: 0.00020716448489110917,test_Loss:22.67228889465332, r2_store:-0.3533854420987472\n",
            "Epoch [6758/10000], train_Loss: 0.00020838149066548795,test_Loss:22.652629852294922, r2_store:-0.35186962542734923\n",
            "Epoch [6759/10000], train_Loss: 0.00019642696133814752,test_Loss:22.665624618530273, r2_store:-0.35308697641235365\n",
            "Epoch [6760/10000], train_Loss: 0.00017887495050672442,test_Loss:22.65753173828125, r2_store:-0.3524345722642046\n",
            "Epoch [6761/10000], train_Loss: 0.00016578982467763126,test_Loss:22.659032821655273, r2_store:-0.3525480124863287\n",
            "Epoch [6762/10000], train_Loss: 0.00016278096882160753,test_Loss:22.664104461669922, r2_store:-0.35303013567015085\n",
            "Epoch [6763/10000], train_Loss: 0.00016799075820017606,test_Loss:22.65283203125, r2_store:-0.3521733154018414\n",
            "Epoch [6764/10000], train_Loss: 0.00017520919209346175,test_Loss:22.665922164916992, r2_store:-0.35326825660428285\n",
            "Epoch [6765/10000], train_Loss: 0.00017828287673182786,test_Loss:22.65468978881836, r2_store:-0.3520641156738187\n",
            "Epoch [6766/10000], train_Loss: 0.00017455205670557916,test_Loss:22.6678466796875, r2_store:-0.3530073236738587\n",
            "Epoch [6767/10000], train_Loss: 0.00016652184422127903,test_Loss:22.660259246826172, r2_store:-0.35225734098378125\n",
            "Epoch [6768/10000], train_Loss: 0.00015827589959371835,test_Loss:22.664779663085938, r2_store:-0.3525825561035294\n",
            "Epoch [6769/10000], train_Loss: 0.0001531869056634605,test_Loss:22.666122436523438, r2_store:-0.3526112324031847\n",
            "Epoch [6770/10000], train_Loss: 0.00015223017544485629,test_Loss:22.661508560180664, r2_store:-0.35225469433799805\n",
            "Epoch [6771/10000], train_Loss: 0.00015410159539896995,test_Loss:22.667232513427734, r2_store:-0.35289550616645826\n",
            "Epoch [6772/10000], train_Loss: 0.00015668701962567866,test_Loss:22.657894134521484, r2_store:-0.3521283081645201\n",
            "Epoch [6773/10000], train_Loss: 0.00015721717500127852,test_Loss:22.666954040527344, r2_store:-0.35287816348164336\n",
            "Epoch [6774/10000], train_Loss: 0.0001551128807477653,test_Loss:22.659170150756836, r2_store:-0.3521374505010675\n",
            "Epoch [6775/10000], train_Loss: 0.0001513278839411214,test_Loss:22.664749145507812, r2_store:-0.3526246535755684\n",
            "Epoch [6776/10000], train_Loss: 0.00014717449084855616,test_Loss:22.66172981262207, r2_store:-0.3522944707314808\n",
            "Epoch [6777/10000], train_Loss: 0.00014400112559087574,test_Loss:22.662965774536133, r2_store:-0.35234669933336704\n",
            "Epoch [6778/10000], train_Loss: 0.00014257131260819733,test_Loss:22.666053771972656, r2_store:-0.35250704626312657\n",
            "Epoch [6779/10000], train_Loss: 0.00014251960965339094,test_Loss:22.662931442260742, r2_store:-0.3521539490059653\n",
            "Epoch [6780/10000], train_Loss: 0.0001431648270227015,test_Loss:22.66865348815918, r2_store:-0.35263767132775325\n",
            "Epoch [6781/10000], train_Loss: 0.00014376417675521225,test_Loss:22.66333770751953, r2_store:-0.35208375057593777\n",
            "Epoch [6782/10000], train_Loss: 0.00014335211017169058,test_Loss:22.67066192626953, r2_store:-0.3526096154483973\n",
            "Epoch [6783/10000], train_Loss: 0.0001417001913068816,test_Loss:22.66513442993164, r2_store:-0.3521145087192683\n",
            "Epoch [6784/10000], train_Loss: 0.00013955862959846854,test_Loss:22.668054580688477, r2_store:-0.35246813958191403\n",
            "Epoch [6785/10000], train_Loss: 0.00013756669068243355,test_Loss:22.665712356567383, r2_store:-0.3522281964158316\n",
            "Epoch [6786/10000], train_Loss: 0.0001356523425783962,test_Loss:22.668020248413086, r2_store:-0.3523006479595312\n",
            "Epoch [6787/10000], train_Loss: 0.00013448325626086444,test_Loss:22.668609619140625, r2_store:-0.3523569630739698\n",
            "Epoch [6788/10000], train_Loss: 0.00013392441906034946,test_Loss:22.665306091308594, r2_store:-0.35216675893708294\n",
            "Epoch [6789/10000], train_Loss: 0.00013391292304731905,test_Loss:22.66969108581543, r2_store:-0.3524405716201253\n",
            "Epoch [6790/10000], train_Loss: 0.0001335974520770833,test_Loss:22.66737937927246, r2_store:-0.35209396400794524\n",
            "Epoch [6791/10000], train_Loss: 0.00013328583736438304,test_Loss:22.669170379638672, r2_store:-0.35244708633889466\n",
            "Epoch [6792/10000], train_Loss: 0.0001324212207691744,test_Loss:22.665237426757812, r2_store:-0.35206587063876715\n",
            "Epoch [6793/10000], train_Loss: 0.00013157895591575652,test_Loss:22.671619415283203, r2_store:-0.35237323414767663\n",
            "Epoch [6794/10000], train_Loss: 0.0001303942990489304,test_Loss:22.6685791015625, r2_store:-0.3520807279205207\n",
            "Epoch [6795/10000], train_Loss: 0.0001289993233513087,test_Loss:22.67014503479004, r2_store:-0.3522540933982268\n",
            "Epoch [6796/10000], train_Loss: 0.00012806520680896938,test_Loss:22.670549392700195, r2_store:-0.35212965934288243\n",
            "Epoch [6797/10000], train_Loss: 0.00012701988453045487,test_Loss:22.67095947265625, r2_store:-0.35214580829292097\n",
            "Epoch [6798/10000], train_Loss: 0.00012615123705472797,test_Loss:22.671419143676758, r2_store:-0.3521689099310803\n",
            "Epoch [6799/10000], train_Loss: 0.00012543032062239945,test_Loss:22.670976638793945, r2_store:-0.3520539989007969\n",
            "Epoch [6800/10000], train_Loss: 0.0001248747721547261,test_Loss:22.673952102661133, r2_store:-0.35217831032475466\n",
            "Epoch [6801/10000], train_Loss: 0.00012435190728865564,test_Loss:22.672094345092773, r2_store:-0.3520012736238436\n",
            "Epoch [6802/10000], train_Loss: 0.00012375941150821745,test_Loss:22.67384910583496, r2_store:-0.3521499852844625\n",
            "Epoch [6803/10000], train_Loss: 0.0001231497008120641,test_Loss:22.673755645751953, r2_store:-0.35195062722968373\n",
            "Epoch [6804/10000], train_Loss: 0.00012236603652127087,test_Loss:22.675369262695312, r2_store:-0.3520685528853986\n",
            "Epoch [6805/10000], train_Loss: 0.00012157946184743196,test_Loss:22.673351287841797, r2_store:-0.35192747118649703\n",
            "Epoch [6806/10000], train_Loss: 0.00012087270442862064,test_Loss:22.675626754760742, r2_store:-0.35199728225857463\n",
            "Epoch [6807/10000], train_Loss: 0.0001200977130793035,test_Loss:22.67513656616211, r2_store:-0.35193346079657895\n",
            "Epoch [6808/10000], train_Loss: 0.00011963554425165057,test_Loss:22.674762725830078, r2_store:-0.35191536860116157\n",
            "Epoch [6809/10000], train_Loss: 0.00011900932440767065,test_Loss:22.677032470703125, r2_store:-0.3519131522476595\n",
            "Epoch [6810/10000], train_Loss: 0.00011840039951493964,test_Loss:22.67757797241211, r2_store:-0.3518244741601335\n",
            "Epoch [6811/10000], train_Loss: 0.0001179810642497614,test_Loss:22.678316116333008, r2_store:-0.35190057732619473\n",
            "Epoch [6812/10000], train_Loss: 0.00011742660717573017,test_Loss:22.677453994750977, r2_store:-0.3517770828119533\n",
            "Epoch [6813/10000], train_Loss: 0.00011688534868881106,test_Loss:22.678890228271484, r2_store:-0.35190672978822857\n",
            "Epoch [6814/10000], train_Loss: 0.00011630265362327918,test_Loss:22.677282333374023, r2_store:-0.35175777019222254\n",
            "Epoch [6815/10000], train_Loss: 0.0001157923397840932,test_Loss:22.68092155456543, r2_store:-0.3518621107447948\n",
            "Epoch [6816/10000], train_Loss: 0.00011518732935655862,test_Loss:22.680818557739258, r2_store:-0.3517127369587154\n",
            "Epoch [6817/10000], train_Loss: 0.00011451635509729385,test_Loss:22.682174682617188, r2_store:-0.3517860090899292\n",
            "Epoch [6818/10000], train_Loss: 0.00011403286771383137,test_Loss:22.682361602783203, r2_store:-0.35168969895744384\n",
            "Epoch [6819/10000], train_Loss: 0.00011344734957674518,test_Loss:22.68291473388672, r2_store:-0.3517445205521612\n",
            "Epoch [6820/10000], train_Loss: 0.00011281960178166628,test_Loss:22.68114471435547, r2_store:-0.35171206208604766\n",
            "Epoch [6821/10000], train_Loss: 0.0001124298432841897,test_Loss:22.682886123657227, r2_store:-0.35171011850989475\n",
            "Epoch [6822/10000], train_Loss: 0.00011186314804945141,test_Loss:22.68478775024414, r2_store:-0.3516969045119085\n",
            "Epoch [6823/10000], train_Loss: 0.00011133338557556272,test_Loss:22.684673309326172, r2_store:-0.3516505836013104\n",
            "Epoch [6824/10000], train_Loss: 0.00011086043377872556,test_Loss:22.684581756591797, r2_store:-0.3516782614066605\n",
            "Epoch [6825/10000], train_Loss: 0.00011034781346097589,test_Loss:22.685165405273438, r2_store:-0.3516211500887152\n",
            "Epoch [6826/10000], train_Loss: 0.00010983875108649954,test_Loss:22.686275482177734, r2_store:-0.3516585590484427\n",
            "Epoch [6827/10000], train_Loss: 0.00010933608427876607,test_Loss:22.685863494873047, r2_store:-0.35156358765454243\n",
            "Epoch [6828/10000], train_Loss: 0.00010901972564170137,test_Loss:22.687824249267578, r2_store:-0.3516255565515576\n",
            "Epoch [6829/10000], train_Loss: 0.00010853818093892187,test_Loss:22.688030242919922, r2_store:-0.35153239943865633\n",
            "Epoch [6830/10000], train_Loss: 0.0001080911752069369,test_Loss:22.68888282775879, r2_store:-0.35161779042687646\n",
            "Epoch [6831/10000], train_Loss: 0.00010764213220681995,test_Loss:22.688074111938477, r2_store:-0.3514973277859923\n",
            "Epoch [6832/10000], train_Loss: 0.00010742363519966602,test_Loss:22.68937873840332, r2_store:-0.35162082037324005\n",
            "Epoch [6833/10000], train_Loss: 0.0001071022343239747,test_Loss:22.688751220703125, r2_store:-0.3514210640991584\n",
            "Epoch [6834/10000], train_Loss: 0.00010668140748748556,test_Loss:22.692245483398438, r2_store:-0.3515884407638161\n",
            "Epoch [6835/10000], train_Loss: 0.00010658758401405066,test_Loss:22.69014549255371, r2_store:-0.35129410282286266\n",
            "Epoch [6836/10000], train_Loss: 0.00010663651482900605,test_Loss:22.694059371948242, r2_store:-0.3515946554221383\n",
            "Epoch [6837/10000], train_Loss: 0.00010671110067050904,test_Loss:22.689485549926758, r2_store:-0.35122439615716905\n",
            "Epoch [6838/10000], train_Loss: 0.00010682117135729641,test_Loss:22.694133758544922, r2_store:-0.3516751121210173\n",
            "Epoch [6839/10000], train_Loss: 0.00010742481390479952,test_Loss:22.689525604248047, r2_store:-0.3511549997398209\n",
            "Epoch [6840/10000], train_Loss: 0.00010824265336850658,test_Loss:22.69711685180664, r2_store:-0.35174005986912094\n",
            "Epoch [6841/10000], train_Loss: 0.00010918462794506922,test_Loss:22.689868927001953, r2_store:-0.3510291405373174\n",
            "Epoch [6842/10000], train_Loss: 0.0001107544667320326,test_Loss:22.699892044067383, r2_store:-0.3518062005758624\n",
            "Epoch [6843/10000], train_Loss: 0.00011308826651657,test_Loss:22.689729690551758, r2_store:-0.35086991899341835\n",
            "Epoch [6844/10000], train_Loss: 0.00011603002349147573,test_Loss:22.701805114746094, r2_store:-0.3519080094205955\n",
            "Epoch [6845/10000], train_Loss: 0.00011999522394035012,test_Loss:22.687416076660156, r2_store:-0.35067997303023657\n",
            "Epoch [6846/10000], train_Loss: 0.00012580263137351722,test_Loss:22.7045955657959, r2_store:-0.35206638656272293\n",
            "Epoch [6847/10000], train_Loss: 0.00013390507956501096,test_Loss:22.68810272216797, r2_store:-0.35041220522752603\n",
            "Epoch [6848/10000], train_Loss: 0.00014523295976687223,test_Loss:22.71018409729004, r2_store:-0.3522980268100482\n",
            "Epoch [6849/10000], train_Loss: 0.00016122301167342812,test_Loss:22.68368911743164, r2_store:-0.3500575717347658\n",
            "Epoch [6850/10000], train_Loss: 0.0001835633593145758,test_Loss:22.71509552001953, r2_store:-0.35265976331844673\n",
            "Epoch [6851/10000], train_Loss: 0.0002143792517017573,test_Loss:22.68220329284668, r2_store:-0.3495874421779426\n",
            "Epoch [6852/10000], train_Loss: 0.0002581171866040677,test_Loss:22.722932815551758, r2_store:-0.35318923632035526\n",
            "Epoch [6853/10000], train_Loss: 0.00031972554279491305,test_Loss:22.67091941833496, r2_store:-0.34892314306834304\n",
            "Epoch [6854/10000], train_Loss: 0.00040685414569452405,test_Loss:22.730253219604492, r2_store:-0.35395795896954296\n",
            "Epoch [6855/10000], train_Loss: 0.0005322938086465001,test_Loss:22.666515350341797, r2_store:-0.34794022127991364\n",
            "Epoch [6856/10000], train_Loss: 0.0007126654381863773,test_Loss:22.753864288330078, r2_store:-0.3550663572822055\n",
            "Epoch [6857/10000], train_Loss: 0.0009651748696342111,test_Loss:22.645954132080078, r2_store:-0.34663250216331964\n",
            "Epoch [6858/10000], train_Loss: 0.0013215463841333985,test_Loss:22.766468048095703, r2_store:-0.356765237785166\n",
            "Epoch [6859/10000], train_Loss: 0.0018295226618647575,test_Loss:22.629281997680664, r2_store:-0.3448118763513366\n",
            "Epoch [6860/10000], train_Loss: 0.0025650428142398596,test_Loss:22.801128387451172, r2_store:-0.35920328682567404\n",
            "Epoch [6861/10000], train_Loss: 0.003620157716795802,test_Loss:22.588842391967773, r2_store:-0.3421406068638524\n",
            "Epoch [6862/10000], train_Loss: 0.005181173328310251,test_Loss:22.840333938598633, r2_store:-0.36290601541027767\n",
            "Epoch [6863/10000], train_Loss: 0.00740212295204401,test_Loss:22.54501724243164, r2_store:-0.33827893641635853\n",
            "Epoch [6864/10000], train_Loss: 0.01069885678589344,test_Loss:22.907482147216797, r2_store:-0.36804468943235524\n",
            "Epoch [6865/10000], train_Loss: 0.01522546075284481,test_Loss:22.474842071533203, r2_store:-0.3328572275780046\n",
            "Epoch [6866/10000], train_Loss: 0.02178104594349861,test_Loss:22.982831954956055, r2_store:-0.3754710078358723\n",
            "Epoch [6867/10000], train_Loss: 0.03051687218248844,test_Loss:22.408527374267578, r2_store:-0.3260993559154466\n",
            "Epoch [6868/10000], train_Loss: 0.04262799769639969,test_Loss:23.1208438873291, r2_store:-0.38482467566448464\n",
            "Epoch [6869/10000], train_Loss: 0.056135911494493484,test_Loss:22.30796241760254, r2_store:-0.3197025900842325\n",
            "Epoch [6870/10000], train_Loss: 0.0714201033115387,test_Loss:23.178268432617188, r2_store:-0.39298939391911847\n",
            "Epoch [6871/10000], train_Loss: 0.08298437297344208,test_Loss:22.306976318359375, r2_store:-0.31656281423998234\n",
            "Epoch [6872/10000], train_Loss: 0.08878956735134125,test_Loss:23.219223022460938, r2_store:-0.39195524684943917\n",
            "Epoch [6873/10000], train_Loss: 0.07958849519491196,test_Loss:22.344348907470703, r2_store:-0.32225325996510845\n",
            "Epoch [6874/10000], train_Loss: 0.0591529980301857,test_Loss:22.973636627197266, r2_store:-0.37482547263499866\n",
            "Epoch [6875/10000], train_Loss: 0.03087528608739376,test_Loss:22.619104385375977, r2_store:-0.33892201527211574\n",
            "Epoch [6876/10000], train_Loss: 0.008382616564631462,test_Loss:22.791053771972656, r2_store:-0.34963994629032613\n",
            "Epoch [6877/10000], train_Loss: 0.0004388304951135069,test_Loss:22.90789794921875, r2_store:-0.36088803937970915\n",
            "Epoch [6878/10000], train_Loss: 0.007298079784959555,test_Loss:22.568313598632812, r2_store:-0.33261293349166965\n",
            "Epoch [6879/10000], train_Loss: 0.020776376128196716,test_Loss:23.117399215698242, r2_store:-0.3737399140036193\n",
            "Epoch [6880/10000], train_Loss: 0.029554134234786034,test_Loss:22.63204002380371, r2_store:-0.3298745385977302\n",
            "Epoch [6881/10000], train_Loss: 0.02836522087454796,test_Loss:23.083860397338867, r2_store:-0.368052295491494\n",
            "Epoch [6882/10000], train_Loss: 0.017629463225603104,test_Loss:22.710559844970703, r2_store:-0.3413194571003948\n",
            "Epoch [6883/10000], train_Loss: 0.005871301516890526,test_Loss:22.816469192504883, r2_store:-0.3521077736450675\n",
            "Epoch [6884/10000], train_Loss: 0.00046696708886884153,test_Loss:22.905290603637695, r2_store:-0.35896568184180766\n",
            "Epoch [6885/10000], train_Loss: 0.0034338037949055433,test_Loss:22.66561508178711, r2_store:-0.3394259349325106\n",
            "Epoch [6886/10000], train_Loss: 0.010237923823297024,test_Loss:22.98922348022461, r2_store:-0.3679294362640235\n",
            "Epoch [6887/10000], train_Loss: 0.014479272067546844,test_Loss:22.626773834228516, r2_store:-0.3377377659699936\n",
            "Epoch [6888/10000], train_Loss: 0.013011731207370758,test_Loss:22.940107345581055, r2_store:-0.36275317217805325\n",
            "Epoch [6889/10000], train_Loss: 0.007284288294613361,test_Loss:22.74658203125, r2_store:-0.34628793704657546\n",
            "Epoch [6890/10000], train_Loss: 0.001932946965098381,test_Loss:22.792522430419922, r2_store:-0.3500918968576463\n",
            "Epoch [6891/10000], train_Loss: 0.0004117681528441608,test_Loss:22.888080596923828, r2_store:-0.3576022067223934\n",
            "Epoch [6892/10000], train_Loss: 0.0027562815230339766,test_Loss:22.701997756958008, r2_store:-0.34168477404086306\n",
            "Epoch [6893/10000], train_Loss: 0.0061557115986943245,test_Loss:22.952396392822266, r2_store:-0.3630244242881975\n",
            "Epoch [6894/10000], train_Loss: 0.007615365087985992,test_Loss:22.682449340820312, r2_store:-0.3418967487692539\n",
            "Epoch [6895/10000], train_Loss: 0.006212235428392887,test_Loss:22.874170303344727, r2_store:-0.35883176374089953\n",
            "Epoch [6896/10000], train_Loss: 0.0031861220486462116,test_Loss:22.751705169677734, r2_store:-0.3490092475507578\n",
            "Epoch [6897/10000], train_Loss: 0.0007811289979144931,test_Loss:22.755069732666016, r2_store:-0.35083625873100344\n",
            "Epoch [6898/10000], train_Loss: 0.00038411220884881914,test_Loss:22.80715560913086, r2_store:-0.3574095849823513\n",
            "Epoch [6899/10000], train_Loss: 0.001696206396445632,test_Loss:22.653789520263672, r2_store:-0.34533795937716305\n",
            "Epoch [6900/10000], train_Loss: 0.0033350319135934114,test_Loss:22.851795196533203, r2_store:-0.36052648207511084\n",
            "Epoch [6901/10000], train_Loss: 0.003963063471019268,test_Loss:22.678775787353516, r2_store:-0.345311933575265\n",
            "Epoch [6902/10000], train_Loss: 0.0032479085493832827,test_Loss:22.815895080566406, r2_store:-0.3575678708458543\n",
            "Epoch [6903/10000], train_Loss: 0.0017748603131622076,test_Loss:22.707767486572266, r2_store:-0.34995759858920605\n",
            "Epoch [6904/10000], train_Loss: 0.0005608586361631751,test_Loss:22.728580474853516, r2_store:-0.35182305962469296\n",
            "Epoch [6905/10000], train_Loss: 0.00022625461861025542,test_Loss:22.778072357177734, r2_store:-0.3553234193442376\n",
            "Epoch [6906/10000], train_Loss: 0.0007416217704303563,test_Loss:22.68114471435547, r2_store:-0.34752646933019715\n",
            "Epoch [6907/10000], train_Loss: 0.0015438348054885864,test_Loss:22.793493270874023, r2_store:-0.3579013194749916\n",
            "Epoch [6908/10000], train_Loss: 0.0020220463629812002,test_Loss:22.660709381103516, r2_store:-0.34681581712927567\n",
            "Epoch [6909/10000], train_Loss: 0.0019086062675341964,test_Loss:22.785293579101562, r2_store:-0.35657698846062047\n",
            "Epoch [6910/10000], train_Loss: 0.0013195127248764038,test_Loss:22.699016571044922, r2_store:-0.34937629214669896\n",
            "Epoch [6911/10000], train_Loss: 0.0006436623516492546,test_Loss:22.73164939880371, r2_store:-0.35318625917091406\n",
            "Epoch [6912/10000], train_Loss: 0.0002298225008416921,test_Loss:22.719356536865234, r2_store:-0.3532843495496254\n",
            "Epoch [6913/10000], train_Loss: 0.00022565913968719542,test_Loss:22.677906036376953, r2_store:-0.35005312607637706\n",
            "Epoch [6914/10000], train_Loss: 0.000515520921908319,test_Loss:22.751230239868164, r2_store:-0.3558920793748852\n",
            "Epoch [6915/10000], train_Loss: 0.0008583018789067864,test_Loss:22.664514541625977, r2_store:-0.34852293157023695\n",
            "Epoch [6916/10000], train_Loss: 0.001041101524606347,test_Loss:22.753936767578125, r2_store:-0.35604606158228025\n",
            "Epoch [6917/10000], train_Loss: 0.0009750098688527942,test_Loss:22.675662994384766, r2_store:-0.34917871002958845\n",
            "Epoch [6918/10000], train_Loss: 0.0007194450008682907,test_Loss:22.740436553955078, r2_store:-0.3543101059508291\n",
            "Epoch [6919/10000], train_Loss: 0.0004185102880001068,test_Loss:22.70403480529785, r2_store:-0.351193618192601\n",
            "Epoch [6920/10000], train_Loss: 0.00021046253095846623,test_Loss:22.713022232055664, r2_store:-0.3518660365074431\n",
            "Epoch [6921/10000], train_Loss: 0.00015993478882592171,test_Loss:22.73322105407715, r2_store:-0.3532876227518149\n",
            "Epoch [6922/10000], train_Loss: 0.00024346057034563273,test_Loss:22.697189331054688, r2_store:-0.35001526012064144\n",
            "Epoch [6923/10000], train_Loss: 0.00038791957194916904,test_Loss:22.74974250793457, r2_store:-0.3544574849069029\n",
            "Epoch [6924/10000], train_Loss: 0.0005057483213022351,test_Loss:22.686269760131836, r2_store:-0.34938060870534304\n",
            "Epoch [6925/10000], train_Loss: 0.0005400319932959974,test_Loss:22.743661880493164, r2_store:-0.35437995763481567\n",
            "Epoch [6926/10000], train_Loss: 0.0004842983034905046,test_Loss:22.690841674804688, r2_store:-0.35000535014690604\n",
            "Epoch [6927/10000], train_Loss: 0.00037114653969183564,test_Loss:22.730525970458984, r2_store:-0.35330327187544075\n",
            "Epoch [6928/10000], train_Loss: 0.00025076462770812213,test_Loss:22.7082576751709, r2_store:-0.35124566423676007\n",
            "Epoch [6929/10000], train_Loss: 0.0001663518778514117,test_Loss:22.718841552734375, r2_store:-0.351827700441671\n",
            "Epoch [6930/10000], train_Loss: 0.00013971756561659276,test_Loss:22.730266571044922, r2_store:-0.3525243364557755\n",
            "Epoch [6931/10000], train_Loss: 0.00016377228894270957,test_Loss:22.70903968811035, r2_store:-0.35070922190288445\n",
            "Epoch [6932/10000], train_Loss: 0.00021520380687434226,test_Loss:22.739301681518555, r2_store:-0.35337359272472746\n",
            "Epoch [6933/10000], train_Loss: 0.0002671286347322166,test_Loss:22.700448989868164, r2_store:-0.35014284368172954\n",
            "Epoch [6934/10000], train_Loss: 0.000300508487271145,test_Loss:22.7418270111084, r2_store:-0.35351825507286816\n",
            "Epoch [6935/10000], train_Loss: 0.00030237252940423787,test_Loss:22.703144073486328, r2_store:-0.35018963860259955\n",
            "Epoch [6936/10000], train_Loss: 0.0002782895171549171,test_Loss:22.736984252929688, r2_store:-0.3531044828750778\n",
            "Epoch [6937/10000], train_Loss: 0.00023557935492135584,test_Loss:22.7084903717041, r2_store:-0.3507400710263737\n",
            "Epoch [6938/10000], train_Loss: 0.00018931282102130353,test_Loss:22.72943687438965, r2_store:-0.35240804017399885\n",
            "Epoch [6939/10000], train_Loss: 0.0001512633461970836,test_Loss:22.720264434814453, r2_store:-0.35153653960880016\n",
            "Epoch [6940/10000], train_Loss: 0.00013010653492528945,test_Loss:22.722341537475586, r2_store:-0.3516979117026382\n",
            "Epoch [6941/10000], train_Loss: 0.00012593684368766844,test_Loss:22.729223251342773, r2_store:-0.35223799449938964\n",
            "Epoch [6942/10000], train_Loss: 0.00013544407556764781,test_Loss:22.717967987060547, r2_store:-0.35108317377550136\n",
            "Epoch [6943/10000], train_Loss: 0.00015203552902676165,test_Loss:22.739343643188477, r2_store:-0.35267465331336356\n",
            "Epoch [6944/10000], train_Loss: 0.0001701869914541021,test_Loss:22.71648597717285, r2_store:-0.35071535735119963\n",
            "Epoch [6945/10000], train_Loss: 0.0001844836660893634,test_Loss:22.740297317504883, r2_store:-0.3528617333455253\n",
            "Epoch [6946/10000], train_Loss: 0.00019111022993456572,test_Loss:22.713666915893555, r2_store:-0.35069480349801396\n",
            "Epoch [6947/10000], train_Loss: 0.0001889285194920376,test_Loss:22.739484786987305, r2_store:-0.3528321900456399\n",
            "Epoch [6948/10000], train_Loss: 0.00018004063167609274,test_Loss:22.717960357666016, r2_store:-0.3508856475198603\n",
            "Epoch [6949/10000], train_Loss: 0.0001666243333602324,test_Loss:22.73952865600586, r2_store:-0.3525651582491751\n",
            "Epoch [6950/10000], train_Loss: 0.00015218238695524633,test_Loss:22.72463607788086, r2_store:-0.35115558481671516\n",
            "Epoch [6951/10000], train_Loss: 0.00013864834909327328,test_Loss:22.738712310791016, r2_store:-0.35221574683240187\n",
            "Epoch [6952/10000], train_Loss: 0.00012721044186037034,test_Loss:22.73062515258789, r2_store:-0.3514892206898128\n",
            "Epoch [6953/10000], train_Loss: 0.00011903909035027027,test_Loss:22.735090255737305, r2_store:-0.35187032310801025\n",
            "Epoch [6954/10000], train_Loss: 0.00011450718011474237,test_Loss:22.734745025634766, r2_store:-0.3518159114813322\n",
            "Epoch [6955/10000], train_Loss: 0.00011332069698255509,test_Loss:22.73296356201172, r2_store:-0.35157082436479103\n",
            "Epoch [6956/10000], train_Loss: 0.00011457798245828599,test_Loss:22.740341186523438, r2_store:-0.35205798171966873\n",
            "Epoch [6957/10000], train_Loss: 0.00011724872456397861,test_Loss:22.73300552368164, r2_store:-0.3513145554253154\n",
            "Epoch [6958/10000], train_Loss: 0.0001208637622767128,test_Loss:22.744441986083984, r2_store:-0.35222199752556427\n",
            "Epoch [6959/10000], train_Loss: 0.0001248250191565603,test_Loss:22.731836318969727, r2_store:-0.351173796959257\n",
            "Epoch [6960/10000], train_Loss: 0.0001282484008697793,test_Loss:22.744903564453125, r2_store:-0.3523670085851254\n",
            "Epoch [6961/10000], train_Loss: 0.00013087104889564216,test_Loss:22.729915618896484, r2_store:-0.35111053813534254\n",
            "Epoch [6962/10000], train_Loss: 0.00013279415725264698,test_Loss:22.745332717895508, r2_store:-0.35242432006620206\n",
            "Epoch [6963/10000], train_Loss: 0.00013425173528958112,test_Loss:22.730854034423828, r2_store:-0.351029987502657\n",
            "Epoch [6964/10000], train_Loss: 0.00013522870722226799,test_Loss:22.748851776123047, r2_store:-0.35241471018917303\n",
            "Epoch [6965/10000], train_Loss: 0.000135849229991436,test_Loss:22.732694625854492, r2_store:-0.35098053039447064\n",
            "Epoch [6966/10000], train_Loss: 0.0001359021116513759,test_Loss:22.74998664855957, r2_store:-0.3524225397128975\n",
            "Epoch [6967/10000], train_Loss: 0.0001357882283627987,test_Loss:22.733585357666016, r2_store:-0.3509665615802169\n",
            "Epoch [6968/10000], train_Loss: 0.00013596848293673247,test_Loss:22.750003814697266, r2_store:-0.3524464751388099\n",
            "Epoch [6969/10000], train_Loss: 0.00013655678776558489,test_Loss:22.73184585571289, r2_store:-0.3509169010292488\n",
            "Epoch [6970/10000], train_Loss: 0.0001373241830151528,test_Loss:22.750396728515625, r2_store:-0.3524302663128742\n",
            "Epoch [6971/10000], train_Loss: 0.00013845515786670148,test_Loss:22.732501983642578, r2_store:-0.3508206752381202\n",
            "Epoch [6972/10000], train_Loss: 0.00014018759247846901,test_Loss:22.752410888671875, r2_store:-0.3524484590220369\n",
            "Epoch [6973/10000], train_Loss: 0.00014255936548579484,test_Loss:22.731924057006836, r2_store:-0.35073861824796126\n",
            "Epoch [6974/10000], train_Loss: 0.00014588265912607312,test_Loss:22.753063201904297, r2_store:-0.3525411749734575\n",
            "Epoch [6975/10000], train_Loss: 0.0001505010004620999,test_Loss:22.73165512084961, r2_store:-0.35062837832775706\n",
            "Epoch [6976/10000], train_Loss: 0.0001570383319631219,test_Loss:22.756006240844727, r2_store:-0.35266549593807217\n",
            "Epoch [6977/10000], train_Loss: 0.00016526780382264405,test_Loss:22.72968292236328, r2_store:-0.3504349406773777\n",
            "Epoch [6978/10000], train_Loss: 0.00017629380454309285,test_Loss:22.758773803710938, r2_store:-0.3528239733286749\n",
            "Epoch [6979/10000], train_Loss: 0.00019034158322028816,test_Loss:22.729324340820312, r2_store:-0.3501817350171439\n",
            "Epoch [6980/10000], train_Loss: 0.00020943144045304507,test_Loss:22.7623233795166, r2_store:-0.35308349361614577\n",
            "Epoch [6981/10000], train_Loss: 0.00023326424707192928,test_Loss:22.72195816040039, r2_store:-0.3498622869216257\n",
            "Epoch [6982/10000], train_Loss: 0.00026558685931377113,test_Loss:22.765220642089844, r2_store:-0.35346273144464524\n",
            "Epoch [6983/10000], train_Loss: 0.0003073017578572035,test_Loss:22.72116470336914, r2_store:-0.3493905157882615\n",
            "Epoch [6984/10000], train_Loss: 0.00036472227657213807,test_Loss:22.775129318237305, r2_store:-0.35394685695955785\n",
            "Epoch [6985/10000], train_Loss: 0.0004407652304507792,test_Loss:22.71108055114746, r2_store:-0.348724602966463\n",
            "Epoch [6986/10000], train_Loss: 0.0005446759751066566,test_Loss:22.781780242919922, r2_store:-0.354680952502072\n",
            "Epoch [6987/10000], train_Loss: 0.0006837857654318213,test_Loss:22.704517364501953, r2_store:-0.34781553894886863\n",
            "Epoch [6988/10000], train_Loss: 0.0008773963199928403,test_Loss:22.798295974731445, r2_store:-0.3556854402079146\n",
            "Epoch [6989/10000], train_Loss: 0.0011317564640194178,test_Loss:22.683116912841797, r2_store:-0.3465420994952464\n",
            "Epoch [6990/10000], train_Loss: 0.001486053573898971,test_Loss:22.81088638305664, r2_store:-0.3570667162205141\n",
            "Epoch [6991/10000], train_Loss: 0.0019594631157815456,test_Loss:22.67729377746582, r2_store:-0.344753490299913\n",
            "Epoch [6992/10000], train_Loss: 0.0026352819986641407,test_Loss:22.84805679321289, r2_store:-0.3590843485719746\n",
            "Epoch [6993/10000], train_Loss: 0.003557016374543309,test_Loss:22.63322639465332, r2_store:-0.3424130508846488\n",
            "Epoch [6994/10000], train_Loss: 0.004869920201599598,test_Loss:22.868446350097656, r2_store:-0.36218456257419285\n",
            "Epoch [6995/10000], train_Loss: 0.006650031544268131,test_Loss:22.613998413085938, r2_store:-0.3391808517280721\n",
            "Epoch [6996/10000], train_Loss: 0.009225323796272278,test_Loss:22.941497802734375, r2_store:-0.36658037088077866\n",
            "Epoch [6997/10000], train_Loss: 0.012689337134361267,test_Loss:22.542118072509766, r2_store:-0.3349383668957209\n",
            "Epoch [6998/10000], train_Loss: 0.017574314028024673,test_Loss:22.992870330810547, r2_store:-0.37277131332938596\n",
            "Epoch [6999/10000], train_Loss: 0.023809289559721947,test_Loss:22.511457443237305, r2_store:-0.3295143609899265\n",
            "Epoch [7000/10000], train_Loss: 0.0323365144431591,test_Loss:23.115684509277344, r2_store:-0.3805283091459537\n",
            "Epoch [7001/10000], train_Loss: 0.042503613978624344,test_Loss:22.387514114379883, r2_store:-0.3238592108767826\n",
            "Epoch [7002/10000], train_Loss: 0.05480369180440903,test_Loss:23.141559600830078, r2_store:-0.38868412015723974\n",
            "Epoch [7003/10000], train_Loss: 0.0653146281838417,test_Loss:22.394763946533203, r2_store:-0.32018736145446036\n",
            "Epoch [7004/10000], train_Loss: 0.07393933087587357,test_Loss:23.252872467041016, r2_store:-0.39090939174449435\n",
            "Epoch [7005/10000], train_Loss: 0.07333407551050186,test_Loss:22.355770111083984, r2_store:-0.3221496778213726\n",
            "Epoch [7006/10000], train_Loss: 0.06421796977519989,test_Loss:23.03327178955078, r2_store:-0.38145723489217653\n",
            "Epoch [7007/10000], train_Loss: 0.04467391222715378,test_Loss:22.559486389160156, r2_store:-0.3331866021114436\n",
            "Epoch [7008/10000], train_Loss: 0.023011479526758194,test_Loss:22.946269989013672, r2_store:-0.3613906993614564\n",
            "Epoch [7009/10000], train_Loss: 0.006334297358989716,test_Loss:22.76680564880371, r2_store:-0.350932602851006\n",
            "Epoch [7010/10000], train_Loss: 0.00042636977741494775,test_Loss:22.651348114013672, r2_store:-0.34239774769635534\n",
            "Epoch [7011/10000], train_Loss: 0.005327875260263681,test_Loss:23.025646209716797, r2_store:-0.3680579904229473\n",
            "Epoch [7012/10000], train_Loss: 0.015009981580078602,test_Loss:22.667720794677734, r2_store:-0.3332815175548367\n",
            "Epoch [7013/10000], train_Loss: 0.022912826389074326,test_Loss:23.109737396240234, r2_store:-0.3723230134717701\n",
            "Epoch [7014/10000], train_Loss: 0.02332467958331108,test_Loss:22.60334587097168, r2_store:-0.33582027735923403\n",
            "Epoch [7015/10000], train_Loss: 0.017126698046922684,test_Loss:22.913978576660156, r2_store:-0.36391858308049185\n",
            "Epoch [7016/10000], train_Loss: 0.007806612644344568,test_Loss:22.767351150512695, r2_store:-0.34816249750958783\n",
            "Epoch [7017/10000], train_Loss: 0.0016336612170562148,test_Loss:22.782611846923828, r2_store:-0.349455417848358\n",
            "Epoch [7018/10000], train_Loss: 0.0007850442198105156,test_Loss:22.880939483642578, r2_store:-0.3603603121545791\n",
            "Epoch [7019/10000], train_Loss: 0.004696846008300781,test_Loss:22.653799057006836, r2_store:-0.3399327586844427\n",
            "Epoch [7020/10000], train_Loss: 0.009233566001057625,test_Loss:22.99725341796875, r2_store:-0.3661414476805209\n",
            "Epoch [7021/10000], train_Loss: 0.011263991706073284,test_Loss:22.70303726196289, r2_store:-0.3397215628330281\n",
            "Epoch [7022/10000], train_Loss: 0.009580714628100395,test_Loss:22.94721221923828, r2_store:-0.36109579804220315\n",
            "Epoch [7023/10000], train_Loss: 0.005490229465067387,test_Loss:22.767396926879883, r2_store:-0.3467390266048005\n",
            "Epoch [7024/10000], train_Loss: 0.00180653331335634,test_Loss:22.82626724243164, r2_store:-0.35230175499409944\n",
            "Epoch [7025/10000], train_Loss: 0.00029845748213119805,test_Loss:22.86643409729004, r2_store:-0.3568474108239277\n",
            "Epoch [7026/10000], train_Loss: 0.001388733391650021,test_Loss:22.713062286376953, r2_store:-0.345248319556102\n",
            "Epoch [7027/10000], train_Loss: 0.0035327605437487364,test_Loss:22.901033401489258, r2_store:-0.36189936806526846\n",
            "Epoch [7028/10000], train_Loss: 0.00523008219897747,test_Loss:22.696918487548828, r2_store:-0.3436266174315592\n",
            "Epoch [7029/10000], train_Loss: 0.005253578536212444,test_Loss:22.888622283935547, r2_store:-0.3608321594334567\n",
            "Epoch [7030/10000], train_Loss: 0.003830683883279562,test_Loss:22.700965881347656, r2_store:-0.34760950244508293\n",
            "Epoch [7031/10000], train_Loss: 0.0018733959877863526,test_Loss:22.774974822998047, r2_store:-0.3547225403517822\n",
            "Epoch [7032/10000], train_Loss: 0.0005368785350583494,test_Loss:22.78579330444336, r2_store:-0.353311285636146\n",
            "Epoch [7033/10000], train_Loss: 0.0002898707170970738,test_Loss:22.745960235595703, r2_store:-0.3488276411053879\n",
            "Epoch [7034/10000], train_Loss: 0.0010013155406340957,test_Loss:22.82794952392578, r2_store:-0.3580488895245457\n",
            "Epoch [7035/10000], train_Loss: 0.001951319514773786,test_Loss:22.665706634521484, r2_store:-0.34631767588712026\n",
            "Epoch [7036/10000], train_Loss: 0.002567786956205964,test_Loss:22.823410034179688, r2_store:-0.3588919093521963\n",
            "Epoch [7037/10000], train_Loss: 0.002470168750733137,test_Loss:22.713603973388672, r2_store:-0.34742384267071325\n",
            "Epoch [7038/10000], train_Loss: 0.0018521040910854936,test_Loss:22.810802459716797, r2_store:-0.35655029247500525\n",
            "Epoch [7039/10000], train_Loss: 0.0010108642745763063,test_Loss:22.70785140991211, r2_store:-0.3510544381482741\n",
            "Epoch [7040/10000], train_Loss: 0.0003897270653396845,test_Loss:22.72467613220215, r2_store:-0.3527976750221882\n",
            "Epoch [7041/10000], train_Loss: 0.0001933048479259014,test_Loss:22.777719497680664, r2_store:-0.3547407770344384\n",
            "Epoch [7042/10000], train_Loss: 0.00037589791463688016,test_Loss:22.723644256591797, r2_store:-0.349670115369477\n",
            "Epoch [7043/10000], train_Loss: 0.0007737411069683731,test_Loss:22.782630920410156, r2_store:-0.35687224782219085\n",
            "Epoch [7044/10000], train_Loss: 0.0010957826161757112,test_Loss:22.671794891357422, r2_store:-0.34870084659906064\n",
            "Epoch [7045/10000], train_Loss: 0.0012286968994885683,test_Loss:22.779346466064453, r2_store:-0.35703079031874996\n",
            "Epoch [7046/10000], train_Loss: 0.0011029450688511133,test_Loss:22.707775115966797, r2_store:-0.34957621907267367\n",
            "Epoch [7047/10000], train_Loss: 0.0008256681030616164,test_Loss:22.77097511291504, r2_store:-0.35527379866644915\n",
            "Epoch [7048/10000], train_Loss: 0.0004946220433339477,test_Loss:22.716190338134766, r2_store:-0.35158954638287954\n",
            "Epoch [7049/10000], train_Loss: 0.0002544429444242269,test_Loss:22.737123489379883, r2_store:-0.35313868355869404\n",
            "Epoch [7050/10000], train_Loss: 0.00015115815040189773,test_Loss:22.75812530517578, r2_store:-0.3538616864247417\n",
            "Epoch [7051/10000], train_Loss: 0.0001957530912477523,test_Loss:22.730022430419922, r2_store:-0.3511377044632835\n",
            "Epoch [7052/10000], train_Loss: 0.0003191129653714597,test_Loss:22.7717227935791, r2_store:-0.355143048571235\n",
            "Epoch [7053/10000], train_Loss: 0.00046761808334849775,test_Loss:22.710826873779297, r2_store:-0.3501572686215202\n",
            "Epoch [7054/10000], train_Loss: 0.000559007516130805,test_Loss:22.7784366607666, r2_store:-0.3556272926242545\n",
            "Epoch [7055/10000], train_Loss: 0.0005847093416377902,test_Loss:22.716392517089844, r2_store:-0.35020031331196244\n",
            "Epoch [7056/10000], train_Loss: 0.00052709283772856,test_Loss:22.770030975341797, r2_store:-0.3549086830330628\n",
            "Epoch [7057/10000], train_Loss: 0.00042600464075803757,test_Loss:22.723487854003906, r2_store:-0.350924666485795\n",
            "Epoch [7058/10000], train_Loss: 0.0003058924921788275,test_Loss:22.758907318115234, r2_store:-0.353808833504236\n",
            "Epoch [7059/10000], train_Loss: 0.00020524408319033682,test_Loss:22.739259719848633, r2_store:-0.3521560081443531\n",
            "Epoch [7060/10000], train_Loss: 0.0001463560911361128,test_Loss:22.742637634277344, r2_store:-0.3524805744249708\n",
            "Epoch [7061/10000], train_Loss: 0.00012831445201300085,test_Loss:22.754236221313477, r2_store:-0.35311355670519373\n",
            "Epoch [7062/10000], train_Loss: 0.00015016456018202007,test_Loss:22.739973068237305, r2_store:-0.3514817307814391\n",
            "Epoch [7063/10000], train_Loss: 0.00018847969477064908,test_Loss:22.76717185974121, r2_store:-0.3539382891475018\n",
            "Epoch [7064/10000], train_Loss: 0.0002336870675208047,test_Loss:22.728065490722656, r2_store:-0.3509857845040607\n",
            "Epoch [7065/10000], train_Loss: 0.0002668021770659834,test_Loss:22.766910552978516, r2_store:-0.3542103076808698\n",
            "Epoch [7066/10000], train_Loss: 0.0002855304628610611,test_Loss:22.735204696655273, r2_store:-0.35085362969282663\n",
            "Epoch [7067/10000], train_Loss: 0.0002837672655005008,test_Loss:22.774141311645508, r2_store:-0.35413105296727254\n",
            "Epoch [7068/10000], train_Loss: 0.0002655408752616495,test_Loss:22.73341178894043, r2_store:-0.351092696208525\n",
            "Epoch [7069/10000], train_Loss: 0.0002350552676944062,test_Loss:22.76339340209961, r2_store:-0.3536524253871389\n",
            "Epoch [7070/10000], train_Loss: 0.00020165566820651293,test_Loss:22.746044158935547, r2_store:-0.35143912639780406\n",
            "Epoch [7071/10000], train_Loss: 0.000168467391631566,test_Loss:22.767139434814453, r2_store:-0.35304536176770807\n",
            "Epoch [7072/10000], train_Loss: 0.00014315618318505585,test_Loss:22.746137619018555, r2_store:-0.3519130417933949\n",
            "Epoch [7073/10000], train_Loss: 0.00012382739805616438,test_Loss:22.749649047851562, r2_store:-0.3524773131425205\n",
            "Epoch [7074/10000], train_Loss: 0.00011539381375769153,test_Loss:22.75521469116211, r2_store:-0.352335926733063\n",
            "Epoch [7075/10000], train_Loss: 0.00011209130752831697,test_Loss:22.75710105895996, r2_store:-0.3519473787432672\n",
            "Epoch [7076/10000], train_Loss: 0.0001161127001978457,test_Loss:22.763614654541016, r2_store:-0.35263157769476416\n",
            "Epoch [7077/10000], train_Loss: 0.0001218128963955678,test_Loss:22.749353408813477, r2_store:-0.3515788640565647\n",
            "Epoch [7078/10000], train_Loss: 0.00013075463357381523,test_Loss:22.768718719482422, r2_store:-0.35291362513544744\n",
            "Epoch [7079/10000], train_Loss: 0.00013846991350874305,test_Loss:22.755237579345703, r2_store:-0.3513879325628624\n",
            "Epoch [7080/10000], train_Loss: 0.00014635149273090065,test_Loss:22.77325439453125, r2_store:-0.35309313518667396\n",
            "Epoch [7081/10000], train_Loss: 0.00015204564260784537,test_Loss:22.748279571533203, r2_store:-0.351316579728268\n",
            "Epoch [7082/10000], train_Loss: 0.000157041460624896,test_Loss:22.772159576416016, r2_store:-0.35324630317340366\n",
            "Epoch [7083/10000], train_Loss: 0.0001590057509019971,test_Loss:22.754343032836914, r2_store:-0.3513116623346475\n",
            "Epoch [7084/10000], train_Loss: 0.0001602373376954347,test_Loss:22.777896881103516, r2_store:-0.3532339703977212\n",
            "Epoch [7085/10000], train_Loss: 0.00015988954692147672,test_Loss:22.75303840637207, r2_store:-0.35125696301865506\n",
            "Epoch [7086/10000], train_Loss: 0.00015942330355755985,test_Loss:22.77737045288086, r2_store:-0.3532087815954641\n",
            "Epoch [7087/10000], train_Loss: 0.0001571957691339776,test_Loss:22.758398056030273, r2_store:-0.35127544060466587\n",
            "Epoch [7088/10000], train_Loss: 0.00015558740415144712,test_Loss:22.78011703491211, r2_store:-0.35312178361701485\n",
            "Epoch [7089/10000], train_Loss: 0.00015238829655572772,test_Loss:22.756277084350586, r2_store:-0.35121709105224164\n",
            "Epoch [7090/10000], train_Loss: 0.00015034065290819854,test_Loss:22.778728485107422, r2_store:-0.35304315967493416\n",
            "Epoch [7091/10000], train_Loss: 0.00014858038048259914,test_Loss:22.759702682495117, r2_store:-0.35120106103064996\n",
            "Epoch [7092/10000], train_Loss: 0.00014823561650700867,test_Loss:22.77932357788086, r2_store:-0.35299429289008843\n",
            "Epoch [7093/10000], train_Loss: 0.00014775581075809896,test_Loss:22.756086349487305, r2_store:-0.3510947690283317\n",
            "Epoch [7094/10000], train_Loss: 0.00014879219816066325,test_Loss:22.781414031982422, r2_store:-0.352947367127443\n",
            "Epoch [7095/10000], train_Loss: 0.00014934178034309298,test_Loss:22.763113021850586, r2_store:-0.35103813164468156\n",
            "Epoch [7096/10000], train_Loss: 0.0001519186480436474,test_Loss:22.784347534179688, r2_store:-0.35300291832230024\n",
            "Epoch [7097/10000], train_Loss: 0.0001541885721962899,test_Loss:22.755678176879883, r2_store:-0.35097158736333345\n",
            "Epoch [7098/10000], train_Loss: 0.0001593364286236465,test_Loss:22.78323745727539, r2_store:-0.353128014329809\n",
            "Epoch [7099/10000], train_Loss: 0.00016564514953643084,test_Loss:22.76160430908203, r2_store:-0.3508577308544212\n",
            "Epoch [7100/10000], train_Loss: 0.00017685418424662203,test_Loss:22.78849983215332, r2_store:-0.3532890024365296\n",
            "Epoch [7101/10000], train_Loss: 0.00018834466754924506,test_Loss:22.7515811920166, r2_store:-0.35059645577714127\n",
            "Epoch [7102/10000], train_Loss: 0.0002058680693153292,test_Loss:22.7895450592041, r2_store:-0.3534588839583299\n",
            "Epoch [7103/10000], train_Loss: 0.00022812126553617418,test_Loss:22.760372161865234, r2_store:-0.3502054215837931\n",
            "Epoch [7104/10000], train_Loss: 0.00026100996183231473,test_Loss:22.801572799682617, r2_store:-0.3537571365823884\n",
            "Epoch [7105/10000], train_Loss: 0.00030166254146024585,test_Loss:22.745100021362305, r2_store:-0.3497262916165327\n",
            "Epoch [7106/10000], train_Loss: 0.0003582236240617931,test_Loss:22.799402236938477, r2_store:-0.3543055350884041\n",
            "Epoch [7107/10000], train_Loss: 0.0004341667518019676,test_Loss:22.74734115600586, r2_store:-0.3491140180752599\n",
            "Epoch [7108/10000], train_Loss: 0.0005414389888755977,test_Loss:22.818653106689453, r2_store:-0.35507510835288847\n",
            "Epoch [7109/10000], train_Loss: 0.0006886721821501851,test_Loss:22.727455139160156, r2_store:-0.3481610464860838\n",
            "Epoch [7110/10000], train_Loss: 0.0008935434743762016,test_Loss:22.821556091308594, r2_store:-0.3562420020826673\n",
            "Epoch [7111/10000], train_Loss: 0.0011845475528389215,test_Loss:22.722867965698242, r2_store:-0.3468323060650804\n",
            "Epoch [7112/10000], train_Loss: 0.0015988243976607919,test_Loss:22.858461380004883, r2_store:-0.3578789032374987\n",
            "Epoch [7113/10000], train_Loss: 0.0021818820387125015,test_Loss:22.690507888793945, r2_store:-0.3447356304717799\n",
            "Epoch [7114/10000], train_Loss: 0.0030499123968183994,test_Loss:22.878808975219727, r2_store:-0.36041779952176567\n",
            "Epoch [7115/10000], train_Loss: 0.004275589250028133,test_Loss:22.672327041625977, r2_store:-0.3419601309132414\n",
            "Epoch [7116/10000], train_Loss: 0.006084228400141001,test_Loss:22.936687469482422, r2_store:-0.36439154100000937\n",
            "Epoch [7117/10000], train_Loss: 0.008658732287585735,test_Loss:22.60221290588379, r2_store:-0.33787012524332805\n",
            "Epoch [7118/10000], train_Loss: 0.012543139979243279,test_Loss:22.987144470214844, r2_store:-0.37033970633376967\n",
            "Epoch [7119/10000], train_Loss: 0.017991533502936363,test_Loss:22.560266494750977, r2_store:-0.3321178989252829\n",
            "Epoch [7120/10000], train_Loss: 0.02604058012366295,test_Loss:23.113319396972656, r2_store:-0.3788339596663213\n",
            "Epoch [7121/10000], train_Loss: 0.03670816123485565,test_Loss:22.430622100830078, r2_store:-0.32494615268685667\n",
            "Epoch [7122/10000], train_Loss: 0.05144532397389412,test_Loss:23.195560455322266, r2_store:-0.3895673875255252\n",
            "Epoch [7123/10000], train_Loss: 0.06759677827358246,test_Loss:22.410476684570312, r2_store:-0.31818207517154007\n",
            "Epoch [7124/10000], train_Loss: 0.0856795459985733,test_Loss:23.38026237487793, r2_store:-0.39785613916415086\n",
            "Epoch [7125/10000], train_Loss: 0.09650637209415436,test_Loss:22.361488342285156, r2_store:-0.31683920818232525\n",
            "Epoch [7126/10000], train_Loss: 0.09725304692983627,test_Loss:23.242725372314453, r2_store:-0.3938892413051571\n",
            "Epoch [7127/10000], train_Loss: 0.07907095551490784,test_Loss:22.49928855895996, r2_store:-0.326206760813319\n",
            "Epoch [7128/10000], train_Loss: 0.05026445537805557,test_Loss:23.048236846923828, r2_store:-0.3710501530481236\n",
            "Epoch [7129/10000], train_Loss: 0.01923304982483387,test_Loss:22.7229061126709, r2_store:-0.3467961423913617\n",
            "Epoch [7130/10000], train_Loss: 0.0018951952224597335,test_Loss:22.697124481201172, r2_store:-0.34406693997207594\n",
            "Epoch [7131/10000], train_Loss: 0.003989511635154486,test_Loss:23.07796287536621, r2_store:-0.3701219806658733\n",
            "Epoch [7132/10000], train_Loss: 0.018560513854026794,test_Loss:22.655920028686523, r2_store:-0.33054347424946706\n",
            "Epoch [7133/10000], train_Loss: 0.03227861970663071,test_Loss:23.199840545654297, r2_store:-0.37747776954992474\n",
            "Epoch [7134/10000], train_Loss: 0.03350798040628433,test_Loss:22.67562484741211, r2_store:-0.33438617793026904\n",
            "Epoch [7135/10000], train_Loss: 0.022926799952983856,test_Loss:23.03957176208496, r2_store:-0.3651351512668779\n",
            "Epoch [7136/10000], train_Loss: 0.008252684958279133,test_Loss:22.87248420715332, r2_store:-0.35177599289635486\n",
            "Epoch [7137/10000], train_Loss: 0.0007268771296367049,test_Loss:22.77810287475586, r2_store:-0.3462228491386994\n",
            "Epoch [7138/10000], train_Loss: 0.003607837948948145,test_Loss:23.02133560180664, r2_store:-0.3673865784621615\n",
            "Epoch [7139/10000], train_Loss: 0.011897807009518147,test_Loss:22.696535110473633, r2_store:-0.3366575159421563\n",
            "Epoch [7140/10000], train_Loss: 0.017207253724336624,test_Loss:23.09513282775879, r2_store:-0.3689767965556483\n",
            "Epoch [7141/10000], train_Loss: 0.015070924535393715,test_Loss:22.743406295776367, r2_store:-0.34143866089272\n",
            "Epoch [7142/10000], train_Loss: 0.00797302182763815,test_Loss:22.909393310546875, r2_store:-0.35715598020393724\n",
            "Epoch [7143/10000], train_Loss: 0.0017777455504983664,test_Loss:22.895109176635742, r2_store:-0.35473232435298985\n",
            "Epoch [7144/10000], train_Loss: 0.0006677194032818079,test_Loss:22.790464401245117, r2_store:-0.34516591583948664\n",
            "Epoch [7145/10000], train_Loss: 0.00411862600594759,test_Loss:23.00160026550293, r2_store:-0.3649036770445091\n",
            "Epoch [7146/10000], train_Loss: 0.008004042319953442,test_Loss:22.698274612426758, r2_store:-0.3415137005714406\n",
            "Epoch [7147/10000], train_Loss: 0.00893096812069416,test_Loss:22.959001541137695, r2_store:-0.3634594211266666\n",
            "Epoch [7148/10000], train_Loss: 0.0062851859256625175,test_Loss:22.787635803222656, r2_store:-0.3470044412770563\n",
            "Epoch [7149/10000], train_Loss: 0.002546433126553893,test_Loss:22.86038589477539, r2_store:-0.3543107805843677\n",
            "Epoch [7150/10000], train_Loss: 0.0004112270544283092,test_Loss:22.848642349243164, r2_store:-0.3565037823797408\n",
            "Epoch [7151/10000], train_Loss: 0.0009662726079113781,test_Loss:22.719465255737305, r2_store:-0.3465622818436813\n",
            "Epoch [7152/10000], train_Loss: 0.0030661839991807938,test_Loss:22.923927307128906, r2_store:-0.36232922820431734\n",
            "Epoch [7153/10000], train_Loss: 0.004629975184798241,test_Loss:22.731042861938477, r2_store:-0.34533983593759054\n",
            "Epoch [7154/10000], train_Loss: 0.0044995201751589775,test_Loss:22.89315414428711, r2_store:-0.36058263660265255\n",
            "Epoch [7155/10000], train_Loss: 0.002861643675714731,test_Loss:22.746856689453125, r2_store:-0.3502698321633304\n",
            "Epoch [7156/10000], train_Loss: 0.0010746947955340147,test_Loss:22.79235076904297, r2_store:-0.3544834511575121\n",
            "Epoch [7157/10000], train_Loss: 0.00025011057732626796,test_Loss:22.827434539794922, r2_store:-0.3569774337778784\n",
            "Epoch [7158/10000], train_Loss: 0.000690583954565227,test_Loss:22.72921371459961, r2_store:-0.34906707975089923\n",
            "Epoch [7159/10000], train_Loss: 0.0017228645738214254,test_Loss:22.853130340576172, r2_store:-0.3602464525684541\n",
            "Epoch [7160/10000], train_Loss: 0.0024532945826649666,test_Loss:22.71026039123535, r2_store:-0.34796771857930353\n",
            "Epoch [7161/10000], train_Loss: 0.0023675982374697924,test_Loss:22.84878921508789, r2_store:-0.3589758500400724\n",
            "Epoch [7162/10000], train_Loss: 0.0016077619511634111,test_Loss:22.755422592163086, r2_store:-0.35110197591083114\n",
            "Epoch [7163/10000], train_Loss: 0.0007154667982831597,test_Loss:22.78829574584961, r2_store:-0.3547862034435787\n",
            "Epoch [7164/10000], train_Loss: 0.000230300662224181,test_Loss:22.79167366027832, r2_store:-0.3556927186136991\n",
            "Epoch [7165/10000], train_Loss: 0.0003229665744584054,test_Loss:22.738862991333008, r2_store:-0.3512162579780942\n",
            "Epoch [7166/10000], train_Loss: 0.0007758543943054974,test_Loss:22.826366424560547, r2_store:-0.3585740462678655\n",
            "Epoch [7167/10000], train_Loss: 0.0011993811931461096,test_Loss:22.721839904785156, r2_store:-0.3499015266822483\n",
            "Epoch [7168/10000], train_Loss: 0.001307184575125575,test_Loss:22.819957733154297, r2_store:-0.35809437855783877\n",
            "Epoch [7169/10000], train_Loss: 0.001064238022081554,test_Loss:22.74359703063965, r2_store:-0.3513666180519637\n",
            "Epoch [7170/10000], train_Loss: 0.0006413692026399076,test_Loss:22.79363250732422, r2_store:-0.3556389254205119\n",
            "Epoch [7171/10000], train_Loss: 0.00029416492907330394,test_Loss:22.773338317871094, r2_store:-0.35421976329088833\n",
            "Epoch [7172/10000], train_Loss: 0.00017051855684258044,test_Loss:22.758220672607422, r2_store:-0.3527862973381408\n",
            "Epoch [7173/10000], train_Loss: 0.0002764953242149204,test_Loss:22.81058692932129, r2_store:-0.35650256627295285\n",
            "Epoch [7174/10000], train_Loss: 0.00048609235091134906,test_Loss:22.753881454467773, r2_store:-0.3512477298521546\n",
            "Epoch [7175/10000], train_Loss: 0.0006595192244276404,test_Loss:22.82098388671875, r2_store:-0.3571726075572188\n",
            "Epoch [7176/10000], train_Loss: 0.0006949030794203281,test_Loss:22.748924255371094, r2_store:-0.35133645160050087\n",
            "Epoch [7177/10000], train_Loss: 0.0005902519915252924,test_Loss:22.807926177978516, r2_store:-0.3560740462236469\n",
            "Epoch [7178/10000], train_Loss: 0.00040816672844812274,test_Loss:22.77133560180664, r2_store:-0.35268064747845185\n",
            "Epoch [7179/10000], train_Loss: 0.00024322672106791288,test_Loss:22.78725242614746, r2_store:-0.35419306908697434\n",
            "Epoch [7180/10000], train_Loss: 0.0001561183453304693,test_Loss:22.786075592041016, r2_store:-0.35432146138985576\n",
            "Epoch [7181/10000], train_Loss: 0.0001639687834540382,test_Loss:22.768115997314453, r2_store:-0.35248775100947394\n",
            "Epoch [7182/10000], train_Loss: 0.00023583756410516798,test_Loss:22.809906005859375, r2_store:-0.35546812780825743\n",
            "Epoch [7183/10000], train_Loss: 0.00032021082006394863,test_Loss:22.7663631439209, r2_store:-0.35174873897201686\n",
            "Epoch [7184/10000], train_Loss: 0.0003714204649440944,test_Loss:22.808025360107422, r2_store:-0.35573600384405135\n",
            "Epoch [7185/10000], train_Loss: 0.0003674327745102346,test_Loss:22.76215934753418, r2_store:-0.35200459195095957\n",
            "Epoch [7186/10000], train_Loss: 0.00031733018113300204,test_Loss:22.803707122802734, r2_store:-0.3551307491352056\n",
            "Epoch [7187/10000], train_Loss: 0.0002436060894979164,test_Loss:22.780941009521484, r2_store:-0.3528696124087265\n",
            "Epoch [7188/10000], train_Loss: 0.00017727988597471267,test_Loss:22.79412269592285, r2_store:-0.35403641550232856\n",
            "Epoch [7189/10000], train_Loss: 0.00013761672016698867,test_Loss:22.79142189025879, r2_store:-0.3538772810698749\n",
            "Epoch [7190/10000], train_Loss: 0.00013202404079493135,test_Loss:22.784542083740234, r2_store:-0.3530457704304075\n",
            "Epoch [7191/10000], train_Loss: 0.00015168599202297628,test_Loss:22.8076171875, r2_store:-0.35463422219211016\n",
            "Epoch [7192/10000], train_Loss: 0.00018278374045621604,test_Loss:22.78116798400879, r2_store:-0.35241613371562974\n",
            "Epoch [7193/10000], train_Loss: 0.00020857418712694198,test_Loss:22.811010360717773, r2_store:-0.35487273210789105\n",
            "Epoch [7194/10000], train_Loss: 0.000220002795686014,test_Loss:22.784387588500977, r2_store:-0.35233721102367044\n",
            "Epoch [7195/10000], train_Loss: 0.00021337010548450053,test_Loss:22.814250946044922, r2_store:-0.3546883421807798\n",
            "Epoch [7196/10000], train_Loss: 0.00019298301776871085,test_Loss:22.79067611694336, r2_store:-0.3526699938214328\n",
            "Epoch [7197/10000], train_Loss: 0.0001654956431593746,test_Loss:22.808427810668945, r2_store:-0.35413966460433977\n",
            "Epoch [7198/10000], train_Loss: 0.00014048410230316222,test_Loss:22.799854278564453, r2_store:-0.3532345735979734\n",
            "Epoch [7199/10000], train_Loss: 0.00012322371185291559,test_Loss:22.80526351928711, r2_store:-0.3535653577788569\n",
            "Epoch [7200/10000], train_Loss: 0.00011667454236885533,test_Loss:22.807695388793945, r2_store:-0.35380756829690796\n",
            "Epoch [7201/10000], train_Loss: 0.00011902143887709826,test_Loss:22.798877716064453, r2_store:-0.35309485965022924\n",
            "Epoch [7202/10000], train_Loss: 0.00012721425446216017,test_Loss:22.813461303710938, r2_store:-0.35419944567778394\n",
            "Epoch [7203/10000], train_Loss: 0.00013639344251714647,test_Loss:22.798725128173828, r2_store:-0.352846597182497\n",
            "Epoch [7204/10000], train_Loss: 0.00014377085608430207,test_Loss:22.815181732177734, r2_store:-0.35435121538887016\n",
            "Epoch [7205/10000], train_Loss: 0.00014681574248243123,test_Loss:22.795915603637695, r2_store:-0.3527646222146963\n",
            "Epoch [7206/10000], train_Loss: 0.00014558776456397027,test_Loss:22.814922332763672, r2_store:-0.3542476518358495\n",
            "Epoch [7207/10000], train_Loss: 0.0001404593203915283,test_Loss:22.800146102905273, r2_store:-0.352838043574341\n",
            "Epoch [7208/10000], train_Loss: 0.0001327670324826613,test_Loss:22.813831329345703, r2_store:-0.3539911391116002\n",
            "Epoch [7209/10000], train_Loss: 0.0001244421291630715,test_Loss:22.802406311035156, r2_store:-0.3529836699711495\n",
            "Epoch [7210/10000], train_Loss: 0.00011664764315355569,test_Loss:22.811893463134766, r2_store:-0.3536564606546009\n",
            "Epoch [7211/10000], train_Loss: 0.00011055010691052303,test_Loss:22.80828094482422, r2_store:-0.3531668300208062\n",
            "Epoch [7212/10000], train_Loss: 0.0001064148818841204,test_Loss:22.809772491455078, r2_store:-0.35336762925780696\n",
            "Epoch [7213/10000], train_Loss: 0.0001040195711539127,test_Loss:22.809097290039062, r2_store:-0.35333066769033605\n",
            "Epoch [7214/10000], train_Loss: 0.000103125894383993,test_Loss:22.80801773071289, r2_store:-0.35310348365719957\n",
            "Epoch [7215/10000], train_Loss: 0.00010344397742301226,test_Loss:22.813920974731445, r2_store:-0.3534664586391043\n",
            "Epoch [7216/10000], train_Loss: 0.00010452074639033526,test_Loss:22.80608558654785, r2_store:-0.3529175517503056\n",
            "Epoch [7217/10000], train_Loss: 0.0001059083006111905,test_Loss:22.813343048095703, r2_store:-0.35354492141775307\n",
            "Epoch [7218/10000], train_Loss: 0.00010715109237935394,test_Loss:22.806293487548828, r2_store:-0.35278919749977433\n",
            "Epoch [7219/10000], train_Loss: 0.00010799630399560556,test_Loss:22.81585693359375, r2_store:-0.3535775390568694\n",
            "Epoch [7220/10000], train_Loss: 0.00010837232548510656,test_Loss:22.804332733154297, r2_store:-0.35270548812649993\n",
            "Epoch [7221/10000], train_Loss: 0.00010812656546477228,test_Loss:22.815242767333984, r2_store:-0.35351192308239576\n",
            "Epoch [7222/10000], train_Loss: 0.00010749445209512487,test_Loss:22.807815551757812, r2_store:-0.3526548454984533\n",
            "Epoch [7223/10000], train_Loss: 0.00010646113514667377,test_Loss:22.8164119720459, r2_store:-0.35343192108154775\n",
            "Epoch [7224/10000], train_Loss: 0.00010468382242834195,test_Loss:22.804805755615234, r2_store:-0.3526501742703476\n",
            "Epoch [7225/10000], train_Loss: 0.00010322227899450809,test_Loss:22.814350128173828, r2_store:-0.35333590978424945\n",
            "Epoch [7226/10000], train_Loss: 0.00010160086821997538,test_Loss:22.810461044311523, r2_store:-0.352629876223032\n",
            "Epoch [7227/10000], train_Loss: 0.0001001782511593774,test_Loss:22.81876564025879, r2_store:-0.35322814334327046\n",
            "Epoch [7228/10000], train_Loss: 9.882607264444232e-05,test_Loss:22.81008529663086, r2_store:-0.3526076968877041\n",
            "Epoch [7229/10000], train_Loss: 9.768521704245359e-05,test_Loss:22.818029403686523, r2_store:-0.3531543022057775\n",
            "Epoch [7230/10000], train_Loss: 9.618840704206377e-05,test_Loss:22.814395904541016, r2_store:-0.3526296163898548\n",
            "Epoch [7231/10000], train_Loss: 9.528957161819562e-05,test_Loss:22.818880081176758, r2_store:-0.3530793422574021\n",
            "Epoch [7232/10000], train_Loss: 9.400502312928438e-05,test_Loss:22.811452865600586, r2_store:-0.3525943087252399\n",
            "Epoch [7233/10000], train_Loss: 9.3354559794534e-05,test_Loss:22.817949295043945, r2_store:-0.3529999582589509\n",
            "Epoch [7234/10000], train_Loss: 9.224087989423424e-05,test_Loss:22.81462860107422, r2_store:-0.3525701215469066\n",
            "Epoch [7235/10000], train_Loss: 9.178963955491781e-05,test_Loss:22.818723678588867, r2_store:-0.35293909855174577\n",
            "Epoch [7236/10000], train_Loss: 9.09998852876015e-05,test_Loss:22.814382553100586, r2_store:-0.3525158130155519\n",
            "Epoch [7237/10000], train_Loss: 9.041022713063285e-05,test_Loss:22.821279525756836, r2_store:-0.3529072328224643\n",
            "Epoch [7238/10000], train_Loss: 9.005203901324421e-05,test_Loss:22.816970825195312, r2_store:-0.3524715228633024\n",
            "Epoch [7239/10000], train_Loss: 8.964192238636315e-05,test_Loss:22.82196617126465, r2_store:-0.3528651926191677\n",
            "Epoch [7240/10000], train_Loss: 8.956607052823529e-05,test_Loss:22.816959381103516, r2_store:-0.3523576645241855\n",
            "Epoch [7241/10000], train_Loss: 8.959523256635293e-05,test_Loss:22.82378578186035, r2_store:-0.3528424173255731\n",
            "Epoch [7242/10000], train_Loss: 8.96938145160675e-05,test_Loss:22.815690994262695, r2_store:-0.35226851925505787\n",
            "Epoch [7243/10000], train_Loss: 8.991310460260138e-05,test_Loss:22.82218360900879, r2_store:-0.35287337679174846\n",
            "Epoch [7244/10000], train_Loss: 9.074591071112081e-05,test_Loss:22.815135955810547, r2_store:-0.3521761162204309\n",
            "Epoch [7245/10000], train_Loss: 9.15331911528483e-05,test_Loss:22.82665252685547, r2_store:-0.35291290588222646\n",
            "Epoch [7246/10000], train_Loss: 9.28232548176311e-05,test_Loss:22.817203521728516, r2_store:-0.352049602695214\n",
            "Epoch [7247/10000], train_Loss: 9.507534559816122e-05,test_Loss:22.828773498535156, r2_store:-0.3530191586906899\n",
            "Epoch [7248/10000], train_Loss: 9.85276055871509e-05,test_Loss:22.815059661865234, r2_store:-0.35187743713219555\n",
            "Epoch [7249/10000], train_Loss: 0.0001038067857734859,test_Loss:22.830852508544922, r2_store:-0.3531967157546274\n",
            "Epoch [7250/10000], train_Loss: 0.00011208436626475304,test_Loss:22.810718536376953, r2_store:-0.3516007065848752\n",
            "Epoch [7251/10000], train_Loss: 0.00012421715655364096,test_Loss:22.832927703857422, r2_store:-0.35345225919444356\n",
            "Epoch [7252/10000], train_Loss: 0.00014175883552525192,test_Loss:22.808284759521484, r2_store:-0.35117755567228537\n",
            "Epoch [7253/10000], train_Loss: 0.000166740981512703,test_Loss:22.84250831604004, r2_store:-0.35382182851880173\n",
            "Epoch [7254/10000], train_Loss: 0.00020404046517796814,test_Loss:22.80449867248535, r2_store:-0.3505966973472847\n",
            "Epoch [7255/10000], train_Loss: 0.0002587924827821553,test_Loss:22.851722717285156, r2_store:-0.35448726540659226\n",
            "Epoch [7256/10000], train_Loss: 0.0003420710563659668,test_Loss:22.7950496673584, r2_store:-0.349811065929831\n",
            "Epoch [7257/10000], train_Loss: 0.0004658034013118595,test_Loss:22.86417007446289, r2_store:-0.355544072419256\n",
            "Epoch [7258/10000], train_Loss: 0.0006521049654111266,test_Loss:22.779983520507812, r2_store:-0.348572382318314\n",
            "Epoch [7259/10000], train_Loss: 0.0009323167614638805,test_Loss:22.883838653564453, r2_store:-0.3571126893353449\n",
            "Epoch [7260/10000], train_Loss: 0.001362342620268464,test_Loss:22.7580509185791, r2_store:-0.3466723001626184\n",
            "Epoch [7261/10000], train_Loss: 0.0020178183913230896,test_Loss:22.914480209350586, r2_store:-0.3596194596491835\n",
            "Epoch [7262/10000], train_Loss: 0.0030273033771663904,test_Loss:22.7255802154541, r2_store:-0.34376035461793153\n",
            "Epoch [7263/10000], train_Loss: 0.004591738805174828,test_Loss:22.964828491210938, r2_store:-0.363566171665034\n",
            "Epoch [7264/10000], train_Loss: 0.006984515581279993,test_Loss:22.671974182128906, r2_store:-0.3393363677475738\n",
            "Epoch [7265/10000], train_Loss: 0.01073121652007103,test_Loss:23.041748046875, r2_store:-0.3699490966104366\n",
            "Epoch [7266/10000], train_Loss: 0.01641196385025978,test_Loss:22.587352752685547, r2_store:-0.3327667736779498\n",
            "Epoch [7267/10000], train_Loss: 0.025374284014105797,test_Loss:23.150787353515625, r2_store:-0.37986780996163483\n",
            "Epoch [7268/10000], train_Loss: 0.03828305006027222,test_Loss:22.50354766845703, r2_store:-0.32376795795325086\n",
            "Epoch [7269/10000], train_Loss: 0.05784897133708,test_Loss:23.342649459838867, r2_store:-0.3944124797087063\n",
            "Epoch [7270/10000], train_Loss: 0.08249106258153915,test_Loss:22.340679168701172, r2_store:-0.31504277907888056\n",
            "Epoch [7271/10000], train_Loss: 0.11210618168115616,test_Loss:23.43233299255371, r2_store:-0.40860670844933966\n",
            "Epoch [7272/10000], train_Loss: 0.13321705162525177,test_Loss:22.347671508789062, r2_store:-0.31213234303154835\n",
            "Epoch [7273/10000], train_Loss: 0.13967417180538177,test_Loss:23.429054260253906, r2_store:-0.4037038125548351\n",
            "Epoch [7274/10000], train_Loss: 0.11138342320919037,test_Loss:22.44179916381836, r2_store:-0.3243630573374814\n",
            "Epoch [7275/10000], train_Loss: 0.06229683756828308,test_Loss:22.935802459716797, r2_store:-0.3698672217475689\n",
            "Epoch [7276/10000], train_Loss: 0.015126529149711132,test_Loss:22.80820083618164, r2_store:-0.35612463293324703\n",
            "Epoch [7277/10000], train_Loss: 0.001387756667099893,test_Loss:22.630889892578125, r2_store:-0.33510123647651757\n",
            "Epoch [7278/10000], train_Loss: 0.02165846712887287,test_Loss:23.261886596679688, r2_store:-0.3826780386447757\n",
            "Epoch [7279/10000], train_Loss: 0.048401035368442535,test_Loss:22.624757766723633, r2_store:-0.3245505288260362\n",
            "Epoch [7280/10000], train_Loss: 0.05460308864712715,test_Loss:23.271493911743164, r2_store:-0.37675560847754785\n",
            "Epoch [7281/10000], train_Loss: 0.03325042128562927,test_Loss:22.8512020111084, r2_store:-0.3417589744458229\n",
            "Epoch [7282/10000], train_Loss: 0.007988243363797665,test_Loss:22.908361434936523, r2_store:-0.34910470540301985\n",
            "Epoch [7283/10000], train_Loss: 0.0016483273357152939,test_Loss:23.11895751953125, r2_store:-0.36920432683119175\n",
            "Epoch [7284/10000], train_Loss: 0.015190454199910164,test_Loss:22.6927490234375, r2_store:-0.3331129309604035\n",
            "Epoch [7285/10000], train_Loss: 0.029167234897613525,test_Loss:23.199256896972656, r2_store:-0.3754512525926206\n",
            "Epoch [7286/10000], train_Loss: 0.026928206905722618,test_Loss:22.75478744506836, r2_store:-0.33913695430505664\n",
            "Epoch [7287/10000], train_Loss: 0.012434890493750572,test_Loss:22.92650604248047, r2_store:-0.355419094734283\n",
            "Epoch [7288/10000], train_Loss: 0.0015119878808036447,test_Loss:22.977798461914062, r2_store:-0.35903641382672147\n",
            "Epoch [7289/10000], train_Loss: 0.0037578013725578785,test_Loss:22.744152069091797, r2_store:-0.33802446701505295\n",
            "Epoch [7290/10000], train_Loss: 0.013228410854935646,test_Loss:23.10110855102539, r2_store:-0.36953184303877795\n",
            "Epoch [7291/10000], train_Loss: 0.017374049872159958,test_Loss:22.725833892822266, r2_store:-0.33903884509920235\n",
            "Epoch [7292/10000], train_Loss: 0.01195942796766758,test_Loss:22.967731475830078, r2_store:-0.35951865078120804\n",
            "Epoch [7293/10000], train_Loss: 0.0034521513152867556,test_Loss:22.929460525512695, r2_store:-0.35409982606328927\n",
            "Epoch [7294/10000], train_Loss: 0.0006434711394831538,test_Loss:22.827688217163086, r2_store:-0.34524484617130935\n",
            "Epoch [7295/10000], train_Loss: 0.004619934596121311,test_Loss:23.041215896606445, r2_store:-0.366291370655778\n",
            "Epoch [7296/10000], train_Loss: 0.009238647297024727,test_Loss:22.736595153808594, r2_store:-0.34238047107603364\n",
            "Epoch [7297/10000], train_Loss: 0.009126857854425907,test_Loss:22.96742057800293, r2_store:-0.362880412321281\n",
            "Epoch [7298/10000], train_Loss: 0.004697531461715698,test_Loss:22.834074020385742, r2_store:-0.35142234853628573\n",
            "Epoch [7299/10000], train_Loss: 0.0008832257008180022,test_Loss:22.817264556884766, r2_store:-0.3508420306156652\n",
            "Epoch [7300/10000], train_Loss: 0.0009973396081477404,test_Loss:22.9337158203125, r2_store:-0.36166719965072924\n",
            "Epoch [7301/10000], train_Loss: 0.0038410131819546223,test_Loss:22.73830223083496, r2_store:-0.3447050981502373\n",
            "Epoch [7302/10000], train_Loss: 0.005696774460375309,test_Loss:22.94712257385254, r2_store:-0.3628039895017139\n",
            "Epoch [7303/10000], train_Loss: 0.004597512073814869,test_Loss:22.76630401611328, r2_store:-0.34911948347381694\n",
            "Epoch [7304/10000], train_Loss: 0.001945878961123526,test_Loss:22.821866989135742, r2_store:-0.35526229914026874\n",
            "Epoch [7305/10000], train_Loss: 0.00038148858584463596,test_Loss:22.85542106628418, r2_store:-0.3580002393941635\n",
            "Epoch [7306/10000], train_Loss: 0.0009779309621080756,test_Loss:22.753454208374023, r2_store:-0.3487314792654186\n",
            "Epoch [7307/10000], train_Loss: 0.0025842408649623394,test_Loss:22.90884017944336, r2_store:-0.3622907889080973\n",
            "Epoch [7308/10000], train_Loss: 0.0033001855481415987,test_Loss:22.740432739257812, r2_store:-0.3491331826059385\n",
            "Epoch [7309/10000], train_Loss: 0.002475991379469633,test_Loss:22.847545623779297, r2_store:-0.35891565225591515\n",
            "Epoch [7310/10000], train_Loss: 0.0010180944809690118,test_Loss:22.8016414642334, r2_store:-0.3551921790106505\n",
            "Epoch [7311/10000], train_Loss: 0.0002813428873196244,test_Loss:22.772289276123047, r2_store:-0.3530288032539788\n",
            "Epoch [7312/10000], train_Loss: 0.0006802970892749727,test_Loss:22.85332679748535, r2_store:-0.36037637076591533\n",
            "Epoch [7313/10000], train_Loss: 0.0015343278646469116,test_Loss:22.735118865966797, r2_store:-0.3503420965570734\n",
            "Epoch [7314/10000], train_Loss: 0.0019182084361091256,test_Loss:22.856775283813477, r2_store:-0.3601496226995251\n",
            "Epoch [7315/10000], train_Loss: 0.0014901369577273726,test_Loss:22.769939422607422, r2_store:-0.35252577215151093\n",
            "Epoch [7316/10000], train_Loss: 0.0007115224725566804,test_Loss:22.80339813232422, r2_store:-0.35560722925264576\n",
            "Epoch [7317/10000], train_Loss: 0.0002551646321080625,test_Loss:22.813884735107422, r2_store:-0.3565219825808881\n",
            "Epoch [7318/10000], train_Loss: 0.00039801179082132876,test_Loss:22.761388778686523, r2_store:-0.3514913548689167\n",
            "Epoch [7319/10000], train_Loss: 0.000845603528432548,test_Loss:22.852458953857422, r2_store:-0.3584897295214753\n",
            "Epoch [7320/10000], train_Loss: 0.0011188676580786705,test_Loss:22.765100479125977, r2_store:-0.3509082580898786\n",
            "Epoch [7321/10000], train_Loss: 0.000984091660939157,test_Loss:22.836851119995117, r2_store:-0.35694870178020666\n",
            "Epoch [7322/10000], train_Loss: 0.0005898443050682545,test_Loss:22.798763275146484, r2_store:-0.3535540002389943\n",
            "Epoch [7323/10000], train_Loss: 0.000269505224423483,test_Loss:22.805389404296875, r2_store:-0.35393667110515725\n",
            "Epoch [7324/10000], train_Loss: 0.00023791973944753408,test_Loss:22.836200714111328, r2_store:-0.35664427572412216\n",
            "Epoch [7325/10000], train_Loss: 0.0004357735742814839,test_Loss:22.779930114746094, r2_store:-0.3519873941242986\n",
            "Epoch [7326/10000], train_Loss: 0.0006372992065735161,test_Loss:22.849138259887695, r2_store:-0.3574820777749259\n",
            "Epoch [7327/10000], train_Loss: 0.0006612910656258464,test_Loss:22.794809341430664, r2_store:-0.3523433582057658\n",
            "Epoch [7328/10000], train_Loss: 0.0005045760190114379,test_Loss:22.83977508544922, r2_store:-0.3558930279704482\n",
            "Epoch [7329/10000], train_Loss: 0.00030030275229364634,test_Loss:22.819246292114258, r2_store:-0.3542555801947067\n",
            "Epoch [7330/10000], train_Loss: 0.0001930145372170955,test_Loss:22.811540603637695, r2_store:-0.3535471886181982\n",
            "Epoch [7331/10000], train_Loss: 0.0002292067074449733,test_Loss:22.844724655151367, r2_store:-0.355963326381987\n",
            "Epoch [7332/10000], train_Loss: 0.00034036446595564485,test_Loss:22.80479621887207, r2_store:-0.3522362760953175\n",
            "Epoch [7333/10000], train_Loss: 0.00041918884380720556,test_Loss:22.85176658630371, r2_store:-0.35614809245751533\n",
            "Epoch [7334/10000], train_Loss: 0.00040682527469471097,test_Loss:22.809574127197266, r2_store:-0.35255255595170376\n",
            "Epoch [7335/10000], train_Loss: 0.0003184163651894778,test_Loss:22.839786529541016, r2_store:-0.35497229928621143\n",
            "Epoch [7336/10000], train_Loss: 0.00021911307703703642,test_Loss:22.82854461669922, r2_store:-0.3539720355024656\n",
            "Epoch [7337/10000], train_Loss: 0.000171308231074363,test_Loss:22.821470260620117, r2_store:-0.3534680553348519\n",
            "Epoch [7338/10000], train_Loss: 0.00018979798187501729,test_Loss:22.842365264892578, r2_store:-0.3552174396604104\n",
            "Epoch [7339/10000], train_Loss: 0.00024177350860554725,test_Loss:22.81595230102539, r2_store:-0.3526780814017003\n",
            "Epoch [7340/10000], train_Loss: 0.0002794861502479762,test_Loss:22.853824615478516, r2_store:-0.3555214997855236\n",
            "Epoch [7341/10000], train_Loss: 0.0002772248408291489,test_Loss:22.8255558013916, r2_store:-0.3529818654736463\n",
            "Epoch [7342/10000], train_Loss: 0.00023826425604056567,test_Loss:22.84872817993164, r2_store:-0.3549396435917964\n",
            "Epoch [7343/10000], train_Loss: 0.00018931750673800707,test_Loss:22.838077545166016, r2_store:-0.3540181059841656\n",
            "Epoch [7344/10000], train_Loss: 0.00015834142686799169,test_Loss:22.839601516723633, r2_store:-0.3540721442094359\n",
            "Epoch [7345/10000], train_Loss: 0.0001568402658449486,test_Loss:22.85065460205078, r2_store:-0.3550194075079305\n",
            "Epoch [7346/10000], train_Loss: 0.0001764422340784222,test_Loss:22.83102035522461, r2_store:-0.3534369919667708\n",
            "Epoch [7347/10000], train_Loss: 0.00019866884395014495,test_Loss:22.85344123840332, r2_store:-0.3553555440393956\n",
            "Epoch [7348/10000], train_Loss: 0.00020822565420530736,test_Loss:22.830860137939453, r2_store:-0.3533405890687493\n",
            "Epoch [7349/10000], train_Loss: 0.00019876149599440396,test_Loss:22.85110855102539, r2_store:-0.3549920941193865\n",
            "Epoch [7350/10000], train_Loss: 0.00017732531705405563,test_Loss:22.836645126342773, r2_store:-0.3537242216677632\n",
            "Epoch [7351/10000], train_Loss: 0.00015521769819315523,test_Loss:22.844078063964844, r2_store:-0.35429106018792345\n",
            "Epoch [7352/10000], train_Loss: 0.0001423001813236624,test_Loss:22.84659194946289, r2_store:-0.3543352350378892\n",
            "Epoch [7353/10000], train_Loss: 0.00014162901788949966,test_Loss:22.841442108154297, r2_store:-0.35373000356965756\n",
            "Epoch [7354/10000], train_Loss: 0.00014900369569659233,test_Loss:22.853740692138672, r2_store:-0.3547915600723919\n",
            "Epoch [7355/10000], train_Loss: 0.0001577938674017787,test_Loss:22.838077545166016, r2_store:-0.35353908424723723\n",
            "Epoch [7356/10000], train_Loss: 0.00016186991706490517,test_Loss:22.85398292541504, r2_store:-0.3549083645029889\n",
            "Epoch [7357/10000], train_Loss: 0.00015868883929215372,test_Loss:22.84039306640625, r2_store:-0.35371213765752274\n",
            "Epoch [7358/10000], train_Loss: 0.00015030740178190172,test_Loss:22.85189437866211, r2_store:-0.35464814025835034\n",
            "Epoch [7359/10000], train_Loss: 0.00013970972213428468,test_Loss:22.84505844116211, r2_store:-0.35402912733268344\n",
            "Epoch [7360/10000], train_Loss: 0.000131498760310933,test_Loss:22.84806251525879, r2_store:-0.35419682216026005\n",
            "Epoch [7361/10000], train_Loss: 0.00012789164611604065,test_Loss:22.85102081298828, r2_store:-0.35436781421763297\n",
            "Epoch [7362/10000], train_Loss: 0.00012856260582339019,test_Loss:22.84483528137207, r2_store:-0.3538430938869648\n",
            "Epoch [7363/10000], train_Loss: 0.00013146319543011487,test_Loss:22.852909088134766, r2_store:-0.3545800797209999\n",
            "Epoch [7364/10000], train_Loss: 0.00013441345072351396,test_Loss:22.843170166015625, r2_store:-0.3536771064094768\n",
            "Epoch [7365/10000], train_Loss: 0.00013509597920347005,test_Loss:22.854839324951172, r2_store:-0.35459614435280296\n",
            "Epoch [7366/10000], train_Loss: 0.00013388137449510396,test_Loss:22.84473991394043, r2_store:-0.3536935847923979\n",
            "Epoch [7367/10000], train_Loss: 0.00012968186638318002,test_Loss:22.85331916809082, r2_store:-0.3543683389167058\n",
            "Epoch [7368/10000], train_Loss: 0.00012412569776643068,test_Loss:22.84836196899414, r2_store:-0.3538292854366538\n",
            "Epoch [7369/10000], train_Loss: 0.000119507618364878,test_Loss:22.852636337280273, r2_store:-0.35406850613259233\n",
            "Epoch [7370/10000], train_Loss: 0.0001165061621577479,test_Loss:22.852306365966797, r2_store:-0.3540536235836911\n",
            "Epoch [7371/10000], train_Loss: 0.00011509030446177348,test_Loss:22.848546981811523, r2_store:-0.3538507016052337\n",
            "Epoch [7372/10000], train_Loss: 0.0001151104224845767,test_Loss:22.852962493896484, r2_store:-0.3542505340629363\n",
            "Epoch [7373/10000], train_Loss: 0.00011566509783733636,test_Loss:22.84783363342285, r2_store:-0.3537163803391994\n",
            "Epoch [7374/10000], train_Loss: 0.00011619650467764586,test_Loss:22.855205535888672, r2_store:-0.3542861890839486\n",
            "Epoch [7375/10000], train_Loss: 0.00011592847295105457,test_Loss:22.848575592041016, r2_store:-0.35364297245480514\n",
            "Epoch [7376/10000], train_Loss: 0.0001146494978456758,test_Loss:22.854694366455078, r2_store:-0.3542065262532694\n",
            "Epoch [7377/10000], train_Loss: 0.00011284947686363012,test_Loss:22.848670959472656, r2_store:-0.35365150536279377\n",
            "Epoch [7378/10000], train_Loss: 0.00011050037574023008,test_Loss:22.85422134399414, r2_store:-0.3540723912573498\n",
            "Epoch [7379/10000], train_Loss: 0.00010833523992914706,test_Loss:22.850984573364258, r2_store:-0.3536793700515566\n",
            "Epoch [7380/10000], train_Loss: 0.00010608680167933926,test_Loss:22.854694366455078, r2_store:-0.353850196184716\n",
            "Epoch [7381/10000], train_Loss: 0.00010427108645671979,test_Loss:22.85455894470215, r2_store:-0.35369792138017053\n",
            "Epoch [7382/10000], train_Loss: 0.00010304035095032305,test_Loss:22.854297637939453, r2_store:-0.35367381684941357\n",
            "Epoch [7383/10000], train_Loss: 0.00010205448052147403,test_Loss:22.854732513427734, r2_store:-0.35373794132798686\n",
            "Epoch [7384/10000], train_Loss: 0.00010135791671928018,test_Loss:22.852874755859375, r2_store:-0.3535619283088396\n",
            "Epoch [7385/10000], train_Loss: 0.00010070935968542472,test_Loss:22.85566520690918, r2_store:-0.3537559837820432\n",
            "Epoch [7386/10000], train_Loss: 0.00010033229773398489,test_Loss:22.852989196777344, r2_store:-0.3534877646113801\n",
            "Epoch [7387/10000], train_Loss: 9.965299250325188e-05,test_Loss:22.85552215576172, r2_store:-0.35372579631949885\n",
            "Epoch [7388/10000], train_Loss: 9.896171832224354e-05,test_Loss:22.852506637573242, r2_store:-0.35340974794992874\n",
            "Epoch [7389/10000], train_Loss: 9.830841008806601e-05,test_Loss:22.856426239013672, r2_store:-0.3536729841158839\n",
            "Epoch [7390/10000], train_Loss: 9.751784818945453e-05,test_Loss:22.852848052978516, r2_store:-0.35337515655000473\n",
            "Epoch [7391/10000], train_Loss: 9.660713112680241e-05,test_Loss:22.85531997680664, r2_store:-0.35362420612681866\n",
            "Epoch [7392/10000], train_Loss: 9.561936894897372e-05,test_Loss:22.853130340576172, r2_store:-0.3533708887517044\n",
            "Epoch [7393/10000], train_Loss: 9.465681068832055e-05,test_Loss:22.85623550415039, r2_store:-0.3535483697464006\n",
            "Epoch [7394/10000], train_Loss: 9.367843449581414e-05,test_Loss:22.854740142822266, r2_store:-0.35332491520269826\n",
            "Epoch [7395/10000], train_Loss: 9.283776307711378e-05,test_Loss:22.85667610168457, r2_store:-0.35343880259171434\n",
            "Epoch [7396/10000], train_Loss: 9.200593922287226e-05,test_Loss:22.855060577392578, r2_store:-0.3532888854414138\n",
            "Epoch [7397/10000], train_Loss: 9.128565579885617e-05,test_Loss:22.85589027404785, r2_store:-0.35336760555878977\n",
            "Epoch [7398/10000], train_Loss: 9.049697837326676e-05,test_Loss:22.854677200317383, r2_store:-0.35326957873776066\n",
            "Epoch [7399/10000], train_Loss: 8.963253640104085e-05,test_Loss:22.85520362854004, r2_store:-0.3533048605311304\n",
            "Epoch [7400/10000], train_Loss: 8.908966992748901e-05,test_Loss:22.854969024658203, r2_store:-0.35324519322207837\n",
            "Epoch [7401/10000], train_Loss: 8.841777162160724e-05,test_Loss:22.85544204711914, r2_store:-0.35319728363252145\n",
            "Epoch [7402/10000], train_Loss: 8.770912972977385e-05,test_Loss:22.856393814086914, r2_store:-0.3531810433830458\n",
            "Epoch [7403/10000], train_Loss: 8.71575393830426e-05,test_Loss:22.855958938598633, r2_store:-0.3530751113177355\n",
            "Epoch [7404/10000], train_Loss: 8.656628051539883e-05,test_Loss:22.857219696044922, r2_store:-0.3531388766354202\n",
            "Epoch [7405/10000], train_Loss: 8.59539068187587e-05,test_Loss:22.856266021728516, r2_store:-0.3530084357998291\n",
            "Epoch [7406/10000], train_Loss: 8.549921039957553e-05,test_Loss:22.858104705810547, r2_store:-0.3531539353351003\n",
            "Epoch [7407/10000], train_Loss: 8.527478348696604e-05,test_Loss:22.855737686157227, r2_store:-0.35295696364132345\n",
            "Epoch [7408/10000], train_Loss: 8.463577250950038e-05,test_Loss:22.85881805419922, r2_store:-0.353129938205619\n",
            "Epoch [7409/10000], train_Loss: 8.39437052491121e-05,test_Loss:22.857738494873047, r2_store:-0.35286880078077587\n",
            "Epoch [7410/10000], train_Loss: 8.373108721571043e-05,test_Loss:22.8604793548584, r2_store:-0.35310939052491075\n",
            "Epoch [7411/10000], train_Loss: 8.340136264450848e-05,test_Loss:22.855388641357422, r2_store:-0.3527737698651654\n",
            "Epoch [7412/10000], train_Loss: 8.314309525303543e-05,test_Loss:22.859149932861328, r2_store:-0.35312183995962965\n",
            "Epoch [7413/10000], train_Loss: 8.316287130583078e-05,test_Loss:22.855255126953125, r2_store:-0.3526790933655646\n",
            "Epoch [7414/10000], train_Loss: 8.349958807229996e-05,test_Loss:22.861360549926758, r2_store:-0.35311887032907796\n",
            "Epoch [7415/10000], train_Loss: 8.365428948309273e-05,test_Loss:22.855134963989258, r2_store:-0.35252472038725724\n",
            "Epoch [7416/10000], train_Loss: 8.41771179693751e-05,test_Loss:22.86409568786621, r2_store:-0.35309829779577906\n",
            "Epoch [7417/10000], train_Loss: 8.484646969009191e-05,test_Loss:22.857919692993164, r2_store:-0.3523907555922754\n",
            "Epoch [7418/10000], train_Loss: 8.59928986756131e-05,test_Loss:22.867517471313477, r2_store:-0.3531337027133994\n",
            "Epoch [7419/10000], train_Loss: 8.716577576706186e-05,test_Loss:22.856443405151367, r2_store:-0.3522701221807649\n",
            "Epoch [7420/10000], train_Loss: 8.899821114027873e-05,test_Loss:22.867523193359375, r2_store:-0.35322794746491293\n",
            "Epoch [7421/10000], train_Loss: 9.139360918197781e-05,test_Loss:22.854930877685547, r2_store:-0.3521592160083804\n",
            "Epoch [7422/10000], train_Loss: 9.44953499129042e-05,test_Loss:22.86891746520996, r2_store:-0.35333098994787004\n",
            "Epoch [7423/10000], train_Loss: 9.87079693004489e-05,test_Loss:22.85236930847168, r2_store:-0.3519703384105213\n",
            "Epoch [7424/10000], train_Loss: 0.00010452813876327127,test_Loss:22.870344161987305, r2_store:-0.3534768198082836\n",
            "Epoch [7425/10000], train_Loss: 0.00011315901065245271,test_Loss:22.850431442260742, r2_store:-0.351714445751387\n",
            "Epoch [7426/10000], train_Loss: 0.0001244210434379056,test_Loss:22.874574661254883, r2_store:-0.3536757199997602\n",
            "Epoch [7427/10000], train_Loss: 0.00014001766976434737,test_Loss:22.847578048706055, r2_store:-0.3513501839851776\n",
            "Epoch [7428/10000], train_Loss: 0.00016097693878691643,test_Loss:22.88091468811035, r2_store:-0.35395315871238475\n",
            "Epoch [7429/10000], train_Loss: 0.00018875623936764896,test_Loss:22.846717834472656, r2_store:-0.35088675926085156\n",
            "Epoch [7430/10000], train_Loss: 0.00022658126545138657,test_Loss:22.8900089263916, r2_store:-0.35438032946186193\n",
            "Epoch [7431/10000], train_Loss: 0.0002804884279612452,test_Loss:22.841020584106445, r2_store:-0.35027572068992985\n",
            "Epoch [7432/10000], train_Loss: 0.00035632605431601405,test_Loss:22.898258209228516, r2_store:-0.35510531940263745\n",
            "Epoch [7433/10000], train_Loss: 0.0004663816071115434,test_Loss:22.83112907409668, r2_store:-0.3494344607017543\n",
            "Epoch [7434/10000], train_Loss: 0.0006252130842767656,test_Loss:22.909814834594727, r2_store:-0.35621226391580185\n",
            "Epoch [7435/10000], train_Loss: 0.0008579235291108489,test_Loss:22.81239128112793, r2_store:-0.34816380744042896\n",
            "Epoch [7436/10000], train_Loss: 0.0011926876613870263,test_Loss:22.927490234375, r2_store:-0.3578271609983441\n",
            "Epoch [7437/10000], train_Loss: 0.0016792595852166414,test_Loss:22.79242706298828, r2_store:-0.34625771294357177\n",
            "Epoch [7438/10000], train_Loss: 0.002389405621215701,test_Loss:22.960529327392578, r2_store:-0.3601735444973395\n",
            "Epoch [7439/10000], train_Loss: 0.0034263990819454193,test_Loss:22.763309478759766, r2_store:-0.343495389048869\n",
            "Epoch [7440/10000], train_Loss: 0.0049588801339268684,test_Loss:23.005496978759766, r2_store:-0.3638745007462403\n",
            "Epoch [7441/10000], train_Loss: 0.007213143166154623,test_Loss:22.71648597717285, r2_store:-0.33961985948173634\n",
            "Epoch [7442/10000], train_Loss: 0.010557604022324085,test_Loss:23.071701049804688, r2_store:-0.36951092132585606\n",
            "Epoch [7443/10000], train_Loss: 0.015350090339779854,test_Loss:22.644315719604492, r2_store:-0.33413615920043216\n",
            "Epoch [7444/10000], train_Loss: 0.022390155121684074,test_Loss:23.167278289794922, r2_store:-0.37747026456658994\n",
            "Epoch [7445/10000], train_Loss: 0.031884271651506424,test_Loss:22.564096450805664, r2_store:-0.3267791280347283\n",
            "Epoch [7446/10000], train_Loss: 0.045386217534542084,test_Loss:23.293413162231445, r2_store:-0.388124569500252\n",
            "Epoch [7447/10000], train_Loss: 0.061851151287555695,test_Loss:22.47129249572754, r2_store:-0.3196182718921201\n",
            "Epoch [7448/10000], train_Loss: 0.08099903166294098,test_Loss:23.398191452026367, r2_store:-0.3984881910173479\n",
            "Epoch [7449/10000], train_Loss: 0.09500106424093246,test_Loss:22.427152633666992, r2_store:-0.3165841906273579\n",
            "Epoch [7450/10000], train_Loss: 0.10186084359884262,test_Loss:23.387371063232422, r2_store:-0.3969315560370168\n",
            "Epoch [7451/10000], train_Loss: 0.0891420841217041,test_Loss:22.514644622802734, r2_store:-0.3238025427443505\n",
            "Epoch [7452/10000], train_Loss: 0.06146606057882309,test_Loss:23.117033004760742, r2_store:-0.3753996620126443\n",
            "Epoch [7453/10000], train_Loss: 0.026843857020139694,test_Loss:22.74338150024414, r2_store:-0.344775201954576\n",
            "Epoch [7454/10000], train_Loss: 0.004083156585693359,test_Loss:22.79794692993164, r2_store:-0.3463390499827186\n",
            "Epoch [7455/10000], train_Loss: 0.0024307952262461185,test_Loss:23.132844924926758, r2_store:-0.36887268436043885\n",
            "Epoch [7456/10000], train_Loss: 0.01696046069264412,test_Loss:22.70872688293457, r2_store:-0.3295552408015623\n",
            "Epoch [7457/10000], train_Loss: 0.03305625170469284,test_Loss:23.29914665222168, r2_store:-0.377463801664238\n",
            "Epoch [7458/10000], train_Loss: 0.03644300252199173,test_Loss:22.750673294067383, r2_store:-0.33210788194229224\n",
            "Epoch [7459/10000], train_Loss: 0.025847718119621277,test_Loss:23.132129669189453, r2_store:-0.36467027318502554\n",
            "Epoch [7460/10000], train_Loss: 0.00964292325079441,test_Loss:22.936962127685547, r2_store:-0.35000726990811204\n",
            "Epoch [7461/10000], train_Loss: 0.0007586696301586926,test_Loss:22.86003303527832, r2_store:-0.34532772206765205\n",
            "Epoch [7462/10000], train_Loss: 0.0037211745511740446,test_Loss:23.123659133911133, r2_store:-0.36773459312251155\n",
            "Epoch [7463/10000], train_Loss: 0.012809881940484047,test_Loss:22.762699127197266, r2_store:-0.3359461321459287\n",
            "Epoch [7464/10000], train_Loss: 0.018796969205141068,test_Loss:23.172473907470703, r2_store:-0.36961583266012865\n",
            "Epoch [7465/10000], train_Loss: 0.016339536756277084,test_Loss:22.83514404296875, r2_store:-0.34098131328537273\n",
            "Epoch [7466/10000], train_Loss: 0.008460640907287598,test_Loss:23.01382064819336, r2_store:-0.35692067516548565\n",
            "Epoch [7467/10000], train_Loss: 0.001665560295805335,test_Loss:22.980924606323242, r2_store:-0.35497533439992535\n",
            "Epoch [7468/10000], train_Loss: 0.0007657913374714553,test_Loss:22.85262680053711, r2_store:-0.3441785967778994\n",
            "Epoch [7469/10000], train_Loss: 0.0047881389036774635,test_Loss:23.105846405029297, r2_store:-0.3653691497413596\n",
            "Epoch [7470/10000], train_Loss: 0.009050572291016579,test_Loss:22.807355880737305, r2_store:-0.3408562421116694\n",
            "Epoch [7471/10000], train_Loss: 0.009714685380458832,test_Loss:23.062082290649414, r2_store:-0.36371171186747886\n",
            "Epoch [7472/10000], train_Loss: 0.006437038071453571,test_Loss:22.85714340209961, r2_store:-0.3478189128329341\n",
            "Epoch [7473/10000], train_Loss: 0.0022343529853969812,test_Loss:22.913864135742188, r2_store:-0.3540716687157679\n",
            "Epoch [7474/10000], train_Loss: 0.0002888366288971156,test_Loss:22.949247360229492, r2_store:-0.358141772915626\n",
            "Epoch [7475/10000], train_Loss: 0.001421261695213616,test_Loss:22.80254364013672, r2_store:-0.3460165286873558\n",
            "Epoch [7476/10000], train_Loss: 0.003885691985487938,test_Loss:23.01148796081543, r2_store:-0.3631937211428775\n",
            "Epoch [7477/10000], train_Loss: 0.00529131293296814,test_Loss:22.802837371826172, r2_store:-0.3452704905566093\n",
            "Epoch [7478/10000], train_Loss: 0.00458020344376564,test_Loss:22.976463317871094, r2_store:-0.35997421254274253\n",
            "Epoch [7479/10000], train_Loss: 0.0024781678803265095,test_Loss:22.866182327270508, r2_store:-0.3511008198186929\n",
            "Epoch [7480/10000], train_Loss: 0.0006630825810134411,test_Loss:22.88502311706543, r2_store:-0.35302922339462683\n",
            "Epoch [7481/10000], train_Loss: 0.0002779937640298158,test_Loss:22.944786071777344, r2_store:-0.35827497023148913\n",
            "Epoch [7482/10000], train_Loss: 0.0011937065282836556,test_Loss:22.825180053710938, r2_store:-0.34829248976748306\n",
            "Epoch [7483/10000], train_Loss: 0.002372800838202238,test_Loss:22.979248046875, r2_store:-0.36114300193876203\n",
            "Epoch [7484/10000], train_Loss: 0.0028210256714373827,test_Loss:22.82990074157715, r2_store:-0.3484981246181642\n",
            "Epoch [7485/10000], train_Loss: 0.0022776792757213116,test_Loss:22.946386337280273, r2_store:-0.35862573539807086\n",
            "Epoch [7486/10000], train_Loss: 0.0011978581314906478,test_Loss:22.867284774780273, r2_store:-0.3527747051858763\n",
            "Epoch [7487/10000], train_Loss: 0.00036043685395270586,test_Loss:22.870437622070312, r2_store:-0.3537383878699871\n",
            "Epoch [7488/10000], train_Loss: 0.00022181085660122335,test_Loss:22.912761688232422, r2_store:-0.3574168873081174\n",
            "Epoch [7489/10000], train_Loss: 0.0006706215208396316,test_Loss:22.830188751220703, r2_store:-0.35021496742590164\n",
            "Epoch [7490/10000], train_Loss: 0.0012414497323334217,test_Loss:22.93825912475586, r2_store:-0.35916602476492154\n",
            "Epoch [7491/10000], train_Loss: 0.0014943450223654509,test_Loss:22.82680892944336, r2_store:-0.34993687459943446\n",
            "Epoch [7492/10000], train_Loss: 0.001283816760405898,test_Loss:22.91425323486328, r2_store:-0.35747302122655356\n",
            "Epoch [7493/10000], train_Loss: 0.0007838028250262141,test_Loss:22.853023529052734, r2_store:-0.3524432728261544\n",
            "Epoch [7494/10000], train_Loss: 0.00033015903318300843,test_Loss:22.872203826904297, r2_store:-0.3541384748781904\n",
            "Epoch [7495/10000], train_Loss: 0.00015867104229982942,test_Loss:22.889911651611328, r2_store:-0.3555665909686978\n",
            "Epoch [7496/10000], train_Loss: 0.0002824798575602472,test_Loss:22.844507217407227, r2_store:-0.3514836209960104\n",
            "Epoch [7497/10000], train_Loss: 0.0005479922983795404,test_Loss:22.916440963745117, r2_store:-0.357330726778587\n",
            "Epoch [7498/10000], train_Loss: 0.0007521976949647069,test_Loss:22.839130401611328, r2_store:-0.3509046092127268\n",
            "Epoch [7499/10000], train_Loss: 0.0007661040290258825,test_Loss:22.90794563293457, r2_store:-0.35699147222906147\n",
            "Epoch [7500/10000], train_Loss: 0.0005995383253321052,test_Loss:22.848058700561523, r2_store:-0.352234389927794\n",
            "Epoch [7501/10000], train_Loss: 0.0003670598962344229,test_Loss:22.88218116760254, r2_store:-0.3551066910416478\n",
            "Epoch [7502/10000], train_Loss: 0.00018908112542703748,test_Loss:22.875181198120117, r2_store:-0.3542674655399325\n",
            "Epoch [7503/10000], train_Loss: 0.00013604367268271744,test_Loss:22.863073348999023, r2_store:-0.352992148527455\n",
            "Epoch [7504/10000], train_Loss: 0.00020184142340440303,test_Loss:22.8978214263916, r2_store:-0.35580335736146695\n",
            "Epoch [7505/10000], train_Loss: 0.00031700037652626634,test_Loss:22.850778579711914, r2_store:-0.3518148311352902\n",
            "Epoch [7506/10000], train_Loss: 0.00040415796684101224,test_Loss:22.903423309326172, r2_store:-0.3561975989213624\n",
            "Epoch [7507/10000], train_Loss: 0.0004199058166705072,test_Loss:22.854066848754883, r2_store:-0.3518954404350445\n",
            "Epoch [7508/10000], train_Loss: 0.00036169597296975553,test_Loss:22.897335052490234, r2_store:-0.3554027823987609\n",
            "Epoch [7509/10000], train_Loss: 0.00026349863037467003,test_Loss:22.868925094604492, r2_store:-0.3528477791769842\n",
            "Epoch [7510/10000], train_Loss: 0.00017332204151898623,test_Loss:22.885120391845703, r2_store:-0.3540305403405941\n",
            "Epoch [7511/10000], train_Loss: 0.0001248959160875529,test_Loss:22.886335372924805, r2_store:-0.3540477019294892\n",
            "Epoch [7512/10000], train_Loss: 0.00012507832434494048,test_Loss:22.871658325195312, r2_store:-0.3528267702820187\n",
            "Epoch [7513/10000], train_Loss: 0.00015998775779735297,test_Loss:22.895906448364258, r2_store:-0.35491784306457763\n",
            "Epoch [7514/10000], train_Loss: 0.00020500218670349568,test_Loss:22.865406036376953, r2_store:-0.3522392188833925\n",
            "Epoch [7515/10000], train_Loss: 0.00023545984004158527,test_Loss:22.901241302490234, r2_store:-0.35516078905653825\n",
            "Epoch [7516/10000], train_Loss: 0.00023952177434694022,test_Loss:22.869836807250977, r2_store:-0.3523122719391001\n",
            "Epoch [7517/10000], train_Loss: 0.00021702582307625562,test_Loss:22.900508880615234, r2_store:-0.3547266527045252\n",
            "Epoch [7518/10000], train_Loss: 0.00017919480160344392,test_Loss:22.880290985107422, r2_store:-0.35288953757474695\n",
            "Epoch [7519/10000], train_Loss: 0.00014114229998085648,test_Loss:22.893495559692383, r2_store:-0.35399117332551033\n",
            "Epoch [7520/10000], train_Loss: 0.00011565693421289325,test_Loss:22.889202117919922, r2_store:-0.35364901708612106\n",
            "Epoch [7521/10000], train_Loss: 0.0001069865538738668,test_Loss:22.885250091552734, r2_store:-0.3532699381182094\n",
            "Epoch [7522/10000], train_Loss: 0.00011303372593829408,test_Loss:22.898027420043945, r2_store:-0.35426713280782485\n",
            "Epoch [7523/10000], train_Loss: 0.00012786957086063921,test_Loss:22.881189346313477, r2_store:-0.35280367824386927\n",
            "Epoch [7524/10000], train_Loss: 0.00014317269960884005,test_Loss:22.90163803100586, r2_store:-0.3545689043482867\n",
            "Epoch [7525/10000], train_Loss: 0.00015260423242580146,test_Loss:22.879655838012695, r2_store:-0.3526738097353439\n",
            "Epoch [7526/10000], train_Loss: 0.00015327701112255454,test_Loss:22.90198516845703, r2_store:-0.354504375737015\n",
            "Epoch [7527/10000], train_Loss: 0.0001462220388930291,test_Loss:22.88324737548828, r2_store:-0.35282618423425083\n",
            "Epoch [7528/10000], train_Loss: 0.00013389477680902928,test_Loss:22.899431228637695, r2_store:-0.3542001846502787\n",
            "Epoch [7529/10000], train_Loss: 0.00011997627734672278,test_Loss:22.886741638183594, r2_store:-0.3531578293191917\n",
            "Epoch [7530/10000], train_Loss: 0.00010764518810901791,test_Loss:22.894420623779297, r2_store:-0.3537865542684848\n",
            "Epoch [7531/10000], train_Loss: 9.916932322084904e-05,test_Loss:22.8927001953125, r2_store:-0.353524993235637\n",
            "Epoch [7532/10000], train_Loss: 9.58131713559851e-05,test_Loss:22.892061233520508, r2_store:-0.35337126292836274\n",
            "Epoch [7533/10000], train_Loss: 9.653115557739511e-05,test_Loss:22.89815902709961, r2_store:-0.35382647033283776\n",
            "Epoch [7534/10000], train_Loss: 9.9849326943513e-05,test_Loss:22.890174865722656, r2_store:-0.35310634078823866\n",
            "Epoch [7535/10000], train_Loss: 0.00010385004861745983,test_Loss:22.901620864868164, r2_store:-0.35403356644563355\n",
            "Epoch [7536/10000], train_Loss: 0.0001071038277586922,test_Loss:22.889698028564453, r2_store:-0.35299627697984826\n",
            "Epoch [7537/10000], train_Loss: 0.00010881099296966568,test_Loss:22.902416229248047, r2_store:-0.3540843848821007\n",
            "Epoch [7538/10000], train_Loss: 0.00010897149331867695,test_Loss:22.889469146728516, r2_store:-0.3529697287599709\n",
            "Epoch [7539/10000], train_Loss: 0.00010692547220969573,test_Loss:22.9017391204834, r2_store:-0.3539531082782099\n",
            "Epoch [7540/10000], train_Loss: 0.00010340561857447028,test_Loss:22.89175033569336, r2_store:-0.35298267956398033\n",
            "Epoch [7541/10000], train_Loss: 9.942297037923709e-05,test_Loss:22.901294708251953, r2_store:-0.35370863530306296\n",
            "Epoch [7542/10000], train_Loss: 9.536663128528744e-05,test_Loss:22.894290924072266, r2_store:-0.3530672934601806\n",
            "Epoch [7543/10000], train_Loss: 9.182922076433897e-05,test_Loss:22.89925765991211, r2_store:-0.3534949363603286\n",
            "Epoch [7544/10000], train_Loss: 8.895528299035504e-05,test_Loss:22.895668029785156, r2_store:-0.35322323460313054\n",
            "Epoch [7545/10000], train_Loss: 8.68408678798005e-05,test_Loss:22.896623611450195, r2_store:-0.353324894043882\n",
            "Epoch [7546/10000], train_Loss: 8.553209045203403e-05,test_Loss:22.897172927856445, r2_store:-0.3533645293040115\n",
            "Epoch [7547/10000], train_Loss: 8.494975190842524e-05,test_Loss:22.89490509033203, r2_store:-0.35316040363723644\n",
            "Epoch [7548/10000], train_Loss: 8.523246651748195e-05,test_Loss:22.898937225341797, r2_store:-0.3534217706311944\n",
            "Epoch [7549/10000], train_Loss: 8.55010948725976e-05,test_Loss:22.895465850830078, r2_store:-0.35297907389180905\n",
            "Epoch [7550/10000], train_Loss: 8.560166315874085e-05,test_Loss:22.90242576599121, r2_store:-0.35339234144190557\n",
            "Epoch [7551/10000], train_Loss: 8.60623549669981e-05,test_Loss:22.897184371948242, r2_store:-0.352828400698898\n",
            "Epoch [7552/10000], train_Loss: 8.641670865472406e-05,test_Loss:22.903627395629883, r2_store:-0.3533993413720846\n",
            "Epoch [7553/10000], train_Loss: 8.667711517773569e-05,test_Loss:22.895544052124023, r2_store:-0.3527853766622868\n",
            "Epoch [7554/10000], train_Loss: 8.675614662934095e-05,test_Loss:22.90270233154297, r2_store:-0.3534402996619841\n",
            "Epoch [7555/10000], train_Loss: 8.670752140460536e-05,test_Loss:22.894914627075195, r2_store:-0.3527540674109524\n",
            "Epoch [7556/10000], train_Loss: 8.644929766887799e-05,test_Loss:22.903371810913086, r2_store:-0.3534308092618694\n",
            "Epoch [7557/10000], train_Loss: 8.613762474851683e-05,test_Loss:22.895036697387695, r2_store:-0.35269021093340935\n",
            "Epoch [7558/10000], train_Loss: 8.592915401095524e-05,test_Loss:22.903430938720703, r2_store:-0.35336910954565726\n",
            "Epoch [7559/10000], train_Loss: 8.586466719862074e-05,test_Loss:22.8958683013916, r2_store:-0.352572058646188\n",
            "Epoch [7560/10000], train_Loss: 8.534210064681247e-05,test_Loss:22.906415939331055, r2_store:-0.3532819585880278\n",
            "Epoch [7561/10000], train_Loss: 8.538986730854958e-05,test_Loss:22.898067474365234, r2_store:-0.3524713828839643\n",
            "Epoch [7562/10000], train_Loss: 8.532706124242395e-05,test_Loss:22.906885147094727, r2_store:-0.35326237174451247\n",
            "Epoch [7563/10000], train_Loss: 8.533299114787951e-05,test_Loss:22.89603042602539, r2_store:-0.3524460295590044\n",
            "Epoch [7564/10000], train_Loss: 8.559228444937617e-05,test_Loss:22.905935287475586, r2_store:-0.35331434951143637\n",
            "Epoch [7565/10000], train_Loss: 8.589711796958e-05,test_Loss:22.895313262939453, r2_store:-0.3524121933503517\n",
            "Epoch [7566/10000], train_Loss: 8.620518929092214e-05,test_Loss:22.90668487548828, r2_store:-0.35332077248788174\n",
            "Epoch [7567/10000], train_Loss: 8.680556493345648e-05,test_Loss:22.89545249938965, r2_store:-0.3523195848319671\n",
            "Epoch [7568/10000], train_Loss: 8.78200662555173e-05,test_Loss:22.908206939697266, r2_store:-0.35333299823864994\n",
            "Epoch [7569/10000], train_Loss: 8.949231414590031e-05,test_Loss:22.894847869873047, r2_store:-0.3521862135301954\n",
            "Epoch [7570/10000], train_Loss: 9.201588545693085e-05,test_Loss:22.909440994262695, r2_store:-0.3533794319225121\n",
            "Epoch [7571/10000], train_Loss: 9.554447751725093e-05,test_Loss:22.89333724975586, r2_store:-0.35200978199003674\n",
            "Epoch [7572/10000], train_Loss: 0.00010061562352348119,test_Loss:22.911540985107422, r2_store:-0.353498982818774\n",
            "Epoch [7573/10000], train_Loss: 0.00010786727943923324,test_Loss:22.891347885131836, r2_store:-0.3517810221454345\n",
            "Epoch [7574/10000], train_Loss: 0.00011778031330322847,test_Loss:22.915279388427734, r2_store:-0.3536872910309523\n",
            "Epoch [7575/10000], train_Loss: 0.0001312047679675743,test_Loss:22.88970375061035, r2_store:-0.3514696960526229\n",
            "Epoch [7576/10000], train_Loss: 0.00014954814105294645,test_Loss:22.920696258544922, r2_store:-0.3539734015855929\n",
            "Epoch [7577/10000], train_Loss: 0.00017501559341326356,test_Loss:22.88582420349121, r2_store:-0.35106526609810174\n",
            "Epoch [7578/10000], train_Loss: 0.0002097881369991228,test_Loss:22.926172256469727, r2_store:-0.3544286827852461\n",
            "Epoch [7579/10000], train_Loss: 0.0002596598060335964,test_Loss:22.879358291625977, r2_store:-0.3505039080269825\n",
            "Epoch [7580/10000], train_Loss: 0.00032767298398539424,test_Loss:22.935590744018555, r2_store:-0.35507744139450925\n",
            "Epoch [7581/10000], train_Loss: 0.00042333686724305153,test_Loss:22.871000289916992, r2_store:-0.3497170114922026\n",
            "Epoch [7582/10000], train_Loss: 0.0005571329966187477,test_Loss:22.94693374633789, r2_store:-0.3560417955156363\n",
            "Epoch [7583/10000], train_Loss: 0.0007491350406780839,test_Loss:22.85679817199707, r2_store:-0.34859539570458575\n",
            "Epoch [7584/10000], train_Loss: 0.001023189863190055,test_Loss:22.965076446533203, r2_store:-0.35746581883364104\n",
            "Epoch [7585/10000], train_Loss: 0.001415627310052514,test_Loss:22.838668823242188, r2_store:-0.3469419888393537\n",
            "Epoch [7586/10000], train_Loss: 0.0019857112783938646,test_Loss:22.99165916442871, r2_store:-0.3595777584542925\n",
            "Epoch [7587/10000], train_Loss: 0.0028199341613799334,test_Loss:22.810409545898438, r2_store:-0.3444941451976087\n",
            "Epoch [7588/10000], train_Loss: 0.0040452852845191956,test_Loss:23.03262710571289, r2_store:-0.3627805186372399\n",
            "Epoch [7589/10000], train_Loss: 0.005824584048241377,test_Loss:22.769649505615234, r2_store:-0.3410166970617563\n",
            "Epoch [7590/10000], train_Loss: 0.008456416428089142,test_Loss:23.092004776000977, r2_store:-0.36763399204759795\n",
            "Epoch [7591/10000], train_Loss: 0.012215188704431057,test_Loss:22.715566635131836, r2_store:-0.3360697449266483\n",
            "Epoch [7592/10000], train_Loss: 0.01776675321161747,test_Loss:23.18020248413086, r2_store:-0.374816970589831\n",
            "Epoch [7593/10000], train_Loss: 0.025482255965471268,test_Loss:22.641674041748047, r2_store:-0.32967674571210037\n",
            "Epoch [7594/10000], train_Loss: 0.03637678176164627,test_Loss:23.300552368164062, r2_store:-0.3848784482375882\n",
            "Epoch [7595/10000], train_Loss: 0.05005323886871338,test_Loss:22.55419158935547, r2_store:-0.3228184371388765\n",
            "Epoch [7596/10000], train_Loss: 0.06688801944255829,test_Loss:23.419904708862305, r2_store:-0.3954963292432636\n",
            "Epoch [7597/10000], train_Loss: 0.08178789913654327,test_Loss:22.50121307373047, r2_store:-0.31858643792491326\n",
            "Epoch [7598/10000], train_Loss: 0.09318239986896515,test_Loss:23.449771881103516, r2_store:-0.3977600364727214\n",
            "Epoch [7599/10000], train_Loss: 0.08941160142421722,test_Loss:22.525310516357422, r2_store:-0.3228122074509132\n",
            "Epoch [7600/10000], train_Loss: 0.07125791162252426,test_Loss:23.219335556030273, r2_store:-0.3821236437122759\n",
            "Epoch [7601/10000], train_Loss: 0.04028463736176491,test_Loss:22.722850799560547, r2_store:-0.33984615176427413\n",
            "Epoch [7602/10000], train_Loss: 0.012633943930268288,test_Loss:22.926822662353516, r2_store:-0.3544918067403655\n",
            "Epoch [7603/10000], train_Loss: 0.0006498334696516395,test_Loss:23.070459365844727, r2_store:-0.3634077435570231\n",
            "Epoch [7604/10000], train_Loss: 0.006996522191911936,test_Loss:22.760107040405273, r2_store:-0.3343693465248043\n",
            "Epoch [7605/10000], train_Loss: 0.02252538874745369,test_Loss:23.310176849365234, r2_store:-0.37747738694157795\n",
            "Epoch [7606/10000], train_Loss: 0.03328482061624527,test_Loss:22.77615737915039, r2_store:-0.3311793286257807\n",
            "Epoch [7607/10000], train_Loss: 0.03170209750533104,test_Loss:23.24013328552246, r2_store:-0.3710710375201909\n",
            "Epoch [7608/10000], train_Loss: 0.018980305641889572,test_Loss:22.889385223388672, r2_store:-0.3436467812210653\n",
            "Epoch [7609/10000], train_Loss: 0.00564971100538969,test_Loss:22.980792999267578, r2_store:-0.35268799249277416\n",
            "Epoch [7610/10000], train_Loss: 0.0004638319369405508,test_Loss:23.085567474365234, r2_store:-0.36164690750138084\n",
            "Epoch [7611/10000], train_Loss: 0.004890567623078823,test_Loss:22.819820404052734, r2_store:-0.33871444803162154\n",
            "Epoch [7612/10000], train_Loss: 0.012947989627718925,test_Loss:23.19972801208496, r2_store:-0.36984569728839833\n",
            "Epoch [7613/10000], train_Loss: 0.016989806666970253,test_Loss:22.832000732421875, r2_store:-0.3377151346300531\n",
            "Epoch [7614/10000], train_Loss: 0.014171913266181946,test_Loss:23.119731903076172, r2_store:-0.3631305158047906\n",
            "Epoch [7615/10000], train_Loss: 0.007048259023576975,test_Loss:22.923847198486328, r2_store:-0.34813235234075424\n",
            "Epoch [7616/10000], train_Loss: 0.001425313064828515,test_Loss:22.93740463256836, r2_store:-0.3502039576102136\n",
            "Epoch [7617/10000], train_Loss: 0.0006830171914771199,test_Loss:23.06487274169922, r2_store:-0.3609338781122209\n",
            "Epoch [7618/10000], train_Loss: 0.00397112313657999,test_Loss:22.845762252807617, r2_store:-0.3425004868905188\n",
            "Epoch [7619/10000], train_Loss: 0.007688303478062153,test_Loss:23.100969314575195, r2_store:-0.36582585962563985\n",
            "Epoch [7620/10000], train_Loss: 0.008580895140767097,test_Loss:22.827739715576172, r2_store:-0.3439871000576884\n",
            "Epoch [7621/10000], train_Loss: 0.006262174807488918,test_Loss:23.013912200927734, r2_store:-0.3603925908140033\n",
            "Epoch [7622/10000], train_Loss: 0.002680384088307619,test_Loss:22.91153907775879, r2_store:-0.35214506234645415\n",
            "Epoch [7623/10000], train_Loss: 0.0004530595033429563,test_Loss:22.896299362182617, r2_store:-0.3512687374933907\n",
            "Epoch [7624/10000], train_Loss: 0.0006865951581858099,test_Loss:23.001190185546875, r2_store:-0.36032363461513417\n",
            "Epoch [7625/10000], train_Loss: 0.002532492158934474,test_Loss:22.832595825195312, r2_store:-0.34595236673613283\n",
            "Epoch [7626/10000], train_Loss: 0.004206703044474125,test_Loss:23.03136444091797, r2_store:-0.36265771007093583\n",
            "Epoch [7627/10000], train_Loss: 0.0043991925194859505,test_Loss:22.839725494384766, r2_store:-0.34720028217709475\n",
            "Epoch [7628/10000], train_Loss: 0.003125792369246483,test_Loss:22.963905334472656, r2_store:-0.3587374961522094\n",
            "Epoch [7629/10000], train_Loss: 0.0013835085555911064,test_Loss:22.88735580444336, r2_store:-0.35300987257400473\n",
            "Epoch [7630/10000], train_Loss: 0.00031415873672813177,test_Loss:22.88237762451172, r2_store:-0.3527514329100201\n",
            "Epoch [7631/10000], train_Loss: 0.00037700191023759544,test_Loss:22.954282760620117, r2_store:-0.3587951198239363\n",
            "Epoch [7632/10000], train_Loss: 0.0012174040311947465,test_Loss:22.8381404876709, r2_store:-0.3490902596783887\n",
            "Epoch [7633/10000], train_Loss: 0.0020671398378908634,test_Loss:22.97701644897461, r2_store:-0.36091408283066695\n",
            "Epoch [7634/10000], train_Loss: 0.0023052669130265713,test_Loss:22.84183120727539, r2_store:-0.34966059845133524\n",
            "Epoch [7635/10000], train_Loss: 0.0018401875859126449,test_Loss:22.94817543029785, r2_store:-0.35881822978678524\n",
            "Epoch [7636/10000], train_Loss: 0.001023745397105813,test_Loss:22.878787994384766, r2_store:-0.35317930011819687\n",
            "Epoch [7637/10000], train_Loss: 0.00036661647027358413,test_Loss:22.895832061767578, r2_store:-0.3546396296611778\n",
            "Epoch [7638/10000], train_Loss: 0.00017791215213946998,test_Loss:22.925065994262695, r2_store:-0.35699191129857955\n",
            "Epoch [7639/10000], train_Loss: 0.00043343519791960716,test_Loss:22.858627319335938, r2_store:-0.3513495934167108\n",
            "Epoch [7640/10000], train_Loss: 0.0008606166811659932,test_Loss:22.94736099243164, r2_store:-0.3587800974720696\n",
            "Epoch [7641/10000], train_Loss: 0.0011464195558801293,test_Loss:22.85001564025879, r2_store:-0.3505121284516397\n",
            "Epoch [7642/10000], train_Loss: 0.0011301030172035098,test_Loss:22.940143585205078, r2_store:-0.3579326361420936\n",
            "Epoch [7643/10000], train_Loss: 0.0008481604163534939,test_Loss:22.870954513549805, r2_store:-0.3520920934790295\n",
            "Epoch [7644/10000], train_Loss: 0.00048123206943273544,test_Loss:22.91025161743164, r2_store:-0.35548548838924954\n",
            "Epoch [7645/10000], train_Loss: 0.00021687409025616944,test_Loss:22.90122413635254, r2_store:-0.3547016236263898\n",
            "Epoch [7646/10000], train_Loss: 0.00015361621626652777,test_Loss:22.882312774658203, r2_store:-0.353013249294023\n",
            "Epoch [7647/10000], train_Loss: 0.0002665845968294889,test_Loss:22.926313400268555, r2_store:-0.3567456619649083\n",
            "Epoch [7648/10000], train_Loss: 0.00044776330469176173,test_Loss:22.865474700927734, r2_store:-0.3517365186564494\n",
            "Epoch [7649/10000], train_Loss: 0.000579525250941515,test_Loss:22.931110382080078, r2_store:-0.3572511062557886\n",
            "Epoch [7650/10000], train_Loss: 0.0005939951515756547,test_Loss:22.871225357055664, r2_store:-0.35196099201313924\n",
            "Epoch [7651/10000], train_Loss: 0.0004974392359144986,test_Loss:22.924907684326172, r2_store:-0.3563158004783322\n",
            "Epoch [7652/10000], train_Loss: 0.00034521956695243716,test_Loss:22.88887596130371, r2_store:-0.35326622660142615\n",
            "Epoch [7653/10000], train_Loss: 0.00020866480190306902,test_Loss:22.90561866760254, r2_store:-0.3547080855195459\n",
            "Epoch [7654/10000], train_Loss: 0.00013712648069486022,test_Loss:22.908092498779297, r2_store:-0.3548430858430067\n",
            "Epoch [7655/10000], train_Loss: 0.00014186333282850683,test_Loss:22.89051055908203, r2_store:-0.353250307459676\n",
            "Epoch [7656/10000], train_Loss: 0.00019924796652048826,test_Loss:22.922351837158203, r2_store:-0.3558883705796796\n",
            "Epoch [7657/10000], train_Loss: 0.000268844683887437,test_Loss:22.882333755493164, r2_store:-0.35247730871196326\n",
            "Epoch [7658/10000], train_Loss: 0.0003147627576254308,test_Loss:22.926286697387695, r2_store:-0.3560755085712013\n",
            "Epoch [7659/10000], train_Loss: 0.00031792878871783614,test_Loss:22.886106491088867, r2_store:-0.3525521472689954\n",
            "Epoch [7660/10000], train_Loss: 0.00028154600295238197,test_Loss:22.922456741333008, r2_store:-0.35550767522002436\n",
            "Epoch [7661/10000], train_Loss: 0.00022346277546603233,test_Loss:22.896617889404297, r2_store:-0.3532386035549604\n",
            "Epoch [7662/10000], train_Loss: 0.00016646584845148027,test_Loss:22.914234161376953, r2_store:-0.35458837652169883\n",
            "Epoch [7663/10000], train_Loss: 0.00012798896932508796,test_Loss:22.911331176757812, r2_store:-0.35417342144241815\n",
            "Epoch [7664/10000], train_Loss: 0.00011527999595273286,test_Loss:22.90671730041504, r2_store:-0.3537237595093681\n",
            "Epoch [7665/10000], train_Loss: 0.00012507260544225574,test_Loss:22.921369552612305, r2_store:-0.3549454346527343\n",
            "Epoch [7666/10000], train_Loss: 0.00014808536798227578,test_Loss:22.901233673095703, r2_store:-0.3531337172565576\n",
            "Epoch [7667/10000], train_Loss: 0.0001720174477668479,test_Loss:22.928693771362305, r2_store:-0.355304123232554\n",
            "Epoch [7668/10000], train_Loss: 0.00018788185843732208,test_Loss:22.902280807495117, r2_store:-0.35295974098795324\n",
            "Epoch [7669/10000], train_Loss: 0.00019057505414821208,test_Loss:22.92913818359375, r2_store:-0.3552695920233522\n",
            "Epoch [7670/10000], train_Loss: 0.00018131655815523118,test_Loss:22.903688430786133, r2_store:-0.3531696842121712\n",
            "Epoch [7671/10000], train_Loss: 0.00016312772640958428,test_Loss:22.924692153930664, r2_store:-0.3549626697713848\n",
            "Epoch [7672/10000], train_Loss: 0.00014235952403396368,test_Loss:22.908803939819336, r2_store:-0.3536058529627648\n",
            "Epoch [7673/10000], train_Loss: 0.00012324820272624493,test_Loss:22.9189395904541, r2_store:-0.3544785325019164\n",
            "Epoch [7674/10000], train_Loss: 0.00010938517516478896,test_Loss:22.9149169921875, r2_store:-0.3540754302870852\n",
            "Epoch [7675/10000], train_Loss: 0.00010265992023050785,test_Loss:22.91558837890625, r2_store:-0.35398073722117585\n",
            "Epoch [7676/10000], train_Loss: 0.00010268545884173363,test_Loss:22.92238426208496, r2_store:-0.3544888534283368\n",
            "Epoch [7677/10000], train_Loss: 0.00010789686348289251,test_Loss:22.912097930908203, r2_store:-0.35359149352993136\n",
            "Epoch [7678/10000], train_Loss: 0.00011506296141305938,test_Loss:22.926118850708008, r2_store:-0.35473946022782843\n",
            "Epoch [7679/10000], train_Loss: 0.00012217494077049196,test_Loss:22.9112606048584, r2_store:-0.35337273634419053\n",
            "Epoch [7680/10000], train_Loss: 0.000127476712805219,test_Loss:22.929086685180664, r2_store:-0.35483565778242987\n",
            "Epoch [7681/10000], train_Loss: 0.00012935609265696257,test_Loss:22.91020965576172, r2_store:-0.35331808924415586\n",
            "Epoch [7682/10000], train_Loss: 0.0001280184369534254,test_Loss:22.927122116088867, r2_store:-0.3547623857368034\n",
            "Epoch [7683/10000], train_Loss: 0.00012363275163806975,test_Loss:22.911792755126953, r2_store:-0.35341269093980787\n",
            "Epoch [7684/10000], train_Loss: 0.00011722657654900104,test_Loss:22.925640106201172, r2_store:-0.3545903575852194\n",
            "Epoch [7685/10000], train_Loss: 0.00011001835810020566,test_Loss:22.91373634338379, r2_store:-0.35356829850323024\n",
            "Epoch [7686/10000], train_Loss: 0.00010347645729780197,test_Loss:22.92351722717285, r2_store:-0.35433968492451196\n",
            "Epoch [7687/10000], train_Loss: 9.781130211194977e-05,test_Loss:22.917827606201172, r2_store:-0.3537281794461835\n",
            "Epoch [7688/10000], train_Loss: 9.36449650907889e-05,test_Loss:22.922870635986328, r2_store:-0.3541020280302143\n",
            "Epoch [7689/10000], train_Loss: 9.074202534975484e-05,test_Loss:22.91997528076172, r2_store:-0.3538428509304261\n",
            "Epoch [7690/10000], train_Loss: 8.888248703442514e-05,test_Loss:22.92123794555664, r2_store:-0.3538721393666282\n",
            "Epoch [7691/10000], train_Loss: 8.790852007223293e-05,test_Loss:22.923416137695312, r2_store:-0.3539347858094122\n",
            "Epoch [7692/10000], train_Loss: 8.746263483772054e-05,test_Loss:22.921133041381836, r2_store:-0.3536916298744912\n",
            "Epoch [7693/10000], train_Loss: 8.748513937462121e-05,test_Loss:22.924861907958984, r2_store:-0.35400179854270775\n",
            "Epoch [7694/10000], train_Loss: 8.78118589753285e-05,test_Loss:22.920164108276367, r2_store:-0.3535513944333535\n",
            "Epoch [7695/10000], train_Loss: 8.834789332468063e-05,test_Loss:22.927505493164062, r2_store:-0.3540723245961448\n",
            "Epoch [7696/10000], train_Loss: 8.895975770428777e-05,test_Loss:22.920854568481445, r2_store:-0.353454769164643\n",
            "Epoch [7697/10000], train_Loss: 8.959451224654913e-05,test_Loss:22.928579330444336, r2_store:-0.3541361997824066\n",
            "Epoch [7698/10000], train_Loss: 9.027655323734507e-05,test_Loss:22.919902801513672, r2_store:-0.3533865747308884\n",
            "Epoch [7699/10000], train_Loss: 9.098016016650945e-05,test_Loss:22.929838180541992, r2_store:-0.3541856661474214\n",
            "Epoch [7700/10000], train_Loss: 9.169294935418293e-05,test_Loss:22.919971466064453, r2_store:-0.35329827388062074\n",
            "Epoch [7701/10000], train_Loss: 9.194394806399941e-05,test_Loss:22.93117904663086, r2_store:-0.3541461456738504\n",
            "Epoch [7702/10000], train_Loss: 9.244155080523342e-05,test_Loss:22.921266555786133, r2_store:-0.3531734865781546\n",
            "Epoch [7703/10000], train_Loss: 9.304864215664566e-05,test_Loss:22.933124542236328, r2_store:-0.3541298627805227\n",
            "Epoch [7704/10000], train_Loss: 9.39608653425239e-05,test_Loss:22.92058563232422, r2_store:-0.3530754976471002\n",
            "Epoch [7705/10000], train_Loss: 9.487487841397524e-05,test_Loss:22.933456420898438, r2_store:-0.3541476178284768\n",
            "Epoch [7706/10000], train_Loss: 9.608404798200354e-05,test_Loss:22.920520782470703, r2_store:-0.3529810278435206\n",
            "Epoch [7707/10000], train_Loss: 9.758156375028193e-05,test_Loss:22.935718536376953, r2_store:-0.354174274169881\n",
            "Epoch [7708/10000], train_Loss: 9.967156074708328e-05,test_Loss:22.92092514038086, r2_store:-0.35283866745823267\n",
            "Epoch [7709/10000], train_Loss: 0.00010212858614977449,test_Loss:22.938011169433594, r2_store:-0.3541894810245647\n",
            "Epoch [7710/10000], train_Loss: 0.00010530031431699172,test_Loss:22.92098617553711, r2_store:-0.3526900038562222\n",
            "Epoch [7711/10000], train_Loss: 0.00010931993892882019,test_Loss:22.93927764892578, r2_store:-0.35428067866674895\n",
            "Epoch [7712/10000], train_Loss: 0.00011496525257825851,test_Loss:22.917659759521484, r2_store:-0.35253676463852757\n",
            "Epoch [7713/10000], train_Loss: 0.00012216313916724175,test_Loss:22.939687728881836, r2_store:-0.35444753191555955\n",
            "Epoch [7714/10000], train_Loss: 0.00013185478746891022,test_Loss:22.915111541748047, r2_store:-0.35232289179444254\n",
            "Epoch [7715/10000], train_Loss: 0.0001438905601389706,test_Loss:22.943721771240234, r2_store:-0.35461676580492285\n",
            "Epoch [7716/10000], train_Loss: 0.0001599619718035683,test_Loss:22.913402557373047, r2_store:-0.35199356379447266\n",
            "Epoch [7717/10000], train_Loss: 0.00018110308155883104,test_Loss:22.94894027709961, r2_store:-0.3548812458157591\n",
            "Epoch [7718/10000], train_Loss: 0.00020975328516215086,test_Loss:22.909751892089844, r2_store:-0.35158783692874396\n",
            "Epoch [7719/10000], train_Loss: 0.00024806716828607023,test_Loss:22.953834533691406, r2_store:-0.35531650813736126\n",
            "Epoch [7720/10000], train_Loss: 0.0003016514820046723,test_Loss:22.90239906311035, r2_store:-0.3510355247878083\n",
            "Epoch [7721/10000], train_Loss: 0.00037472235271707177,test_Loss:22.961671829223633, r2_store:-0.35594738551127003\n",
            "Epoch [7722/10000], train_Loss: 0.0004750115913338959,test_Loss:22.894123077392578, r2_store:-0.35023271476902007\n",
            "Epoch [7723/10000], train_Loss: 0.0006130902329459786,test_Loss:22.974388122558594, r2_store:-0.3568258810920575\n",
            "Epoch [7724/10000], train_Loss: 0.0008061538683250546,test_Loss:22.882753372192383, r2_store:-0.3491071589078212\n",
            "Epoch [7725/10000], train_Loss: 0.001077780150808394,test_Loss:22.991199493408203, r2_store:-0.35819053169069837\n",
            "Epoch [7726/10000], train_Loss: 0.0014680796302855015,test_Loss:22.86262321472168, r2_store:-0.34754526645254713\n",
            "Epoch [7727/10000], train_Loss: 0.0020248640794306993,test_Loss:23.01443099975586, r2_store:-0.36028052475499583\n",
            "Epoch [7728/10000], train_Loss: 0.002818642882630229,test_Loss:22.837848663330078, r2_store:-0.3452654631868832\n",
            "Epoch [7729/10000], train_Loss: 0.0039703031070530415,test_Loss:23.05197525024414, r2_store:-0.3632999226223532\n",
            "Epoch [7730/10000], train_Loss: 0.005628203507512808,test_Loss:22.790517807006836, r2_store:-0.34194437061386096\n",
            "Epoch [7731/10000], train_Loss: 0.00805036909878254,test_Loss:23.10525131225586, r2_store:-0.36784133524795926\n",
            "Epoch [7732/10000], train_Loss: 0.011488501913845539,test_Loss:22.747894287109375, r2_store:-0.3372598165814724\n",
            "Epoch [7733/10000], train_Loss: 0.016503628343343735,test_Loss:23.190580368041992, r2_store:-0.3743928139668822\n",
            "Epoch [7734/10000], train_Loss: 0.023414630442857742,test_Loss:22.662883758544922, r2_store:-0.3311241599989938\n",
            "Epoch [7735/10000], train_Loss: 0.03315560519695282,test_Loss:23.289770126342773, r2_store:-0.3839981423685408\n",
            "Epoch [7736/10000], train_Loss: 0.04581164941191673,test_Loss:22.589725494384766, r2_store:-0.32456570255990047\n",
            "Epoch [7737/10000], train_Loss: 0.061840008944272995,test_Loss:23.418052673339844, r2_store:-0.39495880494056634\n",
            "Epoch [7738/10000], train_Loss: 0.0773499459028244,test_Loss:22.498538970947266, r2_store:-0.3195277581271623\n",
            "Epoch [7739/10000], train_Loss: 0.09106267988681793,test_Loss:23.438947677612305, r2_store:-0.3989313707587785\n",
            "Epoch [7740/10000], train_Loss: 0.0918612852692604,test_Loss:22.525672912597656, r2_store:-0.3216698492482497\n",
            "Epoch [7741/10000], train_Loss: 0.0784226655960083,test_Loss:23.262096405029297, r2_store:-0.38530605813949403\n",
            "Epoch [7742/10000], train_Loss: 0.049518171697854996,test_Loss:22.67658805847168, r2_store:-0.33616917169403804\n",
            "Epoch [7743/10000], train_Loss: 0.019607270136475563,test_Loss:22.96139907836914, r2_store:-0.35802768092968895\n",
            "Epoch [7744/10000], train_Loss: 0.0021047047339379787,test_Loss:23.025741577148438, r2_store:-0.35995521349578974\n",
            "Epoch [7745/10000], train_Loss: 0.0036267403047531843,test_Loss:22.777217864990234, r2_store:-0.33632476725724714\n",
            "Epoch [7746/10000], train_Loss: 0.017827710136771202,test_Loss:23.28248405456543, r2_store:-0.37663691717450987\n",
            "Epoch [7747/10000], train_Loss: 0.030994540080428123,test_Loss:22.750003814697266, r2_store:-0.3310581764786278\n",
            "Epoch [7748/10000], train_Loss: 0.033138930797576904,test_Loss:23.256633758544922, r2_store:-0.37356661028364124\n",
            "Epoch [7749/10000], train_Loss: 0.022433485835790634,test_Loss:22.850202560424805, r2_store:-0.3425021085403259\n",
            "Epoch [7750/10000], train_Loss: 0.008235028944909573,test_Loss:22.973031997680664, r2_store:-0.355602141517815\n",
            "Epoch [7751/10000], train_Loss: 0.0006619048654101789,test_Loss:23.038419723510742, r2_store:-0.36077357693864665\n",
            "Epoch [7752/10000], train_Loss: 0.0033723481465131044,test_Loss:22.81818962097168, r2_store:-0.34020994505094393\n",
            "Epoch [7753/10000], train_Loss: 0.011443255469202995,test_Loss:23.186283111572266, r2_store:-0.3703202458230481\n",
            "Epoch [7754/10000], train_Loss: 0.016704505309462547,test_Loss:22.800827026367188, r2_store:-0.33773629394577065\n",
            "Epoch [7755/10000], train_Loss: 0.014777159318327904,test_Loss:23.107938766479492, r2_store:-0.3639064205851139\n",
            "Epoch [7756/10000], train_Loss: 0.007751909084618092,test_Loss:22.918596267700195, r2_store:-0.34773586215979835\n",
            "Epoch [7757/10000], train_Loss: 0.0016364663606509566,test_Loss:22.940555572509766, r2_store:-0.3501983912967932\n",
            "Epoch [7758/10000], train_Loss: 0.0006193922599777579,test_Loss:23.055788040161133, r2_store:-0.3606816649527331\n",
            "Epoch [7759/10000], train_Loss: 0.004064487759023905,test_Loss:22.83359146118164, r2_store:-0.34194319357716885\n",
            "Epoch [7760/10000], train_Loss: 0.007874745875597,test_Loss:23.09315299987793, r2_store:-0.3653365014063634\n",
            "Epoch [7761/10000], train_Loss: 0.008444425649940968,test_Loss:22.824382781982422, r2_store:-0.3442758649152584\n",
            "Epoch [7762/10000], train_Loss: 0.005609940737485886,test_Loss:22.97726058959961, r2_store:-0.3591889174917917\n",
            "Epoch [7763/10000], train_Loss: 0.0019404500490054488,test_Loss:22.904727935791016, r2_store:-0.35373126212734674\n",
            "Epoch [7764/10000], train_Loss: 0.00027939234860241413,test_Loss:22.859182357788086, r2_store:-0.3502523794795478\n",
            "Epoch [7765/10000], train_Loss: 0.001290615415200591,test_Loss:22.994258880615234, r2_store:-0.362163809348623\n",
            "Epoch [7766/10000], train_Loss: 0.003429108764976263,test_Loss:22.80695915222168, r2_store:-0.3464115386129476\n",
            "Epoch [7767/10000], train_Loss: 0.004613869823515415,test_Loss:23.00612449645996, r2_store:-0.3630906886283203\n",
            "Epoch [7768/10000], train_Loss: 0.003880065632984042,test_Loss:22.843582153320312, r2_store:-0.349659298124275\n",
            "Epoch [7769/10000], train_Loss: 0.0020254203118383884,test_Loss:22.928333282470703, r2_store:-0.3574387772886194\n",
            "Epoch [7770/10000], train_Loss: 0.0005184716428630054,test_Loss:22.910808563232422, r2_store:-0.3564386054316113\n",
            "Epoch [7771/10000], train_Loss: 0.0003020511067006737,test_Loss:22.85083770751953, r2_store:-0.3512764555860748\n",
            "Epoch [7772/10000], train_Loss: 0.0011690475512295961,test_Loss:22.97069549560547, r2_store:-0.36123321050023316\n",
            "Epoch [7773/10000], train_Loss: 0.002161076758056879,test_Loss:22.819133758544922, r2_store:-0.3492924232428385\n",
            "Epoch [7774/10000], train_Loss: 0.002427445724606514,test_Loss:22.94805908203125, r2_store:-0.36079668101728024\n",
            "Epoch [7775/10000], train_Loss: 0.0018178399186581373,test_Loss:22.838153839111328, r2_store:-0.3520691945709731\n",
            "Epoch [7776/10000], train_Loss: 0.0008700843900442123,test_Loss:22.890695571899414, r2_store:-0.35652200827497293\n",
            "Epoch [7777/10000], train_Loss: 0.00024950309307314456,test_Loss:22.89328956604004, r2_store:-0.35660571466244084\n",
            "Epoch [7778/10000], train_Loss: 0.0002672613481990993,test_Loss:22.843259811401367, r2_store:-0.3521679128450894\n",
            "Epoch [7779/10000], train_Loss: 0.0007351159583777189,test_Loss:22.933870315551758, r2_store:-0.35942224843795767\n",
            "Epoch [7780/10000], train_Loss: 0.0011895459610968828,test_Loss:22.83306884765625, r2_store:-0.35081327785713023\n",
            "Epoch [7781/10000], train_Loss: 0.0012809004401788116,test_Loss:22.92856216430664, r2_store:-0.35888212077607573\n",
            "Epoch [7782/10000], train_Loss: 0.0009781301487237215,test_Loss:22.853797912597656, r2_store:-0.3525786199405099\n",
            "Epoch [7783/10000], train_Loss: 0.0005243216874077916,test_Loss:22.897319793701172, r2_store:-0.35602439089422444\n",
            "Epoch [7784/10000], train_Loss: 0.0002068339817924425,test_Loss:22.895305633544922, r2_store:-0.3557002099788349\n",
            "Epoch [7785/10000], train_Loss: 0.00017385950195603073,test_Loss:22.864381790161133, r2_store:-0.35315168313635037\n",
            "Epoch [7786/10000], train_Loss: 0.0003646958793979138,test_Loss:22.919336318969727, r2_store:-0.35786804370899494\n",
            "Epoch [7787/10000], train_Loss: 0.0005947592435404658,test_Loss:22.8491153717041, r2_store:-0.35196540045425984\n",
            "Epoch [7788/10000], train_Loss: 0.0006989270332269371,test_Loss:22.919321060180664, r2_store:-0.35790317524075865\n",
            "Epoch [7789/10000], train_Loss: 0.0006196100730448961,test_Loss:22.857282638549805, r2_store:-0.35273715236838865\n",
            "Epoch [7790/10000], train_Loss: 0.0004223856085445732,test_Loss:22.897815704345703, r2_store:-0.35616964047684596\n",
            "Epoch [7791/10000], train_Loss: 0.00022915440786164254,test_Loss:22.880502700805664, r2_store:-0.35460464342752207\n",
            "Epoch [7792/10000], train_Loss: 0.00013505140668712556,test_Loss:22.874847412109375, r2_store:-0.35407868607309445\n",
            "Epoch [7793/10000], train_Loss: 0.00016121343651320785,test_Loss:22.900253295898438, r2_store:-0.3563347732117348\n",
            "Epoch [7794/10000], train_Loss: 0.0002603707544039935,test_Loss:22.8579044342041, r2_store:-0.35282734669698357\n",
            "Epoch [7795/10000], train_Loss: 0.00035497755743563175,test_Loss:22.908098220825195, r2_store:-0.35696370903627095\n",
            "Epoch [7796/10000], train_Loss: 0.0003866416809614748,test_Loss:22.863061904907227, r2_store:-0.35286329362396396\n",
            "Epoch [7797/10000], train_Loss: 0.0003441293665673584,test_Loss:22.90311050415039, r2_store:-0.35634656369967965\n",
            "Epoch [7798/10000], train_Loss: 0.00025620489032007754,test_Loss:22.872669219970703, r2_store:-0.35384840887371727\n",
            "Epoch [7799/10000], train_Loss: 0.0001694720413070172,test_Loss:22.886993408203125, r2_store:-0.35507219947575464\n",
            "Epoch [7800/10000], train_Loss: 0.00012073876860085875,test_Loss:22.889060974121094, r2_store:-0.35512787624026254\n",
            "Epoch [7801/10000], train_Loss: 0.00012188441178295761,test_Loss:22.873973846435547, r2_store:-0.3538734218865316\n",
            "Epoch [7802/10000], train_Loss: 0.00015767375589348376,test_Loss:22.898582458496094, r2_store:-0.3559616153946308\n",
            "Epoch [7803/10000], train_Loss: 0.00020121256238780916,test_Loss:22.87008285522461, r2_store:-0.35327916345946364\n",
            "Epoch [7804/10000], train_Loss: 0.00022766141046304256,test_Loss:22.904035568237305, r2_store:-0.35608460716114787\n",
            "Epoch [7805/10000], train_Loss: 0.00022483621432911605,test_Loss:22.872041702270508, r2_store:-0.35339286492988387\n",
            "Epoch [7806/10000], train_Loss: 0.0001972436875803396,test_Loss:22.896591186523438, r2_store:-0.355540823249721\n",
            "Epoch [7807/10000], train_Loss: 0.00015853530203457922,test_Loss:22.880229949951172, r2_store:-0.3540034810940851\n",
            "Epoch [7808/10000], train_Loss: 0.0001250118511961773,test_Loss:22.889440536499023, r2_store:-0.3547311437585987\n",
            "Epoch [7809/10000], train_Loss: 0.00010663422290235758,test_Loss:22.888418197631836, r2_store:-0.35471572847528043\n",
            "Epoch [7810/10000], train_Loss: 0.00010571532038738951,test_Loss:22.879657745361328, r2_store:-0.35399178265764863\n",
            "Epoch [7811/10000], train_Loss: 0.00011746556265279651,test_Loss:22.894882202148438, r2_store:-0.35524320278396093\n",
            "Epoch [7812/10000], train_Loss: 0.00013330965884961188,test_Loss:22.87651252746582, r2_store:-0.35358498496832413\n",
            "Epoch [7813/10000], train_Loss: 0.0001451013085898012,test_Loss:22.896831512451172, r2_store:-0.35536642586795164\n",
            "Epoch [7814/10000], train_Loss: 0.00014862923126202077,test_Loss:22.876222610473633, r2_store:-0.35354316085812765\n",
            "Epoch [7815/10000], train_Loss: 0.0001423777430318296,test_Loss:22.8958683013916, r2_store:-0.35516542655502104\n",
            "Epoch [7816/10000], train_Loss: 0.00012930402590427548,test_Loss:22.880884170532227, r2_store:-0.35383996799775796\n",
            "Epoch [7817/10000], train_Loss: 0.00011454874038463458,test_Loss:22.89080047607422, r2_store:-0.35476014532689604\n",
            "Epoch [7818/10000], train_Loss: 0.0001024315133690834,test_Loss:22.88590431213379, r2_store:-0.3542590300184474\n",
            "Epoch [7819/10000], train_Loss: 9.531475370749831e-05,test_Loss:22.887409210205078, r2_store:-0.35435168949410145\n",
            "Epoch [7820/10000], train_Loss: 9.341547411167994e-05,test_Loss:22.89034652709961, r2_store:-0.3546361765333761\n",
            "Epoch [7821/10000], train_Loss: 9.566502558300272e-05,test_Loss:22.884075164794922, r2_store:-0.35399676930588275\n",
            "Epoch [7822/10000], train_Loss: 0.00010032746649812907,test_Loss:22.895523071289062, r2_store:-0.3548362549318349\n",
            "Epoch [7823/10000], train_Loss: 0.00010506474791327491,test_Loss:22.88372802734375, r2_store:-0.35374536551871816\n",
            "Epoch [7824/10000], train_Loss: 0.00010825948265846819,test_Loss:22.89600944519043, r2_store:-0.3548557507445902\n",
            "Epoch [7825/10000], train_Loss: 0.00010909871343756095,test_Loss:22.88298797607422, r2_store:-0.3536914869621153\n",
            "Epoch [7826/10000], train_Loss: 0.00010734873649198562,test_Loss:22.89565658569336, r2_store:-0.35476964810119194\n",
            "Epoch [7827/10000], train_Loss: 0.00010373643453931436,test_Loss:22.884592056274414, r2_store:-0.353800137673687\n",
            "Epoch [7828/10000], train_Loss: 9.903403406497091e-05,test_Loss:22.8933048248291, r2_store:-0.3546100955355638\n",
            "Epoch [7829/10000], train_Loss: 9.439796122023836e-05,test_Loss:22.886842727661133, r2_store:-0.35398156359897803\n",
            "Epoch [7830/10000], train_Loss: 9.010859503177926e-05,test_Loss:22.89234161376953, r2_store:-0.3543978775323302\n",
            "Epoch [7831/10000], train_Loss: 8.71465599630028e-05,test_Loss:22.890544891357422, r2_store:-0.3541500692935027\n",
            "Epoch [7832/10000], train_Loss: 8.525867451680824e-05,test_Loss:22.891529083251953, r2_store:-0.35418063970129277\n",
            "Epoch [7833/10000], train_Loss: 8.44434107420966e-05,test_Loss:22.892364501953125, r2_store:-0.35429735799927276\n",
            "Epoch [7834/10000], train_Loss: 8.453385817119852e-05,test_Loss:22.88971710205078, r2_store:-0.3540026172424855\n",
            "Epoch [7835/10000], train_Loss: 8.510710904374719e-05,test_Loss:22.89565658569336, r2_store:-0.3544073565564523\n",
            "Epoch [7836/10000], train_Loss: 8.588076161686331e-05,test_Loss:22.889686584472656, r2_store:-0.35387387472753074\n",
            "Epoch [7837/10000], train_Loss: 8.648611401440576e-05,test_Loss:22.89571762084961, r2_store:-0.3544232372684408\n",
            "Epoch [7838/10000], train_Loss: 8.712246926734224e-05,test_Loss:22.890222549438477, r2_store:-0.3537715211072443\n",
            "Epoch [7839/10000], train_Loss: 8.716783486306667e-05,test_Loss:22.89908790588379, r2_store:-0.35440149405789323\n",
            "Epoch [7840/10000], train_Loss: 8.682221232447773e-05,test_Loss:22.891633987426758, r2_store:-0.35371948916846985\n",
            "Epoch [7841/10000], train_Loss: 8.59697101986967e-05,test_Loss:22.898212432861328, r2_store:-0.35433268865582157\n",
            "Epoch [7842/10000], train_Loss: 8.512263593729585e-05,test_Loss:22.892271041870117, r2_store:-0.353720825789847\n",
            "Epoch [7843/10000], train_Loss: 8.404057007282972e-05,test_Loss:22.899169921875, r2_store:-0.3542948584057646\n",
            "Epoch [7844/10000], train_Loss: 8.304329821839929e-05,test_Loss:22.892864227294922, r2_store:-0.35372852334589644\n",
            "Epoch [7845/10000], train_Loss: 8.173880632966757e-05,test_Loss:22.89907455444336, r2_store:-0.3541923222076393\n",
            "Epoch [7846/10000], train_Loss: 8.06723182904534e-05,test_Loss:22.895191192626953, r2_store:-0.3537316748436443\n",
            "Epoch [7847/10000], train_Loss: 7.958401693031192e-05,test_Loss:22.89922523498535, r2_store:-0.3541096622991686\n",
            "Epoch [7848/10000], train_Loss: 7.851328700780869e-05,test_Loss:22.894611358642578, r2_store:-0.35373742034797373\n",
            "Epoch [7849/10000], train_Loss: 7.75928347138688e-05,test_Loss:22.898700714111328, r2_store:-0.35402542248405955\n",
            "Epoch [7850/10000], train_Loss: 7.67802121117711e-05,test_Loss:22.89647674560547, r2_store:-0.35374458963644817\n",
            "Epoch [7851/10000], train_Loss: 7.602012919960544e-05,test_Loss:22.898391723632812, r2_store:-0.3539628081402766\n",
            "Epoch [7852/10000], train_Loss: 7.529964932473376e-05,test_Loss:22.896141052246094, r2_store:-0.3537381178877159\n",
            "Epoch [7853/10000], train_Loss: 7.485527021344751e-05,test_Loss:22.89979362487793, r2_store:-0.3538943153736964\n",
            "Epoch [7854/10000], train_Loss: 7.428601384162903e-05,test_Loss:22.899150848388672, r2_store:-0.35367605927182666\n",
            "Epoch [7855/10000], train_Loss: 7.386790821328759e-05,test_Loss:22.901206970214844, r2_store:-0.3538194937539032\n",
            "Epoch [7856/10000], train_Loss: 7.338631257880479e-05,test_Loss:22.89876937866211, r2_store:-0.3536276471222424\n",
            "Epoch [7857/10000], train_Loss: 7.305313920369372e-05,test_Loss:22.900854110717773, r2_store:-0.35378822649679975\n",
            "Epoch [7858/10000], train_Loss: 7.271268987096846e-05,test_Loss:22.899328231811523, r2_store:-0.3536023644920381\n",
            "Epoch [7859/10000], train_Loss: 7.232365169329569e-05,test_Loss:22.90142059326172, r2_store:-0.3537796653334131\n",
            "Epoch [7860/10000], train_Loss: 7.191825716290623e-05,test_Loss:22.898883819580078, r2_store:-0.35358285672021617\n",
            "Epoch [7861/10000], train_Loss: 7.16163485776633e-05,test_Loss:22.901460647583008, r2_store:-0.3537710523172697\n",
            "Epoch [7862/10000], train_Loss: 7.136110798455775e-05,test_Loss:22.899829864501953, r2_store:-0.353527222327064\n",
            "Epoch [7863/10000], train_Loss: 7.116889901226386e-05,test_Loss:22.9032039642334, r2_store:-0.3537443999076375\n",
            "Epoch [7864/10000], train_Loss: 7.093069143593311e-05,test_Loss:22.90024185180664, r2_store:-0.35344622791537805\n",
            "Epoch [7865/10000], train_Loss: 7.072267180774361e-05,test_Loss:22.9040584564209, r2_store:-0.35372931616679115\n",
            "Epoch [7866/10000], train_Loss: 7.060532516334206e-05,test_Loss:22.90090560913086, r2_store:-0.35338923528751254\n",
            "Epoch [7867/10000], train_Loss: 7.06007776898332e-05,test_Loss:22.905261993408203, r2_store:-0.35374288888977135\n",
            "Epoch [7868/10000], train_Loss: 7.064095552777871e-05,test_Loss:22.90137481689453, r2_store:-0.3533208248006703\n",
            "Epoch [7869/10000], train_Loss: 7.088402344379574e-05,test_Loss:22.90768814086914, r2_store:-0.35377134544059485\n",
            "Epoch [7870/10000], train_Loss: 7.141442620195448e-05,test_Loss:22.901700973510742, r2_store:-0.3532071202047602\n",
            "Epoch [7871/10000], train_Loss: 7.238761463668197e-05,test_Loss:22.908599853515625, r2_store:-0.35381107370117526\n",
            "Epoch [7872/10000], train_Loss: 7.380544411716983e-05,test_Loss:22.90038299560547, r2_store:-0.35304951231465753\n",
            "Epoch [7873/10000], train_Loss: 7.588947482872754e-05,test_Loss:22.910823822021484, r2_store:-0.3538976449847815\n",
            "Epoch [7874/10000], train_Loss: 7.933026063255966e-05,test_Loss:22.89926528930664, r2_store:-0.35284925810802004\n",
            "Epoch [7875/10000], train_Loss: 8.459693344775587e-05,test_Loss:22.913307189941406, r2_store:-0.35408178319694916\n",
            "Epoch [7876/10000], train_Loss: 9.250670700566843e-05,test_Loss:22.89693832397461, r2_store:-0.3525736867641516\n",
            "Epoch [7877/10000], train_Loss: 0.00010472832946106791,test_Loss:22.91900634765625, r2_store:-0.354372235062848\n",
            "Epoch [7878/10000], train_Loss: 0.00012269850412849337,test_Loss:22.895034790039062, r2_store:-0.35213837168193085\n",
            "Epoch [7879/10000], train_Loss: 0.00015004471060819924,test_Loss:22.926380157470703, r2_store:-0.35480575794394165\n",
            "Epoch [7880/10000], train_Loss: 0.00019142556993756443,test_Loss:22.888639450073242, r2_store:-0.35151385422400705\n",
            "Epoch [7881/10000], train_Loss: 0.0002544017042964697,test_Loss:22.9349365234375, r2_store:-0.3555520392501166\n",
            "Epoch [7882/10000], train_Loss: 0.0003538183809723705,test_Loss:22.8773136138916, r2_store:-0.35057598592683425\n",
            "Epoch [7883/10000], train_Loss: 0.0005059265531599522,test_Loss:22.948627471923828, r2_store:-0.3567467323661897\n",
            "Epoch [7884/10000], train_Loss: 0.0007388303056359291,test_Loss:22.861257553100586, r2_store:-0.34916160507018956\n",
            "Epoch [7885/10000], train_Loss: 0.001096469582989812,test_Loss:22.972347259521484, r2_store:-0.3586570401731135\n",
            "Epoch [7886/10000], train_Loss: 0.0016676613595336676,test_Loss:22.837879180908203, r2_store:-0.346934009900713\n",
            "Epoch [7887/10000], train_Loss: 0.0025511914864182472,test_Loss:23.01503562927246, r2_store:-0.36168574544641485\n",
            "Epoch [7888/10000], train_Loss: 0.003913764841854572,test_Loss:22.803447723388672, r2_store:-0.3435661295130439\n",
            "Epoch [7889/10000], train_Loss: 0.006032620556652546,test_Loss:23.075315475463867, r2_store:-0.36649765884345653\n",
            "Epoch [7890/10000], train_Loss: 0.009263989515602589,test_Loss:22.745779037475586, r2_store:-0.33866425262437994\n",
            "Epoch [7891/10000], train_Loss: 0.014273980632424355,test_Loss:23.169841766357422, r2_store:-0.3740255515115043\n",
            "Epoch [7892/10000], train_Loss: 0.021593982353806496,test_Loss:22.652847290039062, r2_store:-0.3317717078139588\n",
            "Epoch [7893/10000], train_Loss: 0.032642755657434464,test_Loss:23.286518096923828, r2_store:-0.3853827782705834\n",
            "Epoch [7894/10000], train_Loss: 0.048396505415439606,test_Loss:22.565275192260742, r2_store:-0.32341651804507254\n",
            "Epoch [7895/10000], train_Loss: 0.06967751681804657,test_Loss:23.45225715637207, r2_store:-0.39995058672508943\n",
            "Epoch [7896/10000], train_Loss: 0.09288283437490463,test_Loss:22.43232536315918, r2_store:-0.31705359052588444\n",
            "Epoch [7897/10000], train_Loss: 0.1147332563996315,test_Loss:23.507308959960938, r2_store:-0.4077121959407233\n",
            "Epoch [7898/10000], train_Loss: 0.11851753294467926,test_Loss:22.447612762451172, r2_store:-0.3197692001886794\n",
            "Epoch [7899/10000], train_Loss: 0.10073342174291611,test_Loss:23.267499923706055, r2_store:-0.39103702536798735\n",
            "Epoch [7900/10000], train_Loss: 0.0591580793261528,test_Loss:22.66668128967285, r2_store:-0.3390628631633077\n",
            "Epoch [7901/10000], train_Loss: 0.018289361149072647,test_Loss:22.905292510986328, r2_store:-0.3558205704333912\n",
            "Epoch [7902/10000], train_Loss: 0.0007566689164377749,test_Loss:23.099468231201172, r2_store:-0.36913442358274806\n",
            "Epoch [7903/10000], train_Loss: 0.01246872078627348,test_Loss:22.692089080810547, r2_store:-0.3316157105597235\n",
            "Epoch [7904/10000], train_Loss: 0.03594926744699478,test_Loss:23.355754852294922, r2_store:-0.3846867237158007\n",
            "Epoch [7905/10000], train_Loss: 0.04657605290412903,test_Loss:22.763195037841797, r2_store:-0.3325585355487555\n",
            "Epoch [7906/10000], train_Loss: 0.03533320873975754,test_Loss:23.18302345275879, r2_store:-0.37080687632029696\n",
            "Epoch [7907/10000], train_Loss: 0.012895631603896618,test_Loss:22.934871673583984, r2_store:-0.3547675244794297\n",
            "Epoch [7908/10000], train_Loss: 0.0008285612566396594,test_Loss:22.82581329345703, r2_store:-0.347020918723814\n",
            "Epoch [7909/10000], train_Loss: 0.006831329315900803,test_Loss:23.186994552612305, r2_store:-0.3761600424140048\n",
            "Epoch [7910/10000], train_Loss: 0.019920680671930313,test_Loss:22.741594314575195, r2_store:-0.3377415011795273\n",
            "Epoch [7911/10000], train_Loss: 0.024727804586291313,test_Loss:23.148710250854492, r2_store:-0.37318097970066866\n",
            "Epoch [7912/10000], train_Loss: 0.01635816879570484,test_Loss:22.844324111938477, r2_store:-0.34773780456136616\n",
            "Epoch [7913/10000], train_Loss: 0.004541412927210331,test_Loss:22.92653465270996, r2_store:-0.35417954640545934\n",
            "Epoch [7914/10000], train_Loss: 0.0006165028316900134,test_Loss:23.06316375732422, r2_store:-0.3657301289043633\n",
            "Epoch [7915/10000], train_Loss: 0.006130479276180267,test_Loss:22.787458419799805, r2_store:-0.34209535869048935\n",
            "Epoch [7916/10000], train_Loss: 0.013016204349696636,test_Loss:23.125835418701172, r2_store:-0.37197409002338766\n",
            "Epoch [7917/10000], train_Loss: 0.013353352434933186,test_Loss:22.819026947021484, r2_store:-0.3464621700721515\n",
            "Epoch [7918/10000], train_Loss: 0.007423917762935162,test_Loss:22.983551025390625, r2_store:-0.3618813822060998\n",
            "Epoch [7919/10000], train_Loss: 0.001501700491644442,test_Loss:22.943805694580078, r2_store:-0.3608549911496366\n",
            "Epoch [7920/10000], train_Loss: 0.0008985755266621709,test_Loss:22.795244216918945, r2_store:-0.34968908796349796\n",
            "Epoch [7921/10000], train_Loss: 0.004716265015304089,test_Loss:23.028520584106445, r2_store:-0.3699375347274907\n",
            "Epoch [7922/10000], train_Loss: 0.007820196449756622,test_Loss:22.778217315673828, r2_store:-0.3479290394065293\n",
            "Epoch [7923/10000], train_Loss: 0.006935541983693838,test_Loss:22.976430892944336, r2_store:-0.3653708939889386\n",
            "Epoch [7924/10000], train_Loss: 0.0032576199155300856,test_Loss:22.873798370361328, r2_store:-0.35623023046618973\n",
            "Epoch [7925/10000], train_Loss: 0.0005626401398330927,test_Loss:22.86394500732422, r2_store:-0.35494501092472874\n",
            "Epoch [7926/10000], train_Loss: 0.0009506130591034889,test_Loss:22.980892181396484, r2_store:-0.36559515155844124\n",
            "Epoch [7927/10000], train_Loss: 0.003220096230506897,test_Loss:22.792179107666016, r2_store:-0.3500265212507847\n",
            "Epoch [7928/10000], train_Loss: 0.004603237845003605,test_Loss:22.981786727905273, r2_store:-0.36633823119834164\n",
            "Epoch [7929/10000], train_Loss: 0.0037043720949441195,test_Loss:22.835582733154297, r2_store:-0.3536768093868363\n",
            "Epoch [7930/10000], train_Loss: 0.0016428818926215172,test_Loss:22.89815902709961, r2_store:-0.3595850838025745\n",
            "Epoch [7931/10000], train_Loss: 0.00033827443257905543,test_Loss:22.902246475219727, r2_store:-0.36141158067494294\n",
            "Epoch [7932/10000], train_Loss: 0.0006749799358658493,test_Loss:22.80014419555664, r2_store:-0.35355247724674377\n",
            "Epoch [7933/10000], train_Loss: 0.001905395882204175,test_Loss:22.933399200439453, r2_store:-0.36546113414096393\n",
            "Epoch [7934/10000], train_Loss: 0.002648929599672556,test_Loss:22.802921295166016, r2_store:-0.3531627183071686\n",
            "Epoch [7935/10000], train_Loss: 0.002231636783108115,test_Loss:22.92215919494629, r2_store:-0.36300676376440477\n",
            "Epoch [7936/10000], train_Loss: 0.0011537836398929358,test_Loss:22.853879928588867, r2_store:-0.35768715361987313\n",
            "Epoch [7937/10000], train_Loss: 0.0003306040307506919,test_Loss:22.848575592041016, r2_store:-0.3574490524104974\n",
            "Epoch [7938/10000], train_Loss: 0.00033895441447384655,test_Loss:22.909603118896484, r2_store:-0.3624015466249919\n",
            "Epoch [7939/10000], train_Loss: 0.0009805706795305014,test_Loss:22.819231033325195, r2_store:-0.35388382344009073\n",
            "Epoch [7940/10000], train_Loss: 0.0015206773532554507,test_Loss:22.927898406982422, r2_store:-0.3632462553937674\n",
            "Epoch [7941/10000], train_Loss: 0.0014784431550651789,test_Loss:22.833393096923828, r2_store:-0.35487425662308625\n",
            "Epoch [7942/10000], train_Loss: 0.000960308127105236,test_Loss:22.900360107421875, r2_store:-0.3603060937650897\n",
            "Epoch [7943/10000], train_Loss: 0.00039543272578157485,test_Loss:22.875102996826172, r2_store:-0.3587167778732103\n",
            "Epoch [7944/10000], train_Loss: 0.00018996564904227853,test_Loss:22.8447265625, r2_store:-0.35647209471800956\n",
            "Epoch [7945/10000], train_Loss: 0.00042873481288552284,test_Loss:22.907577514648438, r2_store:-0.3616754820563117\n",
            "Epoch [7946/10000], train_Loss: 0.0007726229960098863,test_Loss:22.837039947509766, r2_store:-0.3549716901134077\n",
            "Epoch [7947/10000], train_Loss: 0.0009079732117243111,test_Loss:22.919422149658203, r2_store:-0.36169388227196575\n",
            "Epoch [7948/10000], train_Loss: 0.0007760523585602641,test_Loss:22.850608825683594, r2_store:-0.3562629095304968\n",
            "Epoch [7949/10000], train_Loss: 0.0004533681203611195,test_Loss:22.887134552001953, r2_store:-0.3592770578468698\n",
            "Epoch [7950/10000], train_Loss: 0.0002039537503151223,test_Loss:22.885805130004883, r2_store:-0.35912085854740217\n",
            "Epoch [7951/10000], train_Loss: 0.00019744496967177838,test_Loss:22.85722541809082, r2_store:-0.3567682336721949\n",
            "Epoch [7952/10000], train_Loss: 0.00035103774280287325,test_Loss:22.907508850097656, r2_store:-0.3611150023803682\n",
            "Epoch [7953/10000], train_Loss: 0.0005135576357133687,test_Loss:22.852519989013672, r2_store:-0.3560702649233465\n",
            "Epoch [7954/10000], train_Loss: 0.0005523617728613317,test_Loss:22.915870666503906, r2_store:-0.36096469194728553\n",
            "Epoch [7955/10000], train_Loss: 0.0004390742687974125,test_Loss:22.869966506958008, r2_store:-0.35733240387051035\n",
            "Epoch [7956/10000], train_Loss: 0.00026654411340132356,test_Loss:22.88534164428711, r2_store:-0.3591784883453304\n",
            "Epoch [7957/10000], train_Loss: 0.00016414695710409433,test_Loss:22.887346267700195, r2_store:-0.35924342394103514\n",
            "Epoch [7958/10000], train_Loss: 0.00016553075693082064,test_Loss:22.87230110168457, r2_store:-0.3574080352540221\n",
            "Epoch [7959/10000], train_Loss: 0.00024024301092140377,test_Loss:22.910045623779297, r2_store:-0.3603913051463836\n",
            "Epoch [7960/10000], train_Loss: 0.0003234678297303617,test_Loss:22.86680793762207, r2_store:-0.3567088895413224\n",
            "Epoch [7961/10000], train_Loss: 0.00034508033422753215,test_Loss:22.906137466430664, r2_store:-0.3602706226391268\n",
            "Epoch [7962/10000], train_Loss: 0.0002938634715974331,test_Loss:22.872058868408203, r2_store:-0.35752991486492225\n",
            "Epoch [7963/10000], train_Loss: 0.00021529404330067337,test_Loss:22.888404846191406, r2_store:-0.3592103414555816\n",
            "Epoch [7964/10000], train_Loss: 0.00015497618005611002,test_Loss:22.887649536132812, r2_store:-0.3588193526482104\n",
            "Epoch [7965/10000], train_Loss: 0.00013534247409552336,test_Loss:22.884382247924805, r2_store:-0.3580495345842616\n",
            "Epoch [7966/10000], train_Loss: 0.00016009635874070227,test_Loss:22.905372619628906, r2_store:-0.3597851767571243\n",
            "Epoch [7967/10000], train_Loss: 0.00019676897500175983,test_Loss:22.875934600830078, r2_store:-0.35750324851272386\n",
            "Epoch [7968/10000], train_Loss: 0.00021694766473956406,test_Loss:22.903270721435547, r2_store:-0.35992718172195626\n",
            "Epoch [7969/10000], train_Loss: 0.00021246573305688798,test_Loss:22.88255500793457, r2_store:-0.3577075253229587\n",
            "Epoch [7970/10000], train_Loss: 0.0001855070295277983,test_Loss:22.90319061279297, r2_store:-0.3593830762721817\n",
            "Epoch [7971/10000], train_Loss: 0.00015170799451880157,test_Loss:22.890710830688477, r2_store:-0.3584629519666467\n",
            "Epoch [7972/10000], train_Loss: 0.00012950859672855586,test_Loss:22.89208984375, r2_store:-0.35866657667203516\n",
            "Epoch [7973/10000], train_Loss: 0.00012478108692448586,test_Loss:22.899700164794922, r2_store:-0.3593346355082243\n",
            "Epoch [7974/10000], train_Loss: 0.00013477346510626376,test_Loss:22.885112762451172, r2_store:-0.3581823224809588\n",
            "Epoch [7975/10000], train_Loss: 0.00015110321692191064,test_Loss:22.901140213012695, r2_store:-0.3597799731132163\n",
            "Epoch [7976/10000], train_Loss: 0.00016095892351586372,test_Loss:22.88144302368164, r2_store:-0.3580853397907877\n",
            "Epoch [7977/10000], train_Loss: 0.00015859067207202315,test_Loss:22.905094146728516, r2_store:-0.3596259414825136\n",
            "Epoch [7978/10000], train_Loss: 0.00014721501793246716,test_Loss:22.891780853271484, r2_store:-0.35829586700480176\n",
            "Epoch [7979/10000], train_Loss: 0.00013165232667233795,test_Loss:22.901533126831055, r2_store:-0.35903221086901094\n",
            "Epoch [7980/10000], train_Loss: 0.00011901687685167417,test_Loss:22.89999008178711, r2_store:-0.35868076115334646\n",
            "Epoch [7981/10000], train_Loss: 0.00011367657862138003,test_Loss:22.8985652923584, r2_store:-0.35843235777619276\n",
            "Epoch [7982/10000], train_Loss: 0.00011536329839145765,test_Loss:22.906383514404297, r2_store:-0.35899032692595\n",
            "Epoch [7983/10000], train_Loss: 0.00012029738718410954,test_Loss:22.896955490112305, r2_store:-0.3580592721708562\n",
            "Epoch [7984/10000], train_Loss: 0.00012550085375551134,test_Loss:22.911510467529297, r2_store:-0.3591578485945113\n",
            "Epoch [7985/10000], train_Loss: 0.00012751173926517367,test_Loss:22.89499282836914, r2_store:-0.358092304162845\n",
            "Epoch [7986/10000], train_Loss: 0.00012448827328626066,test_Loss:22.904617309570312, r2_store:-0.3591211782939403\n",
            "Epoch [7987/10000], train_Loss: 0.00011913970956811681,test_Loss:22.897762298583984, r2_store:-0.35834994871649983\n",
            "Epoch [7988/10000], train_Loss: 0.00011290518887108192,test_Loss:22.905147552490234, r2_store:-0.3588441150538524\n",
            "Epoch [7989/10000], train_Loss: 0.00010731934889918193,test_Loss:22.903005599975586, r2_store:-0.3585754474907781\n",
            "Epoch [7990/10000], train_Loss: 0.000104702623502817,test_Loss:22.906063079833984, r2_store:-0.3584521337380189\n",
            "Epoch [7991/10000], train_Loss: 0.00010431183181935921,test_Loss:22.911317825317383, r2_store:-0.35874545813561975\n",
            "Epoch [7992/10000], train_Loss: 0.00010566170385573059,test_Loss:22.90355110168457, r2_store:-0.35814254171120297\n",
            "Epoch [7993/10000], train_Loss: 0.0001075152977136895,test_Loss:22.913480758666992, r2_store:-0.35880570316454863\n",
            "Epoch [7994/10000], train_Loss: 0.00010850763646885753,test_Loss:22.905811309814453, r2_store:-0.3580553841480061\n",
            "Epoch [7995/10000], train_Loss: 0.00010819158342201263,test_Loss:22.913393020629883, r2_store:-0.3587976904567507\n",
            "Epoch [7996/10000], train_Loss: 0.00010692795331124216,test_Loss:22.906795501708984, r2_store:-0.35810441010152716\n",
            "Epoch [7997/10000], train_Loss: 0.00010437345190439373,test_Loss:22.915613174438477, r2_store:-0.3586850919803666\n",
            "Epoch [7998/10000], train_Loss: 0.00010145588021259755,test_Loss:22.909378051757812, r2_store:-0.3582389779336641\n",
            "Epoch [7999/10000], train_Loss: 9.868615597952157e-05,test_Loss:22.912160873413086, r2_store:-0.35849248084640606\n",
            "Epoch [8000/10000], train_Loss: 9.666708501754329e-05,test_Loss:22.91529083251953, r2_store:-0.35839507661800085\n",
            "Epoch [8001/10000], train_Loss: 9.534104901831597e-05,test_Loss:22.91545867919922, r2_store:-0.35832594386868744\n",
            "Epoch [8002/10000], train_Loss: 9.477086859988049e-05,test_Loss:22.916114807128906, r2_store:-0.3584897876940718\n",
            "Epoch [8003/10000], train_Loss: 9.495383710600436e-05,test_Loss:22.915151596069336, r2_store:-0.35820837120157\n",
            "Epoch [8004/10000], train_Loss: 9.453963866690174e-05,test_Loss:22.920467376708984, r2_store:-0.35854259215567863\n",
            "Epoch [8005/10000], train_Loss: 9.467307245358825e-05,test_Loss:22.91563606262207, r2_store:-0.35809283612661647\n",
            "Epoch [8006/10000], train_Loss: 9.451629011891782e-05,test_Loss:22.92169761657715, r2_store:-0.358512139938014\n",
            "Epoch [8007/10000], train_Loss: 9.389562183059752e-05,test_Loss:22.918352127075195, r2_store:-0.3580697930891641\n",
            "Epoch [8008/10000], train_Loss: 9.308750304626301e-05,test_Loss:22.922813415527344, r2_store:-0.3584732371441657\n",
            "Epoch [8009/10000], train_Loss: 9.210466669173911e-05,test_Loss:22.919170379638672, r2_store:-0.35807561165442614\n",
            "Epoch [8010/10000], train_Loss: 9.095986752072349e-05,test_Loss:22.92416763305664, r2_store:-0.35841288663634896\n",
            "Epoch [8011/10000], train_Loss: 8.998817793326452e-05,test_Loss:22.92075538635254, r2_store:-0.35809378329102115\n",
            "Epoch [8012/10000], train_Loss: 8.88332215254195e-05,test_Loss:22.925870895385742, r2_store:-0.3583463120431274\n",
            "Epoch [8013/10000], train_Loss: 8.793509914539754e-05,test_Loss:22.924510955810547, r2_store:-0.35810412702969985\n",
            "Epoch [8014/10000], train_Loss: 8.701575279701501e-05,test_Loss:22.92672348022461, r2_store:-0.35822545797892946\n",
            "Epoch [8015/10000], train_Loss: 8.623813482699916e-05,test_Loss:22.927696228027344, r2_store:-0.3580902663011305\n",
            "Epoch [8016/10000], train_Loss: 8.554882515454665e-05,test_Loss:22.928104400634766, r2_store:-0.3581549117208589\n",
            "Epoch [8017/10000], train_Loss: 8.493097266182303e-05,test_Loss:22.926105499267578, r2_store:-0.3581149397485692\n",
            "Epoch [8018/10000], train_Loss: 8.433282346231863e-05,test_Loss:22.927743911743164, r2_store:-0.35813677398809296\n",
            "Epoch [8019/10000], train_Loss: 8.364154200535268e-05,test_Loss:22.929668426513672, r2_store:-0.35817179765958906\n",
            "Epoch [8020/10000], train_Loss: 8.322483336087316e-05,test_Loss:22.92715835571289, r2_store:-0.358098882285214\n",
            "Epoch [8021/10000], train_Loss: 8.259432070190087e-05,test_Loss:22.92909049987793, r2_store:-0.35814947243648554\n",
            "Epoch [8022/10000], train_Loss: 8.198234718292952e-05,test_Loss:22.93029022216797, r2_store:-0.358042352583668\n",
            "Epoch [8023/10000], train_Loss: 8.146844629663974e-05,test_Loss:22.931716918945312, r2_store:-0.3580822871833973\n",
            "Epoch [8024/10000], train_Loss: 8.088351023616269e-05,test_Loss:22.93051528930664, r2_store:-0.3579687445011699\n",
            "Epoch [8025/10000], train_Loss: 8.044914284255356e-05,test_Loss:22.93355941772461, r2_store:-0.3580205856165175\n",
            "Epoch [8026/10000], train_Loss: 7.991938764462247e-05,test_Loss:22.93291664123535, r2_store:-0.3579382243617546\n",
            "Epoch [8027/10000], train_Loss: 7.937615009723231e-05,test_Loss:22.932584762573242, r2_store:-0.35797943284138967\n",
            "Epoch [8028/10000], train_Loss: 7.89048062870279e-05,test_Loss:22.934070587158203, r2_store:-0.3579298299154412\n",
            "Epoch [8029/10000], train_Loss: 7.840634498279542e-05,test_Loss:22.93528938293457, r2_store:-0.3579828229004498\n",
            "Epoch [8030/10000], train_Loss: 7.792742690071464e-05,test_Loss:22.933963775634766, r2_store:-0.3579184328510805\n",
            "Epoch [8031/10000], train_Loss: 7.741914305370301e-05,test_Loss:22.93637466430664, r2_store:-0.3579819378985216\n",
            "Epoch [8032/10000], train_Loss: 7.700049900449812e-05,test_Loss:22.936155319213867, r2_store:-0.3578869377381424\n",
            "Epoch [8033/10000], train_Loss: 7.653162901988253e-05,test_Loss:22.93694496154785, r2_store:-0.3579342179014162\n",
            "Epoch [8034/10000], train_Loss: 7.615048525622115e-05,test_Loss:22.936717987060547, r2_store:-0.35781135132767616\n",
            "Epoch [8035/10000], train_Loss: 7.578268559882417e-05,test_Loss:22.93923568725586, r2_store:-0.35790923164901356\n",
            "Epoch [8036/10000], train_Loss: 7.54311477066949e-05,test_Loss:22.937742233276367, r2_store:-0.35777211540850584\n",
            "Epoch [8037/10000], train_Loss: 7.503510278183967e-05,test_Loss:22.93899917602539, r2_store:-0.35791307037894504\n",
            "Epoch [8038/10000], train_Loss: 7.4746974860318e-05,test_Loss:22.93922233581543, r2_store:-0.3577497514452308\n",
            "Epoch [8039/10000], train_Loss: 7.43795681046322e-05,test_Loss:22.941865921020508, r2_store:-0.3579289965232224\n",
            "Epoch [8040/10000], train_Loss: 7.400615140795708e-05,test_Loss:22.939207077026367, r2_store:-0.3576877893391306\n",
            "Epoch [8041/10000], train_Loss: 7.381877367151901e-05,test_Loss:22.944591522216797, r2_store:-0.3579165261911095\n",
            "Epoch [8042/10000], train_Loss: 7.38155358703807e-05,test_Loss:22.94242286682129, r2_store:-0.3575999530504599\n",
            "Epoch [8043/10000], train_Loss: 7.363810436800122e-05,test_Loss:22.945667266845703, r2_store:-0.35788555676643696\n",
            "Epoch [8044/10000], train_Loss: 7.361231837421656e-05,test_Loss:22.94194793701172, r2_store:-0.35749259919733656\n",
            "Epoch [8045/10000], train_Loss: 7.380195893347263e-05,test_Loss:22.94778060913086, r2_store:-0.3579064986486249\n",
            "Epoch [8046/10000], train_Loss: 7.417595770675689e-05,test_Loss:22.9417724609375, r2_store:-0.35739856028580363\n",
            "Epoch [8047/10000], train_Loss: 7.469405682059005e-05,test_Loss:22.948692321777344, r2_store:-0.35795292388235334\n",
            "Epoch [8048/10000], train_Loss: 7.546636334154755e-05,test_Loss:22.942974090576172, r2_store:-0.3573115737196979\n",
            "Epoch [8049/10000], train_Loss: 7.700841524638236e-05,test_Loss:22.951133728027344, r2_store:-0.3580515258957768\n",
            "Epoch [8050/10000], train_Loss: 7.900744822109118e-05,test_Loss:22.94154167175293, r2_store:-0.35717300139015085\n",
            "Epoch [8051/10000], train_Loss: 8.199790318030864e-05,test_Loss:22.955230712890625, r2_store:-0.35817929094210643\n",
            "Epoch [8052/10000], train_Loss: 8.610764052718878e-05,test_Loss:22.942373275756836, r2_store:-0.3569628771458797\n",
            "Epoch [8053/10000], train_Loss: 9.209683048538864e-05,test_Loss:22.95751190185547, r2_store:-0.35832976249597137\n",
            "Epoch [8054/10000], train_Loss: 0.00010112575546372682,test_Loss:22.93865966796875, r2_store:-0.3566610909413632\n",
            "Epoch [8055/10000], train_Loss: 0.00011407785495975986,test_Loss:22.962337493896484, r2_store:-0.3586211198825726\n",
            "Epoch [8056/10000], train_Loss: 0.0001326385245192796,test_Loss:22.937734603881836, r2_store:-0.3562786815325243\n",
            "Epoch [8057/10000], train_Loss: 0.0001600224059075117,test_Loss:22.968036651611328, r2_store:-0.35908205077311983\n",
            "Epoch [8058/10000], train_Loss: 0.00020128788310103118,test_Loss:22.932140350341797, r2_store:-0.35571178728242736\n",
            "Epoch [8059/10000], train_Loss: 0.0002630684175528586,test_Loss:22.98031997680664, r2_store:-0.35984392915028884\n",
            "Epoch [8060/10000], train_Loss: 0.00035745996865443885,test_Loss:22.922998428344727, r2_store:-0.35481130113076276\n",
            "Epoch [8061/10000], train_Loss: 0.0004998468211852014,test_Loss:22.994169235229492, r2_store:-0.3609576982503111\n",
            "Epoch [8062/10000], train_Loss: 0.0007172740297392011,test_Loss:22.909687042236328, r2_store:-0.3534234823439617\n",
            "Epoch [8063/10000], train_Loss: 0.001052167033776641,test_Loss:23.015247344970703, r2_store:-0.362746835208583\n",
            "Epoch [8064/10000], train_Loss: 0.0015697836643084884,test_Loss:22.88864517211914, r2_store:-0.3512921724698923\n",
            "Epoch [8065/10000], train_Loss: 0.0023792057763785124,test_Loss:23.04909896850586, r2_store:-0.36565577273328675\n",
            "Epoch [8066/10000], train_Loss: 0.00362934242002666,test_Loss:22.845548629760742, r2_store:-0.34800824524966467\n",
            "Epoch [8067/10000], train_Loss: 0.005601691547781229,test_Loss:23.104406356811523, r2_store:-0.37037639583047754\n",
            "Epoch [8068/10000], train_Loss: 0.008645881898701191,test_Loss:22.806015014648438, r2_store:-0.3431091362703107\n",
            "Epoch [8069/10000], train_Loss: 0.013433736748993397,test_Loss:23.21595001220703, r2_store:-0.37799487299123324\n",
            "Epoch [8070/10000], train_Loss: 0.020332956686615944,test_Loss:22.71508026123047, r2_store:-0.33666325305640354\n",
            "Epoch [8071/10000], train_Loss: 0.030299287289381027,test_Loss:23.333812713623047, r2_store:-0.3888906142198747\n",
            "Epoch [8072/10000], train_Loss: 0.043541617691516876,test_Loss:22.607576370239258, r2_store:-0.32964605297830385\n",
            "Epoch [8073/10000], train_Loss: 0.061104051768779755,test_Loss:23.4675350189209, r2_store:-0.4021296160502801\n",
            "Epoch [8074/10000], train_Loss: 0.07969234138727188,test_Loss:22.55205535888672, r2_store:-0.32408476191990143\n",
            "Epoch [8075/10000], train_Loss: 0.09748995304107666,test_Loss:23.566286087036133, r2_store:-0.40938013363594283\n",
            "Epoch [8076/10000], train_Loss: 0.10223100334405899,test_Loss:22.549837112426758, r2_store:-0.32538449894973054\n",
            "Epoch [8077/10000], train_Loss: 0.0916588231921196,test_Loss:23.356534957885742, r2_store:-0.39680822209098787\n",
            "Epoch [8078/10000], train_Loss: 0.061463259160518646,test_Loss:22.727783203125, r2_store:-0.34024149883359756\n",
            "Epoch [8079/10000], train_Loss: 0.026656296104192734,test_Loss:23.062389373779297, r2_store:-0.36771205689145314\n",
            "Epoch [8080/10000], train_Loss: 0.0036309666465967894,test_Loss:23.03502082824707, r2_store:-0.3662740974513987\n",
            "Epoch [8081/10000], train_Loss: 0.002980294171720743,test_Loss:22.780075073242188, r2_store:-0.3425342352521614\n",
            "Epoch [8082/10000], train_Loss: 0.018767373636364937,test_Loss:23.34437370300293, r2_store:-0.3860851426431766\n",
            "Epoch [8083/10000], train_Loss: 0.03420855849981308,test_Loss:22.78232765197754, r2_store:-0.33744990345726134\n",
            "Epoch [8084/10000], train_Loss: 0.03652036935091019,test_Loss:23.274179458618164, r2_store:-0.3827761966406853\n",
            "Epoch [8085/10000], train_Loss: 0.023406291380524635,test_Loss:22.884910583496094, r2_store:-0.35169172975036234\n",
            "Epoch [8086/10000], train_Loss: 0.007256839424371719,test_Loss:23.011871337890625, r2_store:-0.3629651837677301\n",
            "Epoch [8087/10000], train_Loss: 0.0004946255357936025,test_Loss:23.117069244384766, r2_store:-0.37303377360986745\n",
            "Epoch [8088/10000], train_Loss: 0.005922248121351004,test_Loss:22.813825607299805, r2_store:-0.34665657220872426\n",
            "Epoch [8089/10000], train_Loss: 0.015602363273501396,test_Loss:23.230602264404297, r2_store:-0.38085413824964265\n",
            "Epoch [8090/10000], train_Loss: 0.019295671954751015,test_Loss:22.83234405517578, r2_store:-0.34606982033550904\n",
            "Epoch [8091/10000], train_Loss: 0.014223366975784302,test_Loss:23.107662200927734, r2_store:-0.3701886071069058\n",
            "Epoch [8092/10000], train_Loss: 0.005317230708897114,test_Loss:22.960674285888672, r2_store:-0.3588488726991308\n",
            "Epoch [8093/10000], train_Loss: 0.00046418854617513716,test_Loss:22.916362762451172, r2_store:-0.35442548989276745\n",
            "Epoch [8094/10000], train_Loss: 0.002379294950515032,test_Loss:23.136213302612305, r2_store:-0.3722780327456683\n",
            "Epoch [8095/10000], train_Loss: 0.007504588924348354,test_Loss:22.838394165039062, r2_store:-0.34805491940022737\n",
            "Epoch [8096/10000], train_Loss: 0.010385078378021717,test_Loss:23.119638442993164, r2_store:-0.37364584095117404\n",
            "Epoch [8097/10000], train_Loss: 0.008406520821154118,test_Loss:22.87453269958496, r2_store:-0.35371536093883926\n",
            "Epoch [8098/10000], train_Loss: 0.0037998096086084843,test_Loss:22.997398376464844, r2_store:-0.36406446008738147\n",
            "Epoch [8099/10000], train_Loss: 0.0005725541850551963,test_Loss:23.00100326538086, r2_store:-0.3652843613766219\n",
            "Epoch [8100/10000], train_Loss: 0.0008734232978895307,test_Loss:22.863134384155273, r2_store:-0.35479930025562334\n",
            "Epoch [8101/10000], train_Loss: 0.003461705520749092,test_Loss:23.0717830657959, r2_store:-0.37236198679283494\n",
            "Epoch [8102/10000], train_Loss: 0.005462867207825184,test_Loss:22.85891342163086, r2_store:-0.3534643391042189\n",
            "Epoch [8103/10000], train_Loss: 0.005115809850394726,test_Loss:23.04789161682129, r2_store:-0.36964239474996674\n",
            "Epoch [8104/10000], train_Loss: 0.0028867674991488457,test_Loss:22.91478729248047, r2_store:-0.3595294385844532\n",
            "Epoch [8105/10000], train_Loss: 0.0007709382334724069,test_Loss:22.930950164794922, r2_store:-0.3617013976391583\n",
            "Epoch [8106/10000], train_Loss: 0.00027489784406498075,test_Loss:22.993492126464844, r2_store:-0.36711952425747385\n",
            "Epoch [8107/10000], train_Loss: 0.0013113459572196007,test_Loss:22.863513946533203, r2_store:-0.3560392594359474\n",
            "Epoch [8108/10000], train_Loss: 0.0026295704301446676,test_Loss:23.01889419555664, r2_store:-0.36973389402268353\n",
            "Epoch [8109/10000], train_Loss: 0.0030185601208359003,test_Loss:22.857704162597656, r2_store:-0.3566230982259917\n",
            "Epoch [8110/10000], train_Loss: 0.0022304700687527657,test_Loss:22.967304229736328, r2_store:-0.36658298660559785\n",
            "Epoch [8111/10000], train_Loss: 0.0009885110193863511,test_Loss:22.908632278442383, r2_store:-0.3618966905601424\n",
            "Epoch [8112/10000], train_Loss: 0.00023319493629969656,test_Loss:22.900726318359375, r2_store:-0.36114827990005605\n",
            "Epoch [8113/10000], train_Loss: 0.0003509361413307488,test_Loss:22.97412872314453, r2_store:-0.3669004158134004\n",
            "Epoch [8114/10000], train_Loss: 0.001009916653856635,test_Loss:22.876455307006836, r2_store:-0.3580100389555818\n",
            "Epoch [8115/10000], train_Loss: 0.0015572772826999426,test_Loss:22.99081802368164, r2_store:-0.36791075263979356\n",
            "Epoch [8116/10000], train_Loss: 0.0015464624157175422,test_Loss:22.88383674621582, r2_store:-0.35876268703613623\n",
            "Epoch [8117/10000], train_Loss: 0.001047872705385089,test_Loss:22.95810890197754, r2_store:-0.3649958774768485\n",
            "Epoch [8118/10000], train_Loss: 0.00045733744627796113,test_Loss:22.929441452026367, r2_store:-0.3622983219485276\n",
            "Epoch [8119/10000], train_Loss: 0.00016069257981143892,test_Loss:22.910566329956055, r2_store:-0.36128477529339253\n",
            "Epoch [8120/10000], train_Loss: 0.0002662569750100374,test_Loss:22.95535659790039, r2_store:-0.36561330425663474\n",
            "Epoch [8121/10000], train_Loss: 0.0005883645499125123,test_Loss:22.885093688964844, r2_store:-0.3593165451223468\n",
            "Epoch [8122/10000], train_Loss: 0.0008371816948056221,test_Loss:22.970218658447266, r2_store:-0.36636978018159194\n",
            "Epoch [8123/10000], train_Loss: 0.0008360024658031762,test_Loss:22.89247703552246, r2_store:-0.359842331172356\n",
            "Epoch [8124/10000], train_Loss: 0.0006060738814994693,test_Loss:22.9478759765625, r2_store:-0.36445178032079495\n",
            "Epoch [8125/10000], train_Loss: 0.00031846589990891516,test_Loss:22.926319122314453, r2_store:-0.36201966939208385\n",
            "Epoch [8126/10000], train_Loss: 0.00014967788592912257,test_Loss:22.926013946533203, r2_store:-0.36167609984231475\n",
            "Epoch [8127/10000], train_Loss: 0.00016176264034584165,test_Loss:22.953182220458984, r2_store:-0.3640510020416816\n",
            "Epoch [8128/10000], train_Loss: 0.0002973415539599955,test_Loss:22.904998779296875, r2_store:-0.3599145616891817\n",
            "Epoch [8129/10000], train_Loss: 0.0004365333297755569,test_Loss:22.963886260986328, r2_store:-0.3648057536005065\n",
            "Epoch [8130/10000], train_Loss: 0.00048045028233900666,test_Loss:22.90812110900879, r2_store:-0.3599867266458143\n",
            "Epoch [8131/10000], train_Loss: 0.00041206664172932506,test_Loss:22.954313278198242, r2_store:-0.36396116239098353\n",
            "Epoch [8132/10000], train_Loss: 0.00028183290851302445,test_Loss:22.924968719482422, r2_store:-0.3613631280164489\n",
            "Epoch [8133/10000], train_Loss: 0.0001653586805332452,test_Loss:22.937076568603516, r2_store:-0.36234105009304907\n",
            "Epoch [8134/10000], train_Loss: 0.0001176888108602725,test_Loss:22.944908142089844, r2_store:-0.36299832969605994\n",
            "Epoch [8135/10000], train_Loss: 0.00014520924014505,test_Loss:22.922916412353516, r2_store:-0.3609300790762615\n",
            "Epoch [8136/10000], train_Loss: 0.0002105140156345442,test_Loss:22.96150016784668, r2_store:-0.36389240511241816\n",
            "Epoch [8137/10000], train_Loss: 0.0002645297790877521,test_Loss:22.925058364868164, r2_store:-0.3605330896639536\n",
            "Epoch [8138/10000], train_Loss: 0.00027560864691622555,test_Loss:22.962228775024414, r2_store:-0.36379915744375824\n",
            "Epoch [8139/10000], train_Loss: 0.000240088818827644,test_Loss:22.930431365966797, r2_store:-0.3611354829168558\n",
            "Epoch [8140/10000], train_Loss: 0.0001815013529267162,test_Loss:22.953121185302734, r2_store:-0.3629330862897733\n",
            "Epoch [8141/10000], train_Loss: 0.00013019358448218554,test_Loss:22.94666862487793, r2_store:-0.3621642672229506\n",
            "Epoch [8142/10000], train_Loss: 0.00010640440450515598,test_Loss:22.94268798828125, r2_store:-0.3618227376453784\n",
            "Epoch [8143/10000], train_Loss: 0.0001134364865720272,test_Loss:22.958251953125, r2_store:-0.3629963954960893\n",
            "Epoch [8144/10000], train_Loss: 0.00013955221220385283,test_Loss:22.938180923461914, r2_store:-0.36108812609926866\n",
            "Epoch [8145/10000], train_Loss: 0.00016663754649925977,test_Loss:22.963308334350586, r2_store:-0.36332086089883187\n",
            "Epoch [8146/10000], train_Loss: 0.00017961820412892848,test_Loss:22.934467315673828, r2_store:-0.36095284633038816\n",
            "Epoch [8147/10000], train_Loss: 0.0001738326100166887,test_Loss:22.959901809692383, r2_store:-0.363086194606822\n",
            "Epoch [8148/10000], train_Loss: 0.00015291126328520477,test_Loss:22.941120147705078, r2_store:-0.36138162138155705\n",
            "Epoch [8149/10000], train_Loss: 0.00012725978740490973,test_Loss:22.953685760498047, r2_store:-0.3625134241788266\n",
            "Epoch [8150/10000], train_Loss: 0.00010649068281054497,test_Loss:22.947799682617188, r2_store:-0.36200635283295535\n",
            "Epoch [8151/10000], train_Loss: 9.648091509006917e-05,test_Loss:22.947683334350586, r2_store:-0.36190113548153224\n",
            "Epoch [8152/10000], train_Loss: 9.74979848251678e-05,test_Loss:22.954872131347656, r2_store:-0.3625573210580373\n",
            "Epoch [8153/10000], train_Loss: 0.00010600769746815786,test_Loss:22.941438674926758, r2_store:-0.36143444288787663\n",
            "Epoch [8154/10000], train_Loss: 0.00011606367479544133,test_Loss:22.961030960083008, r2_store:-0.36279306175257275\n",
            "Epoch [8155/10000], train_Loss: 0.00012300864909775555,test_Loss:22.94369888305664, r2_store:-0.361264959153462\n",
            "Epoch [8156/10000], train_Loss: 0.0001237486576428637,test_Loss:22.960086822509766, r2_store:-0.36268115379610477\n",
            "Epoch [8157/10000], train_Loss: 0.00011812076991191134,test_Loss:22.947731018066406, r2_store:-0.3613798987829757\n",
            "Epoch [8158/10000], train_Loss: 0.00010861465852940455,test_Loss:22.96102523803711, r2_store:-0.3623250801229385\n",
            "Epoch [8159/10000], train_Loss: 9.890535147860646e-05,test_Loss:22.953245162963867, r2_store:-0.3616549090926995\n",
            "Epoch [8160/10000], train_Loss: 9.17681900318712e-05,test_Loss:22.957542419433594, r2_store:-0.3619200068786861\n",
            "Epoch [8161/10000], train_Loss: 8.820592483971268e-05,test_Loss:22.959646224975586, r2_store:-0.3620075009817372\n",
            "Epoch [8162/10000], train_Loss: 8.816540503175929e-05,test_Loss:22.954160690307617, r2_store:-0.3616124846243347\n",
            "Epoch [8163/10000], train_Loss: 9.044930629897863e-05,test_Loss:22.961223602294922, r2_store:-0.36222540288631455\n",
            "Epoch [8164/10000], train_Loss: 9.34487979975529e-05,test_Loss:22.953134536743164, r2_store:-0.3614080512093334\n",
            "Epoch [8165/10000], train_Loss: 9.537128789816052e-05,test_Loss:22.96579360961914, r2_store:-0.3622491446599656\n",
            "Epoch [8166/10000], train_Loss: 9.576560114510357e-05,test_Loss:22.956295013427734, r2_store:-0.3613212413144802\n",
            "Epoch [8167/10000], train_Loss: 9.457857959205285e-05,test_Loss:22.96767234802246, r2_store:-0.36212559161280633\n",
            "Epoch [8168/10000], train_Loss: 9.210292773786932e-05,test_Loss:22.960451126098633, r2_store:-0.36138923896900343\n",
            "Epoch [8169/10000], train_Loss: 8.875651110429317e-05,test_Loss:22.96790313720703, r2_store:-0.36197210532244406\n",
            "Epoch [8170/10000], train_Loss: 8.555997919756919e-05,test_Loss:22.96261978149414, r2_store:-0.36153178201571157\n",
            "Epoch [8171/10000], train_Loss: 8.29989803605713e-05,test_Loss:22.966869354248047, r2_store:-0.3617488994674123\n",
            "Epoch [8172/10000], train_Loss: 8.113143121590838e-05,test_Loss:22.968097686767578, r2_store:-0.36164791478726155\n",
            "Epoch [8173/10000], train_Loss: 8.017319487407804e-05,test_Loss:22.96763038635254, r2_store:-0.3615266983826557\n",
            "Epoch [8174/10000], train_Loss: 8.003244874998927e-05,test_Loss:22.97039222717285, r2_store:-0.3617393948483145\n",
            "Epoch [8175/10000], train_Loss: 8.045356662478298e-05,test_Loss:22.967063903808594, r2_store:-0.36136067694814966\n",
            "Epoch [8176/10000], train_Loss: 8.092498319456354e-05,test_Loss:22.973974227905273, r2_store:-0.3618139940787659\n",
            "Epoch [8177/10000], train_Loss: 8.141845319187269e-05,test_Loss:22.96810531616211, r2_store:-0.36127111170992476\n",
            "Epoch [8178/10000], train_Loss: 8.161547157214954e-05,test_Loss:22.975360870361328, r2_store:-0.3618159793504907\n",
            "Epoch [8179/10000], train_Loss: 8.139295823639259e-05,test_Loss:22.970012664794922, r2_store:-0.36123873433353215\n",
            "Epoch [8180/10000], train_Loss: 8.07039177743718e-05,test_Loss:22.977783203125, r2_store:-0.3617599969219265\n",
            "Epoch [8181/10000], train_Loss: 7.989681034814566e-05,test_Loss:22.972517013549805, r2_store:-0.3612075163513455\n",
            "Epoch [8182/10000], train_Loss: 7.882863428676501e-05,test_Loss:22.97923469543457, r2_store:-0.36165817738349815\n",
            "Epoch [8183/10000], train_Loss: 7.778088183840737e-05,test_Loss:22.974897384643555, r2_store:-0.3612232638581654\n",
            "Epoch [8184/10000], train_Loss: 7.664232543902472e-05,test_Loss:22.979175567626953, r2_store:-0.3615806439911484\n",
            "Epoch [8185/10000], train_Loss: 7.546036067651585e-05,test_Loss:22.975677490234375, r2_store:-0.3612745477915271\n",
            "Epoch [8186/10000], train_Loss: 7.456283492501825e-05,test_Loss:22.979368209838867, r2_store:-0.3614981329338973\n",
            "Epoch [8187/10000], train_Loss: 7.370210369117558e-05,test_Loss:22.978458404541016, r2_store:-0.36130230201076974\n",
            "Epoch [8188/10000], train_Loss: 7.281883154064417e-05,test_Loss:22.980770111083984, r2_store:-0.36139121090266424\n",
            "Epoch [8189/10000], train_Loss: 7.227672904264182e-05,test_Loss:22.980712890625, r2_store:-0.3612938535988932\n",
            "Epoch [8190/10000], train_Loss: 7.181854743976146e-05,test_Loss:22.98187255859375, r2_store:-0.36129410140127316\n",
            "Epoch [8191/10000], train_Loss: 7.131344318622723e-05,test_Loss:22.982608795166016, r2_store:-0.36129684781294014\n",
            "Epoch [8192/10000], train_Loss: 7.087425183271989e-05,test_Loss:22.982133865356445, r2_store:-0.3612422572882792\n",
            "Epoch [8193/10000], train_Loss: 7.045291567919776e-05,test_Loss:22.983495712280273, r2_store:-0.3613089259854503\n",
            "Epoch [8194/10000], train_Loss: 7.000287587288767e-05,test_Loss:22.983400344848633, r2_store:-0.36120689510520076\n",
            "Epoch [8195/10000], train_Loss: 6.975483847782016e-05,test_Loss:22.9859561920166, r2_store:-0.36128519812466076\n",
            "Epoch [8196/10000], train_Loss: 6.940214370843023e-05,test_Loss:22.986125946044922, r2_store:-0.361137652864727\n",
            "Epoch [8197/10000], train_Loss: 6.89557782607153e-05,test_Loss:22.989177703857422, r2_store:-0.36121711511594423\n",
            "Epoch [8198/10000], train_Loss: 6.850744102848694e-05,test_Loss:22.98856544494629, r2_store:-0.3610644946038337\n",
            "Epoch [8199/10000], train_Loss: 6.822641444159672e-05,test_Loss:22.99007797241211, r2_store:-0.36119460220003474\n",
            "Epoch [8200/10000], train_Loss: 6.792494241381064e-05,test_Loss:22.987934112548828, r2_store:-0.36104922976730536\n",
            "Epoch [8201/10000], train_Loss: 6.754348578397185e-05,test_Loss:22.989797592163086, r2_store:-0.3612167694476389\n",
            "Epoch [8202/10000], train_Loss: 6.722692342009395e-05,test_Loss:22.988235473632812, r2_store:-0.3610351449836773\n",
            "Epoch [8203/10000], train_Loss: 6.697677599731833e-05,test_Loss:22.991174697875977, r2_store:-0.3612118809074041\n",
            "Epoch [8204/10000], train_Loss: 6.672601739410311e-05,test_Loss:22.98988151550293, r2_store:-0.3609427299313974\n",
            "Epoch [8205/10000], train_Loss: 6.649346323683858e-05,test_Loss:22.9945011138916, r2_store:-0.36116301590541267\n",
            "Epoch [8206/10000], train_Loss: 6.646964175160974e-05,test_Loss:22.992279052734375, r2_store:-0.36082281731533383\n",
            "Epoch [8207/10000], train_Loss: 6.659862992819399e-05,test_Loss:22.996864318847656, r2_store:-0.36116213691438737\n",
            "Epoch [8208/10000], train_Loss: 6.681982631562278e-05,test_Loss:22.992544174194336, r2_store:-0.36072102384879745\n",
            "Epoch [8209/10000], train_Loss: 6.72142268740572e-05,test_Loss:22.999250411987305, r2_store:-0.3612055781267818\n",
            "Epoch [8210/10000], train_Loss: 6.809931073803455e-05,test_Loss:22.99338150024414, r2_store:-0.3605930535425832\n",
            "Epoch [8211/10000], train_Loss: 6.939325976418331e-05,test_Loss:23.001676559448242, r2_store:-0.3612610326483392\n",
            "Epoch [8212/10000], train_Loss: 7.116716733435169e-05,test_Loss:22.993045806884766, r2_store:-0.3604275579660716\n",
            "Epoch [8213/10000], train_Loss: 7.368443766608834e-05,test_Loss:23.004924774169922, r2_store:-0.3613573854516261\n",
            "Epoch [8214/10000], train_Loss: 7.731492223683745e-05,test_Loss:22.992963790893555, r2_store:-0.3602316759156221\n",
            "Epoch [8215/10000], train_Loss: 8.283122588181868e-05,test_Loss:23.00830841064453, r2_store:-0.36154773321203915\n",
            "Epoch [8216/10000], train_Loss: 9.109578968491405e-05,test_Loss:22.991168975830078, r2_store:-0.35994785510918303\n",
            "Epoch [8217/10000], train_Loss: 0.00010366025526309386,test_Loss:23.014543533325195, r2_store:-0.36183678922552875\n",
            "Epoch [8218/10000], train_Loss: 0.0001221889688167721,test_Loss:22.989261627197266, r2_store:-0.3595144593812434\n",
            "Epoch [8219/10000], train_Loss: 0.00015046496991999447,test_Loss:23.02126693725586, r2_store:-0.36229671051683865\n",
            "Epoch [8220/10000], train_Loss: 0.00019289689953438938,test_Loss:22.98244857788086, r2_store:-0.35887950586334094\n",
            "Epoch [8221/10000], train_Loss: 0.0002571857476141304,test_Loss:23.030488967895508, r2_store:-0.3630388096935451\n",
            "Epoch [8222/10000], train_Loss: 0.0003548163513187319,test_Loss:22.972698211669922, r2_store:-0.3579157419626824\n",
            "Epoch [8223/10000], train_Loss: 0.000504222116433084,test_Loss:23.04509162902832, r2_store:-0.3641916063078079\n",
            "Epoch [8224/10000], train_Loss: 0.0007339565781876445,test_Loss:22.958189010620117, r2_store:-0.35641394274746596\n",
            "Epoch [8225/10000], train_Loss: 0.0010915978346019983,test_Loss:23.070011138916016, r2_store:-0.3660544490804518\n",
            "Epoch [8226/10000], train_Loss: 0.0016508061671629548,test_Loss:22.93512725830078, r2_store:-0.3540984706286632\n",
            "Epoch [8227/10000], train_Loss: 0.0025326753966510296,test_Loss:23.118057250976562, r2_store:-0.3691791510401201\n",
            "Epoch [8228/10000], train_Loss: 0.0038682185113430023,test_Loss:22.902240753173828, r2_store:-0.3508623173471903\n",
            "Epoch [8229/10000], train_Loss: 0.00590855535119772,test_Loss:23.167774200439453, r2_store:-0.3740633222274816\n",
            "Epoch [8230/10000], train_Loss: 0.008900949731469154,test_Loss:22.836896896362305, r2_store:-0.3463570254135777\n",
            "Epoch [8231/10000], train_Loss: 0.013373916037380695,test_Loss:23.25722312927246, r2_store:-0.38119432701823786\n",
            "Epoch [8232/10000], train_Loss: 0.019827738404273987,test_Loss:22.75228500366211, r2_store:-0.33987724357702964\n",
            "Epoch [8233/10000], train_Loss: 0.029288887977600098,test_Loss:23.362659454345703, r2_store:-0.39121009323277733\n",
            "Epoch [8234/10000], train_Loss: 0.04187840223312378,test_Loss:22.683027267456055, r2_store:-0.3323772751183669\n",
            "Epoch [8235/10000], train_Loss: 0.058441270142793655,test_Loss:23.52499771118164, r2_store:-0.40307932420195014\n",
            "Epoch [8236/10000], train_Loss: 0.07577721774578094,test_Loss:22.600601196289062, r2_store:-0.3265360942141218\n",
            "Epoch [8237/10000], train_Loss: 0.0924425721168518,test_Loss:23.556255340576172, r2_store:-0.4100446238540003\n",
            "Epoch [8238/10000], train_Loss: 0.09850310534238815,test_Loss:22.591442108154297, r2_store:-0.32770826201832204\n",
            "Epoch [8239/10000], train_Loss: 0.0901230052113533,test_Loss:23.413002014160156, r2_store:-0.39966103463748937\n",
            "Epoch [8240/10000], train_Loss: 0.06166418641805649,test_Loss:22.722244262695312, r2_store:-0.34215256332474864\n",
            "Epoch [8241/10000], train_Loss: 0.02763671800494194,test_Loss:23.07626724243164, r2_store:-0.3708557371385013\n",
            "Epoch [8242/10000], train_Loss: 0.00422013271600008,test_Loss:23.085304260253906, r2_store:-0.3683386494371086\n",
            "Epoch [8243/10000], train_Loss: 0.002578651998192072,test_Loss:22.85799789428711, r2_store:-0.3458535104650635\n",
            "Epoch [8244/10000], train_Loss: 0.01758890226483345,test_Loss:23.401248931884766, r2_store:-0.3885256167939526\n",
            "Epoch [8245/10000], train_Loss: 0.033618178218603134,test_Loss:22.78740119934082, r2_store:-0.3394986349739735\n",
            "Epoch [8246/10000], train_Loss: 0.03760414943099022,test_Loss:23.358583450317383, r2_store:-0.38634542551792395\n",
            "Epoch [8247/10000], train_Loss: 0.025852221995592117,test_Loss:22.939228057861328, r2_store:-0.35199935921937153\n",
            "Epoch [8248/10000], train_Loss: 0.00933519285172224,test_Loss:23.055484771728516, r2_store:-0.36565570144466286\n",
            "Epoch [8249/10000], train_Loss: 0.0007250717608258128,test_Loss:23.1256046295166, r2_store:-0.3720516999223795\n",
            "Epoch [8250/10000], train_Loss: 0.004471852444112301,test_Loss:22.889846801757812, r2_store:-0.3485965691457453\n",
            "Epoch [8251/10000], train_Loss: 0.014002511277794838,test_Loss:23.306316375732422, r2_store:-0.3817497924981128\n",
            "Epoch [8252/10000], train_Loss: 0.019399480894207954,test_Loss:22.85698699951172, r2_store:-0.3461690077495423\n",
            "Epoch [8253/10000], train_Loss: 0.016135241836309433,test_Loss:23.18368911743164, r2_store:-0.37291006548360484\n",
            "Epoch [8254/10000], train_Loss: 0.007470232900232077,test_Loss:23.00796127319336, r2_store:-0.3579495430024531\n",
            "Epoch [8255/10000], train_Loss: 0.0011627360945567489,test_Loss:22.981040954589844, r2_store:-0.35764504832865396\n",
            "Epoch [8256/10000], train_Loss: 0.0013058001641184092,test_Loss:23.13836669921875, r2_store:-0.3720122957344014\n",
            "Epoch [8257/10000], train_Loss: 0.006005917210131884,test_Loss:22.885597229003906, r2_store:-0.3494935787243003\n",
            "Epoch [8258/10000], train_Loss: 0.010035420767962933,test_Loss:23.21017074584961, r2_store:-0.3758128919043111\n",
            "Epoch [8259/10000], train_Loss: 0.00967333186417818,test_Loss:22.901185989379883, r2_store:-0.35316007426201423\n",
            "Epoch [8260/10000], train_Loss: 0.005664915777742863,test_Loss:23.051485061645508, r2_store:-0.3676836589622523\n",
            "Epoch [8261/10000], train_Loss: 0.0015451174695044756,test_Loss:23.013713836669922, r2_store:-0.3642369517674451\n",
            "Epoch [8262/10000], train_Loss: 0.00035188780748285353,test_Loss:22.930919647216797, r2_store:-0.3577869408113856\n",
            "Epoch [8263/10000], train_Loss: 0.0021540140733122826,test_Loss:23.087730407714844, r2_store:-0.3726906087701267\n",
            "Epoch [8264/10000], train_Loss: 0.004663418047130108,test_Loss:22.859241485595703, r2_store:-0.354172907090438\n",
            "Epoch [8265/10000], train_Loss: 0.005516798701137304,test_Loss:23.084585189819336, r2_store:-0.37227045815845594\n",
            "Epoch [8266/10000], train_Loss: 0.004076623357832432,test_Loss:22.911808013916016, r2_store:-0.3585398216080604\n",
            "Epoch [8267/10000], train_Loss: 0.0017484925920143723,test_Loss:22.97492218017578, r2_store:-0.3649792640167244\n",
            "Epoch [8268/10000], train_Loss: 0.00032487412681803107,test_Loss:22.997339248657227, r2_store:-0.3662493604133008\n",
            "Epoch [8269/10000], train_Loss: 0.0005403055110946298,test_Loss:22.914941787719727, r2_store:-0.35874836572616897\n",
            "Epoch [8270/10000], train_Loss: 0.0017952462658286095,test_Loss:23.05192756652832, r2_store:-0.3712605978397969\n",
            "Epoch [8271/10000], train_Loss: 0.002805837197229266,test_Loss:22.873672485351562, r2_store:-0.3578222150219488\n",
            "Epoch [8272/10000], train_Loss: 0.002773724030703306,test_Loss:23.021648406982422, r2_store:-0.3703260216431037\n",
            "Epoch [8273/10000], train_Loss: 0.0018032006919384003,test_Loss:22.916316986083984, r2_store:-0.3619285767335798\n",
            "Epoch [8274/10000], train_Loss: 0.0007017002208158374,test_Loss:22.945575714111328, r2_store:-0.365266337705318\n",
            "Epoch [8275/10000], train_Loss: 0.00017762253992259502,test_Loss:22.9680118560791, r2_store:-0.3669344760933555\n",
            "Epoch [8276/10000], train_Loss: 0.0004243025614414364,test_Loss:22.907928466796875, r2_store:-0.36062806175806195\n",
            "Epoch [8277/10000], train_Loss: 0.0010551598388701677,test_Loss:23.01681900024414, r2_store:-0.3694089997639953\n",
            "Epoch [8278/10000], train_Loss: 0.0014997071120887995,test_Loss:22.89488410949707, r2_store:-0.3594478118159017\n",
            "Epoch [8279/10000], train_Loss: 0.001451810821890831,test_Loss:23.004390716552734, r2_store:-0.36810781374998536\n",
            "Epoch [8280/10000], train_Loss: 0.0009833791991695762,test_Loss:22.940837860107422, r2_store:-0.3619025504947988\n",
            "Epoch [8281/10000], train_Loss: 0.00044659999548457563,test_Loss:22.96887969970703, r2_store:-0.3647175874926718\n",
            "Epoch [8282/10000], train_Loss: 0.00015645679377485067,test_Loss:22.970657348632812, r2_store:-0.3653677858036908\n",
            "Epoch [8283/10000], train_Loss: 0.0002222895564045757,test_Loss:22.933216094970703, r2_store:-0.3616108461525316\n",
            "Epoch [8284/10000], train_Loss: 0.0004966655978932977,test_Loss:23.00809097290039, r2_store:-0.3674077592622327\n",
            "Epoch [8285/10000], train_Loss: 0.000749184750020504,test_Loss:22.926042556762695, r2_store:-0.36044840785308896\n",
            "Epoch [8286/10000], train_Loss: 0.0008040863904170692,test_Loss:23.002897262573242, r2_store:-0.3668953740381151\n",
            "Epoch [8287/10000], train_Loss: 0.0006474328110925853,test_Loss:22.950393676757812, r2_store:-0.3616969360945974\n",
            "Epoch [8288/10000], train_Loss: 0.000392409332562238,test_Loss:22.989591598510742, r2_store:-0.36499910757779896\n",
            "Epoch [8289/10000], train_Loss: 0.00018712067685555667,test_Loss:22.971654891967773, r2_store:-0.3641138296398816\n",
            "Epoch [8290/10000], train_Loss: 0.0001229716872330755,test_Loss:22.95724105834961, r2_store:-0.3629570930412491\n",
            "Epoch [8291/10000], train_Loss: 0.00019428787345532328,test_Loss:22.997629165649414, r2_store:-0.366184459118462\n",
            "Epoch [8292/10000], train_Loss: 0.0003244899562560022,test_Loss:22.942699432373047, r2_store:-0.361933252931693\n",
            "Epoch [8293/10000], train_Loss: 0.00041995401261374354,test_Loss:22.994342803955078, r2_store:-0.3666283136920603\n",
            "Epoch [8294/10000], train_Loss: 0.00043001113226637244,test_Loss:22.944894790649414, r2_store:-0.3620956063905245\n",
            "Epoch [8295/10000], train_Loss: 0.00035468494752421975,test_Loss:22.992488861083984, r2_store:-0.3656647559454569\n",
            "Epoch [8296/10000], train_Loss: 0.0002427377039566636,test_Loss:22.962453842163086, r2_store:-0.36318071985470857\n",
            "Epoch [8297/10000], train_Loss: 0.00014771806308999658,test_Loss:22.973857879638672, r2_store:-0.36403073317884993\n",
            "Epoch [8298/10000], train_Loss: 0.00010843788186321035,test_Loss:22.986570358276367, r2_store:-0.36451755903375527\n",
            "Epoch [8299/10000], train_Loss: 0.00012538146984297782,test_Loss:22.96887969970703, r2_store:-0.3627827670094639\n",
            "Epoch [8300/10000], train_Loss: 0.00017568159091752023,test_Loss:22.996326446533203, r2_store:-0.36534597058426876\n",
            "Epoch [8301/10000], train_Loss: 0.0002240677858935669,test_Loss:22.960418701171875, r2_store:-0.36222945260322326\n",
            "Epoch [8302/10000], train_Loss: 0.00024513836251571774,test_Loss:23.00218963623047, r2_store:-0.36535556905980027\n",
            "Epoch [8303/10000], train_Loss: 0.00023193485685624182,test_Loss:22.968570709228516, r2_store:-0.3624788312932343\n",
            "Epoch [8304/10000], train_Loss: 0.0001923770469147712,test_Loss:22.992883682250977, r2_store:-0.36465621061158116\n",
            "Epoch [8305/10000], train_Loss: 0.00014604903117287904,test_Loss:22.978219985961914, r2_store:-0.36325280591005593\n",
            "Epoch [8306/10000], train_Loss: 0.00011082868149969727,test_Loss:22.987529754638672, r2_store:-0.36377027851327526\n",
            "Epoch [8307/10000], train_Loss: 9.712799510452896e-05,test_Loss:22.991302490234375, r2_store:-0.3640897189658654\n",
            "Epoch [8308/10000], train_Loss: 0.00010354898404330015,test_Loss:22.978418350219727, r2_store:-0.36296902679787224\n",
            "Epoch [8309/10000], train_Loss: 0.00012247714039403945,test_Loss:23.001201629638672, r2_store:-0.36459206666574895\n",
            "Epoch [8310/10000], train_Loss: 0.0001413290447089821,test_Loss:22.978727340698242, r2_store:-0.3626119242213135\n",
            "Epoch [8311/10000], train_Loss: 0.0001515653420938179,test_Loss:23.00074577331543, r2_store:-0.3646468423978293\n",
            "Epoch [8312/10000], train_Loss: 0.0001501634978922084,test_Loss:22.97652816772461, r2_store:-0.36267930591900854\n",
            "Epoch [8313/10000], train_Loss: 0.0001382291375193745,test_Loss:22.99769401550293, r2_store:-0.36434996824658894\n",
            "Epoch [8314/10000], train_Loss: 0.00012116545985918492,test_Loss:22.982473373413086, r2_store:-0.36306840804073115\n",
            "Epoch [8315/10000], train_Loss: 0.00010416066652396694,test_Loss:22.991167068481445, r2_store:-0.3638270561406489\n",
            "Epoch [8316/10000], train_Loss: 9.261710511054844e-05,test_Loss:22.989391326904297, r2_store:-0.3635506073190802\n",
            "Epoch [8317/10000], train_Loss: 8.811218140181154e-05,test_Loss:22.988351821899414, r2_store:-0.36335764333661946\n",
            "Epoch [8318/10000], train_Loss: 8.99696970009245e-05,test_Loss:22.994640350341797, r2_store:-0.36396546405108987\n",
            "Epoch [8319/10000], train_Loss: 9.53976996243e-05,test_Loss:22.982730865478516, r2_store:-0.3630374129075955\n",
            "Epoch [8320/10000], train_Loss: 0.00010150129674002528,test_Loss:22.997447967529297, r2_store:-0.3641872003615534\n",
            "Epoch [8321/10000], train_Loss: 0.00010567014396656305,test_Loss:22.98312759399414, r2_store:-0.3629318965368806\n",
            "Epoch [8322/10000], train_Loss: 0.00010721296712290496,test_Loss:22.99772071838379, r2_store:-0.3641702562161897\n",
            "Epoch [8323/10000], train_Loss: 0.00010529498104006052,test_Loss:22.984832763671875, r2_store:-0.36296775970342443\n",
            "Epoch [8324/10000], train_Loss: 0.0001005075391731225,test_Loss:22.99929428100586, r2_store:-0.36397516796181373\n",
            "Epoch [8325/10000], train_Loss: 9.41553880693391e-05,test_Loss:22.990392684936523, r2_store:-0.3631519954291016\n",
            "Epoch [8326/10000], train_Loss: 8.838616486173123e-05,test_Loss:22.996410369873047, r2_store:-0.3637062560900426\n",
            "Epoch [8327/10000], train_Loss: 8.40879583847709e-05,test_Loss:22.992984771728516, r2_store:-0.3634177121179336\n",
            "Epoch [8328/10000], train_Loss: 8.132551738526672e-05,test_Loss:22.993663787841797, r2_store:-0.36351221596002126\n",
            "Epoch [8329/10000], train_Loss: 8.027299190871418e-05,test_Loss:22.99413299560547, r2_store:-0.36365901137351986\n",
            "Epoch [8330/10000], train_Loss: 8.041819091886282e-05,test_Loss:22.990177154541016, r2_store:-0.36332896923563607\n",
            "Epoch [8331/10000], train_Loss: 8.133573282975703e-05,test_Loss:22.997394561767578, r2_store:-0.3637857937490798\n",
            "Epoch [8332/10000], train_Loss: 8.232320396928117e-05,test_Loss:22.991701126098633, r2_store:-0.3631774535612584\n",
            "Epoch [8333/10000], train_Loss: 8.321598579641432e-05,test_Loss:23.000059127807617, r2_store:-0.36379339098537145\n",
            "Epoch [8334/10000], train_Loss: 8.386140689253807e-05,test_Loss:22.993473052978516, r2_store:-0.363057253202441\n",
            "Epoch [8335/10000], train_Loss: 8.371791045647115e-05,test_Loss:23.003690719604492, r2_store:-0.3637231624012929\n",
            "Epoch [8336/10000], train_Loss: 8.303250069729984e-05,test_Loss:22.99626350402832, r2_store:-0.36303753878830913\n",
            "Epoch [8337/10000], train_Loss: 8.169624925358221e-05,test_Loss:23.002582550048828, r2_store:-0.3636566774562078\n",
            "Epoch [8338/10000], train_Loss: 7.997818465810269e-05,test_Loss:22.99566650390625, r2_store:-0.36314349187527317\n",
            "Epoch [8339/10000], train_Loss: 7.843787170713767e-05,test_Loss:23.0011043548584, r2_store:-0.36362303832614984\n",
            "Epoch [8340/10000], train_Loss: 7.69056860008277e-05,test_Loss:22.997024536132812, r2_store:-0.3632666150700614\n",
            "Epoch [8341/10000], train_Loss: 7.542238745372742e-05,test_Loss:23.001022338867188, r2_store:-0.3635249955043536\n",
            "Epoch [8342/10000], train_Loss: 7.412927516270429e-05,test_Loss:23.000106811523438, r2_store:-0.3633299136292809\n",
            "Epoch [8343/10000], train_Loss: 7.32386251911521e-05,test_Loss:23.001840591430664, r2_store:-0.3633851739352634\n",
            "Epoch [8344/10000], train_Loss: 7.271956565091386e-05,test_Loss:23.002225875854492, r2_store:-0.3633489968234489\n",
            "Epoch [8345/10000], train_Loss: 7.22964177839458e-05,test_Loss:23.00187873840332, r2_store:-0.3632246329090669\n",
            "Epoch [8346/10000], train_Loss: 7.195548096206039e-05,test_Loss:23.004438400268555, r2_store:-0.36336941454997307\n",
            "Epoch [8347/10000], train_Loss: 7.175119390012696e-05,test_Loss:23.001461029052734, r2_store:-0.3631560915356489\n",
            "Epoch [8348/10000], train_Loss: 7.171790639404207e-05,test_Loss:23.004039764404297, r2_store:-0.3634058699577032\n",
            "Epoch [8349/10000], train_Loss: 7.153164187911898e-05,test_Loss:23.001876831054688, r2_store:-0.3631086725771122\n",
            "Epoch [8350/10000], train_Loss: 7.136265048757195e-05,test_Loss:23.007030487060547, r2_store:-0.36341568712465633\n",
            "Epoch [8351/10000], train_Loss: 7.119474321370944e-05,test_Loss:23.0034122467041, r2_store:-0.36307770460249933\n",
            "Epoch [8352/10000], train_Loss: 7.089065911713988e-05,test_Loss:23.00733184814453, r2_store:-0.36339711285432386\n",
            "Epoch [8353/10000], train_Loss: 7.050506246741861e-05,test_Loss:23.004186630249023, r2_store:-0.36305216110777105\n",
            "Epoch [8354/10000], train_Loss: 7.015668961685151e-05,test_Loss:23.008319854736328, r2_store:-0.3633951600799954\n",
            "Epoch [8355/10000], train_Loss: 6.985518848523498e-05,test_Loss:23.002182006835938, r2_store:-0.36301616266720593\n",
            "Epoch [8356/10000], train_Loss: 6.972848495934159e-05,test_Loss:23.007678985595703, r2_store:-0.36336281959529515\n",
            "Epoch [8357/10000], train_Loss: 6.936881254659966e-05,test_Loss:23.00545310974121, r2_store:-0.36295381585051434\n",
            "Epoch [8358/10000], train_Loss: 6.911785749252886e-05,test_Loss:23.009220123291016, r2_store:-0.36330788076856324\n",
            "Epoch [8359/10000], train_Loss: 6.912554090376943e-05,test_Loss:23.00489616394043, r2_store:-0.3628463498786185\n",
            "Epoch [8360/10000], train_Loss: 6.919697625562549e-05,test_Loss:23.01235580444336, r2_store:-0.36329934944142517\n",
            "Epoch [8361/10000], train_Loss: 6.930319068487734e-05,test_Loss:23.005413055419922, r2_store:-0.3627831659615517\n",
            "Epoch [8362/10000], train_Loss: 6.929285154910758e-05,test_Loss:23.012130737304688, r2_store:-0.36330644809833257\n",
            "Epoch [8363/10000], train_Loss: 6.959497841307893e-05,test_Loss:23.007335662841797, r2_store:-0.3627224274642531\n",
            "Epoch [8364/10000], train_Loss: 7.01674580341205e-05,test_Loss:23.014131546020508, r2_store:-0.36336071687247795\n",
            "Epoch [8365/10000], train_Loss: 7.102989184204489e-05,test_Loss:23.0057373046875, r2_store:-0.3626081648481647\n",
            "Epoch [8366/10000], train_Loss: 7.245574670378119e-05,test_Loss:23.016904830932617, r2_store:-0.36340500182247126\n",
            "Epoch [8367/10000], train_Loss: 7.443454524036497e-05,test_Loss:23.006649017333984, r2_store:-0.36243527065829984\n",
            "Epoch [8368/10000], train_Loss: 7.722136797383428e-05,test_Loss:23.019567489624023, r2_store:-0.36347932652487347\n",
            "Epoch [8369/10000], train_Loss: 8.117389370454475e-05,test_Loss:23.00442123413086, r2_store:-0.3622293476245708\n",
            "Epoch [8370/10000], train_Loss: 8.645071648061275e-05,test_Loss:23.022228240966797, r2_store:-0.3636165834415961\n",
            "Epoch [8371/10000], train_Loss: 9.341869736090302e-05,test_Loss:23.002782821655273, r2_store:-0.3619783473525171\n",
            "Epoch [8372/10000], train_Loss: 0.00010311925871064886,test_Loss:23.025728225708008, r2_store:-0.3638080437859146\n",
            "Epoch [8373/10000], train_Loss: 0.0001167168520623818,test_Loss:23.002721786499023, r2_store:-0.36163765629960154\n",
            "Epoch [8374/10000], train_Loss: 0.00013591161405202,test_Loss:23.032346725463867, r2_store:-0.36413087346869655\n",
            "Epoch [8375/10000], train_Loss: 0.00016313113155774772,test_Loss:22.995765686035156, r2_store:-0.36115966420753276\n",
            "Epoch [8376/10000], train_Loss: 0.00020194114767946303,test_Loss:23.039642333984375, r2_store:-0.36464384304737285\n",
            "Epoch [8377/10000], train_Loss: 0.0002578162238933146,test_Loss:22.9904842376709, r2_store:-0.36050767982562015\n",
            "Epoch [8378/10000], train_Loss: 0.00033788743894547224,test_Loss:23.048303604125977, r2_store:-0.3654013455285825\n",
            "Epoch [8379/10000], train_Loss: 0.0004537723434623331,test_Loss:22.980730056762695, r2_store:-0.35953528804794344\n",
            "Epoch [8380/10000], train_Loss: 0.0006217079935595393,test_Loss:23.065723419189453, r2_store:-0.36654435299788823\n",
            "Epoch [8381/10000], train_Loss: 0.0008699721656739712,test_Loss:22.962810516357422, r2_store:-0.35809476061406564\n",
            "Epoch [8382/10000], train_Loss: 0.0012369320029392838,test_Loss:23.085439682006836, r2_store:-0.36831405060686917\n",
            "Epoch [8383/10000], train_Loss: 0.0017851559678092599,test_Loss:22.944866180419922, r2_store:-0.3560144231325524\n",
            "Epoch [8384/10000], train_Loss: 0.002607164904475212,test_Loss:23.121685028076172, r2_store:-0.3711186289475852\n",
            "Epoch [8385/10000], train_Loss: 0.0038263003807514906,test_Loss:22.895153045654297, r2_store:-0.3528521406640017\n",
            "Epoch [8386/10000], train_Loss: 0.005672551691532135,test_Loss:23.1715145111084, r2_store:-0.3754120512115191\n",
            "Epoch [8387/10000], train_Loss: 0.00841265544295311,test_Loss:22.864482879638672, r2_store:-0.3483405255477363\n",
            "Epoch [8388/10000], train_Loss: 0.012555668130517006,test_Loss:23.262128829956055, r2_store:-0.38201235784568377\n",
            "Epoch [8389/10000], train_Loss: 0.01852830871939659,test_Loss:22.762165069580078, r2_store:-0.342114184515691\n",
            "Epoch [8390/10000], train_Loss: 0.027365505695343018,test_Loss:23.36117935180664, r2_store:-0.3919611354758439\n",
            "Epoch [8391/10000], train_Loss: 0.039207182824611664,test_Loss:22.69369888305664, r2_store:-0.3346914371473193\n",
            "Epoch [8392/10000], train_Loss: 0.0554082915186882,test_Loss:23.513870239257812, r2_store:-0.4038690120515753\n",
            "Epoch [8393/10000], train_Loss: 0.07311089336872101,test_Loss:22.595857620239258, r2_store:-0.3282069206777689\n",
            "Epoch [8394/10000], train_Loss: 0.09132872521877289,test_Loss:23.592395782470703, r2_store:-0.41206043455025787\n",
            "Epoch [8395/10000], train_Loss: 0.0991540402173996,test_Loss:22.59756851196289, r2_store:-0.328584066573832\n",
            "Epoch [8396/10000], train_Loss: 0.09351173788309097,test_Loss:23.45098114013672, r2_store:-0.40263347023195917\n",
            "Epoch [8397/10000], train_Loss: 0.06722225248813629,test_Loss:22.72535514831543, r2_store:-0.34147081663620793\n",
            "Epoch [8398/10000], train_Loss: 0.03344113007187843,test_Loss:23.11677360534668, r2_store:-0.37483868393703856\n",
            "Epoch [8399/10000], train_Loss: 0.006939338985830545,test_Loss:23.039499282836914, r2_store:-0.3669353896631402\n",
            "Epoch [8400/10000], train_Loss: 0.0012155332369729877,test_Loss:22.85713005065918, r2_store:-0.34852758311321264\n",
            "Epoch [8401/10000], train_Loss: 0.013894791714847088,test_Loss:23.368358612060547, r2_store:-0.3878906339225241\n",
            "Epoch [8402/10000], train_Loss: 0.03078945353627205,test_Loss:22.834136962890625, r2_store:-0.34009301463039154\n",
            "Epoch [8403/10000], train_Loss: 0.03772035986185074,test_Loss:23.401334762573242, r2_store:-0.38836865288120315\n",
            "Epoch [8404/10000], train_Loss: 0.028528068214654922,test_Loss:22.873647689819336, r2_store:-0.35083352643367016\n",
            "Epoch [8405/10000], train_Loss: 0.012345846742391586,test_Loss:23.111099243164062, r2_store:-0.3691003041480001\n",
            "Epoch [8406/10000], train_Loss: 0.0014084518188610673,test_Loss:23.163759231567383, r2_store:-0.37119283658919744\n",
            "Epoch [8407/10000], train_Loss: 0.002688450738787651,test_Loss:22.865089416503906, r2_store:-0.3509307206515282\n",
            "Epoch [8408/10000], train_Loss: 0.01155700534582138,test_Loss:23.24128532409668, r2_store:-0.3829287224128479\n",
            "Epoch [8409/10000], train_Loss: 0.018468499183654785,test_Loss:22.848670959472656, r2_store:-0.34744435777449767\n",
            "Epoch [8410/10000], train_Loss: 0.017366638407111168,test_Loss:23.208681106567383, r2_store:-0.37637805744884556\n",
            "Epoch [8411/10000], train_Loss: 0.009500479325652122,test_Loss:22.937541961669922, r2_store:-0.35720512565805396\n",
            "Epoch [8412/10000], train_Loss: 0.0022056957241147757,test_Loss:22.989704132080078, r2_store:-0.36099336814465666\n",
            "Epoch [8413/10000], train_Loss: 0.0005723746726289392,test_Loss:23.146963119506836, r2_store:-0.3719734462181432\n",
            "Epoch [8414/10000], train_Loss: 0.004348329268395901,test_Loss:22.882129669189453, r2_store:-0.35148638267909615\n",
            "Epoch [8415/10000], train_Loss: 0.008904223330318928,test_Loss:23.174495697021484, r2_store:-0.3768160811061061\n",
            "Epoch [8416/10000], train_Loss: 0.0099340146407485,test_Loss:22.91727066040039, r2_store:-0.3531035156301936\n",
            "Epoch [8417/10000], train_Loss: 0.006832207087427378,test_Loss:23.112276077270508, r2_store:-0.37018788040817263\n",
            "Epoch [8418/10000], train_Loss: 0.002495515625923872,test_Loss:22.98501205444336, r2_store:-0.36310693757107604\n",
            "Epoch [8419/10000], train_Loss: 0.0003321158292237669,test_Loss:22.94554901123047, r2_store:-0.35982506837375805\n",
            "Epoch [8420/10000], train_Loss: 0.001319091534242034,test_Loss:23.128206253051758, r2_store:-0.37265137972542095\n",
            "Epoch [8421/10000], train_Loss: 0.0038208060432225466,test_Loss:22.90970230102539, r2_store:-0.3553954639832062\n",
            "Epoch [8422/10000], train_Loss: 0.005325660575181246,test_Loss:23.093509674072266, r2_store:-0.373916235688305\n",
            "Epoch [8423/10000], train_Loss: 0.0045919353142380714,test_Loss:22.914825439453125, r2_store:-0.3589026097082786\n",
            "Epoch [8424/10000], train_Loss: 0.0024401466362178326,test_Loss:23.03526496887207, r2_store:-0.3680378204498209\n",
            "Epoch [8425/10000], train_Loss: 0.000630432739853859,test_Loss:23.002098083496094, r2_store:-0.36643996903773535\n",
            "Epoch [8426/10000], train_Loss: 0.00027429338661022484,test_Loss:22.923799514770508, r2_store:-0.361042621033989\n",
            "Epoch [8427/10000], train_Loss: 0.0012556444853544235,test_Loss:23.066173553466797, r2_store:-0.37212325210625474\n",
            "Epoch [8428/10000], train_Loss: 0.0024336660280823708,test_Loss:22.91312599182129, r2_store:-0.35908899043119\n",
            "Epoch [8429/10000], train_Loss: 0.0028064819052815437,test_Loss:23.047588348388672, r2_store:-0.37192355457729254\n",
            "Epoch [8430/10000], train_Loss: 0.0021341671235859394,test_Loss:22.926753997802734, r2_store:-0.36207997423366933\n",
            "Epoch [8431/10000], train_Loss: 0.0010342341847717762,test_Loss:23.00037956237793, r2_store:-0.36745125129473144\n",
            "Epoch [8432/10000], train_Loss: 0.00027203006902709603,test_Loss:22.99346923828125, r2_store:-0.36724744656910846\n",
            "Epoch [8433/10000], train_Loss: 0.00025182394892908633,test_Loss:22.928945541381836, r2_store:-0.3623814353006112\n",
            "Epoch [8434/10000], train_Loss: 0.0007839844329282641,test_Loss:23.033870697021484, r2_store:-0.3702134391349243\n",
            "Epoch [8435/10000], train_Loss: 0.0013251056661829352,test_Loss:22.927446365356445, r2_store:-0.3606799935057201\n",
            "Epoch [8436/10000], train_Loss: 0.0014765494270250201,test_Loss:23.01995277404785, r2_store:-0.3697536234913017\n",
            "Epoch [8437/10000], train_Loss: 0.0011493416968733072,test_Loss:22.926570892333984, r2_store:-0.3625629173903919\n",
            "Epoch [8438/10000], train_Loss: 0.0006204627570696175,test_Loss:22.98725700378418, r2_store:-0.36679818781963536\n",
            "Epoch [8439/10000], train_Loss: 0.00022358442947734147,test_Loss:22.983135223388672, r2_store:-0.3661566314622646\n",
            "Epoch [8440/10000], train_Loss: 0.0001579591480549425,test_Loss:22.943744659423828, r2_store:-0.3635156620106992\n",
            "Epoch [8441/10000], train_Loss: 0.00036427105078473687,test_Loss:23.00692367553711, r2_store:-0.36850191411610433\n",
            "Epoch [8442/10000], train_Loss: 0.0006397204706445336,test_Loss:22.94478988647461, r2_store:-0.3619842208523416\n",
            "Epoch [8443/10000], train_Loss: 0.0007794330595061183,test_Loss:23.02434539794922, r2_store:-0.3684669525018658\n",
            "Epoch [8444/10000], train_Loss: 0.0007007629028521478,test_Loss:22.951143264770508, r2_store:-0.3626146104011123\n",
            "Epoch [8445/10000], train_Loss: 0.000480130867799744,test_Loss:23.001201629638672, r2_store:-0.36667298729468745\n",
            "Epoch [8446/10000], train_Loss: 0.0002489452308509499,test_Loss:22.98166275024414, r2_store:-0.3648867618085241\n",
            "Epoch [8447/10000], train_Loss: 0.0001306007179664448,test_Loss:22.971097946166992, r2_store:-0.36448436611172563\n",
            "Epoch [8448/10000], train_Loss: 0.00015177087334450334,test_Loss:22.997724533081055, r2_store:-0.3668809354968914\n",
            "Epoch [8449/10000], train_Loss: 0.0002642183389980346,test_Loss:22.958831787109375, r2_store:-0.3631695933743915\n",
            "Epoch [8450/10000], train_Loss: 0.0003772061609197408,test_Loss:23.011737823486328, r2_store:-0.3677190368757999\n",
            "Epoch [8451/10000], train_Loss: 0.00042277644388377666,test_Loss:22.954059600830078, r2_store:-0.3630967875318911\n",
            "Epoch [8452/10000], train_Loss: 0.00038095199852250516,test_Loss:23.004709243774414, r2_store:-0.36699317080621663\n",
            "Epoch [8453/10000], train_Loss: 0.0002810018486343324,test_Loss:22.977134704589844, r2_store:-0.36408321889038775\n",
            "Epoch [8454/10000], train_Loss: 0.00017958645184990019,test_Loss:22.993213653564453, r2_store:-0.3654925266192115\n",
            "Epoch [8455/10000], train_Loss: 0.000117556206532754,test_Loss:22.991790771484375, r2_store:-0.36533130436898653\n",
            "Epoch [8456/10000], train_Loss: 0.00011358961637597531,test_Loss:22.984493255615234, r2_store:-0.3640677246977546\n",
            "Epoch [8457/10000], train_Loss: 0.00015158001042436808,test_Loss:23.01447296142578, r2_store:-0.36627904939220945\n",
            "Epoch [8458/10000], train_Loss: 0.00020208695787005126,test_Loss:22.976171493530273, r2_store:-0.3634034999933895\n",
            "Epoch [8459/10000], train_Loss: 0.0002342028310522437,test_Loss:23.01034164428711, r2_store:-0.36652167849532713\n",
            "Epoch [8460/10000], train_Loss: 0.00023414907627739012,test_Loss:22.979528427124023, r2_store:-0.36365364535454625\n",
            "Epoch [8461/10000], train_Loss: 0.00020438044157344848,test_Loss:23.007802963256836, r2_store:-0.36606609893218334\n",
            "Epoch [8462/10000], train_Loss: 0.0001605845900485292,test_Loss:22.985740661621094, r2_store:-0.3643107245240109\n",
            "Epoch [8463/10000], train_Loss: 0.00012140517355874181,test_Loss:22.999034881591797, r2_store:-0.36513405921282227\n",
            "Epoch [8464/10000], train_Loss: 9.883919119602069e-05,test_Loss:23.002805709838867, r2_store:-0.3651077364468345\n",
            "Epoch [8465/10000], train_Loss: 9.815582598093897e-05,test_Loss:22.992633819580078, r2_store:-0.36429164232719424\n",
            "Epoch [8466/10000], train_Loss: 0.00011164696479681879,test_Loss:23.00901222229004, r2_store:-0.36565621316547436\n",
            "Epoch [8467/10000], train_Loss: 0.0001303850585827604,test_Loss:22.990808486938477, r2_store:-0.36389676307775587\n",
            "Epoch [8468/10000], train_Loss: 0.00014388216368388385,test_Loss:23.014389038085938, r2_store:-0.36586564917409237\n",
            "Epoch [8469/10000], train_Loss: 0.00014686021313536912,test_Loss:22.989810943603516, r2_store:-0.36389086676672044\n",
            "Epoch [8470/10000], train_Loss: 0.00013879526522941887,test_Loss:23.01302719116211, r2_store:-0.3655891726683791\n",
            "Epoch [8471/10000], train_Loss: 0.00012369148316793144,test_Loss:23.000734329223633, r2_store:-0.3642250416788557\n",
            "Epoch [8472/10000], train_Loss: 0.00010735289106378332,test_Loss:23.010356903076172, r2_store:-0.3651317159519889\n",
            "Epoch [8473/10000], train_Loss: 9.421094000572339e-05,test_Loss:23.003870010375977, r2_store:-0.3646964844013414\n",
            "Epoch [8474/10000], train_Loss: 8.766523387748748e-05,test_Loss:23.005624771118164, r2_store:-0.3646557750044179\n",
            "Epoch [8475/10000], train_Loss: 8.733807044336572e-05,test_Loss:23.012277603149414, r2_store:-0.3651323623488625\n",
            "Epoch [8476/10000], train_Loss: 9.209963900502771e-05,test_Loss:23.00065040588379, r2_store:-0.3642580098545216\n",
            "Epoch [8477/10000], train_Loss: 9.82004203251563e-05,test_Loss:23.014015197753906, r2_store:-0.3653159593637938\n",
            "Epoch [8478/10000], train_Loss: 0.00010339255823055282,test_Loss:23.002071380615234, r2_store:-0.3640761706627378\n",
            "Epoch [8479/10000], train_Loss: 0.00010625338472891599,test_Loss:23.016525268554688, r2_store:-0.3653457667407345\n",
            "Epoch [8480/10000], train_Loss: 0.00010533215390751138,test_Loss:22.99933433532715, r2_store:-0.36410513862163296\n",
            "Epoch [8481/10000], train_Loss: 0.00010172792099183425,test_Loss:23.01316261291504, r2_store:-0.3652510961593156\n",
            "Epoch [8482/10000], train_Loss: 9.614419104764238e-05,test_Loss:23.002519607543945, r2_store:-0.36433127170230417\n",
            "Epoch [8483/10000], train_Loss: 9.055633563548326e-05,test_Loss:23.00969696044922, r2_store:-0.36502206925993175\n",
            "Epoch [8484/10000], train_Loss: 8.522444841219112e-05,test_Loss:23.0052433013916, r2_store:-0.36450118067018655\n",
            "Epoch [8485/10000], train_Loss: 8.115055243251845e-05,test_Loss:23.011703491210938, r2_store:-0.3647049713136983\n",
            "Epoch [8486/10000], train_Loss: 7.917526818346232e-05,test_Loss:23.011808395385742, r2_store:-0.36467388411434043\n",
            "Epoch [8487/10000], train_Loss: 7.866099622333422e-05,test_Loss:23.007413864135742, r2_store:-0.364466876578053\n",
            "Epoch [8488/10000], train_Loss: 7.925447425805032e-05,test_Loss:23.012371063232422, r2_store:-0.3648583578586122\n",
            "Epoch [8489/10000], train_Loss: 8.011658064788207e-05,test_Loss:23.007280349731445, r2_store:-0.36438308789197715\n",
            "Epoch [8490/10000], train_Loss: 8.131477807182819e-05,test_Loss:23.01266098022461, r2_store:-0.3650086533717012\n",
            "Epoch [8491/10000], train_Loss: 8.224104385590181e-05,test_Loss:23.003337860107422, r2_store:-0.3643094151631421\n",
            "Epoch [8492/10000], train_Loss: 8.277400047518313e-05,test_Loss:23.013792037963867, r2_store:-0.36502533394201286\n",
            "Epoch [8493/10000], train_Loss: 8.309907570946962e-05,test_Loss:23.00583267211914, r2_store:-0.36421606085878455\n",
            "Epoch [8494/10000], train_Loss: 8.243567572208121e-05,test_Loss:23.01505470275879, r2_store:-0.36485981984499527\n",
            "Epoch [8495/10000], train_Loss: 8.094218355836347e-05,test_Loss:23.009143829345703, r2_store:-0.3641269930454847\n",
            "Epoch [8496/10000], train_Loss: 7.942583761177957e-05,test_Loss:23.017959594726562, r2_store:-0.3647118829419489\n",
            "Epoch [8497/10000], train_Loss: 7.777947030263022e-05,test_Loss:23.010555267333984, r2_store:-0.36416805524551377\n",
            "Epoch [8498/10000], train_Loss: 7.594435737701133e-05,test_Loss:23.014263153076172, r2_store:-0.3646233435863617\n",
            "Epoch [8499/10000], train_Loss: 7.452456338796765e-05,test_Loss:23.010448455810547, r2_store:-0.36426918855405543\n",
            "Epoch [8500/10000], train_Loss: 7.313914102269337e-05,test_Loss:23.01424789428711, r2_store:-0.3645397093892542\n",
            "Epoch [8501/10000], train_Loss: 7.203942368505523e-05,test_Loss:23.01139259338379, r2_store:-0.3643362814488036\n",
            "Epoch [8502/10000], train_Loss: 7.110503065632656e-05,test_Loss:23.01310920715332, r2_store:-0.36441038420547467\n",
            "Epoch [8503/10000], train_Loss: 7.048862607916817e-05,test_Loss:23.014659881591797, r2_store:-0.3643874196443\n",
            "Epoch [8504/10000], train_Loss: 7.008894317550585e-05,test_Loss:23.01412582397461, r2_store:-0.36432101274609563\n",
            "Epoch [8505/10000], train_Loss: 6.977026350796223e-05,test_Loss:23.015018463134766, r2_store:-0.36444314520148713\n",
            "Epoch [8506/10000], train_Loss: 6.950921670068055e-05,test_Loss:23.013751983642578, r2_store:-0.36425757828447947\n",
            "Epoch [8507/10000], train_Loss: 6.946969369892031e-05,test_Loss:23.01772117614746, r2_store:-0.3644995488831224\n",
            "Epoch [8508/10000], train_Loss: 6.952090916456655e-05,test_Loss:23.013996124267578, r2_store:-0.36415273795722447\n",
            "Epoch [8509/10000], train_Loss: 6.961335020605475e-05,test_Loss:23.01852798461914, r2_store:-0.36448552558597824\n",
            "Epoch [8510/10000], train_Loss: 6.97095092618838e-05,test_Loss:23.014432907104492, r2_store:-0.3640596808347898\n",
            "Epoch [8511/10000], train_Loss: 6.988253153394908e-05,test_Loss:23.01959228515625, r2_store:-0.36449223211478277\n",
            "Epoch [8512/10000], train_Loss: 7.000744517426938e-05,test_Loss:23.013370513916016, r2_store:-0.36399428644183596\n",
            "Epoch [8513/10000], train_Loss: 7.006835949141532e-05,test_Loss:23.019851684570312, r2_store:-0.3645237496860523\n",
            "Epoch [8514/10000], train_Loss: 7.017912867013365e-05,test_Loss:23.013267517089844, r2_store:-0.3639526846080481\n",
            "Epoch [8515/10000], train_Loss: 7.071067375363782e-05,test_Loss:23.020309448242188, r2_store:-0.3645323867427235\n",
            "Epoch [8516/10000], train_Loss: 7.100439688656479e-05,test_Loss:23.01387596130371, r2_store:-0.3638529780726256\n",
            "Epoch [8517/10000], train_Loss: 7.110973820090294e-05,test_Loss:23.023902893066406, r2_store:-0.364507265132449\n",
            "Epoch [8518/10000], train_Loss: 7.160891254898161e-05,test_Loss:23.015655517578125, r2_store:-0.3637535619187071\n",
            "Epoch [8519/10000], train_Loss: 7.24599594832398e-05,test_Loss:23.024513244628906, r2_store:-0.3645326741781054\n",
            "Epoch [8520/10000], train_Loss: 7.350202940870076e-05,test_Loss:23.014633178710938, r2_store:-0.36368978720511413\n",
            "Epoch [8521/10000], train_Loss: 7.477478357031941e-05,test_Loss:23.025665283203125, r2_store:-0.36462828049364404\n",
            "Epoch [8522/10000], train_Loss: 7.650000043213367e-05,test_Loss:23.012821197509766, r2_store:-0.3636071700980221\n",
            "Epoch [8523/10000], train_Loss: 7.873233698774129e-05,test_Loss:23.025863647460938, r2_store:-0.36470988132848503\n",
            "Epoch [8524/10000], train_Loss: 8.19049309939146e-05,test_Loss:23.01232147216797, r2_store:-0.36342263961964205\n",
            "Epoch [8525/10000], train_Loss: 8.615827391622588e-05,test_Loss:23.030080795288086, r2_store:-0.364761053673742\n",
            "Epoch [8526/10000], train_Loss: 9.196541213896126e-05,test_Loss:23.01230239868164, r2_store:-0.36315258918510573\n",
            "Epoch [8527/10000], train_Loss: 9.969833627110347e-05,test_Loss:23.033893585205078, r2_store:-0.3648992554769659\n",
            "Epoch [8528/10000], train_Loss: 0.00011013612675014883,test_Loss:23.010684967041016, r2_store:-0.3628816969646702\n",
            "Epoch [8529/10000], train_Loss: 0.00012476234405767173,test_Loss:23.03803825378418, r2_store:-0.3652011160300159\n",
            "Epoch [8530/10000], train_Loss: 0.000145896861795336,test_Loss:23.00674057006836, r2_store:-0.3625143882201214\n",
            "Epoch [8531/10000], train_Loss: 0.0001754477561917156,test_Loss:23.044723510742188, r2_store:-0.3656441509945296\n",
            "Epoch [8532/10000], train_Loss: 0.00021795963402837515,test_Loss:22.998985290527344, r2_store:-0.361948090123444\n",
            "Epoch [8533/10000], train_Loss: 0.0002783817471936345,test_Loss:23.052284240722656, r2_store:-0.36628543464359775\n",
            "Epoch [8534/10000], train_Loss: 0.00036525243194773793,test_Loss:22.992387771606445, r2_store:-0.3611381279824415\n",
            "Epoch [8535/10000], train_Loss: 0.0004900980857200921,test_Loss:23.064456939697266, r2_store:-0.3672495097980124\n",
            "Epoch [8536/10000], train_Loss: 0.0006721531390212476,test_Loss:22.97664451599121, r2_store:-0.35994147344999505\n",
            "Epoch [8537/10000], train_Loss: 0.0009372759377583861,test_Loss:23.082233428955078, r2_store:-0.36873146280975955\n",
            "Epoch [8538/10000], train_Loss: 0.001327147358097136,test_Loss:22.96042823791504, r2_store:-0.3581668703741474\n",
            "Epoch [8539/10000], train_Loss: 0.0019033640855923295,test_Loss:23.11721420288086, r2_store:-0.3709730759879035\n",
            "Epoch [8540/10000], train_Loss: 0.0027624776121228933,test_Loss:22.922414779663086, r2_store:-0.35552348132541467\n",
            "Epoch [8541/10000], train_Loss: 0.004051254130899906,test_Loss:23.151369094848633, r2_store:-0.3745189414614343\n",
            "Epoch [8542/10000], train_Loss: 0.005965844262391329,test_Loss:22.889562606811523, r2_store:-0.3517550957375759\n",
            "Epoch [8543/10000], train_Loss: 0.008851123973727226,test_Loss:23.228534698486328, r2_store:-0.37995069337584164\n",
            "Epoch [8544/10000], train_Loss: 0.013063818216323853,test_Loss:22.799222946166992, r2_store:-0.346141996607531\n",
            "Epoch [8545/10000], train_Loss: 0.01937098614871502,test_Loss:23.325366973876953, r2_store:-0.38800203679435885\n",
            "Epoch [8546/10000], train_Loss: 0.028173601254820824,test_Loss:22.761398315429688, r2_store:-0.3391222578419013\n",
            "Epoch [8547/10000], train_Loss: 0.04089752957224846,test_Loss:23.468027114868164, r2_store:-0.3993566816584422\n",
            "Epoch [8548/10000], train_Loss: 0.0565105564892292,test_Loss:22.6359920501709, r2_store:-0.3318576471328518\n",
            "Epoch [8549/10000], train_Loss: 0.07566531002521515,test_Loss:23.58706283569336, r2_store:-0.41105550328712437\n",
            "Epoch [8550/10000], train_Loss: 0.0917007178068161,test_Loss:22.5872859954834, r2_store:-0.3283592225129468\n",
            "Epoch [8551/10000], train_Loss: 0.10118313133716583,test_Loss:23.5482177734375, r2_store:-0.4114542544423614\n",
            "Epoch [8552/10000], train_Loss: 0.09179337322711945,test_Loss:22.62238311767578, r2_store:-0.3348676417679397\n",
            "Epoch [8553/10000], train_Loss: 0.06599687039852142,test_Loss:23.284643173217773, r2_store:-0.3903974632438387\n",
            "Epoch [8554/10000], train_Loss: 0.03025927022099495,test_Loss:22.88345718383789, r2_store:-0.35623665106178826\n",
            "Epoch [8555/10000], train_Loss: 0.005207250360399485,test_Loss:22.950580596923828, r2_store:-0.35954703914584996\n",
            "Epoch [8556/10000], train_Loss: 0.002001479733735323,test_Loss:23.27992820739746, r2_store:-0.38204382237625456\n",
            "Epoch [8557/10000], train_Loss: 0.016580674797296524,test_Loss:22.84844207763672, r2_store:-0.3424058037646971\n",
            "Epoch [8558/10000], train_Loss: 0.03349452465772629,test_Loss:23.45841407775879, r2_store:-0.392848063570284\n",
            "Epoch [8559/10000], train_Loss: 0.037472084164619446,test_Loss:22.86452865600586, r2_store:-0.34575844881241613\n",
            "Epoch [8560/10000], train_Loss: 0.026414671912789345,test_Loss:23.260488510131836, r2_store:-0.37945557150673515\n",
            "Epoch [8561/10000], train_Loss: 0.009568706154823303,test_Loss:23.03431510925293, r2_store:-0.3642905372494878\n",
            "Epoch [8562/10000], train_Loss: 0.0006952254334464669,test_Loss:22.945709228515625, r2_store:-0.35798250953091193\n",
            "Epoch [8563/10000], train_Loss: 0.00425295252352953,test_Loss:23.240253448486328, r2_store:-0.3814865759501256\n",
            "Epoch [8564/10000], train_Loss: 0.01371854543685913,test_Loss:22.837696075439453, r2_store:-0.34794313439824265\n",
            "Epoch [8565/10000], train_Loss: 0.019110724329948425,test_Loss:23.25286102294922, r2_store:-0.38142147952336725\n",
            "Epoch [8566/10000], train_Loss: 0.015433955006301403,test_Loss:22.921297073364258, r2_store:-0.3537321571723726\n",
            "Epoch [8567/10000], train_Loss: 0.0068892380222678185,test_Loss:23.094924926757812, r2_store:-0.36698416130937583\n",
            "Epoch [8568/10000], train_Loss: 0.0009237599442712963,test_Loss:23.111963272094727, r2_store:-0.3684118725988077\n",
            "Epoch [8569/10000], train_Loss: 0.001469300128519535,test_Loss:22.933439254760742, r2_store:-0.35434971784382885\n",
            "Epoch [8570/10000], train_Loss: 0.006247609853744507,test_Loss:23.222225189208984, r2_store:-0.3783647118575082\n",
            "Epoch [8571/10000], train_Loss: 0.00995841808617115,test_Loss:22.901458740234375, r2_store:-0.35287449363445833\n",
            "Epoch [8572/10000], train_Loss: 0.009230691939592361,test_Loss:23.14480209350586, r2_store:-0.374500477116799\n",
            "Epoch [8573/10000], train_Loss: 0.005007976666092873,test_Loss:22.96853256225586, r2_store:-0.3611512401538224\n",
            "Epoch [8574/10000], train_Loss: 0.001179162529297173,test_Loss:22.99312400817871, r2_store:-0.3635863746230481\n",
            "Epoch [8575/10000], train_Loss: 0.0004388746456243098,test_Loss:23.086641311645508, r2_store:-0.37180087662150507\n",
            "Epoch [8576/10000], train_Loss: 0.0024917456321418285,test_Loss:22.89679527282715, r2_store:-0.3566499316456495\n",
            "Epoch [8577/10000], train_Loss: 0.004903354682028294,test_Loss:23.128551483154297, r2_store:-0.3754557906214089\n",
            "Epoch [8578/10000], train_Loss: 0.005352827720344067,test_Loss:22.914045333862305, r2_store:-0.3579632656070373\n",
            "Epoch [8579/10000], train_Loss: 0.0036618472076952457,test_Loss:23.0474910736084, r2_store:-0.3702400442071814\n",
            "Epoch [8580/10000], train_Loss: 0.0013895961456000805,test_Loss:22.98601722717285, r2_store:-0.3651541670067493\n",
            "Epoch [8581/10000], train_Loss: 0.0002489252365194261,test_Loss:22.961444854736328, r2_store:-0.3626413671461659\n",
            "Epoch [8582/10000], train_Loss: 0.0007557639619335532,test_Loss:23.068126678466797, r2_store:-0.37164747313716884\n",
            "Epoch [8583/10000], train_Loss: 0.002073145704343915,test_Loss:22.90997314453125, r2_store:-0.3590847724267945\n",
            "Epoch [8584/10000], train_Loss: 0.0028767655603587627,test_Loss:23.0694522857666, r2_store:-0.3727436556080792\n",
            "Epoch [8585/10000], train_Loss: 0.0025332453660666943,test_Loss:22.929052352905273, r2_store:-0.3615934396441658\n",
            "Epoch [8586/10000], train_Loss: 0.001440513995476067,test_Loss:23.00259017944336, r2_store:-0.36861925610294666\n",
            "Epoch [8587/10000], train_Loss: 0.0004427607636898756,test_Loss:22.980648040771484, r2_store:-0.3669970702873224\n",
            "Epoch [8588/10000], train_Loss: 0.0001850365661084652,test_Loss:22.939926147460938, r2_store:-0.3635117773374148\n",
            "Epoch [8589/10000], train_Loss: 0.0006390473572537303,test_Loss:23.022953033447266, r2_store:-0.370795824868263\n",
            "Epoch [8590/10000], train_Loss: 0.0012661329237744212,test_Loss:22.90497589111328, r2_store:-0.3611568502866942\n",
            "Epoch [8591/10000], train_Loss: 0.0015422416618093848,test_Loss:23.020183563232422, r2_store:-0.3705719768541973\n",
            "Epoch [8592/10000], train_Loss: 0.0012864824384450912,test_Loss:22.929397583007812, r2_store:-0.36269133807689746\n",
            "Epoch [8593/10000], train_Loss: 0.0007293404778465629,test_Loss:22.985759735107422, r2_store:-0.3673980348466017\n",
            "Epoch [8594/10000], train_Loss: 0.00026594087830744684,test_Loss:22.97386360168457, r2_store:-0.36633237105242555\n",
            "Epoch [8595/10000], train_Loss: 0.00014675973216071725,test_Loss:22.947404861450195, r2_store:-0.364132174419451\n",
            "Epoch [8596/10000], train_Loss: 0.0003480208106338978,test_Loss:23.004541397094727, r2_store:-0.36924694297920335\n",
            "Epoch [8597/10000], train_Loss: 0.0006534616113640368,test_Loss:22.92413330078125, r2_store:-0.3626892124188903\n",
            "Epoch [8598/10000], train_Loss: 0.0008227102225646377,test_Loss:23.005260467529297, r2_store:-0.3695561619690917\n",
            "Epoch [8599/10000], train_Loss: 0.0007534202304668725,test_Loss:22.934263229370117, r2_store:-0.3634551783766029\n",
            "Epoch [8600/10000], train_Loss: 0.0005155403050594032,test_Loss:22.983531951904297, r2_store:-0.3675728229164308\n",
            "Epoch [8601/10000], train_Loss: 0.00026381350471638143,test_Loss:22.961027145385742, r2_store:-0.36557550975542985\n",
            "Epoch [8602/10000], train_Loss: 0.0001301750889979303,test_Loss:22.956783294677734, r2_store:-0.3651312352963696\n",
            "Epoch [8603/10000], train_Loss: 0.00015598695608787239,test_Loss:22.986833572387695, r2_store:-0.36764820625827443\n",
            "Epoch [8604/10000], train_Loss: 0.0002802172675728798,test_Loss:22.940845489501953, r2_store:-0.36367841855807614\n",
            "Epoch [8605/10000], train_Loss: 0.00040328362956643105,test_Loss:22.998390197753906, r2_store:-0.36841953927636584\n",
            "Epoch [8606/10000], train_Loss: 0.00044874250306747854,test_Loss:22.941917419433594, r2_store:-0.36368411759556185\n",
            "Epoch [8607/10000], train_Loss: 0.00039561386802233756,test_Loss:22.987173080444336, r2_store:-0.36764875193133983\n",
            "Epoch [8608/10000], train_Loss: 0.0002828737779054791,test_Loss:22.95448112487793, r2_store:-0.36472420594718646\n",
            "Epoch [8609/10000], train_Loss: 0.00017270189709961414,test_Loss:22.974239349365234, r2_store:-0.3660323702823234\n",
            "Epoch [8610/10000], train_Loss: 0.00011190853547304869,test_Loss:22.977659225463867, r2_store:-0.3661154666543702\n",
            "Epoch [8611/10000], train_Loss: 0.00011530918709468096,test_Loss:22.96077537536621, r2_store:-0.36465752880874236\n",
            "Epoch [8612/10000], train_Loss: 0.00016305223107337952,test_Loss:22.991382598876953, r2_store:-0.3671632034762127\n",
            "Epoch [8613/10000], train_Loss: 0.00021755493071395904,test_Loss:22.95669174194336, r2_store:-0.3641197478712872\n",
            "Epoch [8614/10000], train_Loss: 0.0002476461522746831,test_Loss:22.99571990966797, r2_store:-0.36732327346461546\n",
            "Epoch [8615/10000], train_Loss: 0.00024040532298386097,test_Loss:22.96231460571289, r2_store:-0.36431573454319244\n",
            "Epoch [8616/10000], train_Loss: 0.00020137670799158514,test_Loss:22.99356460571289, r2_store:-0.3666186334103829\n",
            "Epoch [8617/10000], train_Loss: 0.0001517358614364639,test_Loss:22.976900100708008, r2_store:-0.3650254319525297\n",
            "Epoch [8618/10000], train_Loss: 0.0001122895409935154,test_Loss:22.98421859741211, r2_store:-0.3655657487958839\n",
            "Epoch [8619/10000], train_Loss: 9.527670772513375e-05,test_Loss:22.98898696899414, r2_store:-0.36584157449423693\n",
            "Epoch [8620/10000], train_Loss: 0.00010149811714654788,test_Loss:22.97705841064453, r2_store:-0.3647468324454979\n",
            "Epoch [8621/10000], train_Loss: 0.0001218370525748469,test_Loss:22.99666404724121, r2_store:-0.36639895053423266\n",
            "Epoch [8622/10000], train_Loss: 0.000142469463753514,test_Loss:22.97372817993164, r2_store:-0.3643552719930916\n",
            "Epoch [8623/10000], train_Loss: 0.00015345748397521675,test_Loss:23.00170135498047, r2_store:-0.3664626847741401\n",
            "Epoch [8624/10000], train_Loss: 0.00015142369375098497,test_Loss:22.978090286254883, r2_store:-0.3644830338726577\n",
            "Epoch [8625/10000], train_Loss: 0.00013760992442257702,test_Loss:22.99624252319336, r2_store:-0.36617699955527017\n",
            "Epoch [8626/10000], train_Loss: 0.0001185514047392644,test_Loss:22.983135223388672, r2_store:-0.3649994110296353\n",
            "Epoch [8627/10000], train_Loss: 0.00010108282003784552,test_Loss:22.991546630859375, r2_store:-0.36576523175747044\n",
            "Epoch [8628/10000], train_Loss: 8.992077346192673e-05,test_Loss:22.987497329711914, r2_store:-0.3655707161019759\n",
            "Epoch [8629/10000], train_Loss: 8.60632280819118e-05,test_Loss:22.98428726196289, r2_store:-0.36528233206238747\n",
            "Epoch [8630/10000], train_Loss: 8.895887731341645e-05,test_Loss:22.99431800842285, r2_store:-0.3659197748544929\n",
            "Epoch [8631/10000], train_Loss: 9.517852595308796e-05,test_Loss:22.983234405517578, r2_store:-0.3648383558437611\n",
            "Epoch [8632/10000], train_Loss: 0.00010169297456741333,test_Loss:22.9989070892334, r2_store:-0.3660046859312711\n",
            "Epoch [8633/10000], train_Loss: 0.00010673482029233128,test_Loss:22.98363494873047, r2_store:-0.36466374895703013\n",
            "Epoch [8634/10000], train_Loss: 0.00010782563913380727,test_Loss:22.99882698059082, r2_store:-0.3659958677533932\n",
            "Epoch [8635/10000], train_Loss: 0.00010503454541321844,test_Loss:22.983867645263672, r2_store:-0.36481520508671106\n",
            "Epoch [8636/10000], train_Loss: 9.93514695437625e-05,test_Loss:22.996248245239258, r2_store:-0.36589902835992927\n",
            "Epoch [8637/10000], train_Loss: 9.25658387131989e-05,test_Loss:22.986675262451172, r2_store:-0.36511590868692134\n",
            "Epoch [8638/10000], train_Loss: 8.621785673312843e-05,test_Loss:22.99410629272461, r2_store:-0.36565094095670614\n",
            "Epoch [8639/10000], train_Loss: 8.154356328304857e-05,test_Loss:22.992847442626953, r2_store:-0.36531967277239197\n",
            "Epoch [8640/10000], train_Loss: 7.884878141339868e-05,test_Loss:22.99510955810547, r2_store:-0.3653089969051275\n",
            "Epoch [8641/10000], train_Loss: 7.818491576472297e-05,test_Loss:22.998075485229492, r2_store:-0.3655008724135549\n",
            "Epoch [8642/10000], train_Loss: 7.885975355748087e-05,test_Loss:22.992530822753906, r2_store:-0.36509423689998943\n",
            "Epoch [8643/10000], train_Loss: 8.016973151825368e-05,test_Loss:22.998735427856445, r2_store:-0.36567561234204926\n",
            "Epoch [8644/10000], train_Loss: 8.174220420187339e-05,test_Loss:22.99103355407715, r2_store:-0.3650103063510348\n",
            "Epoch [8645/10000], train_Loss: 8.324041118612513e-05,test_Loss:22.999347686767578, r2_store:-0.3657631879970491\n",
            "Epoch [8646/10000], train_Loss: 8.382313535548747e-05,test_Loss:22.990116119384766, r2_store:-0.36494713403273527\n",
            "Epoch [8647/10000], train_Loss: 8.332514698849991e-05,test_Loss:23.001073837280273, r2_store:-0.3656970471880392\n",
            "Epoch [8648/10000], train_Loss: 8.212195098167285e-05,test_Loss:22.993602752685547, r2_store:-0.36494427229091286\n",
            "Epoch [8649/10000], train_Loss: 8.029718446778134e-05,test_Loss:23.00054931640625, r2_store:-0.3655714990620256\n",
            "Epoch [8650/10000], train_Loss: 7.835278665879741e-05,test_Loss:22.994373321533203, r2_store:-0.3650237612745262\n",
            "Epoch [8651/10000], train_Loss: 7.622347038704902e-05,test_Loss:23.00005340576172, r2_store:-0.36549572273333264\n",
            "Epoch [8652/10000], train_Loss: 7.437312888214365e-05,test_Loss:22.99538803100586, r2_store:-0.36514521502052055\n",
            "Epoch [8653/10000], train_Loss: 7.309751526918262e-05,test_Loss:22.99850845336914, r2_store:-0.3653803076158131\n",
            "Epoch [8654/10000], train_Loss: 7.196790829766542e-05,test_Loss:22.998476028442383, r2_store:-0.3652061027048483\n",
            "Epoch [8655/10000], train_Loss: 7.095532782841474e-05,test_Loss:22.999971389770508, r2_store:-0.36525610902811523\n",
            "Epoch [8656/10000], train_Loss: 7.043399091344327e-05,test_Loss:22.999664306640625, r2_store:-0.3652273119597318\n",
            "Epoch [8657/10000], train_Loss: 7.00326418154873e-05,test_Loss:22.999818801879883, r2_store:-0.3651533244416607\n",
            "Epoch [8658/10000], train_Loss: 6.9734342105221e-05,test_Loss:23.002002716064453, r2_store:-0.365273110194966\n",
            "Epoch [8659/10000], train_Loss: 6.949948874535039e-05,test_Loss:22.999048233032227, r2_store:-0.36509214488771824\n",
            "Epoch [8660/10000], train_Loss: 6.928286893526092e-05,test_Loss:23.001136779785156, r2_store:-0.3652990612611857\n",
            "Epoch [8661/10000], train_Loss: 6.920664600329474e-05,test_Loss:22.999345779418945, r2_store:-0.3650222864432924\n",
            "Epoch [8662/10000], train_Loss: 6.907853821758181e-05,test_Loss:23.00357437133789, r2_store:-0.36529449935578473\n",
            "Epoch [8663/10000], train_Loss: 6.895991100464016e-05,test_Loss:22.99959945678711, r2_store:-0.3649373657941357\n",
            "Epoch [8664/10000], train_Loss: 6.875368853798136e-05,test_Loss:23.004478454589844, r2_store:-0.3652606114272752\n",
            "Epoch [8665/10000], train_Loss: 6.848173507023603e-05,test_Loss:23.00124740600586, r2_store:-0.3649159623089193\n",
            "Epoch [8666/10000], train_Loss: 6.822474824730307e-05,test_Loss:23.004764556884766, r2_store:-0.36528001817979616\n",
            "Epoch [8667/10000], train_Loss: 6.791613850509748e-05,test_Loss:23.00012969970703, r2_store:-0.36492072435713707\n",
            "Epoch [8668/10000], train_Loss: 6.770634354325011e-05,test_Loss:23.005613327026367, r2_store:-0.3652996673412967\n",
            "Epoch [8669/10000], train_Loss: 6.736671639373526e-05,test_Loss:23.001489639282227, r2_store:-0.36489878588919034\n",
            "Epoch [8670/10000], train_Loss: 6.715957715641707e-05,test_Loss:23.00572967529297, r2_store:-0.36526170720708695\n",
            "Epoch [8671/10000], train_Loss: 6.689658766845241e-05,test_Loss:23.00136375427246, r2_store:-0.3648478003427622\n",
            "Epoch [8672/10000], train_Loss: 6.654365279246122e-05,test_Loss:23.00632095336914, r2_store:-0.3652328362949371\n",
            "Epoch [8673/10000], train_Loss: 6.616807513637468e-05,test_Loss:23.000858306884766, r2_store:-0.3648341605369849\n",
            "Epoch [8674/10000], train_Loss: 6.573936843778938e-05,test_Loss:23.00515365600586, r2_store:-0.3652307185029202\n",
            "Epoch [8675/10000], train_Loss: 6.533406849484891e-05,test_Loss:23.000804901123047, r2_store:-0.36483663544132194\n",
            "Epoch [8676/10000], train_Loss: 6.499849405372515e-05,test_Loss:23.005781173706055, r2_store:-0.3652312532718833\n",
            "Epoch [8677/10000], train_Loss: 6.491896056104451e-05,test_Loss:23.00003433227539, r2_store:-0.36476609015962125\n",
            "Epoch [8678/10000], train_Loss: 6.494169065263122e-05,test_Loss:23.007564544677734, r2_store:-0.3652008082756706\n",
            "Epoch [8679/10000], train_Loss: 6.494512490462512e-05,test_Loss:23.001127243041992, r2_store:-0.36468764626145256\n",
            "Epoch [8680/10000], train_Loss: 6.497198774013668e-05,test_Loss:23.006263732910156, r2_store:-0.36518820061330115\n",
            "Epoch [8681/10000], train_Loss: 6.523359479615465e-05,test_Loss:23.001018524169922, r2_store:-0.36462421587410465\n",
            "Epoch [8682/10000], train_Loss: 6.567743548657745e-05,test_Loss:23.007965087890625, r2_store:-0.36525216200389665\n",
            "Epoch [8683/10000], train_Loss: 6.657485209871083e-05,test_Loss:22.998397827148438, r2_store:-0.36452405895851814\n",
            "Epoch [8684/10000], train_Loss: 6.813112850068137e-05,test_Loss:23.011199951171875, r2_store:-0.36533877959644623\n",
            "Epoch [8685/10000], train_Loss: 7.018964242888615e-05,test_Loss:22.999813079833984, r2_store:-0.36438765216171576\n",
            "Epoch [8686/10000], train_Loss: 7.342291792156175e-05,test_Loss:23.011720657348633, r2_store:-0.36546005976596097\n",
            "Epoch [8687/10000], train_Loss: 7.81640483182855e-05,test_Loss:22.998645782470703, r2_store:-0.3641802307992812\n",
            "Epoch [8688/10000], train_Loss: 8.462750702165067e-05,test_Loss:23.016727447509766, r2_store:-0.3656500426688225\n",
            "Epoch [8689/10000], train_Loss: 9.405340097146109e-05,test_Loss:22.993345260620117, r2_store:-0.363882155847733\n",
            "Epoch [8690/10000], train_Loss: 0.00010738467244664207,test_Loss:23.020030975341797, r2_store:-0.3659483723654029\n",
            "Epoch [8691/10000], train_Loss: 0.0001267824845854193,test_Loss:22.99028205871582, r2_store:-0.36349857601895397\n",
            "Epoch [8692/10000], train_Loss: 0.0001545689010526985,test_Loss:23.02471351623535, r2_store:-0.36639524014682334\n",
            "Epoch [8693/10000], train_Loss: 0.0001958701031981036,test_Loss:22.985475540161133, r2_store:-0.3629025449291541\n",
            "Epoch [8694/10000], train_Loss: 0.00025502825155854225,test_Loss:23.037399291992188, r2_store:-0.3670643622545262\n",
            "Epoch [8695/10000], train_Loss: 0.00034321247949264944,test_Loss:22.973791122436523, r2_store:-0.36202494581892\n",
            "Epoch [8696/10000], train_Loss: 0.0004726277547888458,test_Loss:23.04984474182129, r2_store:-0.3681093940959703\n",
            "Epoch [8697/10000], train_Loss: 0.0006647984264418483,test_Loss:22.960737228393555, r2_store:-0.360769300123176\n",
            "Epoch [8698/10000], train_Loss: 0.0009515693527646363,test_Loss:23.067296981811523, r2_store:-0.36971992875522797\n",
            "Epoch [8699/10000], train_Loss: 0.0013881779741495848,test_Loss:22.939796447753906, r2_store:-0.35886373711841\n",
            "Epoch [8700/10000], train_Loss: 0.0020462071988731623,test_Loss:23.103248596191406, r2_store:-0.3722885218091563\n",
            "Epoch [8701/10000], train_Loss: 0.0030420299153774977,test_Loss:22.897005081176758, r2_store:-0.3558935169028712\n",
            "Epoch [8702/10000], train_Loss: 0.004574698396027088,test_Loss:23.153167724609375, r2_store:-0.3762717848616377\n",
            "Epoch [8703/10000], train_Loss: 0.006908095441758633,test_Loss:22.854045867919922, r2_store:-0.3515790461038275\n",
            "Epoch [8704/10000], train_Loss: 0.01050040777772665,test_Loss:23.219606399536133, r2_store:-0.3825680640490101\n",
            "Epoch [8705/10000], train_Loss: 0.015854593366384506,test_Loss:22.77310562133789, r2_store:-0.34538353009222744\n",
            "Epoch [8706/10000], train_Loss: 0.02393576130270958,test_Loss:23.340553283691406, r2_store:-0.39225543263515106\n",
            "Epoch [8707/10000], train_Loss: 0.03543856739997864,test_Loss:22.681682586669922, r2_store:-0.33733323747179345\n",
            "Epoch [8708/10000], train_Loss: 0.051848698407411575,test_Loss:23.490787506103516, r2_store:-0.4053132038477243\n",
            "Epoch [8709/10000], train_Loss: 0.071335569024086,test_Loss:22.582746505737305, r2_store:-0.32966114385252765\n",
            "Epoch [8710/10000], train_Loss: 0.09368370473384857,test_Loss:23.616527557373047, r2_store:-0.41644683365763524\n",
            "Epoch [8711/10000], train_Loss: 0.10795414447784424,test_Loss:22.556278228759766, r2_store:-0.328241196278904\n",
            "Epoch [8712/10000], train_Loss: 0.10861098766326904,test_Loss:23.486066818237305, r2_store:-0.4096924853877104\n",
            "Epoch [8713/10000], train_Loss: 0.08141058683395386,test_Loss:22.664363861083984, r2_store:-0.3419067568784733\n",
            "Epoch [8714/10000], train_Loss: 0.04153895378112793,test_Loss:23.109601974487305, r2_store:-0.3783216498600317\n",
            "Epoch [8715/10000], train_Loss: 0.00828491896390915,test_Loss:23.05068588256836, r2_store:-0.3701076929810063\n",
            "Epoch [8716/10000], train_Loss: 0.0018560064490884542,test_Loss:22.828847885131836, r2_store:-0.34811287186964646\n",
            "Epoch [8717/10000], train_Loss: 0.019220177084207535,test_Loss:23.400894165039062, r2_store:-0.39354612764496166\n",
            "Epoch [8718/10000], train_Loss: 0.039361823350191116,test_Loss:22.760208129882812, r2_store:-0.340966888055688\n",
            "Epoch [8719/10000], train_Loss: 0.043199487030506134,test_Loss:23.333486557006836, r2_store:-0.3889739575757116\n",
            "Epoch [8720/10000], train_Loss: 0.026619691401720047,test_Loss:22.944337844848633, r2_store:-0.3564136672511753\n",
            "Epoch [8721/10000], train_Loss: 0.006869109813123941,test_Loss:23.01340675354004, r2_store:-0.3645295805482913\n",
            "Epoch [8722/10000], train_Loss: 0.0009060275624506176,test_Loss:23.19089126586914, r2_store:-0.38013941968879195\n",
            "Epoch [8723/10000], train_Loss: 0.010093184188008308,test_Loss:22.831382751464844, r2_store:-0.3489700017734072\n",
            "Epoch [8724/10000], train_Loss: 0.02134554460644722,test_Loss:23.295013427734375, r2_store:-0.3868130217468164\n",
            "Epoch [8725/10000], train_Loss: 0.02173708751797676,test_Loss:22.86208724975586, r2_store:-0.35246383223554334\n",
            "Epoch [8726/10000], train_Loss: 0.011729633435606956,test_Loss:23.092880249023438, r2_store:-0.37057735814346504\n",
            "Epoch [8727/10000], train_Loss: 0.00205825874581933,test_Loss:23.084056854248047, r2_store:-0.36941214868821337\n",
            "Epoch [8728/10000], train_Loss: 0.001468585105612874,test_Loss:22.893095016479492, r2_store:-0.35418539877273725\n",
            "Epoch [8729/10000], train_Loss: 0.007925048470497131,test_Loss:23.221145629882812, r2_store:-0.38066618324323276\n",
            "Epoch [8730/10000], train_Loss: 0.012913445942103863,test_Loss:22.894779205322266, r2_store:-0.35240684062151395\n",
            "Epoch [8731/10000], train_Loss: 0.01115227211266756,test_Loss:23.142690658569336, r2_store:-0.37472794929745823\n",
            "Epoch [8732/10000], train_Loss: 0.004782382864505053,test_Loss:22.981901168823242, r2_store:-0.3639892824208337\n",
            "Epoch [8733/10000], train_Loss: 0.0006051916861906648,test_Loss:22.950345993041992, r2_store:-0.3614025742646094\n",
            "Epoch [8734/10000], train_Loss: 0.0017637114506214857,test_Loss:23.12371063232422, r2_store:-0.3764251452153946\n",
            "Epoch [8735/10000], train_Loss: 0.005593098234385252,test_Loss:22.841899871826172, r2_store:-0.3558989879646759\n",
            "Epoch [8736/10000], train_Loss: 0.007539473474025726,test_Loss:23.084026336669922, r2_store:-0.37688731413552157\n",
            "Epoch [8737/10000], train_Loss: 0.005575975403189659,test_Loss:22.902883529663086, r2_store:-0.3616075071827798\n",
            "Epoch [8738/10000], train_Loss: 0.0020291402470320463,test_Loss:22.96100616455078, r2_store:-0.36700796710343764\n",
            "Epoch [8739/10000], train_Loss: 0.0003345147124491632,test_Loss:23.014156341552734, r2_store:-0.3710540079347169\n",
            "Epoch [8740/10000], train_Loss: 0.0014793253503739834,test_Loss:22.890138626098633, r2_store:-0.3590025065940823\n",
            "Epoch [8741/10000], train_Loss: 0.003557818476110697,test_Loss:23.08646011352539, r2_store:-0.375269739360254\n",
            "Epoch [8742/10000], train_Loss: 0.004274632781744003,test_Loss:22.882734298706055, r2_store:-0.36007814341275957\n",
            "Epoch [8743/10000], train_Loss: 0.0029831433203071356,test_Loss:23.006940841674805, r2_store:-0.3709119765708486\n",
            "Epoch [8744/10000], train_Loss: 0.0010431100381538272,test_Loss:22.959243774414062, r2_store:-0.3675036085412755\n",
            "Epoch [8745/10000], train_Loss: 0.0002596149279270321,test_Loss:22.895143508911133, r2_store:-0.3642231600269157\n",
            "Epoch [8746/10000], train_Loss: 0.0009284060215577483,test_Loss:22.991741180419922, r2_store:-0.3734981031150362\n",
            "Epoch [8747/10000], train_Loss: 0.0020374483428895473,test_Loss:22.857685089111328, r2_store:-0.3615783168954594\n",
            "Epoch [8748/10000], train_Loss: 0.002408524975180626,test_Loss:22.995193481445312, r2_store:-0.37260309356663157\n",
            "Epoch [8749/10000], train_Loss: 0.0017180480062961578,test_Loss:22.88533592224121, r2_store:-0.36406078187787894\n",
            "Epoch [8750/10000], train_Loss: 0.000683951482642442,test_Loss:22.926773071289062, r2_store:-0.36689406220714527\n",
            "Epoch [8751/10000], train_Loss: 0.0002204949560109526,test_Loss:22.961029052734375, r2_store:-0.36887008207998395\n",
            "Epoch [8752/10000], train_Loss: 0.0005036910879425704,test_Loss:22.88149642944336, r2_store:-0.3625193363479935\n",
            "Epoch [8753/10000], train_Loss: 0.0010903883958235383,test_Loss:22.98330307006836, r2_store:-0.37119579531097635\n",
            "Epoch [8754/10000], train_Loss: 0.0013880713377147913,test_Loss:22.88149642944336, r2_store:-0.36272277522790475\n",
            "Epoch [8755/10000], train_Loss: 0.0011178451823070645,test_Loss:22.951427459716797, r2_store:-0.36950877937378745\n",
            "Epoch [8756/10000], train_Loss: 0.0005778945051133633,test_Loss:22.901958465576172, r2_store:-0.3659583082900675\n",
            "Epoch [8757/10000], train_Loss: 0.00022042138152755797,test_Loss:22.90713882446289, r2_store:-0.3656664572898507\n",
            "Epoch [8758/10000], train_Loss: 0.00023092915944289416,test_Loss:22.953617095947266, r2_store:-0.36915633615512866\n",
            "Epoch [8759/10000], train_Loss: 0.0005153414094820619,test_Loss:22.876811981201172, r2_store:-0.3633599529954856\n",
            "Epoch [8760/10000], train_Loss: 0.0007676096865907311,test_Loss:22.951900482177734, r2_store:-0.36995915985223093\n",
            "Epoch [8761/10000], train_Loss: 0.0007597948424518108,test_Loss:22.884174346923828, r2_store:-0.36422055203540804\n",
            "Epoch [8762/10000], train_Loss: 0.0005376488552428782,test_Loss:22.92519187927246, r2_store:-0.36838322724945716\n",
            "Epoch [8763/10000], train_Loss: 0.00027877261163666844,test_Loss:22.90050506591797, r2_store:-0.3667660134969901\n",
            "Epoch [8764/10000], train_Loss: 0.00015015358803793788,test_Loss:22.896902084350586, r2_store:-0.36592308470997303\n",
            "Epoch [8765/10000], train_Loss: 0.00020794730517081916,test_Loss:22.9352970123291, r2_store:-0.3688185694910966\n",
            "Epoch [8766/10000], train_Loss: 0.00035502706305123866,test_Loss:22.88010025024414, r2_store:-0.3643802513648713\n",
            "Epoch [8767/10000], train_Loss: 0.00045306398533284664,test_Loss:22.93685531616211, r2_store:-0.3689576606844085\n",
            "Epoch [8768/10000], train_Loss: 0.0004379810707177967,test_Loss:22.891096115112305, r2_store:-0.3647632713866915\n",
            "Epoch [8769/10000], train_Loss: 0.00032467322307638824,test_Loss:22.922836303710938, r2_store:-0.36755535188692345\n",
            "Epoch [8770/10000], train_Loss: 0.00019514604355208576,test_Loss:22.907535552978516, r2_store:-0.36627502721181004\n",
            "Epoch [8771/10000], train_Loss: 0.0001339878945145756,test_Loss:22.905227661132812, r2_store:-0.36579089627689565\n",
            "Epoch [8772/10000], train_Loss: 0.00015339601668529212,test_Loss:22.926761627197266, r2_store:-0.36768786678742105\n",
            "Epoch [8773/10000], train_Loss: 0.00021875047241337597,test_Loss:22.889528274536133, r2_store:-0.3647054302232353\n",
            "Epoch [8774/10000], train_Loss: 0.00027499752468429506,test_Loss:22.93208885192871, r2_store:-0.3679399195479238\n",
            "Epoch [8775/10000], train_Loss: 0.00027759248041547835,test_Loss:22.898910522460938, r2_store:-0.3648331517028969\n",
            "Epoch [8776/10000], train_Loss: 0.00023134963703341782,test_Loss:22.9251651763916, r2_store:-0.3671211211532941\n",
            "Epoch [8777/10000], train_Loss: 0.0001692010264378041,test_Loss:22.909969329833984, r2_store:-0.3658140295183132\n",
            "Epoch [8778/10000], train_Loss: 0.00012485326442401856,test_Loss:22.91457748413086, r2_store:-0.3659282548981331\n",
            "Epoch [8779/10000], train_Loss: 0.0001191057963296771,test_Loss:22.926586151123047, r2_store:-0.3668356463066742\n",
            "Epoch [8780/10000], train_Loss: 0.0001440139312762767,test_Loss:22.90572738647461, r2_store:-0.36504368971228507\n",
            "Epoch [8781/10000], train_Loss: 0.00017395488976035267,test_Loss:22.934452056884766, r2_store:-0.36724970513301236\n",
            "Epoch [8782/10000], train_Loss: 0.00018859998090192676,test_Loss:22.907575607299805, r2_store:-0.364963325625985\n",
            "Epoch [8783/10000], train_Loss: 0.00017919988022185862,test_Loss:22.929094314575195, r2_store:-0.36693562769873345\n",
            "Epoch [8784/10000], train_Loss: 0.00015231905854307115,test_Loss:22.91221809387207, r2_store:-0.3654885192624606\n",
            "Epoch [8785/10000], train_Loss: 0.00012444649473764002,test_Loss:22.92290496826172, r2_store:-0.366219328348494\n",
            "Epoch [8786/10000], train_Loss: 0.00010760685108834878,test_Loss:22.92331314086914, r2_store:-0.3662444576182782\n",
            "Epoch [8787/10000], train_Loss: 0.00010630275210132822,test_Loss:22.915170669555664, r2_store:-0.3655613669890576\n",
            "Epoch [8788/10000], train_Loss: 0.00011742876085918397,test_Loss:22.930681228637695, r2_store:-0.36680317127944595\n",
            "Epoch [8789/10000], train_Loss: 0.00013037626922596246,test_Loss:22.911705017089844, r2_store:-0.3652970872087229\n",
            "Epoch [8790/10000], train_Loss: 0.00013720430433750153,test_Loss:22.929210662841797, r2_store:-0.3668712472880824\n",
            "Epoch [8791/10000], train_Loss: 0.00013445201329886913,test_Loss:22.91302490234375, r2_store:-0.3653955807145226\n",
            "Epoch [8792/10000], train_Loss: 0.00012311326281633228,test_Loss:22.92788314819336, r2_store:-0.3664865826500776\n",
            "Epoch [8793/10000], train_Loss: 0.00010959171777358279,test_Loss:22.919065475463867, r2_store:-0.3657744452205618\n",
            "Epoch [8794/10000], train_Loss: 9.949388913810253e-05,test_Loss:22.920944213867188, r2_store:-0.3659605190943489\n",
            "Epoch [8795/10000], train_Loss: 9.594149014446884e-05,test_Loss:22.92498207092285, r2_store:-0.36620676753742676\n",
            "Epoch [8796/10000], train_Loss: 9.821700950851664e-05,test_Loss:22.91875648498535, r2_store:-0.3655592778867731\n",
            "Epoch [8797/10000], train_Loss: 0.00010308119090041146,test_Loss:22.930408477783203, r2_store:-0.3664274376119565\n",
            "Epoch [8798/10000], train_Loss: 0.00010715139796957374,test_Loss:22.92037582397461, r2_store:-0.3654048835824941\n",
            "Epoch [8799/10000], train_Loss: 0.00010812622349476442,test_Loss:22.93303680419922, r2_store:-0.36643031082239874\n",
            "Epoch [8800/10000], train_Loss: 0.00010530903091421351,test_Loss:22.92190170288086, r2_store:-0.36553703950578065\n",
            "Epoch [8801/10000], train_Loss: 0.00010021378693636507,test_Loss:22.930217742919922, r2_store:-0.3662336738344556\n",
            "Epoch [8802/10000], train_Loss: 9.498243889538571e-05,test_Loss:22.926355361938477, r2_store:-0.36577108497255617\n",
            "Epoch [8803/10000], train_Loss: 9.07268695300445e-05,test_Loss:22.929210662841797, r2_store:-0.3659215239205309\n",
            "Epoch [8804/10000], train_Loss: 8.87588394107297e-05,test_Loss:22.930192947387695, r2_store:-0.3659603084306058\n",
            "Epoch [8805/10000], train_Loss: 8.864144183462486e-05,test_Loss:22.926923751831055, r2_store:-0.3656526441067407\n",
            "Epoch [8806/10000], train_Loss: 8.94503464223817e-05,test_Loss:22.931533813476562, r2_store:-0.36608320994150256\n",
            "Epoch [8807/10000], train_Loss: 9.0336638095323e-05,test_Loss:22.924034118652344, r2_store:-0.36549773140182884\n",
            "Epoch [8808/10000], train_Loss: 9.103660704568028e-05,test_Loss:22.930885314941406, r2_store:-0.36606773053290476\n",
            "Epoch [8809/10000], train_Loss: 9.07667854335159e-05,test_Loss:22.92448616027832, r2_store:-0.3654345426168655\n",
            "Epoch [8810/10000], train_Loss: 8.930583135224879e-05,test_Loss:22.93074607849121, r2_store:-0.3659134595463551\n",
            "Epoch [8811/10000], train_Loss: 8.73014287208207e-05,test_Loss:22.926311492919922, r2_store:-0.36544564087977327\n",
            "Epoch [8812/10000], train_Loss: 8.549082122044638e-05,test_Loss:22.930110931396484, r2_store:-0.3657263348146058\n",
            "Epoch [8813/10000], train_Loss: 8.38499836390838e-05,test_Loss:22.927608489990234, r2_store:-0.36557489393951736\n",
            "Epoch [8814/10000], train_Loss: 8.251245890278369e-05,test_Loss:22.926700592041016, r2_store:-0.36560297981790324\n",
            "Epoch [8815/10000], train_Loss: 8.166841143975034e-05,test_Loss:22.927627563476562, r2_store:-0.3657249888166827\n",
            "Epoch [8816/10000], train_Loss: 8.160818833857775e-05,test_Loss:22.925256729125977, r2_store:-0.3654968886079206\n",
            "Epoch [8817/10000], train_Loss: 8.170357614289969e-05,test_Loss:22.929088592529297, r2_store:-0.36575474946019026\n",
            "Epoch [8818/10000], train_Loss: 8.152079681167379e-05,test_Loss:22.926109313964844, r2_store:-0.3653737259875167\n",
            "Epoch [8819/10000], train_Loss: 8.127590990625322e-05,test_Loss:22.93012809753418, r2_store:-0.3657008796877972\n",
            "Epoch [8820/10000], train_Loss: 8.119086123770103e-05,test_Loss:22.92715072631836, r2_store:-0.3652962099286383\n",
            "Epoch [8821/10000], train_Loss: 8.076620724750683e-05,test_Loss:22.92995262145996, r2_store:-0.3656511772401252\n",
            "Epoch [8822/10000], train_Loss: 7.980850932653993e-05,test_Loss:22.925508499145508, r2_store:-0.36532332014423385\n",
            "Epoch [8823/10000], train_Loss: 7.869390537962317e-05,test_Loss:22.92885971069336, r2_store:-0.3656064763310696\n",
            "Epoch [8824/10000], train_Loss: 7.795538840582594e-05,test_Loss:22.924610137939453, r2_store:-0.3653439938815879\n",
            "Epoch [8825/10000], train_Loss: 7.725525938440114e-05,test_Loss:22.929126739501953, r2_store:-0.36548505448049773\n",
            "Epoch [8826/10000], train_Loss: 7.638918032171205e-05,test_Loss:22.928659439086914, r2_store:-0.3653112006135426\n",
            "Epoch [8827/10000], train_Loss: 7.562058453913778e-05,test_Loss:22.929418563842773, r2_store:-0.36532381242087\n",
            "Epoch [8828/10000], train_Loss: 7.518427446484566e-05,test_Loss:22.930334091186523, r2_store:-0.36528982335525395\n",
            "Epoch [8829/10000], train_Loss: 7.471067510778084e-05,test_Loss:22.929580688476562, r2_store:-0.36523205108026424\n",
            "Epoch [8830/10000], train_Loss: 7.430237747030333e-05,test_Loss:22.92881965637207, r2_store:-0.36533343169992016\n",
            "Epoch [8831/10000], train_Loss: 7.401418406516314e-05,test_Loss:22.928485870361328, r2_store:-0.36516326151710143\n",
            "Epoch [8832/10000], train_Loss: 7.382268086075783e-05,test_Loss:22.9312686920166, r2_store:-0.3653562853725765\n",
            "Epoch [8833/10000], train_Loss: 7.360301242442802e-05,test_Loss:22.928142547607422, r2_store:-0.3650620291302\n",
            "Epoch [8834/10000], train_Loss: 7.345600897679105e-05,test_Loss:22.935100555419922, r2_store:-0.3653272287222191\n",
            "Epoch [8835/10000], train_Loss: 7.33045453671366e-05,test_Loss:22.931190490722656, r2_store:-0.3649748475852139\n",
            "Epoch [8836/10000], train_Loss: 7.302270387299359e-05,test_Loss:22.934528350830078, r2_store:-0.3652833611594224\n",
            "Epoch [8837/10000], train_Loss: 7.287664629984647e-05,test_Loss:22.93160057067871, r2_store:-0.36493463452609864\n",
            "Epoch [8838/10000], train_Loss: 7.241855200845748e-05,test_Loss:22.935623168945312, r2_store:-0.3652438897425574\n",
            "Epoch [8839/10000], train_Loss: 7.194825593614951e-05,test_Loss:22.930997848510742, r2_store:-0.36486804581605803\n",
            "Epoch [8840/10000], train_Loss: 7.16703143552877e-05,test_Loss:22.93624496459961, r2_store:-0.36516352166319366\n",
            "Epoch [8841/10000], train_Loss: 7.120250666048378e-05,test_Loss:22.93289566040039, r2_store:-0.36483660154517916\n",
            "Epoch [8842/10000], train_Loss: 7.063076918711886e-05,test_Loss:22.93535041809082, r2_store:-0.3650973709318077\n",
            "Epoch [8843/10000], train_Loss: 6.99546217219904e-05,test_Loss:22.932767868041992, r2_store:-0.3648218571943538\n",
            "Epoch [8844/10000], train_Loss: 6.949153612367809e-05,test_Loss:22.93672752380371, r2_store:-0.36504928551729043\n",
            "Epoch [8845/10000], train_Loss: 6.91490713506937e-05,test_Loss:22.933910369873047, r2_store:-0.36478369827843427\n",
            "Epoch [8846/10000], train_Loss: 6.868247146485373e-05,test_Loss:22.937633514404297, r2_store:-0.3649831916631763\n",
            "Epoch [8847/10000], train_Loss: 6.818823021603748e-05,test_Loss:22.936628341674805, r2_store:-0.3647259166207273\n",
            "Epoch [8848/10000], train_Loss: 6.794992077630013e-05,test_Loss:22.939579010009766, r2_store:-0.3649311171595322\n",
            "Epoch [8849/10000], train_Loss: 6.765099533367902e-05,test_Loss:22.93625831604004, r2_store:-0.3646920931550477\n",
            "Epoch [8850/10000], train_Loss: 6.731655594194308e-05,test_Loss:22.93936538696289, r2_store:-0.36492273729794156\n",
            "Epoch [8851/10000], train_Loss: 6.690790178254247e-05,test_Loss:22.936260223388672, r2_store:-0.3646793294513311\n",
            "Epoch [8852/10000], train_Loss: 6.654683238593861e-05,test_Loss:22.938905715942383, r2_store:-0.3648940227517661\n",
            "Epoch [8853/10000], train_Loss: 6.633608427364379e-05,test_Loss:22.937177658081055, r2_store:-0.3646000788333901\n",
            "Epoch [8854/10000], train_Loss: 6.605767703149468e-05,test_Loss:22.942203521728516, r2_store:-0.36482947408895083\n",
            "Epoch [8855/10000], train_Loss: 6.583372305613011e-05,test_Loss:22.939125061035156, r2_store:-0.36449590730453885\n",
            "Epoch [8856/10000], train_Loss: 6.566322554135695e-05,test_Loss:22.943634033203125, r2_store:-0.36478545385391326\n",
            "Epoch [8857/10000], train_Loss: 6.544080679304898e-05,test_Loss:22.940462112426758, r2_store:-0.36443331023312564\n",
            "Epoch [8858/10000], train_Loss: 6.545238284161314e-05,test_Loss:22.945110321044922, r2_store:-0.3647941869320914\n",
            "Epoch [8859/10000], train_Loss: 6.55337207717821e-05,test_Loss:22.939956665039062, r2_store:-0.3643727721733534\n",
            "Epoch [8860/10000], train_Loss: 6.563489296240732e-05,test_Loss:22.94627571105957, r2_store:-0.3648181906152048\n",
            "Epoch [8861/10000], train_Loss: 6.595584272872657e-05,test_Loss:22.940567016601562, r2_store:-0.36428858422429866\n",
            "Epoch [8862/10000], train_Loss: 6.653954915236682e-05,test_Loss:22.947887420654297, r2_store:-0.3648453961776248\n",
            "Epoch [8863/10000], train_Loss: 6.734249473083764e-05,test_Loss:22.940303802490234, r2_store:-0.3641752422294866\n",
            "Epoch [8864/10000], train_Loss: 6.859339191578329e-05,test_Loss:22.950212478637695, r2_store:-0.3648980273152844\n",
            "Epoch [8865/10000], train_Loss: 7.055776222841814e-05,test_Loss:22.940244674682617, r2_store:-0.3640023903897627\n",
            "Epoch [8866/10000], train_Loss: 7.330592779908329e-05,test_Loss:22.95351219177246, r2_store:-0.3649803826961282\n",
            "Epoch [8867/10000], train_Loss: 7.761297456454486e-05,test_Loss:22.93927764892578, r2_store:-0.3637677698933419\n",
            "Epoch [8868/10000], train_Loss: 8.3748614997603e-05,test_Loss:22.956462860107422, r2_store:-0.3651479268700748\n",
            "Epoch [8869/10000], train_Loss: 9.273155592381954e-05,test_Loss:22.93600082397461, r2_store:-0.3634696284857848\n",
            "Epoch [8870/10000], train_Loss: 0.00010559421207290143,test_Loss:22.961204528808594, r2_store:-0.3654364335011029\n",
            "Epoch [8871/10000], train_Loss: 0.00012480808072723448,test_Loss:22.932584762573242, r2_store:-0.3630456944670519\n",
            "Epoch [8872/10000], train_Loss: 0.00015231547877192497,test_Loss:22.96892547607422, r2_store:-0.3658658863209574\n",
            "Epoch [8873/10000], train_Loss: 0.00019314009114168584,test_Loss:22.928251266479492, r2_store:-0.3624537299442585\n",
            "Epoch [8874/10000], train_Loss: 0.00025266746524721384,test_Loss:22.97818946838379, r2_store:-0.36656492663080287\n",
            "Epoch [8875/10000], train_Loss: 0.00034194428008049726,test_Loss:22.916248321533203, r2_store:-0.3615709596427392\n",
            "Epoch [8876/10000], train_Loss: 0.0004741674638353288,test_Loss:22.99045181274414, r2_store:-0.36760298017957904\n",
            "Epoch [8877/10000], train_Loss: 0.0006742607802152634,test_Loss:22.903079986572266, r2_store:-0.36024758292119574\n",
            "Epoch [8878/10000], train_Loss: 0.0009756184881553054,test_Loss:23.013019561767578, r2_store:-0.36927295739274957\n",
            "Epoch [8879/10000], train_Loss: 0.0014360357308760285,test_Loss:22.874570846557617, r2_store:-0.35823710431608213\n",
            "Epoch [8880/10000], train_Loss: 0.0021352083422243595,test_Loss:23.04019546508789, r2_store:-0.3718853666628692\n",
            "Epoch [8881/10000], train_Loss: 0.003197741461917758,test_Loss:22.85404396057129, r2_store:-0.3553151889150321\n",
            "Epoch [8882/10000], train_Loss: 0.004826568998396397,test_Loss:23.09916114807129, r2_store:-0.37605457785906915\n",
            "Epoch [8883/10000], train_Loss: 0.007302726618945599,test_Loss:22.782814025878906, r2_store:-0.350829580122469\n",
            "Epoch [8884/10000], train_Loss: 0.011114695109426975,test_Loss:23.179096221923828, r2_store:-0.3826934432817448\n",
            "Epoch [8885/10000], train_Loss: 0.016795000061392784,test_Loss:22.714187622070312, r2_store:-0.3445715843882249\n",
            "Epoch [8886/10000], train_Loss: 0.025345001369714737,test_Loss:23.28472137451172, r2_store:-0.39248124858088174\n",
            "Epoch [8887/10000], train_Loss: 0.03740756958723068,test_Loss:22.632226943969727, r2_store:-0.33680456341428955\n",
            "Epoch [8888/10000], train_Loss: 0.05416475981473923,test_Loss:23.43905258178711, r2_store:-0.405703548024388\n",
            "Epoch [8889/10000], train_Loss: 0.07345353066921234,test_Loss:22.51460075378418, r2_store:-0.3298700829393282\n",
            "Epoch [8890/10000], train_Loss: 0.09442384541034698,test_Loss:23.561588287353516, r2_store:-0.4157039995841234\n",
            "Epoch [8891/10000], train_Loss: 0.10561342537403107,test_Loss:22.52643394470215, r2_store:-0.33002619158893554\n",
            "Epoch [8892/10000], train_Loss: 0.10233338177204132,test_Loss:23.413745880126953, r2_store:-0.4078263585630142\n",
            "Epoch [8893/10000], train_Loss: 0.07414749264717102,test_Loss:22.681612014770508, r2_store:-0.34492936866655177\n",
            "Epoch [8894/10000], train_Loss: 0.03595566749572754,test_Loss:23.059154510498047, r2_store:-0.3777089604977404\n",
            "Epoch [8895/10000], train_Loss: 0.0066104731522500515,test_Loss:23.016616821289062, r2_store:-0.3714476777693916\n",
            "Epoch [8896/10000], train_Loss: 0.002128029242157936,test_Loss:22.8248291015625, r2_store:-0.34993887730308115\n",
            "Epoch [8897/10000], train_Loss: 0.018199468031525612,test_Loss:23.357519149780273, r2_store:-0.3936615961239738\n",
            "Epoch [8898/10000], train_Loss: 0.036886151880025864,test_Loss:22.756620407104492, r2_store:-0.3429487403033509\n",
            "Epoch [8899/10000], train_Loss: 0.04169725626707077,test_Loss:23.30156135559082, r2_store:-0.3908160368868654\n",
            "Epoch [8900/10000], train_Loss: 0.0278121680021286,test_Loss:22.905271530151367, r2_store:-0.3562314379371878\n",
            "Epoch [8901/10000], train_Loss: 0.009173328056931496,test_Loss:23.031400680541992, r2_store:-0.36863846296709446\n",
            "Epoch [8902/10000], train_Loss: 0.000624995562247932,test_Loss:23.11264419555664, r2_store:-0.3781816699285274\n",
            "Epoch [8903/10000], train_Loss: 0.00633415300399065,test_Loss:22.827510833740234, r2_store:-0.35154104505475425\n",
            "Epoch [8904/10000], train_Loss: 0.017307860776782036,test_Loss:23.26030158996582, r2_store:-0.38705184217326405\n",
            "Epoch [8905/10000], train_Loss: 0.021492406725883484,test_Loss:22.805753707885742, r2_store:-0.3503252576941056\n",
            "Epoch [8906/10000], train_Loss: 0.015541011467576027,test_Loss:23.13494873046875, r2_store:-0.374673591081621\n",
            "Epoch [8907/10000], train_Loss: 0.005528123117983341,test_Loss:23.009048461914062, r2_store:-0.3640127278705769\n",
            "Epoch [8908/10000], train_Loss: 0.00048590119695290923,test_Loss:22.910341262817383, r2_store:-0.35834783162258677\n",
            "Epoch [8909/10000], train_Loss: 0.0031749482732266188,test_Loss:23.16464614868164, r2_store:-0.3784282423775611\n",
            "Epoch [8910/10000], train_Loss: 0.009062649682164192,test_Loss:22.864849090576172, r2_store:-0.3527883884141665\n",
            "Epoch [8911/10000], train_Loss: 0.011779861524701118,test_Loss:23.15810203552246, r2_store:-0.37925740547690645\n",
            "Epoch [8912/10000], train_Loss: 0.008774339221417904,test_Loss:22.883968353271484, r2_store:-0.35962452605748374\n",
            "Epoch [8913/10000], train_Loss: 0.0034525226801633835,test_Loss:22.99912452697754, r2_store:-0.36834329235312957\n",
            "Epoch [8914/10000], train_Loss: 0.0004166151920799166,test_Loss:23.037302017211914, r2_store:-0.3717324099530044\n",
            "Epoch [8915/10000], train_Loss: 0.001527712563984096,test_Loss:22.857662200927734, r2_store:-0.3582369984101892\n",
            "Epoch [8916/10000], train_Loss: 0.0046828920021653175,test_Loss:23.104887008666992, r2_store:-0.37752985533643413\n",
            "Epoch [8917/10000], train_Loss: 0.006345382891595364,test_Loss:22.866992950439453, r2_store:-0.357840183384202\n",
            "Epoch [8918/10000], train_Loss: 0.005148063413798809,test_Loss:23.03377914428711, r2_store:-0.3728815710929003\n",
            "Epoch [8919/10000], train_Loss: 0.0023397135082632303,test_Loss:22.94129180908203, r2_store:-0.3652199157574594\n",
            "Epoch [8920/10000], train_Loss: 0.00042018666863441467,test_Loss:22.93496322631836, r2_store:-0.3647098673042961\n",
            "Epoch [8921/10000], train_Loss: 0.0006348866736516356,test_Loss:23.015165328979492, r2_store:-0.37365416000699114\n",
            "Epoch [8922/10000], train_Loss: 0.002198986941948533,test_Loss:22.836322784423828, r2_store:-0.3606426043502058\n",
            "Epoch [8923/10000], train_Loss: 0.003392766462638974,test_Loss:23.022747039794922, r2_store:-0.3756175377640132\n",
            "Epoch [8924/10000], train_Loss: 0.0031240980606526136,test_Loss:22.85979652404785, r2_store:-0.3631576457247758\n",
            "Epoch [8925/10000], train_Loss: 0.0017810985445976257,test_Loss:22.936920166015625, r2_store:-0.3706890664373621\n",
            "Epoch [8926/10000], train_Loss: 0.0005198420258238912,test_Loss:22.925342559814453, r2_store:-0.369008874687351\n",
            "Epoch [8927/10000], train_Loss: 0.00022806742344982922,test_Loss:22.88473892211914, r2_store:-0.364540336664416\n",
            "Epoch [8928/10000], train_Loss: 0.0008596247062087059,test_Loss:22.98883819580078, r2_store:-0.3727571464942432\n",
            "Epoch [8929/10000], train_Loss: 0.0016539751086384058,test_Loss:22.86233139038086, r2_store:-0.3619127361271248\n",
            "Epoch [8930/10000], train_Loss: 0.0018870967905968428,test_Loss:22.989456176757812, r2_store:-0.37203944699022196\n",
            "Epoch [8931/10000], train_Loss: 0.0014193429378792644,test_Loss:22.887046813964844, r2_store:-0.36427189291847095\n",
            "Epoch [8932/10000], train_Loss: 0.0006735197966918349,test_Loss:22.923736572265625, r2_store:-0.36802613717616284\n",
            "Epoch [8933/10000], train_Loss: 0.00020655221305787563,test_Loss:22.934106826782227, r2_store:-0.36857433834639286\n",
            "Epoch [8934/10000], train_Loss: 0.00025650422321632504,test_Loss:22.879411697387695, r2_store:-0.36445742055797403\n",
            "Epoch [8935/10000], train_Loss: 0.0006433034432120621,test_Loss:22.94906997680664, r2_store:-0.37119322432365354\n",
            "Epoch [8936/10000], train_Loss: 0.0009844775777310133,test_Loss:22.860830307006836, r2_store:-0.36340886885214196\n",
            "Epoch [8937/10000], train_Loss: 0.0010129541624337435,test_Loss:22.954654693603516, r2_store:-0.37048258861070416\n",
            "Epoch [8938/10000], train_Loss: 0.0007386606303043664,test_Loss:22.884380340576172, r2_store:-0.3651456552679575\n",
            "Epoch [8939/10000], train_Loss: 0.00037641674862243235,test_Loss:22.91155242919922, r2_store:-0.36774487347818385\n",
            "Epoch [8940/10000], train_Loss: 0.00016176013741642237,test_Loss:22.92005157470703, r2_store:-0.36818213284179224\n",
            "Epoch [8941/10000], train_Loss: 0.00018391277990303934,test_Loss:22.882266998291016, r2_store:-0.36540636894063994\n",
            "Epoch [8942/10000], train_Loss: 0.00036162062315270305,test_Loss:22.93333625793457, r2_store:-0.37014271839024504\n",
            "Epoch [8943/10000], train_Loss: 0.0005336140748113394,test_Loss:22.87191390991211, r2_store:-0.36479068653733093\n",
            "Epoch [8944/10000], train_Loss: 0.0005743105430155993,test_Loss:22.9345645904541, r2_store:-0.37006383360620876\n",
            "Epoch [8945/10000], train_Loss: 0.0004698628908954561,test_Loss:22.883533477783203, r2_store:-0.36575332595765775\n",
            "Epoch [8946/10000], train_Loss: 0.0002972974325530231,test_Loss:22.91823959350586, r2_store:-0.3681466587962907\n",
            "Epoch [8947/10000], train_Loss: 0.00016165748820640147,test_Loss:22.916296005249023, r2_store:-0.3673908129877781\n",
            "Epoch [8948/10000], train_Loss: 0.0001264267775695771,test_Loss:22.89956283569336, r2_store:-0.3660596078537486\n",
            "Epoch [8949/10000], train_Loss: 0.00018141893087886274,test_Loss:22.92989730834961, r2_store:-0.3686169355951241\n",
            "Epoch [8950/10000], train_Loss: 0.00026973875355906785,test_Loss:22.89179229736328, r2_store:-0.3650520788648548\n",
            "Epoch [8951/10000], train_Loss: 0.00032709300285205245,test_Loss:22.934892654418945, r2_store:-0.3688459884024302\n",
            "Epoch [8952/10000], train_Loss: 0.00032008052221499383,test_Loss:22.890098571777344, r2_store:-0.3653496202678128\n",
            "Epoch [8953/10000], train_Loss: 0.0002588689385447651,test_Loss:22.923433303833008, r2_store:-0.3680680310932791\n",
            "Epoch [8954/10000], train_Loss: 0.00018051298684440553,test_Loss:22.906646728515625, r2_store:-0.36646621523875544\n",
            "Epoch [8955/10000], train_Loss: 0.000124551443150267,test_Loss:22.91059684753418, r2_store:-0.3667555870575463\n",
            "Epoch [8956/10000], train_Loss: 0.00011081572301918641,test_Loss:22.92250633239746, r2_store:-0.3675307852876566\n",
            "Epoch [8957/10000], train_Loss: 0.00013346594641916454,test_Loss:22.90309715270996, r2_store:-0.3657805938425869\n",
            "Epoch [8958/10000], train_Loss: 0.00017029207083396614,test_Loss:22.928203582763672, r2_store:-0.36806416767220473\n",
            "Epoch [8959/10000], train_Loss: 0.00019711125059984624,test_Loss:22.899282455444336, r2_store:-0.36543870850162175\n",
            "Epoch [8960/10000], train_Loss: 0.00019969503046013415,test_Loss:22.930896759033203, r2_store:-0.36788204227215004\n",
            "Epoch [8961/10000], train_Loss: 0.00017889385344460607,test_Loss:22.90599250793457, r2_store:-0.36575523474706717\n",
            "Epoch [8962/10000], train_Loss: 0.0001458478654967621,test_Loss:22.923770904541016, r2_store:-0.3671589112101137\n",
            "Epoch [8963/10000], train_Loss: 0.00011568056652322412,test_Loss:22.918426513671875, r2_store:-0.36644956449196786\n",
            "Epoch [8964/10000], train_Loss: 9.909726213663816e-05,test_Loss:22.917640686035156, r2_store:-0.3663925101818626\n",
            "Epoch [8965/10000], train_Loss: 9.869054338196293e-05,test_Loss:22.924888610839844, r2_store:-0.36711375085781683\n",
            "Epoch [8966/10000], train_Loss: 0.00011030798486899585,test_Loss:22.91115951538086, r2_store:-0.36588349079295845\n",
            "Epoch [8967/10000], train_Loss: 0.00012461745063774288,test_Loss:22.929492950439453, r2_store:-0.36744581816487054\n",
            "Epoch [8968/10000], train_Loss: 0.00013357127318158746,test_Loss:22.909048080444336, r2_store:-0.3657092788402876\n",
            "Epoch [8969/10000], train_Loss: 0.0001334234548266977,test_Loss:22.929367065429688, r2_store:-0.3673209345229147\n",
            "Epoch [8970/10000], train_Loss: 0.00012489230721257627,test_Loss:22.91333770751953, r2_store:-0.36594653539954924\n",
            "Epoch [8971/10000], train_Loss: 0.00011187471682205796,test_Loss:22.92335319519043, r2_store:-0.3669682807506318\n",
            "Epoch [8972/10000], train_Loss: 9.919136937242001e-05,test_Loss:22.918502807617188, r2_store:-0.3664108243124604\n",
            "Epoch [8973/10000], train_Loss: 9.066170605365187e-05,test_Loss:22.919965744018555, r2_store:-0.3665634805218074\n",
            "Epoch [8974/10000], train_Loss: 8.791225991444662e-05,test_Loss:22.92151641845703, r2_store:-0.3668430621463106\n",
            "Epoch [8975/10000], train_Loss: 9.038745338330045e-05,test_Loss:22.91460418701172, r2_store:-0.366197862134783\n",
            "Epoch [8976/10000], train_Loss: 9.505033813184127e-05,test_Loss:22.927038192749023, r2_store:-0.36703967571529494\n",
            "Epoch [8977/10000], train_Loss: 9.91577617242001e-05,test_Loss:22.914026260375977, r2_store:-0.36592867997702294\n",
            "Epoch [8978/10000], train_Loss: 0.00010122653475264087,test_Loss:22.93008041381836, r2_store:-0.3669638834607323\n",
            "Epoch [8979/10000], train_Loss: 0.00010030496923718601,test_Loss:22.9169864654541, r2_store:-0.36590720685707145\n",
            "Epoch [8980/10000], train_Loss: 9.691181912785396e-05,test_Loss:22.928510665893555, r2_store:-0.366800417810506\n",
            "Epoch [8981/10000], train_Loss: 9.22305989661254e-05,test_Loss:22.92161750793457, r2_store:-0.3660875906846863\n",
            "Epoch [8982/10000], train_Loss: 8.742383943172172e-05,test_Loss:22.925731658935547, r2_store:-0.3665787737903645\n",
            "Epoch [8983/10000], train_Loss: 8.330879791174084e-05,test_Loss:22.92449951171875, r2_store:-0.36631962840921095\n",
            "Epoch [8984/10000], train_Loss: 8.108410111162812e-05,test_Loss:22.924442291259766, r2_store:-0.3663148371613194\n",
            "Epoch [8985/10000], train_Loss: 8.033342601265758e-05,test_Loss:22.926223754882812, r2_store:-0.3664284014168815\n",
            "Epoch [8986/10000], train_Loss: 8.060548861976713e-05,test_Loss:22.926090240478516, r2_store:-0.36603313464385967\n",
            "Epoch [8987/10000], train_Loss: 8.133791561704129e-05,test_Loss:22.930252075195312, r2_store:-0.36645851638146754\n",
            "Epoch [8988/10000], train_Loss: 8.212821558117867e-05,test_Loss:22.921688079833984, r2_store:-0.3658606989508648\n",
            "Epoch [8989/10000], train_Loss: 8.296931628137827e-05,test_Loss:22.933467864990234, r2_store:-0.36650006421932635\n",
            "Epoch [8990/10000], train_Loss: 8.293033170048147e-05,test_Loss:22.923381805419922, r2_store:-0.36584683418990793\n",
            "Epoch [8991/10000], train_Loss: 8.200253068935126e-05,test_Loss:22.931049346923828, r2_store:-0.36643898785939655\n",
            "Epoch [8992/10000], train_Loss: 8.080770203378052e-05,test_Loss:22.92843246459961, r2_store:-0.365881434372588\n",
            "Epoch [8993/10000], train_Loss: 7.941883086459711e-05,test_Loss:22.932025909423828, r2_store:-0.3663057568759578\n",
            "Epoch [8994/10000], train_Loss: 7.773841934977099e-05,test_Loss:22.92690658569336, r2_store:-0.3658913509489352\n",
            "Epoch [8995/10000], train_Loss: 7.628023740835488e-05,test_Loss:22.933332443237305, r2_store:-0.3661684612566847\n",
            "Epoch [8996/10000], train_Loss: 7.487169204978272e-05,test_Loss:22.928573608398438, r2_store:-0.36597346259135843\n",
            "Epoch [8997/10000], train_Loss: 7.36810834496282e-05,test_Loss:22.927106857299805, r2_store:-0.3660349386223214\n",
            "Epoch [8998/10000], train_Loss: 7.335359987337142e-05,test_Loss:22.93158721923828, r2_store:-0.36604700996964157\n",
            "Epoch [8999/10000], train_Loss: 7.302818994503468e-05,test_Loss:22.929523468017578, r2_store:-0.3659072363777003\n",
            "Epoch [9000/10000], train_Loss: 7.2241120506078e-05,test_Loss:22.93148422241211, r2_store:-0.36602041770948435\n",
            "Epoch [9001/10000], train_Loss: 7.232915959320962e-05,test_Loss:22.932933807373047, r2_store:-0.36578525135832396\n",
            "Epoch [9002/10000], train_Loss: 7.238348189275712e-05,test_Loss:22.935213088989258, r2_store:-0.3660456645636505\n",
            "Epoch [9003/10000], train_Loss: 7.207560702227056e-05,test_Loss:22.928119659423828, r2_store:-0.3657064076646914\n",
            "Epoch [9004/10000], train_Loss: 7.193331839516759e-05,test_Loss:22.935922622680664, r2_store:-0.36606699906417517\n",
            "Epoch [9005/10000], train_Loss: 7.17419752618298e-05,test_Loss:22.930070877075195, r2_store:-0.3656759257059521\n",
            "Epoch [9006/10000], train_Loss: 7.137122156564146e-05,test_Loss:22.933015823364258, r2_store:-0.3660295735380539\n",
            "Epoch [9007/10000], train_Loss: 7.133666076697409e-05,test_Loss:22.933034896850586, r2_store:-0.36564885399703995\n",
            "Epoch [9008/10000], train_Loss: 7.094252214301378e-05,test_Loss:22.936370849609375, r2_store:-0.3659965351161516\n",
            "Epoch [9009/10000], train_Loss: 7.018594624241814e-05,test_Loss:22.930171966552734, r2_store:-0.3655773778748379\n",
            "Epoch [9010/10000], train_Loss: 6.995927105890587e-05,test_Loss:22.938501358032227, r2_store:-0.3659502474499552\n",
            "Epoch [9011/10000], train_Loss: 6.94552218192257e-05,test_Loss:22.933189392089844, r2_store:-0.3655385649757297\n",
            "Epoch [9012/10000], train_Loss: 6.883770402055234e-05,test_Loss:22.935489654541016, r2_store:-0.36587652258093484\n",
            "Epoch [9013/10000], train_Loss: 6.866782496217638e-05,test_Loss:22.93296241760254, r2_store:-0.36549037842490284\n",
            "Epoch [9014/10000], train_Loss: 6.819241389166564e-05,test_Loss:22.938255310058594, r2_store:-0.36584281629715343\n",
            "Epoch [9015/10000], train_Loss: 6.784299330320209e-05,test_Loss:22.93194580078125, r2_store:-0.36541486718253857\n",
            "Epoch [9016/10000], train_Loss: 6.766238948330283e-05,test_Loss:22.938833236694336, r2_store:-0.36580908741247153\n",
            "Epoch [9017/10000], train_Loss: 6.738783122273162e-05,test_Loss:22.93484878540039, r2_store:-0.365375520384813\n",
            "Epoch [9018/10000], train_Loss: 6.743617996107787e-05,test_Loss:22.9387264251709, r2_store:-0.36580294274132874\n",
            "Epoch [9019/10000], train_Loss: 6.750377360731363e-05,test_Loss:22.933889389038086, r2_store:-0.36529353079620375\n",
            "Epoch [9020/10000], train_Loss: 6.746204599039629e-05,test_Loss:22.94308090209961, r2_store:-0.36580146050750617\n",
            "Epoch [9021/10000], train_Loss: 6.787235906813294e-05,test_Loss:22.934738159179688, r2_store:-0.3652094779048838\n",
            "Epoch [9022/10000], train_Loss: 6.81896781316027e-05,test_Loss:22.942493438720703, r2_store:-0.36582608508660397\n",
            "Epoch [9023/10000], train_Loss: 6.875093095004559e-05,test_Loss:22.93570899963379, r2_store:-0.3651698179539231\n",
            "Epoch [9024/10000], train_Loss: 6.966629007365555e-05,test_Loss:22.943157196044922, r2_store:-0.3659087878839373\n",
            "Epoch [9025/10000], train_Loss: 7.093279418768361e-05,test_Loss:22.935171127319336, r2_store:-0.3650648663923437\n",
            "Epoch [9026/10000], train_Loss: 7.277336408151314e-05,test_Loss:22.946928024291992, r2_store:-0.36597228205207966\n",
            "Epoch [9027/10000], train_Loss: 7.527680281782523e-05,test_Loss:22.934003829956055, r2_store:-0.36489861806142554\n",
            "Epoch [9028/10000], train_Loss: 7.874079165048897e-05,test_Loss:22.949941635131836, r2_store:-0.36608627889624135\n",
            "Epoch [9029/10000], train_Loss: 8.374178287340328e-05,test_Loss:22.932437896728516, r2_store:-0.364684365177665\n",
            "Epoch [9030/10000], train_Loss: 9.021561709232628e-05,test_Loss:22.952228546142578, r2_store:-0.36621932967626547\n",
            "Epoch [9031/10000], train_Loss: 9.888414206216112e-05,test_Loss:22.930742263793945, r2_store:-0.3644281233080582\n",
            "Epoch [9032/10000], train_Loss: 0.00011064126010751352,test_Loss:22.955490112304688, r2_store:-0.36646194730829085\n",
            "Epoch [9033/10000], train_Loss: 0.00012719955702777952,test_Loss:22.926244735717773, r2_store:-0.3640628087335178\n",
            "Epoch [9034/10000], train_Loss: 0.00014996311801951379,test_Loss:22.962543487548828, r2_store:-0.36680940122603767\n",
            "Epoch [9035/10000], train_Loss: 0.0001824650535127148,test_Loss:22.922849655151367, r2_store:-0.3635727963009132\n",
            "Epoch [9036/10000], train_Loss: 0.00022791570518165827,test_Loss:22.968448638916016, r2_store:-0.3673592889323569\n",
            "Epoch [9037/10000], train_Loss: 0.00029342120978981256,test_Loss:22.91546058654785, r2_store:-0.3628887273558592\n",
            "Epoch [9038/10000], train_Loss: 0.0003864196187350899,test_Loss:22.979780197143555, r2_store:-0.3681773555892476\n",
            "Epoch [9039/10000], train_Loss: 0.0005212490796111524,test_Loss:22.902008056640625, r2_store:-0.3618553351545586\n",
            "Epoch [9040/10000], train_Loss: 0.0007163590053096414,test_Loss:22.993812561035156, r2_store:-0.3693916114085978\n",
            "Epoch [9041/10000], train_Loss: 0.0010019094916060567,test_Loss:22.891469955444336, r2_store:-0.36039476897016476\n",
            "Epoch [9042/10000], train_Loss: 0.0014218149008229375,test_Loss:23.01848030090332, r2_store:-0.3712786714059624\n",
            "Epoch [9043/10000], train_Loss: 0.0020403373055160046,test_Loss:22.854557037353516, r2_store:-0.3581084745069385\n",
            "Epoch [9044/10000], train_Loss: 0.0029687013011425734,test_Loss:23.057785034179688, r2_store:-0.37417400029113956\n",
            "Epoch [9045/10000], train_Loss: 0.004340359941124916,test_Loss:22.820932388305664, r2_store:-0.3547928721988307\n",
            "Epoch [9046/10000], train_Loss: 0.006413689348846674,test_Loss:23.101390838623047, r2_store:-0.3785457489004995\n",
            "Epoch [9047/10000], train_Loss: 0.009476478211581707,test_Loss:22.774147033691406, r2_store:-0.3501749593253112\n",
            "Epoch [9048/10000], train_Loss: 0.01408907026052475,test_Loss:23.1929874420166, r2_store:-0.3855865041413349\n",
            "Epoch [9049/10000], train_Loss: 0.02069425769150257,test_Loss:22.70096206665039, r2_store:-0.34384969116069075\n",
            "Epoch [9050/10000], train_Loss: 0.030471226200461388,test_Loss:23.33260726928711, r2_store:-0.39625757028307973\n",
            "Epoch [9051/10000], train_Loss: 0.042838312685489655,test_Loss:22.59433364868164, r2_store:-0.33760267636762165\n",
            "Epoch [9052/10000], train_Loss: 0.058399319648742676,test_Loss:23.415170669555664, r2_store:-0.40741278260712344\n",
            "Epoch [9053/10000], train_Loss: 0.07407746464014053,test_Loss:22.543060302734375, r2_store:-0.33229521038203624\n",
            "Epoch [9054/10000], train_Loss: 0.08789391070604324,test_Loss:23.49003791809082, r2_store:-0.4116171066059482\n",
            "Epoch [9055/10000], train_Loss: 0.08923007547855377,test_Loss:22.568817138671875, r2_store:-0.3344861076136012\n",
            "Epoch [9056/10000], train_Loss: 0.07675108313560486,test_Loss:23.322004318237305, r2_store:-0.3983260957321193\n",
            "Epoch [9057/10000], train_Loss: 0.047707438468933105,test_Loss:22.760534286499023, r2_store:-0.3497088294766344\n",
            "Epoch [9058/10000], train_Loss: 0.018679460510611534,test_Loss:23.06705665588379, r2_store:-0.37144513201103413\n",
            "Epoch [9059/10000], train_Loss: 0.0021062837913632393,test_Loss:23.05055809020996, r2_store:-0.37379398793916874\n",
            "Epoch [9060/10000], train_Loss: 0.003585758153349161,test_Loss:22.7923583984375, r2_store:-0.3508682005862891\n",
            "Epoch [9061/10000], train_Loss: 0.017185106873512268,test_Loss:23.30339813232422, r2_store:-0.3911682614184506\n",
            "Epoch [9062/10000], train_Loss: 0.02943919226527214,test_Loss:22.74451446533203, r2_store:-0.34511352297700526\n",
            "Epoch [9063/10000], train_Loss: 0.03097641095519066,test_Loss:23.223087310791016, r2_store:-0.3861226011542529\n",
            "Epoch [9064/10000], train_Loss: 0.020954793319106102,test_Loss:22.840465545654297, r2_store:-0.3555898349451383\n",
            "Epoch [9065/10000], train_Loss: 0.007694080471992493,test_Loss:22.987485885620117, r2_store:-0.3685138550867755\n",
            "Epoch [9066/10000], train_Loss: 0.0006996844313107431,test_Loss:23.030033111572266, r2_store:-0.37284166605203684\n",
            "Epoch [9067/10000], train_Loss: 0.003081751521676779,test_Loss:22.82366371154785, r2_store:-0.3527752388371401\n",
            "Epoch [9068/10000], train_Loss: 0.010478395037353039,test_Loss:23.21493911743164, r2_store:-0.38227011073274575\n",
            "Epoch [9069/10000], train_Loss: 0.015550119802355766,test_Loss:22.80147933959961, r2_store:-0.3502766668699324\n",
            "Epoch [9070/10000], train_Loss: 0.014408634975552559,test_Loss:23.131956100463867, r2_store:-0.3774633120131099\n",
            "Epoch [9071/10000], train_Loss: 0.00831245630979538,test_Loss:22.935300827026367, r2_store:-0.3597287918933376\n",
            "Epoch [9072/10000], train_Loss: 0.0023186334874480963,test_Loss:22.98647689819336, r2_store:-0.364828642723944\n",
            "Epoch [9073/10000], train_Loss: 0.0003489963128231466,test_Loss:23.048561096191406, r2_store:-0.3725136143089902\n",
            "Epoch [9074/10000], train_Loss: 0.002751328982412815,test_Loss:22.833534240722656, r2_store:-0.3560980618616343\n",
            "Epoch [9075/10000], train_Loss: 0.006545259151607752,test_Loss:23.107643127441406, r2_store:-0.3789660439526761\n",
            "Epoch [9076/10000], train_Loss: 0.00823216699063778,test_Loss:22.81118392944336, r2_store:-0.35652589024012293\n",
            "Epoch [9077/10000], train_Loss: 0.006790769286453724,test_Loss:23.028200149536133, r2_store:-0.3749487766403483\n",
            "Epoch [9078/10000], train_Loss: 0.0034358769189566374,test_Loss:22.89275360107422, r2_store:-0.36444644845969587\n",
            "Epoch [9079/10000], train_Loss: 0.000751781219150871,test_Loss:22.905704498291016, r2_store:-0.3657296899032405\n",
            "Epoch [9080/10000], train_Loss: 0.0003806662862189114,test_Loss:23.00288200378418, r2_store:-0.3727016833083032\n",
            "Epoch [9081/10000], train_Loss: 0.001922466792166233,test_Loss:22.85288429260254, r2_store:-0.3595075538904693\n",
            "Epoch [9082/10000], train_Loss: 0.003729292657226324,test_Loss:23.04207420349121, r2_store:-0.37611587977863636\n",
            "Epoch [9083/10000], train_Loss: 0.004348326940089464,test_Loss:22.82927131652832, r2_store:-0.36003500415824363\n",
            "Epoch [9084/10000], train_Loss: 0.003431475255638361,test_Loss:22.987445831298828, r2_store:-0.3728561729034734\n",
            "Epoch [9085/10000], train_Loss: 0.0017094581853598356,test_Loss:22.881818771362305, r2_store:-0.36545538532892774\n",
            "Epoch [9086/10000], train_Loss: 0.0004403740749694407,test_Loss:22.87851333618164, r2_store:-0.36667938471885364\n",
            "Epoch [9087/10000], train_Loss: 0.00023678815341554582,test_Loss:22.935157775878906, r2_store:-0.37167717082447993\n",
            "Epoch [9088/10000], train_Loss: 0.0009305027197115123,test_Loss:22.821022033691406, r2_store:-0.36253213537952167\n",
            "Epoch [9089/10000], train_Loss: 0.0018279023934155703,test_Loss:22.962614059448242, r2_store:-0.37382060938905015\n",
            "Epoch [9090/10000], train_Loss: 0.0022011876571923494,test_Loss:22.829683303833008, r2_store:-0.3620496461744289\n",
            "Epoch [9091/10000], train_Loss: 0.0018535805866122246,test_Loss:22.946643829345703, r2_store:-0.37156603404566413\n",
            "Epoch [9092/10000], train_Loss: 0.0010990183800458908,test_Loss:22.869609832763672, r2_store:-0.365271075405893\n",
            "Epoch [9093/10000], train_Loss: 0.00040410313522443175,test_Loss:22.8997859954834, r2_store:-0.367463734359726\n",
            "Epoch [9094/10000], train_Loss: 0.00013794297410640866,test_Loss:22.930561065673828, r2_store:-0.3694185067550866\n",
            "Epoch [9095/10000], train_Loss: 0.0003407002077437937,test_Loss:22.864112854003906, r2_store:-0.3643839693039519\n",
            "Epoch [9096/10000], train_Loss: 0.0007436497253365815,test_Loss:22.942697525024414, r2_store:-0.37182812079351724\n",
            "Epoch [9097/10000], train_Loss: 0.0010529168648645282,test_Loss:22.845972061157227, r2_store:-0.3637346341811283\n",
            "Epoch [9098/10000], train_Loss: 0.0010781839955598116,test_Loss:22.934703826904297, r2_store:-0.37128115635190717\n",
            "Epoch [9099/10000], train_Loss: 0.0008215524139814079,test_Loss:22.861310958862305, r2_store:-0.3651963928252635\n",
            "Epoch [9100/10000], train_Loss: 0.0004668223555199802,test_Loss:22.90287971496582, r2_store:-0.36877808770032194\n",
            "Epoch [9101/10000], train_Loss: 0.00019716532551683486,test_Loss:22.888195037841797, r2_store:-0.3677521360791254\n",
            "Epoch [9102/10000], train_Loss: 0.00011817838822025806,test_Loss:22.87044906616211, r2_store:-0.36611487729502024\n",
            "Epoch [9103/10000], train_Loss: 0.0002231808175565675,test_Loss:22.918386459350586, r2_store:-0.36972674407766415\n",
            "Epoch [9104/10000], train_Loss: 0.0004017507308162749,test_Loss:22.862327575683594, r2_store:-0.3647479162457927\n",
            "Epoch [9105/10000], train_Loss: 0.0005345300887711346,test_Loss:22.926807403564453, r2_store:-0.3703494181017819\n",
            "Epoch [9106/10000], train_Loss: 0.0005579590797424316,test_Loss:22.86501693725586, r2_store:-0.3650734345829971\n",
            "Epoch [9107/10000], train_Loss: 0.00046511762775480747,test_Loss:22.916767120361328, r2_store:-0.3695248655423373\n",
            "Epoch [9108/10000], train_Loss: 0.00031334912637248635,test_Loss:22.87891387939453, r2_store:-0.3664516409282834\n",
            "Epoch [9109/10000], train_Loss: 0.00017987730097956955,test_Loss:22.895065307617188, r2_store:-0.36791149031513837\n",
            "Epoch [9110/10000], train_Loss: 0.00010811274114530534,test_Loss:22.89780044555664, r2_store:-0.3680425467692898\n",
            "Epoch [9111/10000], train_Loss: 0.00011421146336942911,test_Loss:22.881513595581055, r2_store:-0.366333358752732\n",
            "Epoch [9112/10000], train_Loss: 0.00017343900981359184,test_Loss:22.91782569885254, r2_store:-0.3689703092146852\n",
            "Epoch [9113/10000], train_Loss: 0.0002414002810837701,test_Loss:22.88036346435547, r2_store:-0.3654583108052727\n",
            "Epoch [9114/10000], train_Loss: 0.0002854549093171954,test_Loss:22.92519760131836, r2_store:-0.36908098843250303\n",
            "Epoch [9115/10000], train_Loss: 0.00028736074455082417,test_Loss:22.880861282348633, r2_store:-0.365515602535879\n",
            "Epoch [9116/10000], train_Loss: 0.00024972367100417614,test_Loss:22.922330856323242, r2_store:-0.36850332301880395\n",
            "Epoch [9117/10000], train_Loss: 0.00019237531523685902,test_Loss:22.896509170532227, r2_store:-0.3662407294804746\n",
            "Epoch [9118/10000], train_Loss: 0.0001371206744806841,test_Loss:22.90652084350586, r2_store:-0.36750497027948836\n",
            "Epoch [9119/10000], train_Loss: 9.973520354833454e-05,test_Loss:22.90520477294922, r2_store:-0.3671147304532063\n",
            "Epoch [9120/10000], train_Loss: 8.857705688569695e-05,test_Loss:22.90313148498535, r2_store:-0.3665568139541835\n",
            "Epoch [9121/10000], train_Loss: 9.943792974809185e-05,test_Loss:22.916996002197266, r2_store:-0.3676964148928348\n",
            "Epoch [9122/10000], train_Loss: 0.00012138755846535787,test_Loss:22.90147590637207, r2_store:-0.365834147006443\n",
            "Epoch [9123/10000], train_Loss: 0.00014351819118019193,test_Loss:22.93094253540039, r2_store:-0.3679630168919992\n",
            "Epoch [9124/10000], train_Loss: 0.00015659887867514044,test_Loss:22.897945404052734, r2_store:-0.36559784544930873\n",
            "Epoch [9125/10000], train_Loss: 0.00015767534205224365,test_Loss:22.930084228515625, r2_store:-0.3678336555678081\n",
            "Epoch [9126/10000], train_Loss: 0.00014620396541431546,test_Loss:22.907007217407227, r2_store:-0.3658707968696444\n",
            "Epoch [9127/10000], train_Loss: 0.00012785301078110933,test_Loss:22.9228515625, r2_store:-0.3674972491149413\n",
            "Epoch [9128/10000], train_Loss: 0.00010801013559103012,test_Loss:22.912235260009766, r2_store:-0.3663892591965692\n",
            "Epoch [9129/10000], train_Loss: 9.10754461074248e-05,test_Loss:22.922306060791016, r2_store:-0.36706864221046986\n",
            "Epoch [9130/10000], train_Loss: 8.068757597357035e-05,test_Loss:22.917400360107422, r2_store:-0.3668666609440214\n",
            "Epoch [9131/10000], train_Loss: 7.817491132300347e-05,test_Loss:22.919675827026367, r2_store:-0.36657969358645626\n",
            "Epoch [9132/10000], train_Loss: 8.079101098701358e-05,test_Loss:22.928651809692383, r2_store:-0.3672173399433667\n",
            "Epoch [9133/10000], train_Loss: 8.63508612383157e-05,test_Loss:22.914226531982422, r2_store:-0.3661581881454661\n",
            "Epoch [9134/10000], train_Loss: 9.322940604761243e-05,test_Loss:22.934541702270508, r2_store:-0.36734317416212114\n",
            "Epoch [9135/10000], train_Loss: 9.800239058677107e-05,test_Loss:22.916126251220703, r2_store:-0.36598253624828714\n",
            "Epoch [9136/10000], train_Loss: 0.0001000479533104226,test_Loss:22.930782318115234, r2_store:-0.3673323454976605\n",
            "Epoch [9137/10000], train_Loss: 9.973456326406449e-05,test_Loss:22.918073654174805, r2_store:-0.36603274523904883\n",
            "Epoch [9138/10000], train_Loss: 9.661725198384374e-05,test_Loss:22.93051528930664, r2_store:-0.36725052844301476\n",
            "Epoch [9139/10000], train_Loss: 9.144269279204309e-05,test_Loss:22.9193115234375, r2_store:-0.36614947480940385\n",
            "Epoch [9140/10000], train_Loss: 8.586318290326744e-05,test_Loss:22.931570053100586, r2_store:-0.367061756004347\n",
            "Epoch [9141/10000], train_Loss: 8.052050543483347e-05,test_Loss:22.91998863220215, r2_store:-0.3663190180239766\n",
            "Epoch [9142/10000], train_Loss: 7.584054401377216e-05,test_Loss:22.926877975463867, r2_store:-0.36682007644927017\n",
            "Epoch [9143/10000], train_Loss: 7.229597395053133e-05,test_Loss:22.924579620361328, r2_store:-0.36645330606112814\n",
            "Epoch [9144/10000], train_Loss: 7.003506470937282e-05,test_Loss:22.926002502441406, r2_store:-0.3665595366314709\n",
            "Epoch [9145/10000], train_Loss: 6.896050763316453e-05,test_Loss:22.928733825683594, r2_store:-0.3665529687766922\n",
            "Epoch [9146/10000], train_Loss: 6.840481364633888e-05,test_Loss:22.925966262817383, r2_store:-0.366376790117495\n",
            "Epoch [9147/10000], train_Loss: 6.84672049828805e-05,test_Loss:22.932300567626953, r2_store:-0.3666269445087169\n",
            "Epoch [9148/10000], train_Loss: 6.882332672830671e-05,test_Loss:22.928264617919922, r2_store:-0.36624122141611526\n",
            "Epoch [9149/10000], train_Loss: 6.919769657542929e-05,test_Loss:22.933958053588867, r2_store:-0.3666626329589897\n",
            "Epoch [9150/10000], train_Loss: 6.973173731239513e-05,test_Loss:22.928434371948242, r2_store:-0.3661461972754798\n",
            "Epoch [9151/10000], train_Loss: 7.003482460277155e-05,test_Loss:22.93410873413086, r2_store:-0.36669536046409723\n",
            "Epoch [9152/10000], train_Loss: 7.021816418273374e-05,test_Loss:22.925487518310547, r2_store:-0.3660680977703117\n",
            "Epoch [9153/10000], train_Loss: 7.046364771667868e-05,test_Loss:22.936372756958008, r2_store:-0.3666662753413139\n",
            "Epoch [9154/10000], train_Loss: 7.039635966066271e-05,test_Loss:22.92822265625, r2_store:-0.36595981922403054\n",
            "Epoch [9155/10000], train_Loss: 6.991607369855046e-05,test_Loss:22.939783096313477, r2_store:-0.3665621078767636\n",
            "Epoch [9156/10000], train_Loss: 6.974281859584153e-05,test_Loss:22.93345832824707, r2_store:-0.3658751697311262\n",
            "Epoch [9157/10000], train_Loss: 6.964344356674701e-05,test_Loss:22.94131851196289, r2_store:-0.36653090462868976\n",
            "Epoch [9158/10000], train_Loss: 6.93297479301691e-05,test_Loss:22.933242797851562, r2_store:-0.3658635228885665\n",
            "Epoch [9159/10000], train_Loss: 6.909627700224519e-05,test_Loss:22.941659927368164, r2_store:-0.3665647812797277\n",
            "Epoch [9160/10000], train_Loss: 6.906779890414327e-05,test_Loss:22.93142318725586, r2_store:-0.36582755618195417\n",
            "Epoch [9161/10000], train_Loss: 6.913780089234933e-05,test_Loss:22.942663192749023, r2_store:-0.36655434264213005\n",
            "Epoch [9162/10000], train_Loss: 6.939251034054905e-05,test_Loss:22.93210220336914, r2_store:-0.365744295983935\n",
            "Epoch [9163/10000], train_Loss: 6.982225750107318e-05,test_Loss:22.943439483642578, r2_store:-0.36654613881807063\n",
            "Epoch [9164/10000], train_Loss: 7.05103884683922e-05,test_Loss:22.93291664123535, r2_store:-0.3656646226824014\n",
            "Epoch [9165/10000], train_Loss: 7.128527795430273e-05,test_Loss:22.94464111328125, r2_store:-0.3665745234047999\n",
            "Epoch [9166/10000], train_Loss: 7.252958312164992e-05,test_Loss:22.933237075805664, r2_store:-0.3655698754484713\n",
            "Epoch [9167/10000], train_Loss: 7.400605682050809e-05,test_Loss:22.947444915771484, r2_store:-0.36659395660582894\n",
            "Epoch [9168/10000], train_Loss: 7.59978502173908e-05,test_Loss:22.93364715576172, r2_store:-0.3654094044120131\n",
            "Epoch [9169/10000], train_Loss: 7.868882676120847e-05,test_Loss:22.949913024902344, r2_store:-0.36663850876195303\n",
            "Epoch [9170/10000], train_Loss: 8.262766641564667e-05,test_Loss:22.932411193847656, r2_store:-0.36524085821152297\n",
            "Epoch [9171/10000], train_Loss: 8.779297058936208e-05,test_Loss:22.95212745666504, r2_store:-0.36678158701913777\n",
            "Epoch [9172/10000], train_Loss: 9.478470019530505e-05,test_Loss:22.930145263671875, r2_store:-0.36506080308432254\n",
            "Epoch [9173/10000], train_Loss: 0.00010418676538392901,test_Loss:22.954442977905273, r2_store:-0.36700368360729585\n",
            "Epoch [9174/10000], train_Loss: 0.00011677345173666254,test_Loss:22.927886962890625, r2_store:-0.3647898051855121\n",
            "Epoch [9175/10000], train_Loss: 0.00013338560529518872,test_Loss:22.95998191833496, r2_store:-0.3672671121347768\n",
            "Epoch [9176/10000], train_Loss: 0.00015634619921911508,test_Loss:22.926036834716797, r2_store:-0.36437354134734745\n",
            "Epoch [9177/10000], train_Loss: 0.0001873529690783471,test_Loss:22.967849731445312, r2_store:-0.36764983661897577\n",
            "Epoch [9178/10000], train_Loss: 0.00022913483553566039,test_Loss:22.91936683654785, r2_store:-0.36385431642594424\n",
            "Epoch [9179/10000], train_Loss: 0.0002867777366191149,test_Loss:22.97365951538086, r2_store:-0.3682513621460404\n",
            "Epoch [9180/10000], train_Loss: 0.0003677841741591692,test_Loss:22.91187286376953, r2_store:-0.36315314436088086\n",
            "Epoch [9181/10000], train_Loss: 0.000482069153804332,test_Loss:22.98336410522461, r2_store:-0.36915810913684743\n",
            "Epoch [9182/10000], train_Loss: 0.0006453805253840983,test_Loss:22.903064727783203, r2_store:-0.3620978178901024\n",
            "Epoch [9183/10000], train_Loss: 0.0008778313058428466,test_Loss:23.00295066833496, r2_store:-0.3704369718608149\n",
            "Epoch [9184/10000], train_Loss: 0.0012125289067626,test_Loss:22.87966537475586, r2_store:-0.36046185656224305\n",
            "Epoch [9185/10000], train_Loss: 0.0016993414610624313,test_Loss:23.03017807006836, r2_store:-0.3724290623113633\n",
            "Epoch [9186/10000], train_Loss: 0.0024031526409089565,test_Loss:22.853832244873047, r2_store:-0.358181928059186\n",
            "Epoch [9187/10000], train_Loss: 0.0034413631074130535,test_Loss:23.057212829589844, r2_store:-0.3753374745698175\n",
            "Epoch [9188/10000], train_Loss: 0.004947352688759565,test_Loss:22.82809066772461, r2_store:-0.354906872927506\n",
            "Epoch [9189/10000], train_Loss: 0.007174762897193432,test_Loss:23.122175216674805, r2_store:-0.37988888876801297\n",
            "Epoch [9190/10000], train_Loss: 0.010390421375632286,test_Loss:22.750219345092773, r2_store:-0.35024197730687234\n",
            "Epoch [9191/10000], train_Loss: 0.015115775167942047,test_Loss:23.211505889892578, r2_store:-0.3870305347109986\n",
            "Epoch [9192/10000], train_Loss: 0.021653752774000168,test_Loss:22.679122924804688, r2_store:-0.34448087310105646\n",
            "Epoch [9193/10000], train_Loss: 0.030793447047472,test_Loss:23.306591033935547, r2_store:-0.3964499500718006\n",
            "Epoch [9194/10000], train_Loss: 0.042273517698049545,test_Loss:22.615293502807617, r2_store:-0.3382010690766395\n",
            "Epoch [9195/10000], train_Loss: 0.056588031351566315,test_Loss:23.42869758605957, r2_store:-0.4064593619145478\n",
            "Epoch [9196/10000], train_Loss: 0.06996689736843109,test_Loss:22.55027961730957, r2_store:-0.3336138118347687\n",
            "Epoch [9197/10000], train_Loss: 0.08081984519958496,test_Loss:23.491519927978516, r2_store:-0.40932971335820034\n",
            "Epoch [9198/10000], train_Loss: 0.08004292100667953,test_Loss:22.628110885620117, r2_store:-0.3363177254873446\n",
            "Epoch [9199/10000], train_Loss: 0.06759513169527054,test_Loss:23.295995712280273, r2_store:-0.3967138145116147\n",
            "Epoch [9200/10000], train_Loss: 0.04256382957100868,test_Loss:22.767261505126953, r2_store:-0.35097507225182967\n",
            "Epoch [9201/10000], train_Loss: 0.01700042374432087,test_Loss:23.057849884033203, r2_store:-0.3723507242287154\n",
            "Epoch [9202/10000], train_Loss: 0.00201366376131773,test_Loss:23.016538619995117, r2_store:-0.37273528533098266\n",
            "Epoch [9203/10000], train_Loss: 0.0027582200709730387,test_Loss:22.81246566772461, r2_store:-0.35178144952928636\n",
            "Epoch [9204/10000], train_Loss: 0.014276484027504921,test_Loss:23.30768585205078, r2_store:-0.38957809119383535\n",
            "Epoch [9205/10000], train_Loss: 0.026057731360197067,test_Loss:22.70307731628418, r2_store:-0.3457824488178347\n",
            "Epoch [9206/10000], train_Loss: 0.0293923020362854,test_Loss:23.26706314086914, r2_store:-0.3875201815734992\n",
            "Epoch [9207/10000], train_Loss: 0.02159978076815605,test_Loss:22.89751625061035, r2_store:-0.3549312707384302\n",
            "Epoch [9208/10000], train_Loss: 0.009680492803454399,test_Loss:23.013696670532227, r2_store:-0.37070713245351317\n",
            "Epoch [9209/10000], train_Loss: 0.001436353661119938,test_Loss:23.04220199584961, r2_store:-0.37063151532872807\n",
            "Epoch [9210/10000], train_Loss: 0.001379714347422123,test_Loss:22.921167373657227, r2_store:-0.3554695311032676\n",
            "Epoch [9211/10000], train_Loss: 0.007410675287246704,test_Loss:23.195695877075195, r2_store:-0.380887706615195\n",
            "Epoch [9212/10000], train_Loss: 0.013188784010708332,test_Loss:22.812198638916016, r2_store:-0.3502220735984589\n",
            "Epoch [9213/10000], train_Loss: 0.0143257025629282,test_Loss:23.21521759033203, r2_store:-0.37916512365269783\n",
            "Epoch [9214/10000], train_Loss: 0.010153532028198242,test_Loss:22.894895553588867, r2_store:-0.35757709482398026\n",
            "Epoch [9215/10000], train_Loss: 0.004165276885032654,test_Loss:22.978939056396484, r2_store:-0.3679825949751785\n",
            "Epoch [9216/10000], train_Loss: 0.0006226621335372329,test_Loss:23.049650192260742, r2_store:-0.37008921906687764\n",
            "Epoch [9217/10000], train_Loss: 0.0010356713319197297,test_Loss:22.891630172729492, r2_store:-0.35873899414713795\n",
            "Epoch [9218/10000], train_Loss: 0.004069442395120859,test_Loss:23.071788787841797, r2_store:-0.37767207448043316\n",
            "Epoch [9219/10000], train_Loss: 0.006799524184316397,test_Loss:22.846803665161133, r2_store:-0.3565353846316519\n",
            "Epoch [9220/10000], train_Loss: 0.0070127807557582855,test_Loss:23.105331420898438, r2_store:-0.37668937553383985\n",
            "Epoch [9221/10000], train_Loss: 0.004856803920120001,test_Loss:22.878719329833984, r2_store:-0.3618478713476059\n",
            "Epoch [9222/10000], train_Loss: 0.0019991188310086727,test_Loss:22.972599029541016, r2_store:-0.36899062849740605\n",
            "Epoch [9223/10000], train_Loss: 0.0003209445276297629,test_Loss:23.018068313598633, r2_store:-0.37041613153619557\n",
            "Epoch [9224/10000], train_Loss: 0.0006135856965556741,test_Loss:22.88666343688965, r2_store:-0.3618416365040611\n",
            "Epoch [9225/10000], train_Loss: 0.002046796726062894,test_Loss:23.037084579467773, r2_store:-0.37490081468793957\n",
            "Epoch [9226/10000], train_Loss: 0.003366063814610243,test_Loss:22.878637313842773, r2_store:-0.35989465747815785\n",
            "Epoch [9227/10000], train_Loss: 0.0035930094309151173,test_Loss:23.023509979248047, r2_store:-0.37424133022788153\n",
            "Epoch [9228/10000], train_Loss: 0.00263784802518785,test_Loss:22.853498458862305, r2_store:-0.3631766137820056\n",
            "Epoch [9229/10000], train_Loss: 0.0012956105638295412,test_Loss:22.949935913085938, r2_store:-0.3696832350452155\n",
            "Epoch [9230/10000], train_Loss: 0.0003294369380455464,test_Loss:22.934513092041016, r2_store:-0.36921139083306675\n",
            "Epoch [9231/10000], train_Loss: 0.00022601238742936403,test_Loss:22.849212646484375, r2_store:-0.3647173417891991\n",
            "Epoch [9232/10000], train_Loss: 0.0008101568673737347,test_Loss:22.972553253173828, r2_store:-0.37315051630132734\n",
            "Epoch [9233/10000], train_Loss: 0.0014932830817997456,test_Loss:22.868715286254883, r2_store:-0.36274172100074353\n",
            "Epoch [9234/10000], train_Loss: 0.0018364855786785483,test_Loss:22.97606658935547, r2_store:-0.37291281307237\n",
            "Epoch [9235/10000], train_Loss: 0.0016159607330337167,test_Loss:22.88077163696289, r2_store:-0.3637610255511168\n",
            "Epoch [9236/10000], train_Loss: 0.001023729331791401,test_Loss:22.975547790527344, r2_store:-0.370129193857496\n",
            "Epoch [9237/10000], train_Loss: 0.0004506279365159571,test_Loss:22.91918182373047, r2_store:-0.3671641791090816\n",
            "Epoch [9238/10000], train_Loss: 0.00014405303227249533,test_Loss:22.90473747253418, r2_store:-0.36644426310301936\n",
            "Epoch [9239/10000], train_Loss: 0.0002162861346732825,test_Loss:22.969345092773438, r2_store:-0.3704606146945686\n",
            "Epoch [9240/10000], train_Loss: 0.0005145514151081443,test_Loss:22.882064819335938, r2_store:-0.3642928462983961\n",
            "Epoch [9241/10000], train_Loss: 0.0007963425596244633,test_Loss:22.952259063720703, r2_store:-0.3713279543231369\n",
            "Epoch [9242/10000], train_Loss: 0.0009137741290032864,test_Loss:22.881874084472656, r2_store:-0.36415844036085976\n",
            "Epoch [9243/10000], train_Loss: 0.0007961447117850184,test_Loss:22.9552001953125, r2_store:-0.3703167307221198\n",
            "Epoch [9244/10000], train_Loss: 0.0005414748447947204,test_Loss:22.886432647705078, r2_store:-0.3657803931709709\n",
            "Epoch [9245/10000], train_Loss: 0.00028547021793201566,test_Loss:22.922821044921875, r2_store:-0.3682606903604766\n",
            "Epoch [9246/10000], train_Loss: 0.0001296677510254085,test_Loss:22.929183959960938, r2_store:-0.36837576616506595\n",
            "Epoch [9247/10000], train_Loss: 0.00012652853911276907,test_Loss:22.89410400390625, r2_store:-0.36639463362264957\n",
            "Epoch [9248/10000], train_Loss: 0.00022763281594961882,test_Loss:22.94171905517578, r2_store:-0.3700072497429703\n",
            "Epoch [9249/10000], train_Loss: 0.00035697719431482255,test_Loss:22.89984703063965, r2_store:-0.3654694238794063\n",
            "Epoch [9250/10000], train_Loss: 0.00044438475742936134,test_Loss:22.950016021728516, r2_store:-0.3702238979659731\n",
            "Epoch [9251/10000], train_Loss: 0.00044498388888314366,test_Loss:22.894241333007812, r2_store:-0.36542044212930014\n",
            "Epoch [9252/10000], train_Loss: 0.0003741430409718305,test_Loss:22.950504302978516, r2_store:-0.3693334845944565\n",
            "Epoch [9253/10000], train_Loss: 0.0002661094185896218,test_Loss:22.909770965576172, r2_store:-0.36648017434183333\n",
            "Epoch [9254/10000], train_Loss: 0.00016402144683524966,test_Loss:22.918964385986328, r2_store:-0.3679818635203713\n",
            "Epoch [9255/10000], train_Loss: 0.00010633932834025472,test_Loss:22.92416000366211, r2_store:-0.3679148149443745\n",
            "Epoch [9256/10000], train_Loss: 9.755963401403278e-05,test_Loss:22.911113739013672, r2_store:-0.36688140336854813\n",
            "Epoch [9257/10000], train_Loss: 0.0001290735963266343,test_Loss:22.929119110107422, r2_store:-0.36883687380188346\n",
            "Epoch [9258/10000], train_Loss: 0.00017769975238479674,test_Loss:22.904815673828125, r2_store:-0.366082830850351\n",
            "Epoch [9259/10000], train_Loss: 0.00021681080397684127,test_Loss:22.946413040161133, r2_store:-0.36909613519142415\n",
            "Epoch [9260/10000], train_Loss: 0.0002340057835681364,test_Loss:22.906644821166992, r2_store:-0.36579034762507057\n",
            "Epoch [9261/10000], train_Loss: 0.000223575159907341,test_Loss:22.94661521911621, r2_store:-0.368638065490523\n",
            "Epoch [9262/10000], train_Loss: 0.00019162888929713517,test_Loss:22.923274993896484, r2_store:-0.3661557340617152\n",
            "Epoch [9263/10000], train_Loss: 0.00015235019964165986,test_Loss:22.93916893005371, r2_store:-0.36794824736161735\n",
            "Epoch [9264/10000], train_Loss: 0.00011544481094460934,test_Loss:22.92502212524414, r2_store:-0.36682370625639504\n",
            "Epoch [9265/10000], train_Loss: 9.087324724532664e-05,test_Loss:22.93389129638672, r2_store:-0.3673050760710992\n",
            "Epoch [9266/10000], train_Loss: 8.147837070282549e-05,test_Loss:22.9329776763916, r2_store:-0.3675584175260225\n",
            "Epoch [9267/10000], train_Loss: 8.450302993878722e-05,test_Loss:22.921173095703125, r2_store:-0.36670463003423603\n",
            "Epoch [9268/10000], train_Loss: 9.667190897744149e-05,test_Loss:22.941740036010742, r2_store:-0.3680619097422382\n",
            "Epoch [9269/10000], train_Loss: 0.00011087034363299608,test_Loss:22.922283172607422, r2_store:-0.3663539578382342\n",
            "Epoch [9270/10000], train_Loss: 0.00012186569074401632,test_Loss:22.943965911865234, r2_store:-0.368141497105529\n",
            "Epoch [9271/10000], train_Loss: 0.0001274234673473984,test_Loss:22.92680549621582, r2_store:-0.3662272644975475\n",
            "Epoch [9272/10000], train_Loss: 0.00012565290671773255,test_Loss:22.94853973388672, r2_store:-0.36802381836084663\n",
            "Epoch [9273/10000], train_Loss: 0.00011802239896496758,test_Loss:22.927146911621094, r2_store:-0.36632114903199287\n",
            "Epoch [9274/10000], train_Loss: 0.00010721887520048767,test_Loss:22.94615364074707, r2_store:-0.36770377808589383\n",
            "Epoch [9275/10000], train_Loss: 9.489552758168429e-05,test_Loss:22.93418312072754, r2_store:-0.3665879754331125\n",
            "Epoch [9276/10000], train_Loss: 8.387074922211468e-05,test_Loss:22.94024658203125, r2_store:-0.3673025233221223\n",
            "Epoch [9277/10000], train_Loss: 7.606913277413696e-05,test_Loss:22.93805503845215, r2_store:-0.36692079034861624\n",
            "Epoch [9278/10000], train_Loss: 7.138762157410383e-05,test_Loss:22.938566207885742, r2_store:-0.3670236881007487\n",
            "Epoch [9279/10000], train_Loss: 7.000404002610594e-05,test_Loss:22.938316345214844, r2_store:-0.3672800939569034\n",
            "Epoch [9280/10000], train_Loss: 7.120089867385104e-05,test_Loss:22.934762954711914, r2_store:-0.366843928335028\n",
            "Epoch [9281/10000], train_Loss: 7.380390889011323e-05,test_Loss:22.94156265258789, r2_store:-0.3675607669776293\n",
            "Epoch [9282/10000], train_Loss: 7.700664718868211e-05,test_Loss:22.928760528564453, r2_store:-0.36664766052151876\n",
            "Epoch [9283/10000], train_Loss: 8.057588274823502e-05,test_Loss:22.945781707763672, r2_store:-0.3676384500628327\n",
            "Epoch [9284/10000], train_Loss: 8.307612733915448e-05,test_Loss:22.931373596191406, r2_store:-0.3664462278515588\n",
            "Epoch [9285/10000], train_Loss: 8.437116775894538e-05,test_Loss:22.946659088134766, r2_store:-0.3675409261085878\n",
            "Epoch [9286/10000], train_Loss: 8.51120421430096e-05,test_Loss:22.933542251586914, r2_store:-0.3663407911246357\n",
            "Epoch [9287/10000], train_Loss: 8.455094939563423e-05,test_Loss:22.946910858154297, r2_store:-0.367488910628206\n",
            "Epoch [9288/10000], train_Loss: 8.291220729006454e-05,test_Loss:22.931333541870117, r2_store:-0.3663826317234\n",
            "Epoch [9289/10000], train_Loss: 8.084993169177324e-05,test_Loss:22.945926666259766, r2_store:-0.3674638192464723\n",
            "Epoch [9290/10000], train_Loss: 7.833469135221094e-05,test_Loss:22.932016372680664, r2_store:-0.3664772954408031\n",
            "Epoch [9291/10000], train_Loss: 7.58884270908311e-05,test_Loss:22.944313049316406, r2_store:-0.3673591425034326\n",
            "Epoch [9292/10000], train_Loss: 7.330144580919296e-05,test_Loss:22.936452865600586, r2_store:-0.3664956296526303\n",
            "Epoch [9293/10000], train_Loss: 7.080288924043998e-05,test_Loss:22.94790267944336, r2_store:-0.36718478979627656\n",
            "Epoch [9294/10000], train_Loss: 6.873249367345124e-05,test_Loss:22.941082000732422, r2_store:-0.36648628835329555\n",
            "Epoch [9295/10000], train_Loss: 6.699325604131445e-05,test_Loss:22.948999404907227, r2_store:-0.36707759328938105\n",
            "Epoch [9296/10000], train_Loss: 6.550465332111344e-05,test_Loss:22.941883087158203, r2_store:-0.36653505631791905\n",
            "Epoch [9297/10000], train_Loss: 6.412148650269955e-05,test_Loss:22.947925567626953, r2_store:-0.3670264699620285\n",
            "Epoch [9298/10000], train_Loss: 6.33167292107828e-05,test_Loss:22.942670822143555, r2_store:-0.36655163447417327\n",
            "Epoch [9299/10000], train_Loss: 6.240855873329565e-05,test_Loss:22.94877815246582, r2_store:-0.36693877601057356\n",
            "Epoch [9300/10000], train_Loss: 6.143563950899988e-05,test_Loss:22.94475746154785, r2_store:-0.3665242713028518\n",
            "Epoch [9301/10000], train_Loss: 6.079638842493296e-05,test_Loss:22.949766159057617, r2_store:-0.36686855134663343\n",
            "Epoch [9302/10000], train_Loss: 6.0217174905119464e-05,test_Loss:22.945852279663086, r2_store:-0.3665014554998065\n",
            "Epoch [9303/10000], train_Loss: 5.979640263831243e-05,test_Loss:22.9505558013916, r2_store:-0.3668464016895776\n",
            "Epoch [9304/10000], train_Loss: 5.9438276366563514e-05,test_Loss:22.94640350341797, r2_store:-0.3664541909298986\n",
            "Epoch [9305/10000], train_Loss: 5.936108573223464e-05,test_Loss:22.95189666748047, r2_store:-0.3668328711616913\n",
            "Epoch [9306/10000], train_Loss: 5.936081288382411e-05,test_Loss:22.946718215942383, r2_store:-0.36638864323035825\n",
            "Epoch [9307/10000], train_Loss: 5.94664306845516e-05,test_Loss:22.953601837158203, r2_store:-0.3668615674203861\n",
            "Epoch [9308/10000], train_Loss: 5.980412970529869e-05,test_Loss:22.945446014404297, r2_store:-0.3663075560302693\n",
            "Epoch [9309/10000], train_Loss: 6.0585713072214276e-05,test_Loss:22.955028533935547, r2_store:-0.3669177053508663\n",
            "Epoch [9310/10000], train_Loss: 6.170089909574017e-05,test_Loss:22.946529388427734, r2_store:-0.3661836482984089\n",
            "Epoch [9311/10000], train_Loss: 6.326533912215382e-05,test_Loss:22.956880569458008, r2_store:-0.3669700513820391\n",
            "Epoch [9312/10000], train_Loss: 6.592665158677846e-05,test_Loss:22.946992874145508, r2_store:-0.3660079150259785\n",
            "Epoch [9313/10000], train_Loss: 6.949432281544432e-05,test_Loss:22.96003532409668, r2_store:-0.36711524537594253\n",
            "Epoch [9314/10000], train_Loss: 7.47239391785115e-05,test_Loss:22.942541122436523, r2_store:-0.3658021855672662\n",
            "Epoch [9315/10000], train_Loss: 8.19284759927541e-05,test_Loss:22.963459014892578, r2_store:-0.3673362435390448\n",
            "Epoch [9316/10000], train_Loss: 9.159294131677598e-05,test_Loss:22.94091033935547, r2_store:-0.36553754983275755\n",
            "Epoch [9317/10000], train_Loss: 0.00010543442476773635,test_Loss:22.96656608581543, r2_store:-0.3676133143013083\n",
            "Epoch [9318/10000], train_Loss: 0.0001254015660379082,test_Loss:22.93859100341797, r2_store:-0.36512405926062086\n",
            "Epoch [9319/10000], train_Loss: 0.00015391831402666867,test_Loss:22.975337982177734, r2_store:-0.36803279993021265\n",
            "Epoch [9320/10000], train_Loss: 0.00019576090562622994,test_Loss:22.932390213012695, r2_store:-0.36448441983640123\n",
            "Epoch [9321/10000], train_Loss: 0.0002569903736002743,test_Loss:22.984722137451172, r2_store:-0.3686801170972507\n",
            "Epoch [9322/10000], train_Loss: 0.00034715450601652265,test_Loss:22.92194175720215, r2_store:-0.36362374581063617\n",
            "Epoch [9323/10000], train_Loss: 0.0004804253112524748,test_Loss:22.99390983581543, r2_store:-0.3697221987064254\n",
            "Epoch [9324/10000], train_Loss: 0.0006790605839341879,test_Loss:22.910911560058594, r2_store:-0.3623775937649143\n",
            "Epoch [9325/10000], train_Loss: 0.0009731216123327613,test_Loss:23.01726722717285, r2_store:-0.3713840559702444\n",
            "Epoch [9326/10000], train_Loss: 0.0014136774698272347,test_Loss:22.879499435424805, r2_store:-0.36048792270676544\n",
            "Epoch [9327/10000], train_Loss: 0.002078090328723192,test_Loss:23.047882080078125, r2_store:-0.37397563867436845\n",
            "Epoch [9328/10000], train_Loss: 0.0030751442536711693,test_Loss:22.84792709350586, r2_store:-0.3576338332630098\n",
            "Epoch [9329/10000], train_Loss: 0.004591017030179501,test_Loss:23.087804794311523, r2_store:-0.3776718823669247\n",
            "Epoch [9330/10000], train_Loss: 0.006854206323623657,test_Loss:22.813541412353516, r2_store:-0.3533648400388343\n",
            "Epoch [9331/10000], train_Loss: 0.010294459760189056,test_Loss:23.175031661987305, r2_store:-0.3836042355154978\n",
            "Epoch [9332/10000], train_Loss: 0.015371322631835938,test_Loss:22.722288131713867, r2_store:-0.34737984932574784\n",
            "Epoch [9333/10000], train_Loss: 0.02299153432250023,test_Loss:23.296489715576172, r2_store:-0.3931244514425809\n",
            "Epoch [9334/10000], train_Loss: 0.03346795588731766,test_Loss:22.661319732666016, r2_store:-0.34058417144939046\n",
            "Epoch [9335/10000], train_Loss: 0.04776923730969429,test_Loss:23.390119552612305, r2_store:-0.4047528237954683\n",
            "Epoch [9336/10000], train_Loss: 0.06443963944911957,test_Loss:22.570354461669922, r2_store:-0.3340063120667369\n",
            "Epoch [9337/10000], train_Loss: 0.08286119997501373,test_Loss:23.531658172607422, r2_store:-0.41474018231456466\n",
            "Epoch [9338/10000], train_Loss: 0.09438119828701019,test_Loss:22.52096176147461, r2_store:-0.33250018056739394\n",
            "Epoch [9339/10000], train_Loss: 0.09537795931100845,test_Loss:23.44316864013672, r2_store:-0.40955951262224954\n",
            "Epoch [9340/10000], train_Loss: 0.07543700933456421,test_Loss:22.655521392822266, r2_store:-0.34342986470790593\n",
            "Epoch [9341/10000], train_Loss: 0.04379286244511604,test_Loss:23.110408782958984, r2_store:-0.3840049580385081\n",
            "Epoch [9342/10000], train_Loss: 0.013275986537337303,test_Loss:22.920490264892578, r2_store:-0.36653001797011564\n",
            "Epoch [9343/10000], train_Loss: 0.0005410242592915893,test_Loss:22.850717544555664, r2_store:-0.35595938484154743\n",
            "Epoch [9344/10000], train_Loss: 0.008219624869525433,test_Loss:23.25069808959961, r2_store:-0.38904538849614534\n",
            "Epoch [9345/10000], train_Loss: 0.02529294416308403,test_Loss:22.724990844726562, r2_store:-0.34371443125945467\n",
            "Epoch [9346/10000], train_Loss: 0.03676348179578781,test_Loss:23.318201065063477, r2_store:-0.392601466706163\n",
            "Epoch [9347/10000], train_Loss: 0.03281940892338753,test_Loss:22.781492233276367, r2_store:-0.3505109216872837\n",
            "Epoch [9348/10000], train_Loss: 0.018008340150117874,test_Loss:23.09687042236328, r2_store:-0.37523304106616795\n",
            "Epoch [9349/10000], train_Loss: 0.003996508661657572,test_Loss:22.99614143371582, r2_store:-0.3693087993276578\n",
            "Epoch [9350/10000], train_Loss: 0.0007977491477504373,test_Loss:22.825672149658203, r2_store:-0.3553218056147174\n",
            "Epoch [9351/10000], train_Loss: 0.007854089140892029,test_Loss:23.194488525390625, r2_store:-0.38366229220186177\n",
            "Epoch [9352/10000], train_Loss: 0.016524124890565872,test_Loss:22.76095199584961, r2_store:-0.3489220528316008\n",
            "Epoch [9353/10000], train_Loss: 0.018642883747816086,test_Loss:23.136615753173828, r2_store:-0.38096923783120773\n",
            "Epoch [9354/10000], train_Loss: 0.012683888897299767,test_Loss:22.855077743530273, r2_store:-0.357634696125124\n",
            "Epoch [9355/10000], train_Loss: 0.004445880185812712,test_Loss:22.973094940185547, r2_store:-0.3669067701383637\n",
            "Epoch [9356/10000], train_Loss: 0.00039199687307700515,test_Loss:23.03082847595215, r2_store:-0.372279830494916\n",
            "Epoch [9357/10000], train_Loss: 0.0024864324368536472,test_Loss:22.83761215209961, r2_store:-0.35548256381098065\n",
            "Epoch [9358/10000], train_Loss: 0.007311376743018627,test_Loss:23.15145492553711, r2_store:-0.37992219231265545\n",
            "Epoch [9359/10000], train_Loss: 0.009879125282168388,test_Loss:22.82356071472168, r2_store:-0.35535297193201876\n",
            "Epoch [9360/10000], train_Loss: 0.008159998804330826,test_Loss:23.050756454467773, r2_store:-0.37511322630042665\n",
            "Epoch [9361/10000], train_Loss: 0.0038552500773221254,test_Loss:22.921142578125, r2_store:-0.36470817359484453\n",
            "Epoch [9362/10000], train_Loss: 0.000667999847792089,test_Loss:22.912029266357422, r2_store:-0.36494374577234856\n",
            "Epoch [9363/10000], train_Loss: 0.0006510715465992689,test_Loss:23.020931243896484, r2_store:-0.3747677675106411\n",
            "Epoch [9364/10000], train_Loss: 0.0029347874224185944,test_Loss:22.83112144470215, r2_store:-0.35903460841829227\n",
            "Epoch [9365/10000], train_Loss: 0.005033000372350216,test_Loss:23.055683135986328, r2_store:-0.3776730767092198\n",
            "Epoch [9366/10000], train_Loss: 0.005100448615849018,test_Loss:22.843589782714844, r2_store:-0.3610496842357527\n",
            "Epoch [9367/10000], train_Loss: 0.0032888378482311964,test_Loss:22.975982666015625, r2_store:-0.37256280528109675\n",
            "Epoch [9368/10000], train_Loss: 0.0011382796801626682,test_Loss:22.92030143737793, r2_store:-0.36837133782143416\n",
            "Epoch [9369/10000], train_Loss: 0.0001989951852010563,test_Loss:22.875118255615234, r2_store:-0.36535788270535585\n",
            "Epoch [9370/10000], train_Loss: 0.0007876772433519363,test_Loss:22.984012603759766, r2_store:-0.3743163096677391\n",
            "Epoch [9371/10000], train_Loss: 0.0020417512860149145,test_Loss:22.834117889404297, r2_store:-0.3616071177535154\n",
            "Epoch [9372/10000], train_Loss: 0.0027960482984781265,test_Loss:22.991886138916016, r2_store:-0.3745807965696115\n",
            "Epoch [9373/10000], train_Loss: 0.002465631812810898,test_Loss:22.852169036865234, r2_store:-0.36319168433398663\n",
            "Epoch [9374/10000], train_Loss: 0.0014250519452616572,test_Loss:22.94426155090332, r2_store:-0.37013312375455\n",
            "Epoch [9375/10000], train_Loss: 0.0004567719588521868,test_Loss:22.920093536376953, r2_store:-0.36819900031664554\n",
            "Epoch [9376/10000], train_Loss: 0.00015583277854602784,test_Loss:22.87860679626465, r2_store:-0.36543310348324853\n",
            "Epoch [9377/10000], train_Loss: 0.000536399835254997,test_Loss:22.964149475097656, r2_store:-0.37260004565594795\n",
            "Epoch [9378/10000], train_Loss: 0.001144896843470633,test_Loss:22.852169036865234, r2_store:-0.3637293946908189\n",
            "Epoch [9379/10000], train_Loss: 0.0014759991317987442,test_Loss:22.960674285888672, r2_store:-0.3732419773746045\n",
            "Epoch [9380/10000], train_Loss: 0.0013099726056680083,test_Loss:22.862966537475586, r2_store:-0.3651709632403961\n",
            "Epoch [9381/10000], train_Loss: 0.0008111164206638932,test_Loss:22.92890739440918, r2_store:-0.3703828232519848\n",
            "Epoch [9382/10000], train_Loss: 0.0003251386806368828,test_Loss:22.903593063354492, r2_store:-0.36819549150157327\n",
            "Epoch [9383/10000], train_Loss: 0.0001261377619812265,test_Loss:22.88698959350586, r2_store:-0.36660707856132024\n",
            "Epoch [9384/10000], train_Loss: 0.0002531225618440658,test_Loss:22.941343307495117, r2_store:-0.37080182633126646\n",
            "Epoch [9385/10000], train_Loss: 0.0005352382431738079,test_Loss:22.8663272857666, r2_store:-0.3648016378046839\n",
            "Epoch [9386/10000], train_Loss: 0.0007454353617504239,test_Loss:22.94142723083496, r2_store:-0.37158841098064577\n",
            "Epoch [9387/10000], train_Loss: 0.0007481700740754604,test_Loss:22.869644165039062, r2_store:-0.3655916520349023\n",
            "Epoch [9388/10000], train_Loss: 0.0005634977715089917,test_Loss:22.92251968383789, r2_store:-0.37042398728186665\n",
            "Epoch [9389/10000], train_Loss: 0.0003156338934786618,test_Loss:22.88711166381836, r2_store:-0.3677918358033516\n",
            "Epoch [9390/10000], train_Loss: 0.0001435324811609462,test_Loss:22.894853591918945, r2_store:-0.368225782535504\n",
            "Epoch [9391/10000], train_Loss: 0.00011501356493681669,test_Loss:22.91551399230957, r2_store:-0.36990042050951577\n",
            "Epoch [9392/10000], train_Loss: 0.000206463853828609,test_Loss:22.873350143432617, r2_store:-0.3665153091298483\n",
            "Epoch [9393/10000], train_Loss: 0.0003330059989821166,test_Loss:22.926483154296875, r2_store:-0.37088715736627775\n",
            "Epoch [9394/10000], train_Loss: 0.00040972843999043107,test_Loss:22.871814727783203, r2_store:-0.3662770258688586\n",
            "Epoch [9395/10000], train_Loss: 0.00039776600897312164,test_Loss:22.91983413696289, r2_store:-0.3705122156041112\n",
            "Epoch [9396/10000], train_Loss: 0.00031141843646764755,test_Loss:22.883153915405273, r2_store:-0.3672094659789218\n",
            "Epoch [9397/10000], train_Loss: 0.00020117088570259511,test_Loss:22.909961700439453, r2_store:-0.36919500113213544\n",
            "Epoch [9398/10000], train_Loss: 0.00011912336049135774,test_Loss:22.903202056884766, r2_store:-0.36852347138774677\n",
            "Epoch [9399/10000], train_Loss: 9.363566641695797e-05,test_Loss:22.896957397460938, r2_store:-0.36766142295442195\n",
            "Epoch [9400/10000], train_Loss: 0.00012061847519362345,test_Loss:22.92201042175293, r2_store:-0.3695195773197679\n",
            "Epoch [9401/10000], train_Loss: 0.0001718970452202484,test_Loss:22.88442039489746, r2_store:-0.36676457110050253\n",
            "Epoch [9402/10000], train_Loss: 0.00021496706176549196,test_Loss:22.922792434692383, r2_store:-0.36985169356577896\n",
            "Epoch [9403/10000], train_Loss: 0.00022757225087843835,test_Loss:22.88607406616211, r2_store:-0.36682158951574806\n",
            "Epoch [9404/10000], train_Loss: 0.00020789024711120874,test_Loss:22.91360855102539, r2_store:-0.3694466555328828\n",
            "Epoch [9405/10000], train_Loss: 0.0001668126496952027,test_Loss:22.895118713378906, r2_store:-0.3674338707793312\n",
            "Epoch [9406/10000], train_Loss: 0.00012202719517517835,test_Loss:22.915420532226562, r2_store:-0.3686196693752415\n",
            "Epoch [9407/10000], train_Loss: 9.163500362774357e-05,test_Loss:22.910444259643555, r2_store:-0.36824899974352676\n",
            "Epoch [9408/10000], train_Loss: 8.306412200909108e-05,test_Loss:22.91233253479004, r2_store:-0.3678166112894008\n",
            "Epoch [9409/10000], train_Loss: 9.242965461453423e-05,test_Loss:22.928316116333008, r2_store:-0.369048161958889\n",
            "Epoch [9410/10000], train_Loss: 0.00011138369154650718,test_Loss:22.903491973876953, r2_store:-0.36739455914705044\n",
            "Epoch [9411/10000], train_Loss: 0.00012947985669597983,test_Loss:22.932178497314453, r2_store:-0.36941943465076865\n",
            "Epoch [9412/10000], train_Loss: 0.00013794255210086703,test_Loss:22.90540885925293, r2_store:-0.3673571229871453\n",
            "Epoch [9413/10000], train_Loss: 0.00013447468518279493,test_Loss:22.926971435546875, r2_store:-0.3692092063182748\n",
            "Epoch [9414/10000], train_Loss: 0.00012238604540470988,test_Loss:22.912982940673828, r2_store:-0.3675812926826756\n",
            "Epoch [9415/10000], train_Loss: 0.00010615455539664254,test_Loss:22.924297332763672, r2_store:-0.3687430263108531\n",
            "Epoch [9416/10000], train_Loss: 8.949432231020182e-05,test_Loss:22.91707992553711, r2_store:-0.3679658844133298\n",
            "Epoch [9417/10000], train_Loss: 7.830395043129101e-05,test_Loss:22.924266815185547, r2_store:-0.3682145153178209\n",
            "Epoch [9418/10000], train_Loss: 7.439118780894205e-05,test_Loss:22.924869537353516, r2_store:-0.36842527995235486\n",
            "Epoch [9419/10000], train_Loss: 7.62585987104103e-05,test_Loss:22.916950225830078, r2_store:-0.3678098460365704\n",
            "Epoch [9420/10000], train_Loss: 8.21235153125599e-05,test_Loss:22.93203353881836, r2_store:-0.3687968047206891\n",
            "Epoch [9421/10000], train_Loss: 8.874848572304472e-05,test_Loss:22.912952423095703, r2_store:-0.3676199396345392\n",
            "Epoch [9422/10000], train_Loss: 9.296504140365869e-05,test_Loss:22.930692672729492, r2_store:-0.3688688245721303\n",
            "Epoch [9423/10000], train_Loss: 9.405594028066844e-05,test_Loss:22.917619705200195, r2_store:-0.36759398046516867\n",
            "Epoch [9424/10000], train_Loss: 9.224687528330833e-05,test_Loss:22.929561614990234, r2_store:-0.36875795187245264\n",
            "Epoch [9425/10000], train_Loss: 8.790155698079616e-05,test_Loss:22.91652488708496, r2_store:-0.3676821067662921\n",
            "Epoch [9426/10000], train_Loss: 8.225168858189136e-05,test_Loss:22.931011199951172, r2_store:-0.3685365119354356\n",
            "Epoch [9427/10000], train_Loss: 7.67381425248459e-05,test_Loss:22.921092987060547, r2_store:-0.36787364426925184\n",
            "Epoch [9428/10000], train_Loss: 7.18398077879101e-05,test_Loss:22.925968170166016, r2_store:-0.36826912212340024\n",
            "Epoch [9429/10000], train_Loss: 6.872691301396117e-05,test_Loss:22.926809310913086, r2_store:-0.3681170587327638\n",
            "Epoch [9430/10000], train_Loss: 6.716380448779091e-05,test_Loss:22.92588996887207, r2_store:-0.3680210415651002\n",
            "Epoch [9431/10000], train_Loss: 6.710052548442036e-05,test_Loss:22.930316925048828, r2_store:-0.36826228314020937\n",
            "Epoch [9432/10000], train_Loss: 6.796512025175616e-05,test_Loss:22.927133560180664, r2_store:-0.3678559641109693\n",
            "Epoch [9433/10000], train_Loss: 6.918435974512249e-05,test_Loss:22.932371139526367, r2_store:-0.3683929943516795\n",
            "Epoch [9434/10000], train_Loss: 7.0320995291695e-05,test_Loss:22.924026489257812, r2_store:-0.3677556141647651\n",
            "Epoch [9435/10000], train_Loss: 7.103699317667633e-05,test_Loss:22.93453025817871, r2_store:-0.36844886947037936\n",
            "Epoch [9436/10000], train_Loss: 7.133664621505886e-05,test_Loss:22.92469596862793, r2_store:-0.3677080494695113\n",
            "Epoch [9437/10000], train_Loss: 7.098518108250573e-05,test_Loss:22.934534072875977, r2_store:-0.36838593047298174\n",
            "Epoch [9438/10000], train_Loss: 7.004149665590376e-05,test_Loss:22.928274154663086, r2_store:-0.36770703121169657\n",
            "Epoch [9439/10000], train_Loss: 6.912329263286665e-05,test_Loss:22.935434341430664, r2_store:-0.3683229919364628\n",
            "Epoch [9440/10000], train_Loss: 6.770975596737117e-05,test_Loss:22.928287506103516, r2_store:-0.3677524463302928\n",
            "Epoch [9441/10000], train_Loss: 6.61628509988077e-05,test_Loss:22.935922622680664, r2_store:-0.36826298293483606\n",
            "Epoch [9442/10000], train_Loss: 6.480333104263991e-05,test_Loss:22.9294376373291, r2_store:-0.3678191856534083\n",
            "Epoch [9443/10000], train_Loss: 6.34182506473735e-05,test_Loss:22.934085845947266, r2_store:-0.3681332612748611\n",
            "Epoch [9444/10000], train_Loss: 6.247880082810298e-05,test_Loss:22.932336807250977, r2_store:-0.36782861008133994\n",
            "Epoch [9445/10000], train_Loss: 6.167455285321921e-05,test_Loss:22.93407440185547, r2_store:-0.3680174517742303\n",
            "Epoch [9446/10000], train_Loss: 6.0818907513748854e-05,test_Loss:22.931819915771484, r2_store:-0.3678684693049181\n",
            "Epoch [9447/10000], train_Loss: 6.017812847858295e-05,test_Loss:22.93429183959961, r2_store:-0.367969209528183\n",
            "Epoch [9448/10000], train_Loss: 5.9655769291566685e-05,test_Loss:22.933374404907227, r2_store:-0.36793022956842747\n",
            "Epoch [9449/10000], train_Loss: 5.925004370510578e-05,test_Loss:22.93327522277832, r2_store:-0.367895263187328\n",
            "Epoch [9450/10000], train_Loss: 5.887975567020476e-05,test_Loss:22.936208724975586, r2_store:-0.36793127835750306\n",
            "Epoch [9451/10000], train_Loss: 5.85496673011221e-05,test_Loss:22.935293197631836, r2_store:-0.3678100905451609\n",
            "Epoch [9452/10000], train_Loss: 5.8363562857266515e-05,test_Loss:22.93656349182129, r2_store:-0.36792953980269716\n",
            "Epoch [9453/10000], train_Loss: 5.818448698846623e-05,test_Loss:22.9356746673584, r2_store:-0.36775933997473453\n",
            "Epoch [9454/10000], train_Loss: 5.7896300859283656e-05,test_Loss:22.938013076782227, r2_store:-0.36796825237533826\n",
            "Epoch [9455/10000], train_Loss: 5.78427680011373e-05,test_Loss:22.93436050415039, r2_store:-0.36771019118494364\n",
            "Epoch [9456/10000], train_Loss: 5.7804234529612586e-05,test_Loss:22.93996810913086, r2_store:-0.3679921614804127\n",
            "Epoch [9457/10000], train_Loss: 5.776582474936731e-05,test_Loss:22.93593406677246, r2_store:-0.36765557190816467\n",
            "Epoch [9458/10000], train_Loss: 5.78140388824977e-05,test_Loss:22.940317153930664, r2_store:-0.3680077356772269\n",
            "Epoch [9459/10000], train_Loss: 5.790356226498261e-05,test_Loss:22.937191009521484, r2_store:-0.36761233974841523\n",
            "Epoch [9460/10000], train_Loss: 5.797799531137571e-05,test_Loss:22.942537307739258, r2_store:-0.3680549951473875\n",
            "Epoch [9461/10000], train_Loss: 5.804542888654396e-05,test_Loss:22.935537338256836, r2_store:-0.3675578988875068\n",
            "Epoch [9462/10000], train_Loss: 5.862025864189491e-05,test_Loss:22.94384765625, r2_store:-0.36808280999674947\n",
            "Epoch [9463/10000], train_Loss: 5.9070946008432657e-05,test_Loss:22.93710708618164, r2_store:-0.3674650455249542\n",
            "Epoch [9464/10000], train_Loss: 5.942292045801878e-05,test_Loss:22.945697784423828, r2_store:-0.36809198169524304\n",
            "Epoch [9465/10000], train_Loss: 6.042308086762205e-05,test_Loss:22.938297271728516, r2_store:-0.36737359900368194\n",
            "Epoch [9466/10000], train_Loss: 6.182583456393331e-05,test_Loss:22.947856903076172, r2_store:-0.36819430568413103\n",
            "Epoch [9467/10000], train_Loss: 6.38107376289554e-05,test_Loss:22.93618392944336, r2_store:-0.3672861964978782\n",
            "Epoch [9468/10000], train_Loss: 6.628169649047777e-05,test_Loss:22.949941635131836, r2_store:-0.3683437051440881\n",
            "Epoch [9469/10000], train_Loss: 6.950161332497373e-05,test_Loss:22.9339542388916, r2_store:-0.3671579636308928\n",
            "Epoch [9470/10000], train_Loss: 7.391425606328994e-05,test_Loss:22.951248168945312, r2_store:-0.36847026543615424\n",
            "Epoch [9471/10000], train_Loss: 8.043393609113991e-05,test_Loss:22.934356689453125, r2_store:-0.3668965263958679\n",
            "Epoch [9472/10000], train_Loss: 8.930661715567112e-05,test_Loss:22.956722259521484, r2_store:-0.3686440070199848\n",
            "Epoch [9473/10000], train_Loss: 0.00010201831173617393,test_Loss:22.930978775024414, r2_store:-0.3665723547562665\n",
            "Epoch [9474/10000], train_Loss: 0.00011976440146099776,test_Loss:22.961368560791016, r2_store:-0.3689850880043093\n",
            "Epoch [9475/10000], train_Loss: 0.00014501140685752034,test_Loss:22.92623519897461, r2_store:-0.3661511173934062\n",
            "Epoch [9476/10000], train_Loss: 0.00018096607527695596,test_Loss:22.967304229736328, r2_store:-0.3694774143366204\n",
            "Epoch [9477/10000], train_Loss: 0.00023262016475200653,test_Loss:22.919246673583984, r2_store:-0.36549826751979064\n",
            "Epoch [9478/10000], train_Loss: 0.0003064941556658596,test_Loss:22.978633880615234, r2_store:-0.3701703867983108\n",
            "Epoch [9479/10000], train_Loss: 0.00041459445492364466,test_Loss:22.90915298461914, r2_store:-0.3645397770844274\n",
            "Epoch [9480/10000], train_Loss: 0.0005717844469472766,test_Loss:22.993030548095703, r2_store:-0.3712819772470315\n",
            "Epoch [9481/10000], train_Loss: 0.000803421251475811,test_Loss:22.892284393310547, r2_store:-0.3632040565764565\n",
            "Epoch [9482/10000], train_Loss: 0.0011459857923910022,test_Loss:23.008686065673828, r2_store:-0.3730155223916316\n",
            "Epoch [9483/10000], train_Loss: 0.0016543383244425058,test_Loss:22.86916732788086, r2_store:-0.3611700924052299\n",
            "Epoch [9484/10000], train_Loss: 0.0024153408594429493,test_Loss:23.042972564697266, r2_store:-0.37559702699333264\n",
            "Epoch [9485/10000], train_Loss: 0.0035459441132843494,test_Loss:22.830970764160156, r2_store:-0.35809875517773415\n",
            "Epoch [9486/10000], train_Loss: 0.0052488818764686584,test_Loss:23.095813751220703, r2_store:-0.37962178687281467\n",
            "Epoch [9487/10000], train_Loss: 0.007771971169859171,test_Loss:22.781152725219727, r2_store:-0.35374672401508866\n",
            "Epoch [9488/10000], train_Loss: 0.011576419696211815,test_Loss:23.169771194458008, r2_store:-0.3859191866622602\n",
            "Epoch [9489/10000], train_Loss: 0.017070693895220757,test_Loss:22.724658966064453, r2_store:-0.3480377348877195\n",
            "Epoch [9490/10000], train_Loss: 0.025096619501709938,test_Loss:23.270278930664062, r2_store:-0.39525537473173045\n",
            "Epoch [9491/10000], train_Loss: 0.03584393486380577,test_Loss:22.640575408935547, r2_store:-0.3413808086969601\n",
            "Epoch [9492/10000], train_Loss: 0.050284773111343384,test_Loss:23.421215057373047, r2_store:-0.40733209729142383\n",
            "Epoch [9493/10000], train_Loss: 0.06607012450695038,test_Loss:22.565189361572266, r2_store:-0.3358222153204853\n",
            "Epoch [9494/10000], train_Loss: 0.08184885233640671,test_Loss:23.481639862060547, r2_store:-0.41466437629208697\n",
            "Epoch [9495/10000], train_Loss: 0.08811494708061218,test_Loss:22.562116622924805, r2_store:-0.33600405858599225\n",
            "Epoch [9496/10000], train_Loss: 0.08306042104959488,test_Loss:23.361156463623047, r2_store:-0.4055047401702412\n",
            "Epoch [9497/10000], train_Loss: 0.060766369104385376,test_Loss:22.69913673400879, r2_store:-0.3468529309749422\n",
            "Epoch [9498/10000], train_Loss: 0.03165523335337639,test_Loss:23.10738754272461, r2_store:-0.3798289774539265\n",
            "Epoch [9499/10000], train_Loss: 0.0076358867809176445,test_Loss:22.9818172454834, r2_store:-0.3689561060953992\n",
            "Epoch [9500/10000], train_Loss: 0.0005581130972132087,test_Loss:22.85500717163086, r2_store:-0.3549975284175235\n",
            "Epoch [9501/10000], train_Loss: 0.009789949283003807,test_Loss:23.303176879882812, r2_store:-0.3898373473460921\n",
            "Epoch [9502/10000], train_Loss: 0.02474397048354149,test_Loss:22.70486831665039, r2_store:-0.3461200775185649\n",
            "Epoch [9503/10000], train_Loss: 0.0333862379193306,test_Loss:23.315567016601562, r2_store:-0.3936342396317716\n",
            "Epoch [9504/10000], train_Loss: 0.028752032667398453,test_Loss:22.7652587890625, r2_store:-0.35409842473239306\n",
            "Epoch [9505/10000], train_Loss: 0.015373374335467815,test_Loss:23.039169311523438, r2_store:-0.37663081210320226\n",
            "Epoch [9506/10000], train_Loss: 0.00339517742395401,test_Loss:23.014646530151367, r2_store:-0.37119460397224047\n",
            "Epoch [9507/10000], train_Loss: 0.0007625790894962847,test_Loss:22.81845474243164, r2_store:-0.35752189963628833\n",
            "Epoch [9508/10000], train_Loss: 0.006734075490385294,test_Loss:23.174440383911133, r2_store:-0.38353726725110815\n",
            "Epoch [9509/10000], train_Loss: 0.014330873265862465,test_Loss:22.817962646484375, r2_store:-0.35087991231507676\n",
            "Epoch [9510/10000], train_Loss: 0.01672874577343464,test_Loss:23.16660499572754, r2_store:-0.3814925808007448\n",
            "Epoch [9511/10000], train_Loss: 0.012143300846219063,test_Loss:22.867313385009766, r2_store:-0.3580382950529888\n",
            "Epoch [9512/10000], train_Loss: 0.004988428205251694,test_Loss:23.037147521972656, r2_store:-0.3697485073237372\n",
            "Epoch [9513/10000], train_Loss: 0.0006397164543159306,test_Loss:23.02998161315918, r2_store:-0.3719391343031955\n",
            "Epoch [9514/10000], train_Loss: 0.0013643690617755055,test_Loss:22.85537338256836, r2_store:-0.3586637623867015\n",
            "Epoch [9515/10000], train_Loss: 0.005270583555102348,test_Loss:23.15907096862793, r2_store:-0.38038661066641466\n",
            "Epoch [9516/10000], train_Loss: 0.008285300806164742,test_Loss:22.83279800415039, r2_store:-0.3568852280482111\n",
            "Epoch [9517/10000], train_Loss: 0.007912112399935722,test_Loss:23.06019401550293, r2_store:-0.3771913505347204\n",
            "Epoch [9518/10000], train_Loss: 0.004768261220306158,test_Loss:22.908016204833984, r2_store:-0.36387099383006904\n",
            "Epoch [9519/10000], train_Loss: 0.0014500777469947934,test_Loss:22.94794464111328, r2_store:-0.3684646168723058\n",
            "Epoch [9520/10000], train_Loss: 0.00022670943872071803,test_Loss:22.976713180541992, r2_store:-0.37334100905261924\n",
            "Epoch [9521/10000], train_Loss: 0.0013843796914443374,test_Loss:22.84553337097168, r2_store:-0.3616835249345305\n",
            "Epoch [9522/10000], train_Loss: 0.0033849093597382307,test_Loss:23.05746841430664, r2_store:-0.3780193308010644\n",
            "Epoch [9523/10000], train_Loss: 0.004452649503946304,test_Loss:22.82980728149414, r2_store:-0.3610371904588472\n",
            "Epoch [9524/10000], train_Loss: 0.0038588172756135464,test_Loss:23.01194953918457, r2_store:-0.37503931811944424\n",
            "Epoch [9525/10000], train_Loss: 0.002159128664061427,test_Loss:22.90675163269043, r2_store:-0.3662907313450694\n",
            "Epoch [9526/10000], train_Loss: 0.0006450096843764186,test_Loss:22.908615112304688, r2_store:-0.3685573638554729\n",
            "Epoch [9527/10000], train_Loss: 0.00017972427303902805,test_Loss:22.95500946044922, r2_store:-0.37239695914712057\n",
            "Epoch [9528/10000], train_Loss: 0.0007811715477146208,test_Loss:22.854190826416016, r2_store:-0.36398359992418916\n",
            "Epoch [9529/10000], train_Loss: 0.0017448371509090066,test_Loss:22.965829849243164, r2_store:-0.3753459076401706\n",
            "Epoch [9530/10000], train_Loss: 0.0022513712756335735,test_Loss:22.82236099243164, r2_store:-0.36343052389673725\n",
            "Epoch [9531/10000], train_Loss: 0.001996745588257909,test_Loss:22.96517562866211, r2_store:-0.3735058380253993\n",
            "Epoch [9532/10000], train_Loss: 0.001218522316776216,test_Loss:22.8738956451416, r2_store:-0.36655822120930814\n",
            "Epoch [9533/10000], train_Loss: 0.00045141749433241785,test_Loss:22.902301788330078, r2_store:-0.3691411499819015\n",
            "Epoch [9534/10000], train_Loss: 0.00013448591926135123,test_Loss:22.939311981201172, r2_store:-0.3710743803596901\n",
            "Epoch [9535/10000], train_Loss: 0.00032101612305268645,test_Loss:22.866125106811523, r2_store:-0.36599493235821323\n",
            "Epoch [9536/10000], train_Loss: 0.0007513031014241278,test_Loss:22.945011138916016, r2_store:-0.3735361600173972\n",
            "Epoch [9537/10000], train_Loss: 0.0010897598695009947,test_Loss:22.85133934020996, r2_store:-0.3652835423123808\n",
            "Epoch [9538/10000], train_Loss: 0.0011089659528806806,test_Loss:22.93553924560547, r2_store:-0.37292152384348753\n",
            "Epoch [9539/10000], train_Loss: 0.0008313853177241981,test_Loss:22.852432250976562, r2_store:-0.3666208602973078\n",
            "Epoch [9540/10000], train_Loss: 0.000451055500889197,test_Loss:22.905920028686523, r2_store:-0.37002337014603737\n",
            "Epoch [9541/10000], train_Loss: 0.00017316118464805186,test_Loss:22.89756202697754, r2_store:-0.36923168507055104\n",
            "Epoch [9542/10000], train_Loss: 0.00011415616609156132,test_Loss:22.86507797241211, r2_store:-0.367333711060835\n",
            "Epoch [9543/10000], train_Loss: 0.0002435745409457013,test_Loss:22.92041778564453, r2_store:-0.37152523714643015\n",
            "Epoch [9544/10000], train_Loss: 0.0004333403776399791,test_Loss:22.85763931274414, r2_store:-0.3663789173462957\n",
            "Epoch [9545/10000], train_Loss: 0.0005632725078612566,test_Loss:22.912195205688477, r2_store:-0.3721175918346389\n",
            "Epoch [9546/10000], train_Loss: 0.0005637805443257093,test_Loss:22.857576370239258, r2_store:-0.366835722904044\n",
            "Epoch [9547/10000], train_Loss: 0.00044070318108424544,test_Loss:22.908626556396484, r2_store:-0.3709973953995538\n",
            "Epoch [9548/10000], train_Loss: 0.0002740540949162096,test_Loss:22.870590209960938, r2_store:-0.36805817340614944\n",
            "Epoch [9549/10000], train_Loss: 0.00014255294809117913,test_Loss:22.88973617553711, r2_store:-0.36895383549736094\n",
            "Epoch [9550/10000], train_Loss: 9.191539720632136e-05,test_Loss:22.898170471191406, r2_store:-0.369627364380557\n",
            "Epoch [9551/10000], train_Loss: 0.00012279150541871786,test_Loss:22.865270614624023, r2_store:-0.3674777137454641\n",
            "Epoch [9552/10000], train_Loss: 0.00019816488202195615,test_Loss:22.908910751342773, r2_store:-0.3707716840152744\n",
            "Epoch [9553/10000], train_Loss: 0.0002688445383682847,test_Loss:22.861087799072266, r2_store:-0.36702850568462875\n",
            "Epoch [9554/10000], train_Loss: 0.0003011610242538154,test_Loss:22.905136108398438, r2_store:-0.3708255606920774\n",
            "Epoch [9555/10000], train_Loss: 0.00028349016793072224,test_Loss:22.86873435974121, r2_store:-0.36725650766056406\n",
            "Epoch [9556/10000], train_Loss: 0.0002272210840601474,test_Loss:22.90180015563965, r2_store:-0.3698575875811638\n",
            "Epoch [9557/10000], train_Loss: 0.00015875417739152908,test_Loss:22.884395599365234, r2_store:-0.367900045278446\n",
            "Epoch [9558/10000], train_Loss: 0.00010508432751521468,test_Loss:22.897010803222656, r2_store:-0.3685958279513042\n",
            "Epoch [9559/10000], train_Loss: 8.082769636530429e-05,test_Loss:22.899396896362305, r2_store:-0.3687816259744645\n",
            "Epoch [9560/10000], train_Loss: 8.64400208229199e-05,test_Loss:22.888818740844727, r2_store:-0.36767587490244646\n",
            "Epoch [9561/10000], train_Loss: 0.00011156875552842394,test_Loss:22.909738540649414, r2_store:-0.36955639924573713\n",
            "Epoch [9562/10000], train_Loss: 0.00014142766303848475,test_Loss:22.880359649658203, r2_store:-0.3672823379842485\n",
            "Epoch [9563/10000], train_Loss: 0.00016293660155497491,test_Loss:22.9132080078125, r2_store:-0.36986079565576757\n",
            "Epoch [9564/10000], train_Loss: 0.00016759397112764418,test_Loss:22.885387420654297, r2_store:-0.3673761820885124\n",
            "Epoch [9565/10000], train_Loss: 0.00015540028107352555,test_Loss:22.909074783325195, r2_store:-0.3695767161714065\n",
            "Epoch [9566/10000], train_Loss: 0.00013305802713148296,test_Loss:22.891876220703125, r2_store:-0.3677954682734217\n",
            "Epoch [9567/10000], train_Loss: 0.00010731993097579107,test_Loss:22.90544319152832, r2_store:-0.369069015701055\n",
            "Epoch [9568/10000], train_Loss: 8.58319690451026e-05,test_Loss:22.893386840820312, r2_store:-0.36835662283695947\n",
            "Epoch [9569/10000], train_Loss: 7.377240399364382e-05,test_Loss:22.899080276489258, r2_store:-0.3684906227190554\n",
            "Epoch [9570/10000], train_Loss: 7.149375596782193e-05,test_Loss:22.90053367614746, r2_store:-0.3688294602684228\n",
            "Epoch [9571/10000], train_Loss: 7.619559619342908e-05,test_Loss:22.891496658325195, r2_store:-0.36790752296997264\n",
            "Epoch [9572/10000], train_Loss: 8.51891454658471e-05,test_Loss:22.910125732421875, r2_store:-0.36909465298193456\n",
            "Epoch [9573/10000], train_Loss: 9.491827222518623e-05,test_Loss:22.890634536743164, r2_store:-0.3676093801008842\n",
            "Epoch [9574/10000], train_Loss: 0.00010138982906937599,test_Loss:22.91229820251465, r2_store:-0.3691993441278023\n",
            "Epoch [9575/10000], train_Loss: 0.00010329594078939408,test_Loss:22.89377784729004, r2_store:-0.36764672400180287\n",
            "Epoch [9576/10000], train_Loss: 0.00010089692659676075,test_Loss:22.909622192382812, r2_store:-0.3691179441162291\n",
            "Epoch [9577/10000], train_Loss: 9.490043885307387e-05,test_Loss:22.894855499267578, r2_store:-0.36777778897840907\n",
            "Epoch [9578/10000], train_Loss: 8.65074252942577e-05,test_Loss:22.910572052001953, r2_store:-0.36882632978057184\n",
            "Epoch [9579/10000], train_Loss: 7.865738734835759e-05,test_Loss:22.898998260498047, r2_store:-0.36794628946033625\n",
            "Epoch [9580/10000], train_Loss: 7.193462806753814e-05,test_Loss:22.907085418701172, r2_store:-0.3684952533323731\n",
            "Epoch [9581/10000], train_Loss: 6.702443351969123e-05,test_Loss:22.905532836914062, r2_store:-0.3682525731317623\n",
            "Epoch [9582/10000], train_Loss: 6.452060915762559e-05,test_Loss:22.90484046936035, r2_store:-0.36827413387586017\n",
            "Epoch [9583/10000], train_Loss: 6.392206705641001e-05,test_Loss:22.909513473510742, r2_store:-0.36853663283895144\n",
            "Epoch [9584/10000], train_Loss: 6.478666182374582e-05,test_Loss:22.90535545349121, r2_store:-0.3681010723802085\n",
            "Epoch [9585/10000], train_Loss: 6.650841532973573e-05,test_Loss:22.91254997253418, r2_store:-0.3686557745617376\n",
            "Epoch [9586/10000], train_Loss: 6.859581480966881e-05,test_Loss:22.90475845336914, r2_store:-0.36789167117849475\n",
            "Epoch [9587/10000], train_Loss: 7.036959868855774e-05,test_Loss:22.91594886779785, r2_store:-0.368668717957519\n",
            "Epoch [9588/10000], train_Loss: 7.137028296710923e-05,test_Loss:22.903919219970703, r2_store:-0.36778257881420906\n",
            "Epoch [9589/10000], train_Loss: 7.156415085773915e-05,test_Loss:22.916318893432617, r2_store:-0.368654467415652\n",
            "Epoch [9590/10000], train_Loss: 7.126985292416066e-05,test_Loss:22.906341552734375, r2_store:-0.36779938602016626\n",
            "Epoch [9591/10000], train_Loss: 7.062964141368866e-05,test_Loss:22.91639518737793, r2_store:-0.3686401934316208\n",
            "Epoch [9592/10000], train_Loss: 6.938826118130237e-05,test_Loss:22.908987045288086, r2_store:-0.3678542179090103\n",
            "Epoch [9593/10000], train_Loss: 6.792355270590633e-05,test_Loss:22.919940948486328, r2_store:-0.3686002634544998\n",
            "Epoch [9594/10000], train_Loss: 6.644764653174207e-05,test_Loss:22.91029930114746, r2_store:-0.36788674683867884\n",
            "Epoch [9595/10000], train_Loss: 6.497139838756993e-05,test_Loss:22.91965103149414, r2_store:-0.368518642184136\n",
            "Epoch [9596/10000], train_Loss: 6.346814916469157e-05,test_Loss:22.912172317504883, r2_store:-0.3679286845956802\n",
            "Epoch [9597/10000], train_Loss: 6.22409424977377e-05,test_Loss:22.917755126953125, r2_store:-0.36841930609870555\n",
            "Epoch [9598/10000], train_Loss: 6.104081694502383e-05,test_Loss:22.913761138916016, r2_store:-0.3679356039063384\n",
            "Epoch [9599/10000], train_Loss: 6.0061072872485965e-05,test_Loss:22.920024871826172, r2_store:-0.36834659246919776\n",
            "Epoch [9600/10000], train_Loss: 5.922662603552453e-05,test_Loss:22.91438102722168, r2_store:-0.36797093357588695\n",
            "Epoch [9601/10000], train_Loss: 5.8404129958944395e-05,test_Loss:22.92003059387207, r2_store:-0.368312794549694\n",
            "Epoch [9602/10000], train_Loss: 5.764122397522442e-05,test_Loss:22.916790008544922, r2_store:-0.36803039919200176\n",
            "Epoch [9603/10000], train_Loss: 5.7044810091611e-05,test_Loss:22.919086456298828, r2_store:-0.36825528924688844\n",
            "Epoch [9604/10000], train_Loss: 5.6504075473640114e-05,test_Loss:22.918567657470703, r2_store:-0.36800087399975934\n",
            "Epoch [9605/10000], train_Loss: 5.5897311540320516e-05,test_Loss:22.922775268554688, r2_store:-0.3681773850342551\n",
            "Epoch [9606/10000], train_Loss: 5.5557706218678504e-05,test_Loss:22.919780731201172, r2_store:-0.3679660686392765\n",
            "Epoch [9607/10000], train_Loss: 5.522056017071009e-05,test_Loss:22.92353630065918, r2_store:-0.36815998595953103\n",
            "Epoch [9608/10000], train_Loss: 5.479857645696029e-05,test_Loss:22.921743392944336, r2_store:-0.36798178692994177\n",
            "Epoch [9609/10000], train_Loss: 5.465321009978652e-05,test_Loss:22.9228515625, r2_store:-0.36814873141798965\n",
            "Epoch [9610/10000], train_Loss: 5.443709596875124e-05,test_Loss:22.921995162963867, r2_store:-0.3679397969307072\n",
            "Epoch [9611/10000], train_Loss: 5.398124994826503e-05,test_Loss:22.925838470458984, r2_store:-0.3681337805281921\n",
            "Epoch [9612/10000], train_Loss: 5.382621748140082e-05,test_Loss:22.92209243774414, r2_store:-0.3679020016554453\n",
            "Epoch [9613/10000], train_Loss: 5.356311521609314e-05,test_Loss:22.92666244506836, r2_store:-0.3681395106946166\n",
            "Epoch [9614/10000], train_Loss: 5.3316267440095544e-05,test_Loss:22.925067901611328, r2_store:-0.3678928784598099\n",
            "Epoch [9615/10000], train_Loss: 5.313963629305363e-05,test_Loss:22.928071975708008, r2_store:-0.3681464202614526\n",
            "Epoch [9616/10000], train_Loss: 5.2990468248026446e-05,test_Loss:22.925220489501953, r2_store:-0.3678657641266958\n",
            "Epoch [9617/10000], train_Loss: 5.2907958888681605e-05,test_Loss:22.929548263549805, r2_store:-0.3681556556951364\n",
            "Epoch [9618/10000], train_Loss: 5.2882154705002904e-05,test_Loss:22.924617767333984, r2_store:-0.36778566228650567\n",
            "Epoch [9619/10000], train_Loss: 5.301374039845541e-05,test_Loss:22.93009376525879, r2_store:-0.3681513362004807\n",
            "Epoch [9620/10000], train_Loss: 5.339022754924372e-05,test_Loss:22.92535400390625, r2_store:-0.3676827112249703\n",
            "Epoch [9621/10000], train_Loss: 5.384721953305416e-05,test_Loss:22.932098388671875, r2_store:-0.3681843287872595\n",
            "Epoch [9622/10000], train_Loss: 5.449276795843616e-05,test_Loss:22.92518424987793, r2_store:-0.3675866217005703\n",
            "Epoch [9623/10000], train_Loss: 5.584435348282568e-05,test_Loss:22.93560028076172, r2_store:-0.36827892714572275\n",
            "Epoch [9624/10000], train_Loss: 5.7677483709994704e-05,test_Loss:22.925601959228516, r2_store:-0.3674434764760177\n",
            "Epoch [9625/10000], train_Loss: 6.04087945248466e-05,test_Loss:22.93897247314453, r2_store:-0.3684004438004598\n",
            "Epoch [9626/10000], train_Loss: 6.43912426312454e-05,test_Loss:22.924299240112305, r2_store:-0.36726487749714143\n",
            "Epoch [9627/10000], train_Loss: 7.025498052826151e-05,test_Loss:22.939950942993164, r2_store:-0.36861545807607277\n",
            "Epoch [9628/10000], train_Loss: 7.907302642706782e-05,test_Loss:22.92039680480957, r2_store:-0.3670047061838224\n",
            "Epoch [9629/10000], train_Loss: 9.212950681103393e-05,test_Loss:22.944673538208008, r2_store:-0.3689414756854523\n",
            "Epoch [9630/10000], train_Loss: 0.0001122185931308195,test_Loss:22.91506576538086, r2_store:-0.3665285623418879\n",
            "Epoch [9631/10000], train_Loss: 0.00014192191883921623,test_Loss:22.9537296295166, r2_store:-0.3693822950825292\n",
            "Epoch [9632/10000], train_Loss: 0.000185891316505149,test_Loss:22.909656524658203, r2_store:-0.365871786622449\n",
            "Epoch [9633/10000], train_Loss: 0.0002521102433092892,test_Loss:22.961795806884766, r2_store:-0.3701346960279661\n",
            "Epoch [9634/10000], train_Loss: 0.00035423104418441653,test_Loss:22.898969650268555, r2_store:-0.3649526814472537\n",
            "Epoch [9635/10000], train_Loss: 0.0005097048706375062,test_Loss:22.976673126220703, r2_store:-0.3713965118002147\n",
            "Epoch [9636/10000], train_Loss: 0.0007495610043406487,test_Loss:22.87876319885254, r2_store:-0.36344391749212734\n",
            "Epoch [9637/10000], train_Loss: 0.0011189557844772935,test_Loss:23.004886627197266, r2_store:-0.37327747405893996\n",
            "Epoch [9638/10000], train_Loss: 0.001691612065769732,test_Loss:22.861574172973633, r2_store:-0.36117056383546275\n",
            "Epoch [9639/10000], train_Loss: 0.002616690006107092,test_Loss:23.037403106689453, r2_store:-0.3764976187799587\n",
            "Epoch [9640/10000], train_Loss: 0.004040469415485859,test_Loss:22.817142486572266, r2_store:-0.35771877136062846\n",
            "Epoch [9641/10000], train_Loss: 0.006253071129322052,test_Loss:23.099294662475586, r2_store:-0.3814559035387486\n",
            "Epoch [9642/10000], train_Loss: 0.009688852354884148,test_Loss:22.744144439697266, r2_store:-0.3521401347697719\n",
            "Epoch [9643/10000], train_Loss: 0.015077022835612297,test_Loss:23.218870162963867, r2_store:-0.38952399316507136\n",
            "Epoch [9644/10000], train_Loss: 0.02308064140379429,test_Loss:22.642559051513672, r2_store:-0.3449608854587707\n",
            "Epoch [9645/10000], train_Loss: 0.03492704778909683,test_Loss:23.350147247314453, r2_store:-0.4014191494709365\n",
            "Epoch [9646/10000], train_Loss: 0.050710730254650116,test_Loss:22.586694717407227, r2_store:-0.3371776467699823\n",
            "Epoch [9647/10000], train_Loss: 0.07124796509742737,test_Loss:23.473665237426758, r2_store:-0.414613664047466\n",
            "Epoch [9648/10000], train_Loss: 0.0915578231215477,test_Loss:22.511112213134766, r2_store:-0.3318699538187171\n",
            "Epoch [9649/10000], train_Loss: 0.10855875164270401,test_Loss:23.5710506439209, r2_store:-0.4202269288539229\n",
            "Epoch [9650/10000], train_Loss: 0.10575304180383682,test_Loss:22.543209075927734, r2_store:-0.3370312765767507\n",
            "Epoch [9651/10000], train_Loss: 0.08236874639987946,test_Loss:23.265113830566406, r2_store:-0.3995064602623526\n",
            "Epoch [9652/10000], train_Loss: 0.04204842448234558,test_Loss:22.823001861572266, r2_store:-0.3575732235822655\n",
            "Epoch [9653/10000], train_Loss: 0.009767312556505203,test_Loss:22.93443489074707, r2_store:-0.36583246296770877\n",
            "Epoch [9654/10000], train_Loss: 0.001105108647607267,test_Loss:23.166128158569336, r2_store:-0.38536642410846356\n",
            "Epoch [9655/10000], train_Loss: 0.015640372410416603,test_Loss:22.765949249267578, r2_store:-0.34662245057540675\n",
            "Epoch [9656/10000], train_Loss: 0.035549063235521317,test_Loss:23.352802276611328, r2_store:-0.39824858942905883\n",
            "Epoch [9657/10000], train_Loss: 0.04136773571372032,test_Loss:22.675537109375, r2_store:-0.3480116833206759\n",
            "Epoch [9658/10000], train_Loss: 0.030491024255752563,test_Loss:23.25305938720703, r2_store:-0.3846404243374886\n",
            "Epoch [9659/10000], train_Loss: 0.011874991469085217,test_Loss:22.925718307495117, r2_store:-0.3672173445082545\n",
            "Epoch [9660/10000], train_Loss: 0.0010012505808845162,test_Loss:22.786518096923828, r2_store:-0.3611864545661907\n",
            "Epoch [9661/10000], train_Loss: 0.004626431502401829,test_Loss:23.20708465576172, r2_store:-0.3857187357478178\n",
            "Epoch [9662/10000], train_Loss: 0.015086540952324867,test_Loss:22.741544723510742, r2_store:-0.34947128000354666\n",
            "Epoch [9663/10000], train_Loss: 0.021157708019018173,test_Loss:23.16031265258789, r2_store:-0.38440160694853387\n",
            "Epoch [9664/10000], train_Loss: 0.017535846680402756,test_Loss:22.866718292236328, r2_store:-0.35614778324977925\n",
            "Epoch [9665/10000], train_Loss: 0.008001262322068214,test_Loss:23.010986328125, r2_store:-0.3711625523573576\n",
            "Epoch [9666/10000], train_Loss: 0.0011431582970544696,test_Loss:22.978309631347656, r2_store:-0.3722629833044817\n",
            "Epoch [9667/10000], train_Loss: 0.001689055236056447,test_Loss:22.866378784179688, r2_store:-0.3578182536823642\n",
            "Epoch [9668/10000], train_Loss: 0.00704159727320075,test_Loss:23.16979217529297, r2_store:-0.38313163764005664\n",
            "Epoch [9669/10000], train_Loss: 0.0110935652628541,test_Loss:22.766748428344727, r2_store:-0.35627700427355524\n",
            "Epoch [9670/10000], train_Loss: 0.010114409029483795,test_Loss:23.048839569091797, r2_store:-0.37891352147104396\n",
            "Epoch [9671/10000], train_Loss: 0.005319432821124792,test_Loss:22.90938949584961, r2_store:-0.36556960241795156\n",
            "Epoch [9672/10000], train_Loss: 0.0011146173346787691,test_Loss:22.894298553466797, r2_store:-0.3669353411034808\n",
            "Epoch [9673/10000], train_Loss: 0.0005929763428866863,test_Loss:23.00653648376465, r2_store:-0.3769141810716985\n",
            "Epoch [9674/10000], train_Loss: 0.003143118228763342,test_Loss:22.82339096069336, r2_store:-0.3606685453465641\n",
            "Epoch [9675/10000], train_Loss: 0.005790523253381252,test_Loss:23.03699493408203, r2_store:-0.3807550246960798\n",
            "Epoch [9676/10000], train_Loss: 0.005979301407933235,test_Loss:22.812725067138672, r2_store:-0.362655189858631\n",
            "Epoch [9677/10000], train_Loss: 0.0038267038762569427,test_Loss:22.989261627197266, r2_store:-0.375111217894885\n",
            "Epoch [9678/10000], train_Loss: 0.0012344617862254381,test_Loss:22.89544105529785, r2_store:-0.3708328465057671\n",
            "Epoch [9679/10000], train_Loss: 0.00021234003361314535,test_Loss:22.81629753112793, r2_store:-0.3664256728778461\n",
            "Epoch [9680/10000], train_Loss: 0.0011609256034716964,test_Loss:22.98223876953125, r2_store:-0.37744493493592324\n",
            "Epoch [9681/10000], train_Loss: 0.002700767945498228,test_Loss:22.796037673950195, r2_store:-0.3629886774762312\n",
            "Epoch [9682/10000], train_Loss: 0.0033882230054587126,test_Loss:22.93362045288086, r2_store:-0.3770471951434575\n",
            "Epoch [9683/10000], train_Loss: 0.0026916717179119587,test_Loss:22.815095901489258, r2_store:-0.3661314452383422\n",
            "Epoch [9684/10000], train_Loss: 0.001255533192306757,test_Loss:22.89756965637207, r2_store:-0.37196696102243143\n",
            "Epoch [9685/10000], train_Loss: 0.0002973344235215336,test_Loss:22.88131332397461, r2_store:-0.3718875609046437\n",
            "Epoch [9686/10000], train_Loss: 0.0003188735863659531,test_Loss:22.827146530151367, r2_store:-0.3664092985881726\n",
            "Epoch [9687/10000], train_Loss: 0.0010330991353839636,test_Loss:22.95529556274414, r2_store:-0.3759010073348821\n",
            "Epoch [9688/10000], train_Loss: 0.0017192913219332695,test_Loss:22.80923843383789, r2_store:-0.3651286584311242\n",
            "Epoch [9689/10000], train_Loss: 0.0017546523595228791,test_Loss:22.922435760498047, r2_store:-0.37478250469653185\n",
            "Epoch [9690/10000], train_Loss: 0.0012058619176968932,test_Loss:22.8603458404541, r2_store:-0.36804666710106737\n",
            "Epoch [9691/10000], train_Loss: 0.0005269229877740145,test_Loss:22.873960494995117, r2_store:-0.3710986587350238\n",
            "Epoch [9692/10000], train_Loss: 0.00014856290363240987,test_Loss:22.868732452392578, r2_store:-0.3720353085623409\n",
            "Epoch [9693/10000], train_Loss: 0.00027003829018212855,test_Loss:22.835294723510742, r2_store:-0.36750554766573496\n",
            "Epoch [9694/10000], train_Loss: 0.0006371919298544526,test_Loss:22.914012908935547, r2_store:-0.37407714850051854\n",
            "Epoch [9695/10000], train_Loss: 0.0009293593466281891,test_Loss:22.80970573425293, r2_store:-0.3662937984666452\n",
            "Epoch [9696/10000], train_Loss: 0.0009405755554325879,test_Loss:22.899892807006836, r2_store:-0.37334392538003747\n",
            "Epoch [9697/10000], train_Loss: 0.0006732574547640979,test_Loss:22.841259002685547, r2_store:-0.36832043931305924\n",
            "Epoch [9698/10000], train_Loss: 0.00033718900522217155,test_Loss:22.861202239990234, r2_store:-0.3708457806913956\n",
            "Epoch [9699/10000], train_Loss: 0.000140443560667336,test_Loss:22.875568389892578, r2_store:-0.37119573693977936\n",
            "Epoch [9700/10000], train_Loss: 0.00014709398965351284,test_Loss:22.848312377929688, r2_store:-0.3686479928331794\n",
            "Epoch [9701/10000], train_Loss: 0.00030672995490022004,test_Loss:22.88605499267578, r2_store:-0.3728703831413964\n",
            "Epoch [9702/10000], train_Loss: 0.0004736201954074204,test_Loss:22.835512161254883, r2_store:-0.367450032663597\n",
            "Epoch [9703/10000], train_Loss: 0.0005271224654279649,test_Loss:22.90677261352539, r2_store:-0.3725525865758821\n",
            "Epoch [9704/10000], train_Loss: 0.00045641540782526135,test_Loss:22.844758987426758, r2_store:-0.36799377687007895\n",
            "Epoch [9705/10000], train_Loss: 0.0003032076929230243,test_Loss:22.87452507019043, r2_store:-0.37090471269137604\n",
            "Epoch [9706/10000], train_Loss: 0.00016259480617009103,test_Loss:22.869556427001953, r2_store:-0.3697807148682797\n",
            "Epoch [9707/10000], train_Loss: 0.00010075228055939078,test_Loss:22.859220504760742, r2_store:-0.3691765054890721\n",
            "Epoch [9708/10000], train_Loss: 0.00012309240992181003,test_Loss:22.880441665649414, r2_store:-0.37118089545575583\n",
            "Epoch [9709/10000], train_Loss: 0.00019686028826981783,test_Loss:22.853439331054688, r2_store:-0.36811833322603316\n",
            "Epoch [9710/10000], train_Loss: 0.00026416531181894243,test_Loss:22.893169403076172, r2_store:-0.371595325996811\n",
            "Epoch [9711/10000], train_Loss: 0.00028441441827453673,test_Loss:22.850379943847656, r2_store:-0.36786014933118594\n",
            "Epoch [9712/10000], train_Loss: 0.00025241042021661997,test_Loss:22.89285659790039, r2_store:-0.37086292847457125\n",
            "Epoch [9713/10000], train_Loss: 0.00018813628412317485,test_Loss:22.866540908813477, r2_store:-0.3686877542981031\n",
            "Epoch [9714/10000], train_Loss: 0.00012388633331283927,test_Loss:22.87165069580078, r2_store:-0.3697566824620351\n",
            "Epoch [9715/10000], train_Loss: 8.82855529198423e-05,test_Loss:22.877531051635742, r2_store:-0.36979865937754264\n",
            "Epoch [9716/10000], train_Loss: 8.65830879774876e-05,test_Loss:22.871143341064453, r2_store:-0.3687792193134807\n",
            "Epoch [9717/10000], train_Loss: 0.00011107933096354827,test_Loss:22.886980056762695, r2_store:-0.37049644347333177\n",
            "Epoch [9718/10000], train_Loss: 0.00014184102474246174,test_Loss:22.862224578857422, r2_store:-0.3682421410580501\n",
            "Epoch [9719/10000], train_Loss: 0.00016154753393493593,test_Loss:22.893451690673828, r2_store:-0.37068630475634\n",
            "Epoch [9720/10000], train_Loss: 0.00016218297241721302,test_Loss:22.86180305480957, r2_store:-0.3682877381573546\n",
            "Epoch [9721/10000], train_Loss: 0.00014439958613365889,test_Loss:22.887004852294922, r2_store:-0.37023937900690207\n",
            "Epoch [9722/10000], train_Loss: 0.00011636623094091192,test_Loss:22.872617721557617, r2_store:-0.36885271319337276\n",
            "Epoch [9723/10000], train_Loss: 9.092256368603557e-05,test_Loss:22.875900268554688, r2_store:-0.3695089324942531\n",
            "Epoch [9724/10000], train_Loss: 7.653841021237895e-05,test_Loss:22.880701065063477, r2_store:-0.36944638526322104\n",
            "Epoch [9725/10000], train_Loss: 7.377415022347122e-05,test_Loss:22.878076553344727, r2_store:-0.36890904835137883\n",
            "Epoch [9726/10000], train_Loss: 8.145451283780858e-05,test_Loss:22.886730194091797, r2_store:-0.36988502945365065\n",
            "Epoch [9727/10000], train_Loss: 9.231407602783293e-05,test_Loss:22.873538970947266, r2_store:-0.36854916464129617\n",
            "Epoch [9728/10000], train_Loss: 0.00010051791468868032,test_Loss:22.891857147216797, r2_store:-0.37004688460005064\n",
            "Epoch [9729/10000], train_Loss: 0.00010415292490506545,test_Loss:22.871273040771484, r2_store:-0.36846348100537085\n",
            "Epoch [9730/10000], train_Loss: 0.00010186713188886642,test_Loss:22.889812469482422, r2_store:-0.3699101344409139\n",
            "Epoch [9731/10000], train_Loss: 9.432415390620008e-05,test_Loss:22.875429153442383, r2_store:-0.3686613976504254\n",
            "Epoch [9732/10000], train_Loss: 8.462360710836947e-05,test_Loss:22.88669776916504, r2_store:-0.36956095380764653\n",
            "Epoch [9733/10000], train_Loss: 7.531243318226188e-05,test_Loss:22.880334854125977, r2_store:-0.36893694736343674\n",
            "Epoch [9734/10000], train_Loss: 6.892452802276239e-05,test_Loss:22.885082244873047, r2_store:-0.3691815100130109\n",
            "Epoch [9735/10000], train_Loss: 6.590427801711485e-05,test_Loss:22.88448715209961, r2_store:-0.36926966132159134\n",
            "Epoch [9736/10000], train_Loss: 6.604329246329144e-05,test_Loss:22.882160186767578, r2_store:-0.3688793188981805\n",
            "Epoch [9737/10000], train_Loss: 6.854729144833982e-05,test_Loss:22.89103889465332, r2_store:-0.36945959068321566\n",
            "Epoch [9738/10000], train_Loss: 7.151706813601777e-05,test_Loss:22.883535385131836, r2_store:-0.3686193951379646\n",
            "Epoch [9739/10000], train_Loss: 7.40852628950961e-05,test_Loss:22.896106719970703, r2_store:-0.36949690503736976\n",
            "Epoch [9740/10000], train_Loss: 7.527007255703211e-05,test_Loss:22.884262084960938, r2_store:-0.36854126749456584\n",
            "Epoch [9741/10000], train_Loss: 7.492379518225789e-05,test_Loss:22.89649200439453, r2_store:-0.3694367463863222\n",
            "Epoch [9742/10000], train_Loss: 7.30931424186565e-05,test_Loss:22.8881778717041, r2_store:-0.36860539434392114\n",
            "Epoch [9743/10000], train_Loss: 7.053416629787534e-05,test_Loss:22.896116256713867, r2_store:-0.3693339128019375\n",
            "Epoch [9744/10000], train_Loss: 6.756344373570755e-05,test_Loss:22.889347076416016, r2_store:-0.3687062538279793\n",
            "Epoch [9745/10000], train_Loss: 6.479941657744348e-05,test_Loss:22.898277282714844, r2_store:-0.369125187214296\n",
            "Epoch [9746/10000], train_Loss: 6.232429586816579e-05,test_Loss:22.89547348022461, r2_store:-0.3687646505487594\n",
            "Epoch [9747/10000], train_Loss: 6.064522312954068e-05,test_Loss:22.897111892700195, r2_store:-0.36889523994720874\n",
            "Epoch [9748/10000], train_Loss: 5.959737973171286e-05,test_Loss:22.898082733154297, r2_store:-0.3688627561183948\n",
            "Epoch [9749/10000], train_Loss: 5.897876690141857e-05,test_Loss:22.89632797241211, r2_store:-0.36877105503669694\n",
            "Epoch [9750/10000], train_Loss: 5.878185766050592e-05,test_Loss:22.89911460876465, r2_store:-0.36892622786416185\n",
            "Epoch [9751/10000], train_Loss: 5.877741568838246e-05,test_Loss:22.898197174072266, r2_store:-0.3686781884735908\n",
            "Epoch [9752/10000], train_Loss: 5.8869853091891855e-05,test_Loss:22.901647567749023, r2_store:-0.3689790648014746\n",
            "Epoch [9753/10000], train_Loss: 5.8950885431841016e-05,test_Loss:22.897930145263672, r2_store:-0.3686339806591661\n",
            "Epoch [9754/10000], train_Loss: 5.8910343796014786e-05,test_Loss:22.904224395751953, r2_store:-0.36902505780567063\n",
            "Epoch [9755/10000], train_Loss: 5.873155896551907e-05,test_Loss:22.898378372192383, r2_store:-0.3686260911451056\n",
            "Epoch [9756/10000], train_Loss: 5.852895992575213e-05,test_Loss:22.90375518798828, r2_store:-0.36901885947047464\n",
            "Epoch [9757/10000], train_Loss: 5.8086152421310544e-05,test_Loss:22.90094757080078, r2_store:-0.3685989936684979\n",
            "Epoch [9758/10000], train_Loss: 5.772485019406304e-05,test_Loss:22.905948638916016, r2_store:-0.3689524240503388\n",
            "Epoch [9759/10000], train_Loss: 5.726009112549946e-05,test_Loss:22.90188217163086, r2_store:-0.3685656951790639\n",
            "Epoch [9760/10000], train_Loss: 5.6687054893700406e-05,test_Loss:22.906747817993164, r2_store:-0.3689119085811703\n",
            "Epoch [9761/10000], train_Loss: 5.6060256611090153e-05,test_Loss:22.90282440185547, r2_store:-0.3685735939094785\n",
            "Epoch [9762/10000], train_Loss: 5.550269270315766e-05,test_Loss:22.907310485839844, r2_store:-0.3688569638463377\n",
            "Epoch [9763/10000], train_Loss: 5.5038581194821745e-05,test_Loss:22.90512466430664, r2_store:-0.3685360625568479\n",
            "Epoch [9764/10000], train_Loss: 5.46714109077584e-05,test_Loss:22.909574508666992, r2_store:-0.3687873350927353\n",
            "Epoch [9765/10000], train_Loss: 5.4142885346664116e-05,test_Loss:22.90677261352539, r2_store:-0.36849411359441686\n",
            "Epoch [9766/10000], train_Loss: 5.372480518417433e-05,test_Loss:22.910701751708984, r2_store:-0.3687331647059675\n",
            "Epoch [9767/10000], train_Loss: 5.338420669431798e-05,test_Loss:22.908388137817383, r2_store:-0.3684772333934436\n",
            "Epoch [9768/10000], train_Loss: 5.3036616009194404e-05,test_Loss:22.911563873291016, r2_store:-0.36872816592011737\n",
            "Epoch [9769/10000], train_Loss: 5.2708666771650314e-05,test_Loss:22.90872573852539, r2_store:-0.3684902406991888\n",
            "Epoch [9770/10000], train_Loss: 5.2461477025644854e-05,test_Loss:22.912012100219727, r2_store:-0.3687390447366936\n",
            "Epoch [9771/10000], train_Loss: 5.2268813306000084e-05,test_Loss:22.910213470458984, r2_store:-0.368440945594972\n",
            "Epoch [9772/10000], train_Loss: 5.200875966693275e-05,test_Loss:22.915218353271484, r2_store:-0.36869761936134093\n",
            "Epoch [9773/10000], train_Loss: 5.203033651923761e-05,test_Loss:22.911725997924805, r2_store:-0.36835242262737045\n",
            "Epoch [9774/10000], train_Loss: 5.2054405387025326e-05,test_Loss:22.915664672851562, r2_store:-0.36868544144508664\n",
            "Epoch [9775/10000], train_Loss: 5.208885340834968e-05,test_Loss:22.911542892456055, r2_store:-0.3682840445335871\n",
            "Epoch [9776/10000], train_Loss: 5.228411828284152e-05,test_Loss:22.917102813720703, r2_store:-0.3687332690664027\n",
            "Epoch [9777/10000], train_Loss: 5.278973185340874e-05,test_Loss:22.9111328125, r2_store:-0.3682072917176633\n",
            "Epoch [9778/10000], train_Loss: 5.371886072680354e-05,test_Loss:22.919092178344727, r2_store:-0.3687864064761581\n",
            "Epoch [9779/10000], train_Loss: 5.4861477110534906e-05,test_Loss:22.912769317626953, r2_store:-0.36805707394866216\n",
            "Epoch [9780/10000], train_Loss: 5.636251808027737e-05,test_Loss:22.92393684387207, r2_store:-0.3688273594624265\n",
            "Epoch [9781/10000], train_Loss: 5.913976929150522e-05,test_Loss:22.913476943969727, r2_store:-0.3678679507709004\n",
            "Epoch [9782/10000], train_Loss: 6.318974919850007e-05,test_Loss:22.926044464111328, r2_store:-0.3689955000709557\n",
            "Epoch [9783/10000], train_Loss: 6.911734817549586e-05,test_Loss:22.910831451416016, r2_store:-0.36767353539136316\n",
            "Epoch [9784/10000], train_Loss: 7.796836871420965e-05,test_Loss:22.929271697998047, r2_store:-0.36929749084133845\n",
            "Epoch [9785/10000], train_Loss: 9.117433364735916e-05,test_Loss:22.907060623168945, r2_store:-0.367360438882393\n",
            "Epoch [9786/10000], train_Loss: 0.00011081593402195722,test_Loss:22.934467315673828, r2_store:-0.36968791955393865\n",
            "Epoch [9787/10000], train_Loss: 0.0001404037029715255,test_Loss:22.902969360351562, r2_store:-0.36679322292637684\n",
            "Epoch [9788/10000], train_Loss: 0.0001843609061324969,test_Loss:22.94502067565918, r2_store:-0.3702109900841122\n",
            "Epoch [9789/10000], train_Loss: 0.00025056119193322957,test_Loss:22.89638900756836, r2_store:-0.3659701430593525\n",
            "Epoch [9790/10000], train_Loss: 0.00035082828253507614,test_Loss:22.95572853088379, r2_store:-0.3711350484970668\n",
            "Epoch [9791/10000], train_Loss: 0.0005026066792197526,test_Loss:22.882518768310547, r2_store:-0.36481855824020415\n",
            "Epoch [9792/10000], train_Loss: 0.0007332467357628047,test_Loss:22.9765625, r2_store:-0.3726402840439844\n",
            "Epoch [9793/10000], train_Loss: 0.0010656493250280619,test_Loss:22.85733985900879, r2_store:-0.36322110203848257\n",
            "Epoch [9794/10000], train_Loss: 0.0015307094436138868,test_Loss:23.001291275024414, r2_store:-0.37466198240647186\n",
            "Epoch [9795/10000], train_Loss: 0.002199663082137704,test_Loss:22.840526580810547, r2_store:-0.36101035417402527\n",
            "Epoch [9796/10000], train_Loss: 0.003192536998540163,test_Loss:23.03470802307129, r2_store:-0.377652864033021\n",
            "Epoch [9797/10000], train_Loss: 0.004599342588335276,test_Loss:22.806222915649414, r2_store:-0.3579900098610991\n",
            "Epoch [9798/10000], train_Loss: 0.006598263047635555,test_Loss:23.08709144592285, r2_store:-0.38187450746921314\n",
            "Epoch [9799/10000], train_Loss: 0.00941363163292408,test_Loss:22.73627471923828, r2_store:-0.3535203201060422\n",
            "Epoch [9800/10000], train_Loss: 0.013417591340839863,test_Loss:23.174283981323242, r2_store:-0.3878054710865195\n",
            "Epoch [9801/10000], train_Loss: 0.018790822476148605,test_Loss:22.678813934326172, r2_store:-0.3482008691499736\n",
            "Epoch [9802/10000], train_Loss: 0.02608022652566433,test_Loss:23.259525299072266, r2_store:-0.3956102864670703\n",
            "Epoch [9803/10000], train_Loss: 0.03493186831474304,test_Loss:22.63705062866211, r2_store:-0.34298796278989685\n",
            "Epoch [9804/10000], train_Loss: 0.04539991170167923,test_Loss:23.341140747070312, r2_store:-0.40355770462188456\n",
            "Epoch [9805/10000], train_Loss: 0.054912369698286057,test_Loss:22.583032608032227, r2_store:-0.3394487939499222\n",
            "Epoch [9806/10000], train_Loss: 0.062076132744550705,test_Loss:23.402706146240234, r2_store:-0.4060458987761617\n",
            "Epoch [9807/10000], train_Loss: 0.06146343797445297,test_Loss:22.618194580078125, r2_store:-0.34154284165092097\n",
            "Epoch [9808/10000], train_Loss: 0.05300554633140564,test_Loss:23.283037185668945, r2_store:-0.396783153687289\n",
            "Epoch [9809/10000], train_Loss: 0.03601563721895218,test_Loss:22.769893646240234, r2_store:-0.3530216251071272\n",
            "Epoch [9810/10000], train_Loss: 0.01763812266290188,test_Loss:23.063358306884766, r2_store:-0.3779099289696721\n",
            "Epoch [9811/10000], train_Loss: 0.004211625549942255,test_Loss:22.981576919555664, r2_store:-0.37028229083561315\n",
            "Epoch [9812/10000], train_Loss: 0.000372771464753896,test_Loss:22.87972640991211, r2_store:-0.3601325873263752\n",
            "Epoch [9813/10000], train_Loss: 0.005250939633697271,test_Loss:23.186033248901367, r2_store:-0.3853436666708949\n",
            "Epoch [9814/10000], train_Loss: 0.013884497806429863,test_Loss:22.74580192565918, r2_store:-0.3510897171450458\n",
            "Epoch [9815/10000], train_Loss: 0.020655933767557144,test_Loss:23.247333526611328, r2_store:-0.3896620956095309\n",
            "Epoch [9816/10000], train_Loss: 0.021296322345733643,test_Loss:22.75797462463379, r2_store:-0.3529259740252917\n",
            "Epoch [9817/10000], train_Loss: 0.01624204032123089,test_Loss:23.083847045898438, r2_store:-0.38091493854943637\n",
            "Epoch [9818/10000], train_Loss: 0.008301052264869213,test_Loss:22.895633697509766, r2_store:-0.3628629093841138\n",
            "Epoch [9819/10000], train_Loss: 0.0020952525082975626,test_Loss:22.923343658447266, r2_store:-0.36710243825673916\n",
            "Epoch [9820/10000], train_Loss: 0.00025921137421391904,test_Loss:23.0191707611084, r2_store:-0.3743151560534783\n",
            "Epoch [9821/10000], train_Loss: 0.0026213820092380047,test_Loss:22.845073699951172, r2_store:-0.3574964337145039\n",
            "Epoch [9822/10000], train_Loss: 0.006723714526742697,test_Loss:23.110944747924805, r2_store:-0.38137271189214283\n",
            "Epoch [9823/10000], train_Loss: 0.009656235575675964,test_Loss:22.78481674194336, r2_store:-0.35576607498077517\n",
            "Epoch [9824/10000], train_Loss: 0.00984870083630085,test_Loss:23.102476119995117, r2_store:-0.38055689429688533\n",
            "Epoch [9825/10000], train_Loss: 0.0073385476134717464,test_Loss:22.809871673583984, r2_store:-0.3611631747349806\n",
            "Epoch [9826/10000], train_Loss: 0.0037518322933465242,test_Loss:22.948650360107422, r2_store:-0.3729250752598434\n",
            "Epoch [9827/10000], train_Loss: 0.0009866722393780947,test_Loss:22.926803588867188, r2_store:-0.36963137968380577\n",
            "Epoch [9828/10000], train_Loss: 0.0001948243734659627,test_Loss:22.836519241333008, r2_store:-0.3647208453808122\n",
            "Epoch [9829/10000], train_Loss: 0.00117400661110878,test_Loss:22.97414207458496, r2_store:-0.3761509759303494\n",
            "Epoch [9830/10000], train_Loss: 0.002940597478300333,test_Loss:22.815750122070312, r2_store:-0.3609797609181562\n",
            "Epoch [9831/10000], train_Loss: 0.004319327883422375,test_Loss:23.010086059570312, r2_store:-0.3785671266408277\n",
            "Epoch [9832/10000], train_Loss: 0.004537737928330898,test_Loss:22.798542022705078, r2_store:-0.36206283074205015\n",
            "Epoch [9833/10000], train_Loss: 0.003655343549326062,test_Loss:22.982891082763672, r2_store:-0.37636620237761154\n",
            "Epoch [9834/10000], train_Loss: 0.0021587591618299484,test_Loss:22.84121322631836, r2_store:-0.3667734323141332\n",
            "Epoch [9835/10000], train_Loss: 0.0008124014129862189,test_Loss:22.88263702392578, r2_store:-0.3708765559460456\n",
            "Epoch [9836/10000], train_Loss: 0.00015739118680357933,test_Loss:22.90907096862793, r2_store:-0.3719039037300069\n",
            "Epoch [9837/10000], train_Loss: 0.0003073297266382724,test_Loss:22.82489776611328, r2_store:-0.36611281790440175\n",
            "Epoch [9838/10000], train_Loss: 0.0009569792891852558,test_Loss:22.918588638305664, r2_store:-0.37518076967567326\n",
            "Epoch [9839/10000], train_Loss: 0.001662346301600337,test_Loss:22.805561065673828, r2_store:-0.36422020556880597\n",
            "Epoch [9840/10000], train_Loss: 0.002030547009781003,test_Loss:22.941038131713867, r2_store:-0.3757110538615114\n",
            "Epoch [9841/10000], train_Loss: 0.0019122635712847114,test_Loss:22.80516242980957, r2_store:-0.36510249792247684\n",
            "Epoch [9842/10000], train_Loss: 0.0014188060304149985,test_Loss:22.916336059570312, r2_store:-0.3734843109001371\n",
            "Epoch [9843/10000], train_Loss: 0.0007919219206087291,test_Loss:22.851987838745117, r2_store:-0.36796130241468483\n",
            "Epoch [9844/10000], train_Loss: 0.0003034960536751896,test_Loss:22.867008209228516, r2_store:-0.3699287982169033\n",
            "Epoch [9845/10000], train_Loss: 0.00010494628077140078,test_Loss:22.892127990722656, r2_store:-0.3710204385925029\n",
            "Epoch [9846/10000], train_Loss: 0.0001857966126408428,test_Loss:22.84850311279297, r2_store:-0.36737398381920117\n",
            "Epoch [9847/10000], train_Loss: 0.00044094250188209116,test_Loss:22.90117073059082, r2_store:-0.37325582592648643\n",
            "Epoch [9848/10000], train_Loss: 0.0007187913288362324,test_Loss:22.823863983154297, r2_store:-0.366321326662538\n",
            "Epoch [9849/10000], train_Loss: 0.0008881156099960208,test_Loss:22.91668701171875, r2_store:-0.37401963831181506\n",
            "Epoch [9850/10000], train_Loss: 0.0009002868901006877,test_Loss:22.810888290405273, r2_store:-0.36658852906795825\n",
            "Epoch [9851/10000], train_Loss: 0.0007675584638491273,test_Loss:22.8963680267334, r2_store:-0.3728753124813238\n",
            "Epoch [9852/10000], train_Loss: 0.0005411161109805107,test_Loss:22.843990325927734, r2_store:-0.36774526840485544\n",
            "Epoch [9853/10000], train_Loss: 0.0003180446510668844,test_Loss:22.87244987487793, r2_store:-0.3706287923059184\n",
            "Epoch [9854/10000], train_Loss: 0.00015911161608528346,test_Loss:22.868759155273438, r2_store:-0.3691997476173092\n",
            "Epoch [9855/10000], train_Loss: 8.224941848311573e-05,test_Loss:22.8707275390625, r2_store:-0.36889992070646205\n",
            "Epoch [9856/10000], train_Loss: 9.773360943654552e-05,test_Loss:22.88034439086914, r2_store:-0.3706662285094857\n",
            "Epoch [9857/10000], train_Loss: 0.00017185317119583488,test_Loss:22.851757049560547, r2_store:-0.3676148204397065\n",
            "Epoch [9858/10000], train_Loss: 0.00026252554380334914,test_Loss:22.90207862854004, r2_store:-0.37164952949176233\n",
            "Epoch [9859/10000], train_Loss: 0.00034651297028176486,test_Loss:22.833675384521484, r2_store:-0.36692023369821225\n",
            "Epoch [9860/10000], train_Loss: 0.00039523691521026194,test_Loss:22.897998809814453, r2_store:-0.37170345468915267\n",
            "Epoch [9861/10000], train_Loss: 0.0003975941217504442,test_Loss:22.851045608520508, r2_store:-0.3669875953102957\n",
            "Epoch [9862/10000], train_Loss: 0.0003665333497337997,test_Loss:22.89255714416504, r2_store:-0.3712282787509362\n",
            "Epoch [9863/10000], train_Loss: 0.00030585963395424187,test_Loss:22.85503387451172, r2_store:-0.3675926840114365\n",
            "Epoch [9864/10000], train_Loss: 0.00023178965784609318,test_Loss:22.89687156677246, r2_store:-0.3707134964708576\n",
            "Epoch [9865/10000], train_Loss: 0.0001657490065554157,test_Loss:22.861278533935547, r2_store:-0.36846001757936286\n",
            "Epoch [9866/10000], train_Loss: 0.00011231748067075387,test_Loss:22.883071899414062, r2_store:-0.36979189354532327\n",
            "Epoch [9867/10000], train_Loss: 7.756440754747018e-05,test_Loss:22.881406784057617, r2_store:-0.36927679672775904\n",
            "Epoch [9868/10000], train_Loss: 6.641220534220338e-05,test_Loss:22.867610931396484, r2_store:-0.3688030713266146\n",
            "Epoch [9869/10000], train_Loss: 7.178499072324485e-05,test_Loss:22.883888244628906, r2_store:-0.36973177796575585\n",
            "Epoch [9870/10000], train_Loss: 8.892215555533767e-05,test_Loss:22.871763229370117, r2_store:-0.3680863978062434\n",
            "Epoch [9871/10000], train_Loss: 0.0001126180068240501,test_Loss:22.89126205444336, r2_store:-0.3700823958329733\n",
            "Epoch [9872/10000], train_Loss: 0.00013494474114850163,test_Loss:22.865541458129883, r2_store:-0.3676996752328976\n",
            "Epoch [9873/10000], train_Loss: 0.0001538510259706527,test_Loss:22.899320602416992, r2_store:-0.3704009324075368\n",
            "Epoch [9874/10000], train_Loss: 0.00016740137652959675,test_Loss:22.86127281188965, r2_store:-0.36757679791500264\n",
            "Epoch [9875/10000], train_Loss: 0.00017324191867373884,test_Loss:22.89659309387207, r2_store:-0.37041785991657306\n",
            "Epoch [9876/10000], train_Loss: 0.00017191644292324781,test_Loss:22.86723518371582, r2_store:-0.36763508699177927\n",
            "Epoch [9877/10000], train_Loss: 0.00016590842278674245,test_Loss:22.891921997070312, r2_store:-0.37023585316038976\n",
            "Epoch [9878/10000], train_Loss: 0.00015509931836277246,test_Loss:22.867019653320312, r2_store:-0.3677010311675488\n",
            "Epoch [9879/10000], train_Loss: 0.00014102451677899808,test_Loss:22.89849090576172, r2_store:-0.3700382735312997\n",
            "Epoch [9880/10000], train_Loss: 0.000128361934912391,test_Loss:22.8677921295166, r2_store:-0.3678726181923617\n",
            "Epoch [9881/10000], train_Loss: 0.00011536052625160664,test_Loss:22.893970489501953, r2_store:-0.36984289636743384\n",
            "Epoch [9882/10000], train_Loss: 0.00010233985085505992,test_Loss:22.875104904174805, r2_store:-0.3681727535609798\n",
            "Epoch [9883/10000], train_Loss: 9.126057557296008e-05,test_Loss:22.88886070251465, r2_store:-0.3696034184037569\n",
            "Epoch [9884/10000], train_Loss: 8.20971472421661e-05,test_Loss:22.875965118408203, r2_store:-0.36832771907234907\n",
            "Epoch [9885/10000], train_Loss: 7.403285417240113e-05,test_Loss:22.891582489013672, r2_store:-0.36937502907165465\n",
            "Epoch [9886/10000], train_Loss: 6.810834020143375e-05,test_Loss:22.878711700439453, r2_store:-0.3684089880142569\n",
            "Epoch [9887/10000], train_Loss: 6.321083492366597e-05,test_Loss:22.8919620513916, r2_store:-0.3690900999204467\n",
            "Epoch [9888/10000], train_Loss: 5.9648853493854403e-05,test_Loss:22.88730239868164, r2_store:-0.3684948968532784\n",
            "Epoch [9889/10000], train_Loss: 5.735044396715239e-05,test_Loss:22.889137268066406, r2_store:-0.3689324688814952\n",
            "Epoch [9890/10000], train_Loss: 5.561843136092648e-05,test_Loss:22.886348724365234, r2_store:-0.3685886769203277\n",
            "Epoch [9891/10000], train_Loss: 5.4008552979212254e-05,test_Loss:22.891677856445312, r2_store:-0.3688858515015201\n",
            "Epoch [9892/10000], train_Loss: 5.3396448493003845e-05,test_Loss:22.88653564453125, r2_store:-0.3686339328522623\n",
            "Epoch [9893/10000], train_Loss: 5.2598410547943786e-05,test_Loss:22.891265869140625, r2_store:-0.3688045845754866\n",
            "Epoch [9894/10000], train_Loss: 5.184831752558239e-05,test_Loss:22.892658233642578, r2_store:-0.3686689523531299\n",
            "Epoch [9895/10000], train_Loss: 5.1613013056339696e-05,test_Loss:22.89179801940918, r2_store:-0.36876428852133025\n",
            "Epoch [9896/10000], train_Loss: 5.117269029142335e-05,test_Loss:22.892314910888672, r2_store:-0.36867087507229535\n",
            "Epoch [9897/10000], train_Loss: 5.062054333393462e-05,test_Loss:22.895076751708984, r2_store:-0.36879371721172594\n",
            "Epoch [9898/10000], train_Loss: 5.049078754382208e-05,test_Loss:22.890840530395508, r2_store:-0.36864768190141195\n",
            "Epoch [9899/10000], train_Loss: 5.0155278586316854e-05,test_Loss:22.894943237304688, r2_store:-0.3687340149541847\n",
            "Epoch [9900/10000], train_Loss: 4.971703310729936e-05,test_Loss:22.89634895324707, r2_store:-0.3686031764433053\n",
            "Epoch [9901/10000], train_Loss: 4.961392914992757e-05,test_Loss:22.89558982849121, r2_store:-0.3686948713477094\n",
            "Epoch [9902/10000], train_Loss: 4.9344256694894284e-05,test_Loss:22.89602279663086, r2_store:-0.36855422946932737\n",
            "Epoch [9903/10000], train_Loss: 4.896689279121347e-05,test_Loss:22.90007972717285, r2_store:-0.36873903324511326\n",
            "Epoch [9904/10000], train_Loss: 4.889866249868646e-05,test_Loss:22.89592170715332, r2_store:-0.36847556023655637\n",
            "Epoch [9905/10000], train_Loss: 4.89209960505832e-05,test_Loss:22.901538848876953, r2_store:-0.36872321836945066\n",
            "Epoch [9906/10000], train_Loss: 4.896405880572274e-05,test_Loss:22.89851188659668, r2_store:-0.3683610795423091\n",
            "Epoch [9907/10000], train_Loss: 4.94823616463691e-05,test_Loss:22.901674270629883, r2_store:-0.36875879766490205\n",
            "Epoch [9908/10000], train_Loss: 5.024011989007704e-05,test_Loss:22.896739959716797, r2_store:-0.3682507126775596\n",
            "Epoch [9909/10000], train_Loss: 5.1324179366929457e-05,test_Loss:22.905826568603516, r2_store:-0.3688928630894306\n",
            "Epoch [9910/10000], train_Loss: 5.340848656487651e-05,test_Loss:22.89432144165039, r2_store:-0.3681043737499299\n",
            "Epoch [9911/10000], train_Loss: 5.654435881297104e-05,test_Loss:22.907413482666016, r2_store:-0.3690649667511561\n",
            "Epoch [9912/10000], train_Loss: 6.14301607129164e-05,test_Loss:22.893882751464844, r2_store:-0.36788415468043345\n",
            "Epoch [9913/10000], train_Loss: 6.876652332721278e-05,test_Loss:22.91146469116211, r2_store:-0.36928909274612276\n",
            "Epoch [9914/10000], train_Loss: 8.022335532587022e-05,test_Loss:22.89053726196289, r2_store:-0.36752113166355604\n",
            "Epoch [9915/10000], train_Loss: 9.737837535794824e-05,test_Loss:22.91867446899414, r2_store:-0.36969699655077615\n",
            "Epoch [9916/10000], train_Loss: 0.00012459143181331456,test_Loss:22.884136199951172, r2_store:-0.3669868155538418\n",
            "Epoch [9917/10000], train_Loss: 0.00016590801533311605,test_Loss:22.927173614501953, r2_store:-0.37029779659276274\n",
            "Epoch [9918/10000], train_Loss: 0.00023050792515277863,test_Loss:22.87702751159668, r2_store:-0.36619213765168124\n",
            "Epoch [9919/10000], train_Loss: 0.00033038415131159127,test_Loss:22.940513610839844, r2_store:-0.37129962021057894\n",
            "Epoch [9920/10000], train_Loss: 0.0004885179223492742,test_Loss:22.860193252563477, r2_store:-0.36492899505084186\n",
            "Epoch [9921/10000], train_Loss: 0.0007363149197772145,test_Loss:22.960094451904297, r2_store:-0.3729178858170801\n",
            "Epoch [9922/10000], train_Loss: 0.0011298339813947678,test_Loss:22.838403701782227, r2_store:-0.36293271157348816\n",
            "Epoch [9923/10000], train_Loss: 0.0017541811103001237,test_Loss:22.993101119995117, r2_store:-0.37549997773321286\n",
            "Epoch [9924/10000], train_Loss: 0.0027506989426910877,test_Loss:22.80217933654785, r2_store:-0.35974017845703865\n",
            "Epoch [9925/10000], train_Loss: 0.004346237517893314,test_Loss:23.049579620361328, r2_store:-0.379771647696693\n",
            "Epoch [9926/10000], train_Loss: 0.0068832142278552055,test_Loss:22.74106216430664, r2_store:-0.35487895558780846\n",
            "Epoch [9927/10000], train_Loss: 0.010937260463833809,test_Loss:23.132280349731445, r2_store:-0.3869501231856709\n",
            "Epoch [9928/10000], train_Loss: 0.017224758863449097,test_Loss:22.68156623840332, r2_store:-0.34813895932470507\n",
            "Epoch [9929/10000], train_Loss: 0.027053704485297203,test_Loss:23.25469970703125, r2_store:-0.3984666185401169\n",
            "Epoch [9930/10000], train_Loss: 0.041354067623615265,test_Loss:22.58393669128418, r2_store:-0.33977065250097094\n",
            "Epoch [9931/10000], train_Loss: 0.06134945899248123,test_Loss:23.46529769897461, r2_store:-0.4138957435950956\n",
            "Epoch [9932/10000], train_Loss: 0.08427349478006363,test_Loss:22.472774505615234, r2_store:-0.3320223701944205\n",
            "Epoch [9933/10000], train_Loss: 0.10810112953186035,test_Loss:23.563779830932617, r2_store:-0.4233780093974211\n",
            "Epoch [9934/10000], train_Loss: 0.11760900914669037,test_Loss:22.479633331298828, r2_store:-0.33249380094869485\n",
            "Epoch [9935/10000], train_Loss: 0.10756297409534454,test_Loss:23.345693588256836, r2_store:-0.408435126845587\n",
            "Epoch [9936/10000], train_Loss: 0.06932798027992249,test_Loss:22.6864013671875, r2_store:-0.34917849299532167\n",
            "Epoch [9937/10000], train_Loss: 0.026170829311013222,test_Loss:22.983705520629883, r2_store:-0.3732865503337912\n",
            "Epoch [9938/10000], train_Loss: 0.0018682999070733786,test_Loss:23.06585693359375, r2_store:-0.38005020777219056\n",
            "Epoch [9939/10000], train_Loss: 0.008134473115205765,test_Loss:22.729286193847656, r2_store:-0.3473771702774413\n",
            "Epoch [9940/10000], train_Loss: 0.031469546258449554,test_Loss:23.405847549438477, r2_store:-0.4009048817047711\n",
            "Epoch [9941/10000], train_Loss: 0.0469348281621933,test_Loss:22.64651870727539, r2_store:-0.34625211287367685\n",
            "Epoch [9942/10000], train_Loss: 0.040869180113077164,test_Loss:23.173934936523438, r2_store:-0.38968086652087264\n",
            "Epoch [9943/10000], train_Loss: 0.018361128866672516,test_Loss:22.909530639648438, r2_store:-0.36578822034780845\n",
            "Epoch [9944/10000], train_Loss: 0.002254319842904806,test_Loss:22.794532775878906, r2_store:-0.3616571597559328\n",
            "Epoch [9945/10000], train_Loss: 0.00419961754232645,test_Loss:23.13302230834961, r2_store:-0.3869754215646821\n",
            "Epoch [9946/10000], train_Loss: 0.01725955680012703,test_Loss:22.69778060913086, r2_store:-0.34953532841420487\n",
            "Epoch [9947/10000], train_Loss: 0.025845352560281754,test_Loss:23.086875915527344, r2_store:-0.38740507388380574\n",
            "Epoch [9948/10000], train_Loss: 0.02021647058427334,test_Loss:22.74155044555664, r2_store:-0.3566413448376784\n",
            "Epoch [9949/10000], train_Loss: 0.007676373235881329,test_Loss:22.971845626831055, r2_store:-0.3694568256177435\n",
            "Epoch [9950/10000], train_Loss: 0.000841330096591264,test_Loss:22.960521697998047, r2_store:-0.3752327673508473\n",
            "Epoch [9951/10000], train_Loss: 0.003688853234052658,test_Loss:22.698633193969727, r2_store:-0.35484214834581596\n",
            "Epoch [9952/10000], train_Loss: 0.011200765147805214,test_Loss:23.155925750732422, r2_store:-0.3847745527979056\n",
            "Epoch [9953/10000], train_Loss: 0.014419803395867348,test_Loss:22.756433486938477, r2_store:-0.35527670854014737\n",
            "Epoch [9954/10000], train_Loss: 0.01011900044977665,test_Loss:22.941898345947266, r2_store:-0.375019483491426\n",
            "Epoch [9955/10000], train_Loss: 0.003520095022395253,test_Loss:22.896114349365234, r2_store:-0.36854827413168834\n",
            "Epoch [9956/10000], train_Loss: 0.00043303886195644736,test_Loss:22.795194625854492, r2_store:-0.3631108097282294\n",
            "Epoch [9957/10000], train_Loss: 0.0026149386540055275,test_Loss:22.932537078857422, r2_store:-0.38016666726432846\n",
            "Epoch [9958/10000], train_Loss: 0.006680747959762812,test_Loss:22.698719024658203, r2_store:-0.35893220538172566\n",
            "Epoch [9959/10000], train_Loss: 0.007845750078558922,test_Loss:22.963424682617188, r2_store:-0.3804760802492728\n",
            "Epoch [9960/10000], train_Loss: 0.005359207279980183,test_Loss:22.724857330322266, r2_store:-0.36528670784625117\n",
            "Epoch [9961/10000], train_Loss: 0.0017819622298702598,test_Loss:22.803791046142578, r2_store:-0.36980769267224867\n",
            "Epoch [9962/10000], train_Loss: 0.000282394903479144,test_Loss:22.931058883666992, r2_store:-0.3747455968079576\n",
            "Epoch [9963/10000], train_Loss: 0.0016000301111489534,test_Loss:22.747268676757812, r2_store:-0.36185589483416014\n",
            "Epoch [9964/10000], train_Loss: 0.0036520243156701326,test_Loss:22.928211212158203, r2_store:-0.37816479950312476\n",
            "Epoch [9965/10000], train_Loss: 0.0043094949796795845,test_Loss:22.781827926635742, r2_store:-0.36310730967015314\n",
            "Epoch [9966/10000], train_Loss: 0.0030321769881993532,test_Loss:22.89255142211914, r2_store:-0.3741232068463105\n",
            "Epoch [9967/10000], train_Loss: 0.0011243701446801424,test_Loss:22.806941986083984, r2_store:-0.36990533407825543\n",
            "Epoch [9968/10000], train_Loss: 0.00024401312111876905,test_Loss:22.79169273376465, r2_store:-0.36764581002643415\n",
            "Epoch [9969/10000], train_Loss: 0.0007604487473145127,test_Loss:22.890213012695312, r2_store:-0.37643053355977196\n",
            "Epoch [9970/10000], train_Loss: 0.001869117608293891,test_Loss:22.725879669189453, r2_store:-0.36435910246972636\n",
            "Epoch [9971/10000], train_Loss: 0.002378744538873434,test_Loss:22.890995025634766, r2_store:-0.3761219404642142\n",
            "Epoch [9972/10000], train_Loss: 0.0018595773726701736,test_Loss:22.790122985839844, r2_store:-0.3672311986248713\n",
            "Epoch [9973/10000], train_Loss: 0.0008685069042257965,test_Loss:22.813520431518555, r2_store:-0.3716070063975816\n",
            "Epoch [9974/10000], train_Loss: 0.0002219673478975892,test_Loss:22.83047866821289, r2_store:-0.3724339467150992\n",
            "Epoch [9975/10000], train_Loss: 0.0003066994249820709,test_Loss:22.79003143310547, r2_store:-0.3674179041294259\n",
            "Epoch [9976/10000], train_Loss: 0.0008578422712162137,test_Loss:22.86553382873535, r2_store:-0.3752005056174965\n",
            "Epoch [9977/10000], train_Loss: 0.0012737179640680552,test_Loss:22.756717681884766, r2_store:-0.3662551443364752\n",
            "Epoch [9978/10000], train_Loss: 0.0012158321915194392,test_Loss:22.86105728149414, r2_store:-0.37394450732073103\n",
            "Epoch [9979/10000], train_Loss: 0.000769272621255368,test_Loss:22.795169830322266, r2_store:-0.3687017646003117\n",
            "Epoch [9980/10000], train_Loss: 0.00030145241180434823,test_Loss:22.80514144897461, r2_store:-0.37015342977350096\n",
            "Epoch [9981/10000], train_Loss: 0.00013994009350426495,test_Loss:22.83745765686035, r2_store:-0.3721747832019624\n",
            "Epoch [9982/10000], train_Loss: 0.0002993814123328775,test_Loss:22.777809143066406, r2_store:-0.3676313354214005\n",
            "Epoch [9983/10000], train_Loss: 0.0005831214366480708,test_Loss:22.835737228393555, r2_store:-0.3736833042308392\n",
            "Epoch [9984/10000], train_Loss: 0.0007381433970294893,test_Loss:22.771928787231445, r2_store:-0.36731862426748796\n",
            "Epoch [9985/10000], train_Loss: 0.0006482970202341676,test_Loss:22.837263107299805, r2_store:-0.3726323755054335\n",
            "Epoch [9986/10000], train_Loss: 0.00041293975664302707,test_Loss:22.777645111083984, r2_store:-0.36895846147899247\n",
            "Epoch [9987/10000], train_Loss: 0.0001919780916068703,test_Loss:22.79646873474121, r2_store:-0.37000208128797807\n",
            "Epoch [9988/10000], train_Loss: 0.00011297775199636817,test_Loss:22.822891235351562, r2_store:-0.37124582580104093\n",
            "Epoch [9989/10000], train_Loss: 0.00018884707242250443,test_Loss:22.777246475219727, r2_store:-0.36805446842535483\n",
            "Epoch [9990/10000], train_Loss: 0.00032052319147624075,test_Loss:22.83096694946289, r2_store:-0.372399830882018\n",
            "Epoch [9991/10000], train_Loss: 0.00040501117473468184,test_Loss:22.788524627685547, r2_store:-0.36790927167718546\n",
            "Epoch [9992/10000], train_Loss: 0.00039167609065771103,test_Loss:22.83086585998535, r2_store:-0.37185423388555283\n",
            "Epoch [9993/10000], train_Loss: 0.00028922970523126423,test_Loss:22.79616928100586, r2_store:-0.36872357360256114\n",
            "Epoch [9994/10000], train_Loss: 0.00017432306776754558,test_Loss:22.82227897644043, r2_store:-0.37020587371171\n",
            "Epoch [9995/10000], train_Loss: 0.00010530458530411124,test_Loss:22.814390182495117, r2_store:-0.37011393981138085\n",
            "Epoch [9996/10000], train_Loss: 0.00010519036732148379,test_Loss:22.79459571838379, r2_store:-0.36850436418821086\n",
            "Epoch [9997/10000], train_Loss: 0.00015618176257703453,test_Loss:22.833927154541016, r2_store:-0.37101062357733117\n",
            "Epoch [9998/10000], train_Loss: 0.00020946520089637488,test_Loss:22.795921325683594, r2_store:-0.36793538543372595\n",
            "Epoch [9999/10000], train_Loss: 0.00023016054183244705,test_Loss:22.825326919555664, r2_store:-0.3709771802543953\n",
            "Epoch [10000/10000], train_Loss: 0.0002092307258863002,test_Loss:22.804576873779297, r2_store:-0.3684627783754464\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 定义CNN模型\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1,16,5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        # self.conv2 = nn.Conv1d(16,32,2)\n",
        "        # self.fc1 = nn.Linear(32 * 64, 64)  # 根据输入大小调整线性层的输入大小\n",
        "        self.flat1 = nn.Flatten()\n",
        "        self.fc2 = nn.Linear(152, 1)  # 输出一个连续的回归值\n",
        "        self.dropout = nn.Dropout(p=0.5)  # dropout训练\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)\n",
        "        # print(y.size())\n",
        "        y = self.relu1(y)\n",
        "        # print(y.size())\n",
        "        y = self.pool1(y)\n",
        "        # print(y.size())\n",
        "        y = self.flat1(y)\n",
        "        y = self.dropout(y)\n",
        "        # print(y.size())\n",
        "        y = self.fc2(y)\n",
        "        # print(y.size())\n",
        "        y = self.dropout(y)\n",
        "        # y = self.conv2(y)\n",
        "        # y = self.relu2(y)\n",
        "        # y = self.pool2(y)\n",
        "        # y = self.conv3(y)\n",
        "        # y = self.relu3(y)\n",
        "        # y = self.pool3(y)\n",
        "        return y\n",
        "\n",
        "#两层卷积层，后面接一个全连接层\n",
        "class D1CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(D1CNN, self).__init__()\n",
        "        self.model1 = nn.Sequential(\n",
        "        \t#输入通道一定为1，输出通道为卷积核的个数，2为卷积核的大小（实际为一个[1,2]大小的卷积核）\n",
        "            nn.Conv1d(1, 8, 2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.MaxPool1d(2),  # 输出大小：torch.Size([128, 16, 5])\n",
        "            nn.Conv1d(8, 16, 2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.MaxPool1d(4),  # 输出大小：torch.Size([128, 32, 1])\n",
        "            nn.Flatten(),  # 输出大小：torch.Size([128, 32])\n",
        "        )\n",
        "        self.model2 = nn.Sequential(\n",
        "            nn.Linear(in_features=128, out_features=1, bias=True),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "    def forward(self, input):\n",
        "        x = self.model1(input)\n",
        "        x = self.dropout(x)\n",
        "        # print(x.size())\n",
        "        x = self.model2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# 定义神经网络模型\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.relu1 = nn.ReLU()  # 添加ReLU激活函数\n",
        "        # self.fc2 = nn.Linear(64, 32)\n",
        "        self.relu2 = nn.ReLU()  # 添加ReLU激活函数\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x) # 应用ReLU激活函数\n",
        "        x = self.dropout(x)\n",
        "        # x = self.relu2(self.fc2(x))  # 应用ReLU激活函数\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# # 定义神经网络模型\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self, input_size):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.fc1 = nn.Linear(input_size, 64)\n",
        "#         self.fc2 = nn.Linear(64, 32)\n",
        "#         self.fc3 = nn.Linear(32, 1)\n",
        "#         self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = torch.relu(self.fc1(x))\n",
        "#         x = torch.relu(self.fc2(x))\n",
        "#         x = self.fc3(x)  # 在回归中，输出层通常不使用激活函数\n",
        "#         x = self.dropout(x)\n",
        "#         return x\n",
        "\n",
        "# 创建模型实例\n",
        "input_size = X_train.shape[1]\n",
        "# model = Net(input_size)\n",
        "model = CNNModel()\n",
        "# model= D1CNN()\n",
        "# 定义均方误差损失函数和优化器\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 10000\n",
        "num_plot=100\n",
        "train_plot=[]\n",
        "dev_plot=[]\n",
        "r2_list=[]\n",
        "step=int(num_epochs/num_plot)\n",
        "for epoch in range(num_epochs):\n",
        "    # print(X_train.size())\n",
        "    # 前向传播\n",
        "    outputs = model(X_train)\n",
        "    # print(X_train.size())\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # 反向传播和优化\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # 测试模型\n",
        "    model.eval()\n",
        "    # print(\"1\")\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test)\n",
        "        test_loss = criterion(test_outputs, y_test)\n",
        "        r2 = r2_score(test_outputs, y_test)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], train_Loss: {loss.item()},test_Loss:{test_loss.item()}, r2_store:{r2}')\n",
        "        if epoch%step==0:\n",
        "          train_plot.append(loss.item())\n",
        "          dev_plot.append(test_loss.item())\n",
        "          r2_list.append(r2)\n",
        "    # print(f'Test Mean Squared Error (MSE): {test_loss.item()}')\n",
        "\n",
        "t = list(range(1, num_epochs + 1, step))\n",
        "plt.title('mse')\n",
        "plt.plot(t, train_plot, color='red', label='train mse')\n",
        "plt.plot(t, dev_plot, color='blue', label='dev mse')\n",
        "\n",
        "plt.legend()\n",
        "plt.ylim(0,10)\n",
        "plt.show()\n",
        "\n",
        "plt.title('r2')\n",
        "plt.plot(t, r2_list, color='red', label='r2_list')\n",
        "plt.legend()\n",
        "# plt.ylim(0,10)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zxpYVLTNMey"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwbduSJEBRtr"
      },
      "source": [
        "#### 神经网络\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l1hUwJwGY7K6",
        "outputId": "c0f95a5d-a312-48b5-e43a-e31134165a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "torch.Size([80, 42])\n",
            "Epoch [7501/10000], train_Loss: 2.548709398912663e-13,test_Loss:5.288077354431152, r2_store:0.3242450056353182\n",
            "torch.Size([80, 42])\n",
            "Epoch [7502/10000], train_Loss: 4.1459704050970936e-13,test_Loss:5.288077354431152, r2_store:0.3242450382197458\n",
            "torch.Size([80, 42])\n",
            "Epoch [7503/10000], train_Loss: 3.2171045883690186e-13,test_Loss:5.288077354431152, r2_store:0.32424499120464545\n",
            "torch.Size([80, 42])\n",
            "Epoch [7504/10000], train_Loss: 3.0187628113388654e-13,test_Loss:5.288078784942627, r2_store:0.3242449920244648\n",
            "torch.Size([80, 42])\n",
            "Epoch [7505/10000], train_Loss: 4.586204463072341e-13,test_Loss:5.288078784942627, r2_store:0.32424501765434\n",
            "torch.Size([80, 42])\n",
            "Epoch [7506/10000], train_Loss: 3.2450414967979957e-13,test_Loss:5.288079261779785, r2_store:0.32424497161351373\n",
            "torch.Size([80, 42])\n",
            "Epoch [7507/10000], train_Loss: 2.887325253018991e-13,test_Loss:5.288079738616943, r2_store:0.3242449582705693\n",
            "torch.Size([80, 42])\n",
            "Epoch [7508/10000], train_Loss: 2.769241541807077e-13,test_Loss:5.288079261779785, r2_store:0.3242449543582221\n",
            "torch.Size([80, 42])\n",
            "Epoch [7509/10000], train_Loss: 2.5870023354426785e-13,test_Loss:5.288079261779785, r2_store:0.324244998359267\n",
            "torch.Size([80, 42])\n",
            "Epoch [7510/10000], train_Loss: 2.846947666761829e-13,test_Loss:5.288080215454102, r2_store:0.32424493603106674\n",
            "torch.Size([80, 42])\n",
            "Epoch [7511/10000], train_Loss: 3.7077315501697627e-13,test_Loss:5.288080215454102, r2_store:0.324244951538315\n",
            "torch.Size([80, 42])\n",
            "Epoch [7512/10000], train_Loss: 2.5816648081475324e-13,test_Loss:5.288079261779785, r2_store:0.3242449698428278\n",
            "torch.Size([80, 42])\n",
            "Epoch [7513/10000], train_Loss: 3.1685670255111875e-13,test_Loss:5.288079261779785, r2_store:0.32424495077871174\n",
            "torch.Size([80, 42])\n",
            "Epoch [7514/10000], train_Loss: 2.0880505983110476e-13,test_Loss:5.288080215454102, r2_store:0.3242449526131398\n",
            "torch.Size([80, 42])\n",
            "Epoch [7515/10000], train_Loss: 2.5861981284812374e-13,test_Loss:5.288079738616943, r2_store:0.3242449652225191\n",
            "torch.Size([80, 42])\n",
            "Epoch [7516/10000], train_Loss: 1.5923471308881831e-13,test_Loss:5.288078784942627, r2_store:0.32424505585533625\n",
            "torch.Size([80, 42])\n",
            "Epoch [7517/10000], train_Loss: 2.2205276354637926e-13,test_Loss:5.288078784942627, r2_store:0.3242449475985689\n",
            "torch.Size([80, 42])\n",
            "Epoch [7518/10000], train_Loss: 2.0291186537003264e-13,test_Loss:5.288079261779785, r2_store:0.3242449441991345\n",
            "torch.Size([80, 42])\n",
            "Epoch [7519/10000], train_Loss: 2.2700808247066995e-13,test_Loss:5.288078308105469, r2_store:0.3242449763892574\n",
            "torch.Size([80, 42])\n",
            "Epoch [7520/10000], train_Loss: 1.5665001576719434e-13,test_Loss:5.288079261779785, r2_store:0.3242450065506587\n",
            "torch.Size([80, 42])\n",
            "Epoch [7521/10000], train_Loss: 3.2578166509963924e-13,test_Loss:5.288079738616943, r2_store:0.32424490753251334\n",
            "torch.Size([80, 42])\n",
            "Epoch [7522/10000], train_Loss: 1.834347154424168e-13,test_Loss:5.288080215454102, r2_store:0.32424492918359527\n",
            "torch.Size([80, 42])\n",
            "Epoch [7523/10000], train_Loss: 2.393119610897415e-13,test_Loss:5.288078308105469, r2_store:0.3242449718705087\n",
            "torch.Size([80, 42])\n",
            "Epoch [7524/10000], train_Loss: 1.6654459387109577e-13,test_Loss:5.288078308105469, r2_store:0.3242449810218281\n",
            "torch.Size([80, 42])\n",
            "Epoch [7525/10000], train_Loss: 1.6130171742560762e-13,test_Loss:5.288079261779785, r2_store:0.32424499328423506\n",
            "torch.Size([80, 42])\n",
            "Epoch [7526/10000], train_Loss: 1.58651141269478e-13,test_Loss:5.288079738616943, r2_store:0.32424489899913855\n",
            "torch.Size([80, 42])\n",
            "Epoch [7527/10000], train_Loss: 2.0757046526476836e-13,test_Loss:5.288080215454102, r2_store:0.32424494777649093\n",
            "torch.Size([80, 42])\n",
            "Epoch [7528/10000], train_Loss: 9.84265837236653e-14,test_Loss:5.288079261779785, r2_store:0.3242449322631282\n",
            "torch.Size([80, 42])\n",
            "Epoch [7529/10000], train_Loss: 1.2423542012848787e-13,test_Loss:5.288079738616943, r2_store:0.3242449583508433\n",
            "torch.Size([80, 42])\n",
            "Epoch [7530/10000], train_Loss: 1.565220663583139e-13,test_Loss:5.28808069229126, r2_store:0.3242449770207382\n",
            "torch.Size([80, 42])\n",
            "Epoch [7531/10000], train_Loss: 2.3803783380169086e-13,test_Loss:5.288078308105469, r2_store:0.3242450198825093\n",
            "torch.Size([80, 42])\n",
            "Epoch [7532/10000], train_Loss: 3.3221673025399245e-13,test_Loss:5.288078308105469, r2_store:0.32424498284503167\n",
            "torch.Size([80, 42])\n",
            "Epoch [7533/10000], train_Loss: 2.170804090954534e-13,test_Loss:5.288079261779785, r2_store:0.32424494579162244\n",
            "torch.Size([80, 42])\n",
            "Epoch [7534/10000], train_Loss: 3.448863915810063e-13,test_Loss:5.288078308105469, r2_store:0.32424502051810633\n",
            "torch.Size([80, 42])\n",
            "Epoch [7535/10000], train_Loss: 2.657256196764851e-13,test_Loss:5.288078784942627, r2_store:0.32424501158987173\n",
            "torch.Size([80, 42])\n",
            "Epoch [7536/10000], train_Loss: 2.1270717121251587e-13,test_Loss:5.288079261779785, r2_store:0.3242449517135958\n",
            "torch.Size([80, 42])\n",
            "Epoch [7537/10000], train_Loss: 2.899713075991267e-13,test_Loss:5.288079261779785, r2_store:0.32424492591894005\n",
            "torch.Size([80, 42])\n",
            "Epoch [7538/10000], train_Loss: 2.0456292909587503e-13,test_Loss:5.288079261779785, r2_store:0.3242449301518586\n",
            "torch.Size([80, 42])\n",
            "Epoch [7539/10000], train_Loss: 3.361570462094565e-13,test_Loss:5.288079261779785, r2_store:0.3242449220381829\n",
            "torch.Size([80, 42])\n",
            "Epoch [7540/10000], train_Loss: 2.0257116838985623e-13,test_Loss:5.288079738616943, r2_store:0.3242449743291871\n",
            "torch.Size([80, 42])\n",
            "Epoch [7541/10000], train_Loss: 3.848833957705716e-13,test_Loss:5.288079261779785, r2_store:0.3242450010243423\n",
            "torch.Size([80, 42])\n",
            "Epoch [7542/10000], train_Loss: 2.667401076492798e-13,test_Loss:5.288079261779785, r2_store:0.32424498565196014\n",
            "torch.Size([80, 42])\n",
            "Epoch [7543/10000], train_Loss: 2.530044587462782e-13,test_Loss:5.288079738616943, r2_store:0.3242449023013704\n",
            "torch.Size([80, 42])\n",
            "Epoch [7544/10000], train_Loss: 2.1398428005654085e-13,test_Loss:5.288079738616943, r2_store:0.32424489743748863\n",
            "torch.Size([80, 42])\n",
            "Epoch [7545/10000], train_Loss: 2.577467590487298e-13,test_Loss:5.288079261779785, r2_store:0.3242449277089936\n",
            "torch.Size([80, 42])\n",
            "Epoch [7546/10000], train_Loss: 1.9641922908032045e-13,test_Loss:5.288079261779785, r2_store:0.32424498223383347\n",
            "torch.Size([80, 42])\n",
            "Epoch [7547/10000], train_Loss: 1.9185030625777644e-13,test_Loss:5.28808069229126, r2_store:0.3242449905015412\n",
            "torch.Size([80, 42])\n",
            "Epoch [7548/10000], train_Loss: 5.585899039324549e-13,test_Loss:5.288079261779785, r2_store:0.3242450091425667\n",
            "torch.Size([80, 42])\n",
            "Epoch [7549/10000], train_Loss: 5.059867997682377e-13,test_Loss:5.288081169128418, r2_store:0.32424487678146063\n",
            "torch.Size([80, 42])\n",
            "Epoch [7550/10000], train_Loss: 2.4267941172231855e-13,test_Loss:5.288081169128418, r2_store:0.32424493812409183\n",
            "torch.Size([80, 42])\n",
            "Epoch [7551/10000], train_Loss: 3.9997416186390855e-13,test_Loss:5.288079261779785, r2_store:0.3242449633751542\n",
            "torch.Size([80, 42])\n",
            "Epoch [7552/10000], train_Loss: 4.889535499576214e-13,test_Loss:5.288080215454102, r2_store:0.32424489231553877\n",
            "torch.Size([80, 42])\n",
            "Epoch [7553/10000], train_Loss: 2.685690482940456e-13,test_Loss:5.288081169128418, r2_store:0.3242448713080588\n",
            "torch.Size([80, 42])\n",
            "Epoch [7554/10000], train_Loss: 1.7895838348540305e-13,test_Loss:5.28808069229126, r2_store:0.32424490482215873\n",
            "torch.Size([80, 42])\n",
            "Epoch [7555/10000], train_Loss: 3.088032488138964e-13,test_Loss:5.288081169128418, r2_store:0.32424490515473026\n",
            "torch.Size([80, 42])\n",
            "Epoch [7556/10000], train_Loss: 2.387351113238706e-13,test_Loss:5.288081169128418, r2_store:0.3242449653529934\n",
            "torch.Size([80, 42])\n",
            "Epoch [7557/10000], train_Loss: 1.8974149237471066e-13,test_Loss:5.28808069229126, r2_store:0.3242449453648215\n",
            "torch.Size([80, 42])\n",
            "Epoch [7558/10000], train_Loss: 2.954863187899087e-13,test_Loss:5.28808069229126, r2_store:0.3242449093197489\n",
            "torch.Size([80, 42])\n",
            "Epoch [7559/10000], train_Loss: 1.448724224351744e-13,test_Loss:5.28808069229126, r2_store:0.3242449359376208\n",
            "torch.Size([80, 42])\n",
            "Epoch [7560/10000], train_Loss: 1.656339724664252e-13,test_Loss:5.288079738616943, r2_store:0.3242449099194715\n",
            "torch.Size([80, 42])\n",
            "Epoch [7561/10000], train_Loss: 1.648114018306876e-13,test_Loss:5.288079738616943, r2_store:0.32424495918892093\n",
            "torch.Size([80, 42])\n",
            "Epoch [7562/10000], train_Loss: 1.910902805348641e-13,test_Loss:5.288079738616943, r2_store:0.32424492126265203\n",
            "torch.Size([80, 42])\n",
            "Epoch [7563/10000], train_Loss: 1.9431923789243327e-13,test_Loss:5.288079738616943, r2_store:0.324244926981906\n",
            "torch.Size([80, 42])\n",
            "Epoch [7564/10000], train_Loss: 1.9901684196032415e-13,test_Loss:5.288079738616943, r2_store:0.3242449695221734\n",
            "torch.Size([80, 42])\n",
            "Epoch [7565/10000], train_Loss: 1.420105217231002e-13,test_Loss:5.288079738616943, r2_store:0.32424496123113833\n",
            "torch.Size([80, 42])\n",
            "Epoch [7566/10000], train_Loss: 1.7832621230368106e-13,test_Loss:5.288079738616943, r2_store:0.32424497543556074\n",
            "torch.Size([80, 42])\n",
            "Epoch [7567/10000], train_Loss: 1.3429004002557532e-13,test_Loss:5.288079738616943, r2_store:0.3242449488531127\n",
            "torch.Size([80, 42])\n",
            "Epoch [7568/10000], train_Loss: 1.318616711046966e-13,test_Loss:5.288079738616943, r2_store:0.32424496081459564\n",
            "torch.Size([80, 42])\n",
            "Epoch [7569/10000], train_Loss: 1.353856940835077e-13,test_Loss:5.288079738616943, r2_store:0.32424499149657304\n",
            "torch.Size([80, 42])\n",
            "Epoch [7570/10000], train_Loss: 1.2983479580081642e-13,test_Loss:5.288079738616943, r2_store:0.3242449351910739\n",
            "torch.Size([80, 42])\n",
            "Epoch [7571/10000], train_Loss: 1.3068643660730378e-13,test_Loss:5.288081169128418, r2_store:0.32424493637900464\n",
            "torch.Size([80, 42])\n",
            "Epoch [7572/10000], train_Loss: 2.4430896758756426e-13,test_Loss:5.28808069229126, r2_store:0.3242449654229228\n",
            "torch.Size([80, 42])\n",
            "Epoch [7573/10000], train_Loss: 1.8698305165494589e-13,test_Loss:5.28808069229126, r2_store:0.3242449187207844\n",
            "torch.Size([80, 42])\n",
            "Epoch [7574/10000], train_Loss: 1.85385262913354e-13,test_Loss:5.28808069229126, r2_store:0.3242448944351095\n",
            "torch.Size([80, 42])\n",
            "Epoch [7575/10000], train_Loss: 1.4444795728464632e-13,test_Loss:5.28808069229126, r2_store:0.3242449093308093\n",
            "torch.Size([80, 42])\n",
            "Epoch [7576/10000], train_Loss: 1.4482157335328483e-13,test_Loss:5.288079261779785, r2_store:0.32424492019333573\n",
            "torch.Size([80, 42])\n",
            "Epoch [7577/10000], train_Loss: 1.0380910540896959e-13,test_Loss:5.288079261779785, r2_store:0.32424493180197744\n",
            "torch.Size([80, 42])\n",
            "Epoch [7578/10000], train_Loss: 1.1287133472879032e-13,test_Loss:5.288079738616943, r2_store:0.3242448883431146\n",
            "torch.Size([80, 42])\n",
            "Epoch [7579/10000], train_Loss: 1.4610762686523282e-13,test_Loss:5.288079738616943, r2_store:0.32424488773032123\n",
            "torch.Size([80, 42])\n",
            "Epoch [7580/10000], train_Loss: 1.6369491753851634e-13,test_Loss:5.288079738616943, r2_store:0.32424488063013024\n",
            "torch.Size([80, 42])\n",
            "Epoch [7581/10000], train_Loss: 1.2022379077512857e-13,test_Loss:5.288079738616943, r2_store:0.3242448959125315\n",
            "torch.Size([80, 42])\n",
            "Epoch [7582/10000], train_Loss: 9.868843887711129e-14,test_Loss:5.288079738616943, r2_store:0.3242449506092596\n",
            "torch.Size([80, 42])\n",
            "Epoch [7583/10000], train_Loss: 1.3134911452765408e-13,test_Loss:5.288079738616943, r2_store:0.3242449216325871\n",
            "torch.Size([80, 42])\n",
            "Epoch [7584/10000], train_Loss: 1.651283818883409e-13,test_Loss:5.288079738616943, r2_store:0.32424491528500365\n",
            "torch.Size([80, 42])\n",
            "Epoch [7585/10000], train_Loss: 1.1108135759959822e-13,test_Loss:5.288079738616943, r2_store:0.3242449035627013\n",
            "torch.Size([80, 42])\n",
            "Epoch [7586/10000], train_Loss: 1.207166961877948e-13,test_Loss:5.288079738616943, r2_store:0.3242449373941144\n",
            "torch.Size([80, 42])\n",
            "Epoch [7587/10000], train_Loss: 1.3708453046757524e-13,test_Loss:5.288079738616943, r2_store:0.3242448922967992\n",
            "torch.Size([80, 42])\n",
            "Epoch [7588/10000], train_Loss: 9.549006279706979e-14,test_Loss:5.288079738616943, r2_store:0.3242449049876531\n",
            "torch.Size([80, 42])\n",
            "Epoch [7589/10000], train_Loss: 1.402218998466237e-13,test_Loss:5.288079738616943, r2_store:0.32424495759611427\n",
            "torch.Size([80, 42])\n",
            "Epoch [7590/10000], train_Loss: 8.645757449809305e-14,test_Loss:5.288079738616943, r2_store:0.3242449534876778\n",
            "torch.Size([80, 42])\n",
            "Epoch [7591/10000], train_Loss: 1.1556670876343433e-13,test_Loss:5.288079738616943, r2_store:0.3242449424807686\n",
            "torch.Size([80, 42])\n",
            "Epoch [7592/10000], train_Loss: 1.1139807338297197e-13,test_Loss:5.288079738616943, r2_store:0.324244965268806\n",
            "torch.Size([80, 42])\n",
            "Epoch [7593/10000], train_Loss: 1.6619946521453932e-13,test_Loss:5.28808069229126, r2_store:0.32424488426404285\n",
            "torch.Size([80, 42])\n",
            "Epoch [7594/10000], train_Loss: 1.3246485343083175e-13,test_Loss:5.288079738616943, r2_store:0.32424490949310303\n",
            "torch.Size([80, 42])\n",
            "Epoch [7595/10000], train_Loss: 1.601946927973913e-13,test_Loss:5.288079738616943, r2_store:0.3242449144699695\n",
            "torch.Size([80, 42])\n",
            "Epoch [7596/10000], train_Loss: 8.853536664649858e-14,test_Loss:5.28808069229126, r2_store:0.3242449327732545\n",
            "torch.Size([80, 42])\n",
            "Epoch [7597/10000], train_Loss: 1.0619367933834348e-13,test_Loss:5.288081169128418, r2_store:0.32424489820142055\n",
            "torch.Size([80, 42])\n",
            "Epoch [7598/10000], train_Loss: 1.4888955411455906e-13,test_Loss:5.288079738616943, r2_store:0.32424495257567865\n",
            "torch.Size([80, 42])\n",
            "Epoch [7599/10000], train_Loss: 1.2921368348125378e-13,test_Loss:5.288079738616943, r2_store:0.32424493845603974\n",
            "torch.Size([80, 42])\n",
            "Epoch [7600/10000], train_Loss: 1.282884117947275e-13,test_Loss:5.288079738616943, r2_store:0.32424487108763533\n",
            "torch.Size([80, 42])\n",
            "Epoch [7601/10000], train_Loss: 2.1618236443598365e-13,test_Loss:5.288079738616943, r2_store:0.3242449263273378\n",
            "torch.Size([80, 42])\n",
            "Epoch [7602/10000], train_Loss: 1.1297734937246867e-13,test_Loss:5.288078784942627, r2_store:0.3242450763772676\n",
            "torch.Size([80, 42])\n",
            "Epoch [7603/10000], train_Loss: 1.74538904379809e-13,test_Loss:5.288079261779785, r2_store:0.3242449946498779\n",
            "torch.Size([80, 42])\n",
            "Epoch [7604/10000], train_Loss: 1.7384542156523297e-13,test_Loss:5.288079738616943, r2_store:0.324244963741696\n",
            "torch.Size([80, 42])\n",
            "Epoch [7605/10000], train_Loss: 2.1784752279006836e-13,test_Loss:5.288079261779785, r2_store:0.324244929158908\n",
            "torch.Size([80, 42])\n",
            "Epoch [7606/10000], train_Loss: 1.793306307487988e-13,test_Loss:5.288079738616943, r2_store:0.3242449520555376\n",
            "torch.Size([80, 42])\n",
            "Epoch [7607/10000], train_Loss: 1.2454729088340333e-13,test_Loss:5.288079738616943, r2_store:0.3242449347935803\n",
            "torch.Size([80, 42])\n",
            "Epoch [7608/10000], train_Loss: 1.052300607762291e-13,test_Loss:5.288079738616943, r2_store:0.32424493907626184\n",
            "torch.Size([80, 42])\n",
            "Epoch [7609/10000], train_Loss: 2.239753792588478e-13,test_Loss:5.288079738616943, r2_store:0.32424494876449295\n",
            "torch.Size([80, 42])\n",
            "Epoch [7610/10000], train_Loss: 1.464928167920626e-13,test_Loss:5.28808069229126, r2_store:0.32424492555097195\n",
            "torch.Size([80, 42])\n",
            "Epoch [7611/10000], train_Loss: 1.2848432712729563e-13,test_Loss:5.288081169128418, r2_store:0.3242448768773072\n",
            "torch.Size([80, 42])\n",
            "Epoch [7612/10000], train_Loss: 1.2680408481048622e-13,test_Loss:5.28808069229126, r2_store:0.32424487374001787\n",
            "torch.Size([80, 42])\n",
            "Epoch [7613/10000], train_Loss: 1.53438758010091e-13,test_Loss:5.28808069229126, r2_store:0.3242448847053504\n",
            "torch.Size([80, 42])\n",
            "Epoch [7614/10000], train_Loss: 9.294394952025914e-14,test_Loss:5.28808069229126, r2_store:0.3242449173966371\n",
            "torch.Size([80, 42])\n",
            "Epoch [7615/10000], train_Loss: 1.1321523010537557e-13,test_Loss:5.288079738616943, r2_store:0.32424498366589083\n",
            "torch.Size([80, 42])\n",
            "Epoch [7616/10000], train_Loss: 1.2692650478828699e-13,test_Loss:5.288079738616943, r2_store:0.32424495315572255\n",
            "torch.Size([80, 42])\n",
            "Epoch [7617/10000], train_Loss: 9.751077170109396e-14,test_Loss:5.28808069229126, r2_store:0.3242449015054004\n",
            "torch.Size([80, 42])\n",
            "Epoch [7618/10000], train_Loss: 1.0684054823576622e-13,test_Loss:5.28808069229126, r2_store:0.32424490192445565\n",
            "torch.Size([80, 42])\n",
            "Epoch [7619/10000], train_Loss: 1.1486647679033457e-13,test_Loss:5.288079738616943, r2_store:0.32424494809482995\n",
            "torch.Size([80, 42])\n",
            "Epoch [7620/10000], train_Loss: 1.0260583750915445e-13,test_Loss:5.28808069229126, r2_store:0.3242449613555026\n",
            "torch.Size([80, 42])\n",
            "Epoch [7621/10000], train_Loss: 1.1429105003981505e-13,test_Loss:5.28808069229126, r2_store:0.32424496096000677\n",
            "torch.Size([80, 42])\n",
            "Epoch [7622/10000], train_Loss: 1.403065218261862e-13,test_Loss:5.28808069229126, r2_store:0.3242449731859902\n",
            "torch.Size([80, 42])\n",
            "Epoch [7623/10000], train_Loss: 1.1756937925381378e-13,test_Loss:5.288081169128418, r2_store:0.324244948450511\n",
            "torch.Size([80, 42])\n",
            "Epoch [7624/10000], train_Loss: 1.5538547011584303e-13,test_Loss:5.28808069229126, r2_store:0.3242449209231516\n",
            "torch.Size([80, 42])\n",
            "Epoch [7625/10000], train_Loss: 1.6000876567733718e-13,test_Loss:5.28808069229126, r2_store:0.32424493477089833\n",
            "torch.Size([80, 42])\n",
            "Epoch [7626/10000], train_Loss: 1.596996460854344e-13,test_Loss:5.288079738616943, r2_store:0.32424491338711947\n",
            "torch.Size([80, 42])\n",
            "Epoch [7627/10000], train_Loss: 1.8404396930071787e-13,test_Loss:5.288079738616943, r2_store:0.32424492834910934\n",
            "torch.Size([80, 42])\n",
            "Epoch [7628/10000], train_Loss: 1.5498619911329808e-13,test_Loss:5.288079738616943, r2_store:0.32424494553802496\n",
            "torch.Size([80, 42])\n",
            "Epoch [7629/10000], train_Loss: 1.2484665265575373e-13,test_Loss:5.288079738616943, r2_store:0.32424495607164106\n",
            "torch.Size([80, 42])\n",
            "Epoch [7630/10000], train_Loss: 1.5452951960572003e-13,test_Loss:5.288079738616943, r2_store:0.3242449762295878\n",
            "torch.Size([80, 42])\n",
            "Epoch [7631/10000], train_Loss: 1.3427219134731078e-13,test_Loss:5.28808069229126, r2_store:0.32424491282081824\n",
            "torch.Size([80, 42])\n",
            "Epoch [7632/10000], train_Loss: 1.0026109445709225e-13,test_Loss:5.28808069229126, r2_store:0.3242449113657955\n",
            "torch.Size([80, 42])\n",
            "Epoch [7633/10000], train_Loss: 1.2427928965889207e-13,test_Loss:5.28808069229126, r2_store:0.3242449055657891\n",
            "torch.Size([80, 42])\n",
            "Epoch [7634/10000], train_Loss: 1.5877189428643856e-13,test_Loss:5.28808069229126, r2_store:0.32424491747739026\n",
            "torch.Size([80, 42])\n",
            "Epoch [7635/10000], train_Loss: 1.2833871877553082e-13,test_Loss:5.288079738616943, r2_store:0.32424490639671066\n",
            "torch.Size([80, 42])\n",
            "Epoch [7636/10000], train_Loss: 1.5060533115757169e-13,test_Loss:5.288079738616943, r2_store:0.3242449339073773\n",
            "torch.Size([80, 42])\n",
            "Epoch [7637/10000], train_Loss: 1.7030010756625968e-13,test_Loss:5.288079738616943, r2_store:0.3242449369445447\n",
            "torch.Size([80, 42])\n",
            "Epoch [7638/10000], train_Loss: 1.5618226384492978e-13,test_Loss:5.288079738616943, r2_store:0.32424493223369866\n",
            "torch.Size([80, 42])\n",
            "Epoch [7639/10000], train_Loss: 1.5537435704357505e-13,test_Loss:5.288079738616943, r2_store:0.3242449508931733\n",
            "torch.Size([80, 42])\n",
            "Epoch [7640/10000], train_Loss: 1.3798428274546665e-13,test_Loss:5.288079738616943, r2_store:0.3242449568272089\n",
            "torch.Size([80, 42])\n",
            "Epoch [7641/10000], train_Loss: 1.3923324299058848e-13,test_Loss:5.288079738616943, r2_store:0.32424496147287696\n",
            "torch.Size([80, 42])\n",
            "Epoch [7642/10000], train_Loss: 1.553472248842086e-13,test_Loss:5.288079738616943, r2_store:0.3242449593237089\n",
            "torch.Size([80, 42])\n",
            "Epoch [7643/10000], train_Loss: 1.3293955779952737e-13,test_Loss:5.288081169128418, r2_store:0.3242449096876473\n",
            "torch.Size([80, 42])\n",
            "Epoch [7644/10000], train_Loss: 1.5256222121121793e-13,test_Loss:5.288081169128418, r2_store:0.3242449392350989\n",
            "torch.Size([80, 42])\n",
            "Epoch [7645/10000], train_Loss: 1.8317452047354743e-13,test_Loss:5.28808069229126, r2_store:0.32424492975074126\n",
            "torch.Size([80, 42])\n",
            "Epoch [7646/10000], train_Loss: 1.2653445728271623e-13,test_Loss:5.28808069229126, r2_store:0.3242449238880748\n",
            "torch.Size([80, 42])\n",
            "Epoch [7647/10000], train_Loss: 1.821019870269433e-13,test_Loss:5.28808069229126, r2_store:0.32424496046055507\n",
            "torch.Size([80, 42])\n",
            "Epoch [7648/10000], train_Loss: 1.2699524320602257e-13,test_Loss:5.288081169128418, r2_store:0.3242449695136663\n",
            "torch.Size([80, 42])\n",
            "Epoch [7649/10000], train_Loss: 1.116191015483603e-13,test_Loss:5.28808069229126, r2_store:0.3242450000138073\n",
            "torch.Size([80, 42])\n",
            "Epoch [7650/10000], train_Loss: 1.292194162002408e-13,test_Loss:5.28808069229126, r2_store:0.32424496401143055\n",
            "torch.Size([80, 42])\n",
            "Epoch [7651/10000], train_Loss: 2.056481341553701e-13,test_Loss:5.28808069229126, r2_store:0.32424494938691195\n",
            "torch.Size([80, 42])\n",
            "Epoch [7652/10000], train_Loss: 1.3508591218281546e-13,test_Loss:5.288079738616943, r2_store:0.32424497440514655\n",
            "torch.Size([80, 42])\n",
            "Epoch [7653/10000], train_Loss: 1.4023409712106416e-13,test_Loss:5.288079738616943, r2_store:0.32424497109580996\n",
            "torch.Size([80, 42])\n",
            "Epoch [7654/10000], train_Loss: 1.1939659872763075e-13,test_Loss:5.28808069229126, r2_store:0.32424494259343495\n",
            "torch.Size([80, 42])\n",
            "Epoch [7655/10000], train_Loss: 1.3919009174412356e-13,test_Loss:5.288081169128418, r2_store:0.3242448934993577\n",
            "torch.Size([80, 42])\n",
            "Epoch [7656/10000], train_Loss: 1.7701820369774024e-13,test_Loss:5.288079738616943, r2_store:0.32424493698779666\n",
            "torch.Size([80, 42])\n",
            "Epoch [7657/10000], train_Loss: 1.919902225481357e-13,test_Loss:5.288079738616943, r2_store:0.32424491316375315\n",
            "torch.Size([80, 42])\n",
            "Epoch [7658/10000], train_Loss: 1.4873348321182978e-13,test_Loss:5.288081169128418, r2_store:0.32424490582782106\n",
            "torch.Size([80, 42])\n",
            "Epoch [7659/10000], train_Loss: 2.5106937470882607e-13,test_Loss:5.288079261779785, r2_store:0.3242448358640331\n",
            "torch.Size([80, 42])\n",
            "Epoch [7660/10000], train_Loss: 2.1237868505930707e-13,test_Loss:5.288079261779785, r2_store:0.32424488040511423\n",
            "torch.Size([80, 42])\n",
            "Epoch [7661/10000], train_Loss: 1.9145535851139428e-13,test_Loss:5.28808069229126, r2_store:0.3242449311821608\n",
            "torch.Size([80, 42])\n",
            "Epoch [7662/10000], train_Loss: 1.908148525254713e-13,test_Loss:5.288079738616943, r2_store:0.32424495762315186\n",
            "torch.Size([80, 42])\n",
            "Epoch [7663/10000], train_Loss: 2.162893074277722e-13,test_Loss:5.288079738616943, r2_store:0.3242449758167595\n",
            "torch.Size([80, 42])\n",
            "Epoch [7664/10000], train_Loss: 2.6961535760060273e-13,test_Loss:5.28808069229126, r2_store:0.3242449064043883\n",
            "torch.Size([80, 42])\n",
            "Epoch [7665/10000], train_Loss: 2.5570870290994585e-13,test_Loss:5.28808069229126, r2_store:0.3242449040322124\n",
            "torch.Size([80, 42])\n",
            "Epoch [7666/10000], train_Loss: 2.3856578604958267e-13,test_Loss:5.28808069229126, r2_store:0.3242449341812713\n",
            "torch.Size([80, 42])\n",
            "Epoch [7667/10000], train_Loss: 1.9275336535229393e-13,test_Loss:5.288081169128418, r2_store:0.32424495566756195\n",
            "torch.Size([80, 42])\n",
            "Epoch [7668/10000], train_Loss: 1.6099457650266963e-13,test_Loss:5.28808069229126, r2_store:0.32424491139539147\n",
            "torch.Size([80, 42])\n",
            "Epoch [7669/10000], train_Loss: 1.8468947616916143e-13,test_Loss:5.288079738616943, r2_store:0.3242449597083019\n",
            "torch.Size([80, 42])\n",
            "Epoch [7670/10000], train_Loss: 1.3983394520425407e-13,test_Loss:5.28808069229126, r2_store:0.32424488684469377\n",
            "torch.Size([80, 42])\n",
            "Epoch [7671/10000], train_Loss: 1.3395602444128685e-13,test_Loss:5.28808069229126, r2_store:0.32424491971626235\n",
            "torch.Size([80, 42])\n",
            "Epoch [7672/10000], train_Loss: 1.673123038769056e-13,test_Loss:5.28808069229126, r2_store:0.3242449298091318\n",
            "torch.Size([80, 42])\n",
            "Epoch [7673/10000], train_Loss: 1.8262381353256057e-13,test_Loss:5.28808069229126, r2_store:0.32424493839498136\n",
            "torch.Size([80, 42])\n",
            "Epoch [7674/10000], train_Loss: 1.3242838358025477e-13,test_Loss:5.28808069229126, r2_store:0.3242448926064845\n",
            "torch.Size([80, 42])\n",
            "Epoch [7675/10000], train_Loss: 1.6714095927607142e-13,test_Loss:5.288081169128418, r2_store:0.32424491465680905\n",
            "torch.Size([80, 42])\n",
            "Epoch [7676/10000], train_Loss: 1.8691248364604424e-13,test_Loss:5.288081169128418, r2_store:0.324244970511092\n",
            "torch.Size([80, 42])\n",
            "Epoch [7677/10000], train_Loss: 2.2475493417339204e-13,test_Loss:5.28808069229126, r2_store:0.32424497313251444\n",
            "torch.Size([80, 42])\n",
            "Epoch [7678/10000], train_Loss: 2.67602590477492e-13,test_Loss:5.288081169128418, r2_store:0.32424495637959694\n",
            "torch.Size([80, 42])\n",
            "Epoch [7679/10000], train_Loss: 2.3021219804596205e-13,test_Loss:5.28808069229126, r2_store:0.32424493565186974\n",
            "torch.Size([80, 42])\n",
            "Epoch [7680/10000], train_Loss: 2.3066959583747937e-13,test_Loss:5.288081169128418, r2_store:0.324244970682102\n",
            "torch.Size([80, 42])\n",
            "Epoch [7681/10000], train_Loss: 1.6350562939172752e-13,test_Loss:5.288079738616943, r2_store:0.3242449752204998\n",
            "torch.Size([80, 42])\n",
            "Epoch [7682/10000], train_Loss: 2.3311688408626796e-13,test_Loss:5.28808069229126, r2_store:0.3242449836253538\n",
            "torch.Size([80, 42])\n",
            "Epoch [7683/10000], train_Loss: 1.7873178523135358e-13,test_Loss:5.288082122802734, r2_store:0.3242449583474114\n",
            "torch.Size([80, 42])\n",
            "Epoch [7684/10000], train_Loss: 1.9145520943359556e-13,test_Loss:5.288082122802734, r2_store:0.3242449118144596\n",
            "torch.Size([80, 42])\n",
            "Epoch [7685/10000], train_Loss: 2.4203889218386843e-13,test_Loss:5.28808069229126, r2_store:0.3242450300580223\n",
            "torch.Size([80, 42])\n",
            "Epoch [7686/10000], train_Loss: 2.0560751723148335e-13,test_Loss:5.288081645965576, r2_store:0.32424493843416646\n",
            "torch.Size([80, 42])\n",
            "Epoch [7687/10000], train_Loss: 1.5196483936670557e-13,test_Loss:5.288082122802734, r2_store:0.3242449462355321\n",
            "torch.Size([80, 42])\n",
            "Epoch [7688/10000], train_Loss: 2.8813022389002907e-13,test_Loss:5.288081645965576, r2_store:0.32424501094749814\n",
            "torch.Size([80, 42])\n",
            "Epoch [7689/10000], train_Loss: 2.341967223450092e-13,test_Loss:5.288081169128418, r2_store:0.32424500381516175\n",
            "torch.Size([80, 42])\n",
            "Epoch [7690/10000], train_Loss: 1.713108821466136e-13,test_Loss:5.288081169128418, r2_store:0.3242449669387304\n",
            "torch.Size([80, 42])\n",
            "Epoch [7691/10000], train_Loss: 2.8076328696842456e-13,test_Loss:5.28808069229126, r2_store:0.32424497077535486\n",
            "torch.Size([80, 42])\n",
            "Epoch [7692/10000], train_Loss: 2.1626498064152705e-13,test_Loss:5.288080215454102, r2_store:0.3242449898380291\n",
            "torch.Size([80, 42])\n",
            "Epoch [7693/10000], train_Loss: 3.01880834783011e-13,test_Loss:5.288081169128418, r2_store:0.32424495802899367\n",
            "torch.Size([80, 42])\n",
            "Epoch [7694/10000], train_Loss: 3.4568387648897803e-13,test_Loss:5.288080215454102, r2_store:0.3242449182913054\n",
            "torch.Size([80, 42])\n",
            "Epoch [7695/10000], train_Loss: 2.24271163164029e-13,test_Loss:5.288078308105469, r2_store:0.3242450392121208\n",
            "torch.Size([80, 42])\n",
            "Epoch [7696/10000], train_Loss: 7.110120868805692e-13,test_Loss:5.288082122802734, r2_store:0.32424480627207675\n",
            "torch.Size([80, 42])\n",
            "Epoch [7697/10000], train_Loss: 1.4429041728797332e-12,test_Loss:5.288077354431152, r2_store:0.3242449335803206\n",
            "torch.Size([80, 42])\n",
            "Epoch [7698/10000], train_Loss: 1.6549317255129536e-12,test_Loss:5.288083076477051, r2_store:0.3242448332956095\n",
            "torch.Size([80, 42])\n",
            "Epoch [7699/10000], train_Loss: 1.7159534427060863e-12,test_Loss:5.288078784942627, r2_store:0.3242450273414115\n",
            "torch.Size([80, 42])\n",
            "Epoch [7700/10000], train_Loss: 1.0882130700023973e-12,test_Loss:5.288081169128418, r2_store:0.3242449173507218\n",
            "torch.Size([80, 42])\n",
            "Epoch [7701/10000], train_Loss: 4.803304563989752e-13,test_Loss:5.288081169128418, r2_store:0.3242449339269976\n",
            "torch.Size([80, 42])\n",
            "Epoch [7702/10000], train_Loss: 3.3157133180576615e-13,test_Loss:5.288078308105469, r2_store:0.32424501238681536\n",
            "torch.Size([80, 42])\n",
            "Epoch [7703/10000], train_Loss: 1.5436558281622936e-12,test_Loss:5.288084983825684, r2_store:0.32424478102613974\n",
            "torch.Size([80, 42])\n",
            "Epoch [7704/10000], train_Loss: 3.662309171204026e-12,test_Loss:5.288074016571045, r2_store:0.32424516502276624\n",
            "torch.Size([80, 42])\n",
            "Epoch [7705/10000], train_Loss: 7.159255827060562e-12,test_Loss:5.288088798522949, r2_store:0.324244632669934\n",
            "torch.Size([80, 42])\n",
            "Epoch [7706/10000], train_Loss: 1.4859452210358448e-11,test_Loss:5.288069248199463, r2_store:0.32424527409578785\n",
            "torch.Size([80, 42])\n",
            "Epoch [7707/10000], train_Loss: 2.952750544071847e-11,test_Loss:5.288095951080322, r2_store:0.3242443746700152\n",
            "torch.Size([80, 42])\n",
            "Epoch [7708/10000], train_Loss: 5.966774990762147e-11,test_Loss:5.288056373596191, r2_store:0.3242457458450678\n",
            "torch.Size([80, 42])\n",
            "Epoch [7709/10000], train_Loss: 1.1601491989310375e-10,test_Loss:5.28810977935791, r2_store:0.32424376190468607\n",
            "torch.Size([80, 42])\n",
            "Epoch [7710/10000], train_Loss: 2.1665055860431437e-10,test_Loss:5.288037300109863, r2_store:0.32424642260867786\n",
            "torch.Size([80, 42])\n",
            "Epoch [7711/10000], train_Loss: 3.913255552934203e-10,test_Loss:5.288136005401611, r2_store:0.3242428515166248\n",
            "torch.Size([80, 42])\n",
            "Epoch [7712/10000], train_Loss: 6.972577515362843e-10,test_Loss:5.288007736206055, r2_store:0.32424765740704165\n",
            "torch.Size([80, 42])\n",
            "Epoch [7713/10000], train_Loss: 1.2359271384099202e-09,test_Loss:5.288178443908691, r2_store:0.32424134053200016\n",
            "torch.Size([80, 42])\n",
            "Epoch [7714/10000], train_Loss: 2.22412843697839e-09,test_Loss:5.287947177886963, r2_store:0.324249751628492\n",
            "torch.Size([80, 42])\n",
            "Epoch [7715/10000], train_Loss: 4.0250438537725586e-09,test_Loss:5.288261413574219, r2_store:0.3242382126128608\n",
            "torch.Size([80, 42])\n",
            "Epoch [7716/10000], train_Loss: 7.343500918466361e-09,test_Loss:5.287835597991943, r2_store:0.3242537595680106\n",
            "torch.Size([80, 42])\n",
            "Epoch [7717/10000], train_Loss: 1.3453913538796769e-08,test_Loss:5.288413047790527, r2_store:0.3242327182609205\n",
            "torch.Size([80, 42])\n",
            "Epoch [7718/10000], train_Loss: 2.47896370098033e-08,test_Loss:5.287630081176758, r2_store:0.3242614065007151\n",
            "torch.Size([80, 42])\n",
            "Epoch [7719/10000], train_Loss: 4.5962362804630175e-08,test_Loss:5.2886962890625, r2_store:0.3242219632964014\n",
            "torch.Size([80, 42])\n",
            "Epoch [7720/10000], train_Loss: 8.635546322466325e-08,test_Loss:5.287230491638184, r2_store:0.3242756301034867\n",
            "torch.Size([80, 42])\n",
            "Epoch [7721/10000], train_Loss: 1.6269765978904616e-07,test_Loss:5.289248943328857, r2_store:0.32420118180563007\n",
            "torch.Size([80, 42])\n",
            "Epoch [7722/10000], train_Loss: 3.098368495102477e-07,test_Loss:5.286464691162109, r2_store:0.32430309450031003\n",
            "torch.Size([80, 42])\n",
            "Epoch [7723/10000], train_Loss: 5.907176614527998e-07,test_Loss:5.290324687957764, r2_store:0.32416173646566326\n",
            "torch.Size([80, 42])\n",
            "Epoch [7724/10000], train_Loss: 1.1294469004496932e-06,test_Loss:5.28498649597168, r2_store:0.3243577456314971\n",
            "torch.Size([80, 42])\n",
            "Epoch [7725/10000], train_Loss: 2.17311594497005e-06,test_Loss:5.292393684387207, r2_store:0.32408411592567465\n",
            "torch.Size([80, 42])\n",
            "Epoch [7726/10000], train_Loss: 4.211677151033655e-06,test_Loss:5.282052040100098, r2_store:0.3244582055550882\n",
            "torch.Size([80, 42])\n",
            "Epoch [7727/10000], train_Loss: 8.116866411000956e-06,test_Loss:5.296440124511719, r2_store:0.32392987217643066\n",
            "torch.Size([80, 42])\n",
            "Epoch [7728/10000], train_Loss: 1.562266334076412e-05,test_Loss:5.276512622833252, r2_store:0.32465551511541013\n",
            "torch.Size([80, 42])\n",
            "Epoch [7729/10000], train_Loss: 3.0000173865118995e-05,test_Loss:5.304076671600342, r2_store:0.3236456061478665\n",
            "torch.Size([80, 42])\n",
            "Epoch [7730/10000], train_Loss: 5.634584158542566e-05,test_Loss:5.266299247741699, r2_store:0.32501621650702095\n",
            "torch.Size([80, 42])\n",
            "Epoch [7731/10000], train_Loss: 0.00010675666999304667,test_Loss:5.319520950317383, r2_store:0.32304964791737967\n",
            "torch.Size([80, 42])\n",
            "Epoch [7732/10000], train_Loss: 0.00020472049072850496,test_Loss:5.247746467590332, r2_store:0.3257035001943095\n",
            "torch.Size([80, 42])\n",
            "Epoch [7733/10000], train_Loss: 0.0004044976958539337,test_Loss:5.350592136383057, r2_store:0.3219428202700786\n",
            "torch.Size([80, 42])\n",
            "Epoch [7734/10000], train_Loss: 0.0007695414242334664,test_Loss:5.210247993469238, r2_store:0.32710833107027726\n",
            "torch.Size([80, 42])\n",
            "Epoch [7735/10000], train_Loss: 0.0015380149707198143,test_Loss:5.408677101135254, r2_store:0.3196335940512609\n",
            "torch.Size([80, 42])\n",
            "Epoch [7736/10000], train_Loss: 0.0029489202424883842,test_Loss:5.133387565612793, r2_store:0.3295345462674182\n",
            "torch.Size([80, 42])\n",
            "Epoch [7737/10000], train_Loss: 0.006058256141841412,test_Loss:5.529496192932129, r2_store:0.31511832361919767\n",
            "torch.Size([80, 42])\n",
            "Epoch [7738/10000], train_Loss: 0.011287549510598183,test_Loss:5.000968933105469, r2_store:0.3334643572645124\n",
            "torch.Size([80, 42])\n",
            "Epoch [7739/10000], train_Loss: 0.024181978777050972,test_Loss:5.764639854431152, r2_store:0.3040188768512758\n",
            "torch.Size([80, 42])\n",
            "Epoch [7740/10000], train_Loss: 0.04140237346291542,test_Loss:4.775245189666748, r2_store:0.3372965480302378\n",
            "torch.Size([80, 42])\n",
            "Epoch [7741/10000], train_Loss: 0.08533904701471329,test_Loss:6.0581135749816895, r2_store:0.2911122447961618\n",
            "torch.Size([80, 42])\n",
            "Epoch [7742/10000], train_Loss: 0.09366045892238617,test_Loss:4.701592922210693, r2_store:0.3401150620366036\n",
            "torch.Size([80, 42])\n",
            "Epoch [7743/10000], train_Loss: 0.1077662855386734,test_Loss:5.562720775604248, r2_store:0.31466349097754387\n",
            "torch.Size([80, 42])\n",
            "Epoch [7744/10000], train_Loss: 0.02207537367939949,test_Loss:5.407965660095215, r2_store:0.32178012684123436\n",
            "torch.Size([80, 42])\n",
            "Epoch [7745/10000], train_Loss: 0.00920866709202528,test_Loss:4.748621463775635, r2_store:0.34280775095652916\n",
            "torch.Size([80, 42])\n",
            "Epoch [7746/10000], train_Loss: 0.06069609522819519,test_Loss:5.569821834564209, r2_store:0.3116794347232449\n",
            "torch.Size([80, 42])\n",
            "Epoch [7747/10000], train_Loss: 0.03528955951333046,test_Loss:5.048508167266846, r2_store:0.3297450645968032\n",
            "torch.Size([80, 42])\n",
            "Epoch [7748/10000], train_Loss: 0.002246904419735074,test_Loss:4.842355728149414, r2_store:0.33510059139890536\n",
            "torch.Size([80, 42])\n",
            "Epoch [7749/10000], train_Loss: 0.017752785235643387,test_Loss:5.457272052764893, r2_store:0.3114018731011179\n",
            "torch.Size([80, 42])\n",
            "Epoch [7750/10000], train_Loss: 0.024149056524038315,test_Loss:4.99387264251709, r2_store:0.33255139269047373\n",
            "torch.Size([80, 42])\n",
            "Epoch [7751/10000], train_Loss: 0.00513389240950346,test_Loss:4.97924280166626, r2_store:0.33445217230637203\n",
            "torch.Size([80, 42])\n",
            "Epoch [7752/10000], train_Loss: 0.006047182250767946,test_Loss:5.400746822357178, r2_store:0.316109741234603\n",
            "torch.Size([80, 42])\n",
            "Epoch [7753/10000], train_Loss: 0.016885187476873398,test_Loss:4.963246822357178, r2_store:0.3336924808423918\n",
            "torch.Size([80, 42])\n",
            "Epoch [7754/10000], train_Loss: 0.007062158081680536,test_Loss:5.045495510101318, r2_store:0.3294769608483856\n",
            "torch.Size([80, 42])\n",
            "Epoch [7755/10000], train_Loss: 0.002418494550511241,test_Loss:5.376331329345703, r2_store:0.3154695534442995\n",
            "torch.Size([80, 42])\n",
            "Epoch [7756/10000], train_Loss: 0.012102216482162476,test_Loss:4.999828338623047, r2_store:0.33317697515648537\n",
            "torch.Size([80, 42])\n",
            "Epoch [7757/10000], train_Loss: 0.006345722824335098,test_Loss:5.109836101531982, r2_store:0.3297033043516753\n",
            "torch.Size([80, 42])\n",
            "Epoch [7758/10000], train_Loss: 0.001422064728103578,test_Loss:5.388976097106934, r2_store:0.3167019250500952\n",
            "torch.Size([80, 42])\n",
            "Epoch [7759/10000], train_Loss: 0.009738165885210037,test_Loss:5.026167869567871, r2_store:0.3304493802379207\n",
            "torch.Size([80, 42])\n",
            "Epoch [7760/10000], train_Loss: 0.005503073334693909,test_Loss:5.120355606079102, r2_store:0.3255732095564119\n",
            "torch.Size([80, 42])\n",
            "Epoch [7761/10000], train_Loss: 0.001055288827046752,test_Loss:5.370106220245361, r2_store:0.31528615524379644\n",
            "torch.Size([80, 42])\n",
            "Epoch [7762/10000], train_Loss: 0.0078032733872532845,test_Loss:5.057701110839844, r2_store:0.3297885881529746\n",
            "torch.Size([80, 42])\n",
            "Epoch [7763/10000], train_Loss: 0.004297269508242607,test_Loss:5.147749900817871, r2_store:0.32747369687244565\n",
            "torch.Size([80, 42])\n",
            "Epoch [7764/10000], train_Loss: 0.0008643367327749729,test_Loss:5.367452621459961, r2_store:0.31830557871478804\n",
            "torch.Size([80, 42])\n",
            "Epoch [7765/10000], train_Loss: 0.006078280508518219,test_Loss:5.085354804992676, r2_store:0.3299492185859254\n",
            "torch.Size([80, 42])\n",
            "Epoch [7766/10000], train_Loss: 0.00295500410720706,test_Loss:5.136142730712891, r2_store:0.32715416917159745\n",
            "torch.Size([80, 42])\n",
            "Epoch [7767/10000], train_Loss: 0.0008105885935947299,test_Loss:5.331726551055908, r2_store:0.3187983593892646\n",
            "torch.Size([80, 42])\n",
            "Epoch [7768/10000], train_Loss: 0.004635549150407314,test_Loss:5.102602958679199, r2_store:0.3286827255965201\n",
            "torch.Size([80, 42])\n",
            "Epoch [7769/10000], train_Loss: 0.0019190596649423242,test_Loss:5.139397621154785, r2_store:0.3271069581942234\n",
            "torch.Size([80, 42])\n",
            "Epoch [7770/10000], train_Loss: 0.0008950964547693729,test_Loss:5.321134567260742, r2_store:0.3187384780214062\n",
            "torch.Size([80, 42])\n",
            "Epoch [7771/10000], train_Loss: 0.003569747554138303,test_Loss:5.1133012771606445, r2_store:0.32645754296010954\n",
            "torch.Size([80, 42])\n",
            "Epoch [7772/10000], train_Loss: 0.0011088323080912232,test_Loss:5.113186359405518, r2_store:0.3261593941709533\n",
            "torch.Size([80, 42])\n",
            "Epoch [7773/10000], train_Loss: 0.0008964312146417797,test_Loss:5.280013084411621, r2_store:0.3196213733287734\n",
            "torch.Size([80, 42])\n",
            "Epoch [7774/10000], train_Loss: 0.0026350351981818676,test_Loss:5.1245927810668945, r2_store:0.32681513911877225\n",
            "torch.Size([80, 42])\n",
            "Epoch [7775/10000], train_Loss: 0.0006030508084222674,test_Loss:5.118769645690918, r2_store:0.3270812780520903\n",
            "torch.Size([80, 42])\n",
            "Epoch [7776/10000], train_Loss: 0.0008197149145416915,test_Loss:5.267702102661133, r2_store:0.31997990702413215\n",
            "torch.Size([80, 42])\n",
            "Epoch [7777/10000], train_Loss: 0.001866224454715848,test_Loss:5.139253616333008, r2_store:0.32512889589674254\n",
            "torch.Size([80, 42])\n",
            "Epoch [7778/10000], train_Loss: 0.0003209180140402168,test_Loss:5.115269184112549, r2_store:0.3264630772039169\n",
            "torch.Size([80, 42])\n",
            "Epoch [7779/10000], train_Loss: 0.0007426227093674242,test_Loss:5.251476764678955, r2_store:0.3217193019036816\n",
            "torch.Size([80, 42])\n",
            "Epoch [7780/10000], train_Loss: 0.0012658126652240753,test_Loss:5.162535667419434, r2_store:0.32649160273459\n",
            "torch.Size([80, 42])\n",
            "Epoch [7781/10000], train_Loss: 0.00014642042515333742,test_Loss:5.1315693855285645, r2_store:0.32800660019414896\n",
            "torch.Size([80, 42])\n",
            "Epoch [7782/10000], train_Loss: 0.0006757004885002971,test_Loss:5.250170707702637, r2_store:0.3226119168380325\n",
            "torch.Size([80, 42])\n",
            "Epoch [7783/10000], train_Loss: 0.0008329519187100232,test_Loss:5.181521415710449, r2_store:0.3250145341482781\n",
            "torch.Size([80, 42])\n",
            "Epoch [7784/10000], train_Loss: 7.54933716962114e-05,test_Loss:5.140961170196533, r2_store:0.3266797801715614\n",
            "torch.Size([80, 42])\n",
            "Epoch [7785/10000], train_Loss: 0.0005743128713220358,test_Loss:5.24465274810791, r2_store:0.32297253455783204\n",
            "torch.Size([80, 42])\n",
            "Epoch [7786/10000], train_Loss: 0.0005333368899300694,test_Loss:5.200642108917236, r2_store:0.3256078788496093\n",
            "torch.Size([80, 42])\n",
            "Epoch [7787/10000], train_Loss: 5.117577893543057e-05,test_Loss:5.154673099517822, r2_store:0.32778905917921486\n",
            "torch.Size([80, 42])\n",
            "Epoch [7788/10000], train_Loss: 0.0004672969807870686,test_Loss:5.23659610748291, r2_store:0.3241864425366938\n",
            "torch.Size([80, 42])\n",
            "Epoch [7789/10000], train_Loss: 0.00032801838824525476,test_Loss:5.203917980194092, r2_store:0.3251307557936035\n",
            "torch.Size([80, 42])\n",
            "Epoch [7790/10000], train_Loss: 4.98928056913428e-05,test_Loss:5.157729625701904, r2_store:0.3268760427100056\n",
            "torch.Size([80, 42])\n",
            "Epoch [7791/10000], train_Loss: 0.00036677386378869414,test_Loss:5.230761528015137, r2_store:0.32414084782523755\n",
            "torch.Size([80, 42])\n",
            "Epoch [7792/10000], train_Loss: 0.00019729584164451808,test_Loss:5.21676778793335, r2_store:0.32521019866513623\n",
            "torch.Size([80, 42])\n",
            "Epoch [7793/10000], train_Loss: 5.5846387112978846e-05,test_Loss:5.172516345977783, r2_store:0.32731604801272074\n",
            "torch.Size([80, 42])\n",
            "Epoch [7794/10000], train_Loss: 0.0002851418685168028,test_Loss:5.229578971862793, r2_store:0.3249319035012156\n",
            "torch.Size([80, 42])\n",
            "Epoch [7795/10000], train_Loss: 0.00011948459723498672,test_Loss:5.220086097717285, r2_store:0.32520754680278074\n",
            "torch.Size([80, 42])\n",
            "Epoch [7796/10000], train_Loss: 5.6329910876229405e-05,test_Loss:5.178837299346924, r2_store:0.32694315642911254\n",
            "torch.Size([80, 42])\n",
            "Epoch [7797/10000], train_Loss: 0.00021278159692883492,test_Loss:5.229506015777588, r2_store:0.32507223484841863\n",
            "torch.Size([80, 42])\n",
            "Epoch [7798/10000], train_Loss: 6.838099216111004e-05,test_Loss:5.229620933532715, r2_store:0.32526695903728586\n",
            "torch.Size([80, 42])\n",
            "Epoch [7799/10000], train_Loss: 5.444853377412073e-05,test_Loss:5.190316200256348, r2_store:0.3269169556630007\n",
            "torch.Size([80, 42])\n",
            "Epoch [7800/10000], train_Loss: 0.0001586040307302028,test_Loss:5.22761344909668, r2_store:0.3252656383716642\n",
            "torch.Size([80, 42])\n",
            "Epoch [7801/10000], train_Loss: 4.0763941797195e-05,test_Loss:5.2291059494018555, r2_store:0.32512947016947513\n",
            "torch.Size([80, 42])\n",
            "Epoch [7802/10000], train_Loss: 4.971919042873196e-05,test_Loss:5.1943583488464355, r2_store:0.3266521135514826\n",
            "torch.Size([80, 42])\n",
            "Epoch [7803/10000], train_Loss: 0.00011388557322788984,test_Loss:5.227554798126221, r2_store:0.32551626610257534\n",
            "torch.Size([80, 42])\n",
            "Epoch [7804/10000], train_Loss: 2.4518469217582606e-05,test_Loss:5.233355522155762, r2_store:0.32539466341268775\n",
            "torch.Size([80, 42])\n",
            "Epoch [7805/10000], train_Loss: 4.533298124442808e-05,test_Loss:5.199714660644531, r2_store:0.32665936247198035\n",
            "torch.Size([80, 42])\n",
            "Epoch [7806/10000], train_Loss: 8.229915692936629e-05,test_Loss:5.2215657234191895, r2_store:0.32552857294966675\n",
            "torch.Size([80, 42])\n",
            "Epoch [7807/10000], train_Loss: 1.4120862942945678e-05,test_Loss:5.225934028625488, r2_store:0.3251706742208599\n",
            "torch.Size([80, 42])\n",
            "Epoch [7808/10000], train_Loss: 3.828013359452598e-05,test_Loss:5.196893692016602, r2_store:0.32636888203388215\n",
            "torch.Size([80, 42])\n",
            "Epoch [7809/10000], train_Loss: 5.795682591269724e-05,test_Loss:5.216893196105957, r2_store:0.3256956061485\n",
            "torch.Size([80, 42])\n",
            "Epoch [7810/10000], train_Loss: 8.036889994400553e-06,test_Loss:5.22542667388916, r2_store:0.3254553115305825\n",
            "torch.Size([80, 42])\n",
            "Epoch [7811/10000], train_Loss: 3.229168214602396e-05,test_Loss:5.1999831199646, r2_store:0.326463108722605\n",
            "torch.Size([80, 42])\n",
            "Epoch [7812/10000], train_Loss: 4.1232437069993466e-05,test_Loss:5.214062690734863, r2_store:0.32575053125015263\n",
            "torch.Size([80, 42])\n",
            "Epoch [7813/10000], train_Loss: 5.216869794821832e-06,test_Loss:5.222001075744629, r2_store:0.3253271908923022\n",
            "torch.Size([80, 42])\n",
            "Epoch [7814/10000], train_Loss: 2.6013347451225854e-05,test_Loss:5.200993537902832, r2_store:0.32623064808388713\n",
            "torch.Size([80, 42])\n",
            "Epoch [7815/10000], train_Loss: 2.8895879950141534e-05,test_Loss:5.2142791748046875, r2_store:0.3258144119299319\n",
            "torch.Size([80, 42])\n",
            "Epoch [7816/10000], train_Loss: 3.984443537774496e-06,test_Loss:5.223804473876953, r2_store:0.3255348677541411\n",
            "torch.Size([80, 42])\n",
            "Epoch [7817/10000], train_Loss: 2.0845900507993065e-05,test_Loss:5.205565929412842, r2_store:0.32630833272242954\n",
            "torch.Size([80, 42])\n",
            "Epoch [7818/10000], train_Loss: 2.039241553575266e-05,test_Loss:5.214888095855713, r2_store:0.32589213207554335\n",
            "torch.Size([80, 42])\n",
            "Epoch [7819/10000], train_Loss: 2.7956004942097934e-06,test_Loss:5.222970485687256, r2_store:0.3255372609929049\n",
            "torch.Size([80, 42])\n",
            "Epoch [7820/10000], train_Loss: 1.607530975888949e-05,test_Loss:5.207396507263184, r2_store:0.32621403062768994\n",
            "torch.Size([80, 42])\n",
            "Epoch [7821/10000], train_Loss: 1.4286631085269619e-05,test_Loss:5.215890407562256, r2_store:0.32595453635586813\n",
            "torch.Size([80, 42])\n",
            "Epoch [7822/10000], train_Loss: 2.0460297491808888e-06,test_Loss:5.224221229553223, r2_store:0.32567587144893795\n",
            "torch.Size([80, 42])\n",
            "Epoch [7823/10000], train_Loss: 1.2480976693041157e-05,test_Loss:5.2107696533203125, r2_store:0.3262461258193915\n",
            "torch.Size([80, 42])\n",
            "Epoch [7824/10000], train_Loss: 1.0550274055276532e-05,test_Loss:5.21696138381958, r2_store:0.32595498827321734\n",
            "torch.Size([80, 42])\n",
            "Epoch [7825/10000], train_Loss: 1.6967571809800575e-06,test_Loss:5.2234787940979, r2_store:0.32566049296007404\n",
            "torch.Size([80, 42])\n",
            "Epoch [7826/10000], train_Loss: 9.49699642660562e-06,test_Loss:5.211899280548096, r2_store:0.32616651034381583\n",
            "torch.Size([80, 42])\n",
            "Epoch [7827/10000], train_Loss: 7.628271760040661e-06,test_Loss:5.217485427856445, r2_store:0.3259843625099046\n",
            "torch.Size([80, 42])\n",
            "Epoch [7828/10000], train_Loss: 1.4409716868613032e-06,test_Loss:5.223603248596191, r2_store:0.3257389911037405\n",
            "torch.Size([80, 42])\n",
            "Epoch [7829/10000], train_Loss: 7.260392067109933e-06,test_Loss:5.213242053985596, r2_store:0.32614161271241693\n",
            "torch.Size([80, 42])\n",
            "Epoch [7830/10000], train_Loss: 5.4847487263032235e-06,test_Loss:5.2169928550720215, r2_store:0.3259503024637377\n",
            "torch.Size([80, 42])\n",
            "Epoch [7831/10000], train_Loss: 1.0777778243209468e-06,test_Loss:5.221928596496582, r2_store:0.32575612495647965\n",
            "torch.Size([80, 42])\n",
            "Epoch [7832/10000], train_Loss: 5.361523108149413e-06,test_Loss:5.213222503662109, r2_store:0.32618567433161205\n",
            "torch.Size([80, 42])\n",
            "Epoch [7833/10000], train_Loss: 4.069493115821388e-06,test_Loss:5.216792583465576, r2_store:0.32609998884342195\n",
            "torch.Size([80, 42])\n",
            "Epoch [7834/10000], train_Loss: 8.931978072723723e-07,test_Loss:5.221071243286133, r2_store:0.32593635013705013\n",
            "torch.Size([80, 42])\n",
            "Epoch [7835/10000], train_Loss: 3.979966095357668e-06,test_Loss:5.213351249694824, r2_store:0.32622867123047294\n",
            "torch.Size([80, 42])\n",
            "Epoch [7836/10000], train_Loss: 3.0003288884472568e-06,test_Loss:5.216225624084473, r2_store:0.3260682944386476\n",
            "torch.Size([80, 42])\n",
            "Epoch [7837/10000], train_Loss: 6.939476406842005e-07,test_Loss:5.219953536987305, r2_store:0.3259053918803503\n",
            "torch.Size([80, 42])\n",
            "Epoch [7838/10000], train_Loss: 2.948171868411009e-06,test_Loss:5.213749885559082, r2_store:0.3261971368469557\n",
            "torch.Size([80, 42])\n",
            "Epoch [7839/10000], train_Loss: 2.2592830646317452e-06,test_Loss:5.216466903686523, r2_store:0.3261213141363214\n",
            "torch.Size([80, 42])\n",
            "Epoch [7840/10000], train_Loss: 5.432592047327489e-07,test_Loss:5.219588279724121, r2_store:0.3259994865899045\n",
            "torch.Size([80, 42])\n",
            "Epoch [7841/10000], train_Loss: 2.1463577013491886e-06,test_Loss:5.214080333709717, r2_store:0.3262097793345775\n",
            "torch.Size([80, 42])\n",
            "Epoch [7842/10000], train_Loss: 1.6948272332228953e-06,test_Loss:5.216446399688721, r2_store:0.32607904370924756\n",
            "torch.Size([80, 42])\n",
            "Epoch [7843/10000], train_Loss: 4.248870482115308e-07,test_Loss:5.219266414642334, r2_store:0.3259529982437843\n",
            "torch.Size([80, 42])\n",
            "Epoch [7844/10000], train_Loss: 1.5860407529544318e-06,test_Loss:5.214959621429443, r2_store:0.3261604832893098\n",
            "torch.Size([80, 42])\n",
            "Epoch [7845/10000], train_Loss: 1.318142494710628e-06,test_Loss:5.217329978942871, r2_store:0.32609631748690693\n",
            "torch.Size([80, 42])\n",
            "Epoch [7846/10000], train_Loss: 3.43885943721034e-07,test_Loss:5.219521522521973, r2_store:0.32602053696018407\n",
            "torch.Size([80, 42])\n",
            "Epoch [7847/10000], train_Loss: 1.1603889333855477e-06,test_Loss:5.215427875518799, r2_store:0.32618494056931135\n",
            "torch.Size([80, 42])\n",
            "Epoch [7848/10000], train_Loss: 1.0136020591744455e-06,test_Loss:5.217278957366943, r2_store:0.3260873695227149\n",
            "torch.Size([80, 42])\n",
            "Epoch [7849/10000], train_Loss: 2.951142050733324e-07,test_Loss:5.219110012054443, r2_store:0.32600648229769447\n",
            "torch.Size([80, 42])\n",
            "Epoch [7850/10000], train_Loss: 8.457235480818781e-07,test_Loss:5.2159342765808105, r2_store:0.3261542048228785\n",
            "torch.Size([80, 42])\n",
            "Epoch [7851/10000], train_Loss: 7.914514981166576e-07,test_Loss:5.217775821685791, r2_store:0.326089048748039\n",
            "torch.Size([80, 42])\n",
            "Epoch [7852/10000], train_Loss: 2.2878626282363257e-07,test_Loss:5.218963623046875, r2_store:0.32603964835322885\n",
            "torch.Size([80, 42])\n",
            "Epoch [7853/10000], train_Loss: 6.055937546989298e-07,test_Loss:5.2158732414245605, r2_store:0.3261659436753779\n",
            "torch.Size([80, 42])\n",
            "Epoch [7854/10000], train_Loss: 6.236672334125615e-07,test_Loss:5.21743106842041, r2_store:0.3261036412779087\n",
            "torch.Size([80, 42])\n",
            "Epoch [7855/10000], train_Loss: 1.939683897944633e-07,test_Loss:5.218533515930176, r2_store:0.32606776496672685\n",
            "torch.Size([80, 42])\n",
            "Epoch [7856/10000], train_Loss: 4.578203913752077e-07,test_Loss:5.216155052185059, r2_store:0.32618082909850554\n",
            "torch.Size([80, 42])\n",
            "Epoch [7857/10000], train_Loss: 4.978868446414708e-07,test_Loss:5.217724800109863, r2_store:0.32611895439903915\n",
            "torch.Size([80, 42])\n",
            "Epoch [7858/10000], train_Loss: 1.609181197181897e-07,test_Loss:5.218466758728027, r2_store:0.3260818049494717\n",
            "torch.Size([80, 42])\n",
            "Epoch [7859/10000], train_Loss: 3.3001674637489486e-07,test_Loss:5.216350078582764, r2_store:0.3261656885861579\n",
            "torch.Size([80, 42])\n",
            "Epoch [7860/10000], train_Loss: 3.945418995954242e-07,test_Loss:5.217792987823486, r2_store:0.32610919415025874\n",
            "torch.Size([80, 42])\n",
            "Epoch [7861/10000], train_Loss: 1.4018119998127077e-07,test_Loss:5.21839714050293, r2_store:0.3260962238082282\n",
            "torch.Size([80, 42])\n",
            "Epoch [7862/10000], train_Loss: 2.3919480440781626e-07,test_Loss:5.216666221618652, r2_store:0.3261777504511044\n",
            "torch.Size([80, 42])\n",
            "Epoch [7863/10000], train_Loss: 3.0778386417296133e-07,test_Loss:5.217924118041992, r2_store:0.32612075286603415\n",
            "torch.Size([80, 42])\n",
            "Epoch [7864/10000], train_Loss: 1.1924683462893881e-07,test_Loss:5.218197345733643, r2_store:0.3260989608801982\n",
            "torch.Size([80, 42])\n",
            "Epoch [7865/10000], train_Loss: 1.6633859445391863e-07,test_Loss:5.216756820678711, r2_store:0.32615232845031605\n",
            "torch.Size([80, 42])\n",
            "Epoch [7866/10000], train_Loss: 2.403558596597577e-07,test_Loss:5.217972278594971, r2_store:0.32610162320173797\n",
            "torch.Size([80, 42])\n",
            "Epoch [7867/10000], train_Loss: 1.1046248715729234e-07,test_Loss:5.218146324157715, r2_store:0.32610635572285007\n",
            "torch.Size([80, 42])\n",
            "Epoch [7868/10000], train_Loss: 1.1920186437919256e-07,test_Loss:5.2170281410217285, r2_store:0.32616787525011237\n",
            "torch.Size([80, 42])\n",
            "Epoch [7869/10000], train_Loss: 1.8711538984916842e-07,test_Loss:5.218145847320557, r2_store:0.326124422281899\n",
            "torch.Size([80, 42])\n",
            "Epoch [7870/10000], train_Loss: 9.973842907129438e-08,test_Loss:5.218138694763184, r2_store:0.32612094577705786\n",
            "torch.Size([80, 42])\n",
            "Epoch [7871/10000], train_Loss: 8.777040250151913e-08,test_Loss:5.2172346115112305, r2_store:0.3261542169843482\n",
            "torch.Size([80, 42])\n",
            "Epoch [7872/10000], train_Loss: 1.455196070310194e-07,test_Loss:5.218264579772949, r2_store:0.32610927359306774\n",
            "torch.Size([80, 42])\n",
            "Epoch [7873/10000], train_Loss: 8.875070278691055e-08,test_Loss:5.218134880065918, r2_store:0.32612091786414077\n",
            "torch.Size([80, 42])\n",
            "Epoch [7874/10000], train_Loss: 6.613443304104294e-08,test_Loss:5.217409610748291, r2_store:0.3261575107224317\n",
            "torch.Size([80, 42])\n",
            "Epoch [7875/10000], train_Loss: 1.092586998652223e-07,test_Loss:5.218254566192627, r2_store:0.3261221303383932\n",
            "torch.Size([80, 42])\n",
            "Epoch [7876/10000], train_Loss: 7.85863747410076e-08,test_Loss:5.218003273010254, r2_store:0.32612950595584445\n",
            "torch.Size([80, 42])\n",
            "Epoch [7877/10000], train_Loss: 5.361871302511645e-08,test_Loss:5.217453956604004, r2_store:0.3261494519307847\n",
            "torch.Size([80, 42])\n",
            "Epoch [7878/10000], train_Loss: 8.593259792633035e-08,test_Loss:5.218222141265869, r2_store:0.326116990770567\n",
            "torch.Size([80, 42])\n",
            "Epoch [7879/10000], train_Loss: 6.643390548788375e-08,test_Loss:5.217940330505371, r2_store:0.32613167805030807\n",
            "torch.Size([80, 42])\n",
            "Epoch [7880/10000], train_Loss: 4.30677999929685e-08,test_Loss:5.217512607574463, r2_store:0.3261505545093839\n",
            "torch.Size([80, 42])\n",
            "Epoch [7881/10000], train_Loss: 6.612578573594874e-08,test_Loss:5.218143463134766, r2_store:0.32612174185400156\n",
            "torch.Size([80, 42])\n",
            "Epoch [7882/10000], train_Loss: 5.797821955866311e-08,test_Loss:5.217831611633301, r2_store:0.32613220676879096\n",
            "torch.Size([80, 42])\n",
            "Epoch [7883/10000], train_Loss: 3.6039430995060684e-08,test_Loss:5.217596530914307, r2_store:0.32614290132763746\n",
            "torch.Size([80, 42])\n",
            "Epoch [7884/10000], train_Loss: 5.120380208722963e-08,test_Loss:5.218214988708496, r2_store:0.32612069193690063\n",
            "torch.Size([80, 42])\n",
            "Epoch [7885/10000], train_Loss: 5.048933715556814e-08,test_Loss:5.217907905578613, r2_store:0.32613742364653586\n",
            "torch.Size([80, 42])\n",
            "Epoch [7886/10000], train_Loss: 3.1037128422894966e-08,test_Loss:5.217738151550293, r2_store:0.32614656701234324\n",
            "torch.Size([80, 42])\n",
            "Epoch [7887/10000], train_Loss: 3.929375580469241e-08,test_Loss:5.218218803405762, r2_store:0.32612459711882014\n",
            "torch.Size([80, 42])\n",
            "Epoch [7888/10000], train_Loss: 4.2683794276854314e-08,test_Loss:5.217885971069336, r2_store:0.3261371750166915\n",
            "torch.Size([80, 42])\n",
            "Epoch [7889/10000], train_Loss: 2.7538851199437886e-08,test_Loss:5.217837333679199, r2_store:0.3261421272027355\n",
            "torch.Size([80, 42])\n",
            "Epoch [7890/10000], train_Loss: 3.088757338787218e-08,test_Loss:5.218282222747803, r2_store:0.3261270746351771\n",
            "torch.Size([80, 42])\n",
            "Epoch [7891/10000], train_Loss: 3.575842555392228e-08,test_Loss:5.217942237854004, r2_store:0.3261448552586478\n",
            "torch.Size([80, 42])\n",
            "Epoch [7892/10000], train_Loss: 2.506662610812782e-08,test_Loss:5.217917442321777, r2_store:0.32614669243002714\n",
            "torch.Size([80, 42])\n",
            "Epoch [7893/10000], train_Loss: 2.479242411368432e-08,test_Loss:5.218230247497559, r2_store:0.32613234900016186\n",
            "torch.Size([80, 42])\n",
            "Epoch [7894/10000], train_Loss: 2.9045292393448108e-08,test_Loss:5.217895030975342, r2_store:0.32614561866297276\n",
            "torch.Size([80, 42])\n",
            "Epoch [7895/10000], train_Loss: 2.198759929683547e-08,test_Loss:5.217936038970947, r2_store:0.32614372989558993\n",
            "torch.Size([80, 42])\n",
            "Epoch [7896/10000], train_Loss: 1.9518520133487982e-08,test_Loss:5.2181782722473145, r2_store:0.3261341235338442\n",
            "torch.Size([80, 42])\n",
            "Epoch [7897/10000], train_Loss: 2.3465958065571613e-08,test_Loss:5.21787691116333, r2_store:0.3261484900171304\n",
            "torch.Size([80, 42])\n",
            "Epoch [7898/10000], train_Loss: 1.945238459200027e-08,test_Loss:5.217982292175293, r2_store:0.3261452459388723\n",
            "torch.Size([80, 42])\n",
            "Epoch [7899/10000], train_Loss: 1.5633350614052688e-08,test_Loss:5.21815299987793, r2_store:0.32613675134877185\n",
            "torch.Size([80, 42])\n",
            "Epoch [7900/10000], train_Loss: 1.9141980445169793e-08,test_Loss:5.217868804931641, r2_store:0.3261480263889084\n",
            "torch.Size([80, 42])\n",
            "Epoch [7901/10000], train_Loss: 1.710546015942782e-08,test_Loss:5.2179975509643555, r2_store:0.32614318790700625\n",
            "torch.Size([80, 42])\n",
            "Epoch [7902/10000], train_Loss: 1.3147288591142114e-08,test_Loss:5.218129634857178, r2_store:0.32613804862442164\n",
            "torch.Size([80, 42])\n",
            "Epoch [7903/10000], train_Loss: 1.5452810586680243e-08,test_Loss:5.217905044555664, r2_store:0.32614852859867893\n",
            "torch.Size([80, 42])\n",
            "Epoch [7904/10000], train_Loss: 1.5196727431998625e-08,test_Loss:5.218077182769775, r2_store:0.3261410768638441\n",
            "torch.Size([80, 42])\n",
            "Epoch [7905/10000], train_Loss: 1.1390930865218252e-08,test_Loss:5.218149185180664, r2_store:0.3261384368220043\n",
            "torch.Size([80, 42])\n",
            "Epoch [7906/10000], train_Loss: 1.2088690937162028e-08,test_Loss:5.217963218688965, r2_store:0.32614777299157915\n",
            "torch.Size([80, 42])\n",
            "Epoch [7907/10000], train_Loss: 1.2812831684527737e-08,test_Loss:5.218128681182861, r2_store:0.3261416099712263\n",
            "torch.Size([80, 42])\n",
            "Epoch [7908/10000], train_Loss: 1.0110325021628341e-08,test_Loss:5.218140602111816, r2_store:0.3261417424445059\n",
            "torch.Size([80, 42])\n",
            "Epoch [7909/10000], train_Loss: 9.775119380606156e-09,test_Loss:5.2180047035217285, r2_store:0.3261475522956069\n",
            "torch.Size([80, 42])\n",
            "Epoch [7910/10000], train_Loss: 1.0596982846777792e-08,test_Loss:5.218180179595947, r2_store:0.32614026747628233\n",
            "torch.Size([80, 42])\n",
            "Epoch [7911/10000], train_Loss: 8.948233265471117e-09,test_Loss:5.218166828155518, r2_store:0.3261406936150719\n",
            "torch.Size([80, 42])\n",
            "Epoch [7912/10000], train_Loss: 8.125023320815217e-09,test_Loss:5.218050003051758, r2_store:0.3261458489256447\n",
            "torch.Size([80, 42])\n",
            "Epoch [7913/10000], train_Loss: 8.675366203192425e-09,test_Loss:5.218194007873535, r2_store:0.3261412758199628\n",
            "torch.Size([80, 42])\n",
            "Epoch [7914/10000], train_Loss: 7.656270284428501e-09,test_Loss:5.218167304992676, r2_store:0.3261436129844796\n",
            "torch.Size([80, 42])\n",
            "Epoch [7915/10000], train_Loss: 6.743147817900308e-09,test_Loss:5.218097686767578, r2_store:0.32614684301621577\n",
            "torch.Size([80, 42])\n",
            "Epoch [7916/10000], train_Loss: 7.235736454447306e-09,test_Loss:5.218226432800293, r2_store:0.3261400106401544\n",
            "torch.Size([80, 42])\n",
            "Epoch [7917/10000], train_Loss: 6.639000904584691e-09,test_Loss:5.21816349029541, r2_store:0.3261420009276461\n",
            "torch.Size([80, 42])\n",
            "Epoch [7918/10000], train_Loss: 5.617130760526834e-09,test_Loss:5.218122482299805, r2_store:0.32614453340515126\n",
            "torch.Size([80, 42])\n",
            "Epoch [7919/10000], train_Loss: 5.991552143314038e-09,test_Loss:5.218241214752197, r2_store:0.32614043519969615\n",
            "torch.Size([80, 42])\n",
            "Epoch [7920/10000], train_Loss: 5.848340478564751e-09,test_Loss:5.21816349029541, r2_store:0.3261439903882063\n",
            "torch.Size([80, 42])\n",
            "Epoch [7921/10000], train_Loss: 4.935309050324577e-09,test_Loss:5.218153953552246, r2_store:0.32614468485378534\n",
            "torch.Size([80, 42])\n",
            "Epoch [7922/10000], train_Loss: 4.9566764026565124e-09,test_Loss:5.218259334564209, r2_store:0.3261401677584359\n",
            "torch.Size([80, 42])\n",
            "Epoch [7923/10000], train_Loss: 5.088081511672726e-09,test_Loss:5.218180179595947, r2_store:0.3261437772532184\n",
            "torch.Size([80, 42])\n",
            "Epoch [7924/10000], train_Loss: 4.275595877345495e-09,test_Loss:5.218191146850586, r2_store:0.3261440071238504\n",
            "torch.Size([80, 42])\n",
            "Epoch [7925/10000], train_Loss: 4.1232643965827265e-09,test_Loss:5.218267440795898, r2_store:0.32614116240459956\n",
            "torch.Size([80, 42])\n",
            "Epoch [7926/10000], train_Loss: 4.392243901918391e-09,test_Loss:5.218174934387207, r2_store:0.32614486593405834\n",
            "torch.Size([80, 42])\n",
            "Epoch [7927/10000], train_Loss: 3.8494163412394755e-09,test_Loss:5.218213081359863, r2_store:0.32614360653319374\n",
            "torch.Size([80, 42])\n",
            "Epoch [7928/10000], train_Loss: 3.357653710622799e-09,test_Loss:5.218275547027588, r2_store:0.3261414830260614\n",
            "torch.Size([80, 42])\n",
            "Epoch [7929/10000], train_Loss: 3.545823856754282e-09,test_Loss:5.218199729919434, r2_store:0.3261453116442592\n",
            "torch.Size([80, 42])\n",
            "Epoch [7930/10000], train_Loss: 3.4292333417340615e-09,test_Loss:5.218242645263672, r2_store:0.32614346730391686\n",
            "torch.Size([80, 42])\n",
            "Epoch [7931/10000], train_Loss: 2.883429051081521e-09,test_Loss:5.218263149261475, r2_store:0.32614192867608516\n",
            "torch.Size([80, 42])\n",
            "Epoch [7932/10000], train_Loss: 3.0152733643262764e-09,test_Loss:5.218199253082275, r2_store:0.3261443626832702\n",
            "torch.Size([80, 42])\n",
            "Epoch [7933/10000], train_Loss: 2.9709217308493407e-09,test_Loss:5.21826171875, r2_store:0.3261419893478288\n",
            "torch.Size([80, 42])\n",
            "Epoch [7934/10000], train_Loss: 2.562712042575299e-09,test_Loss:5.218277931213379, r2_store:0.32614210070967586\n",
            "torch.Size([80, 42])\n",
            "Epoch [7935/10000], train_Loss: 2.455935455003555e-09,test_Loss:5.218227386474609, r2_store:0.32614509782359835\n",
            "torch.Size([80, 42])\n",
            "Epoch [7936/10000], train_Loss: 2.5087407706791964e-09,test_Loss:5.2182745933532715, r2_store:0.326143102941005\n",
            "torch.Size([80, 42])\n",
            "Epoch [7937/10000], train_Loss: 2.2779047537113684e-09,test_Loss:5.218255996704102, r2_store:0.3261435222810475\n",
            "torch.Size([80, 42])\n",
            "Epoch [7938/10000], train_Loss: 2.072127136543145e-09,test_Loss:5.218225955963135, r2_store:0.3261445437622653\n",
            "torch.Size([80, 42])\n",
            "Epoch [7939/10000], train_Loss: 2.050627223582069e-09,test_Loss:5.218284606933594, r2_store:0.3261422712126816\n",
            "torch.Size([80, 42])\n",
            "Epoch [7940/10000], train_Loss: 1.9746120294428238e-09,test_Loss:5.218264579772949, r2_store:0.3261435506040641\n",
            "torch.Size([80, 42])\n",
            "Epoch [7941/10000], train_Loss: 1.7585415346133004e-09,test_Loss:5.218242645263672, r2_store:0.32614433796914954\n",
            "torch.Size([80, 42])\n",
            "Epoch [7942/10000], train_Loss: 1.6746971587267012e-09,test_Loss:5.218278408050537, r2_store:0.326142971668012\n",
            "torch.Size([80, 42])\n",
            "Epoch [7943/10000], train_Loss: 1.6920127521302675e-09,test_Loss:5.218253135681152, r2_store:0.3261442664559401\n",
            "torch.Size([80, 42])\n",
            "Epoch [7944/10000], train_Loss: 1.4736492026656833e-09,test_Loss:5.21826171875, r2_store:0.3261439416141173\n",
            "torch.Size([80, 42])\n",
            "Epoch [7945/10000], train_Loss: 1.3817627042556069e-09,test_Loss:5.218291282653809, r2_store:0.3261424632977752\n",
            "torch.Size([80, 42])\n",
            "Epoch [7946/10000], train_Loss: 1.4070448139946734e-09,test_Loss:5.218266010284424, r2_store:0.3261436924235718\n",
            "torch.Size([80, 42])\n",
            "Epoch [7947/10000], train_Loss: 1.2945006178100016e-09,test_Loss:5.218277454376221, r2_store:0.32614348896709355\n",
            "torch.Size([80, 42])\n",
            "Epoch [7948/10000], train_Loss: 1.2167729046552722e-09,test_Loss:5.218296527862549, r2_store:0.32614309822893905\n",
            "torch.Size([80, 42])\n",
            "Epoch [7949/10000], train_Loss: 1.172089647560881e-09,test_Loss:5.2182722091674805, r2_store:0.3261446840880814\n",
            "torch.Size([80, 42])\n",
            "Epoch [7950/10000], train_Loss: 1.098963808843223e-09,test_Loss:5.218289852142334, r2_store:0.32614418416007773\n",
            "torch.Size([80, 42])\n",
            "Epoch [7951/10000], train_Loss: 1.0158210939081869e-09,test_Loss:5.218296051025391, r2_store:0.32614371884714977\n",
            "torch.Size([80, 42])\n",
            "Epoch [7952/10000], train_Loss: 9.840258607951569e-10,test_Loss:5.218276500701904, r2_store:0.32614437587031475\n",
            "torch.Size([80, 42])\n",
            "Epoch [7953/10000], train_Loss: 9.50125533805135e-10,test_Loss:5.21829891204834, r2_store:0.32614341226937893\n",
            "torch.Size([80, 42])\n",
            "Epoch [7954/10000], train_Loss: 8.642896398569633e-10,test_Loss:5.2183051109313965, r2_store:0.3261433018396329\n",
            "torch.Size([80, 42])\n",
            "Epoch [7955/10000], train_Loss: 8.209058433017447e-10,test_Loss:5.218287467956543, r2_store:0.3261443217779173\n",
            "torch.Size([80, 42])\n",
            "Epoch [7956/10000], train_Loss: 8.17174494738282e-10,test_Loss:5.2183027267456055, r2_store:0.32614366257515137\n",
            "torch.Size([80, 42])\n",
            "Epoch [7957/10000], train_Loss: 7.388883949133174e-10,test_Loss:5.218295097351074, r2_store:0.326143845068146\n",
            "torch.Size([80, 42])\n",
            "Epoch [7958/10000], train_Loss: 7.139457913751812e-10,test_Loss:5.218283176422119, r2_store:0.32614405115264045\n",
            "torch.Size([80, 42])\n",
            "Epoch [7959/10000], train_Loss: 6.973107646857102e-10,test_Loss:5.2183122634887695, r2_store:0.32614296729991377\n",
            "torch.Size([80, 42])\n",
            "Epoch [7960/10000], train_Loss: 6.537143049101246e-10,test_Loss:5.218306064605713, r2_store:0.3261436265564628\n",
            "torch.Size([80, 42])\n",
            "Epoch [7961/10000], train_Loss: 6.050492329379153e-10,test_Loss:5.218304634094238, r2_store:0.32614407978990667\n",
            "torch.Size([80, 42])\n",
            "Epoch [7962/10000], train_Loss: 5.762602617309653e-10,test_Loss:5.218316078186035, r2_store:0.32614382977429834\n",
            "torch.Size([80, 42])\n",
            "Epoch [7963/10000], train_Loss: 5.491602728113776e-10,test_Loss:5.218296051025391, r2_store:0.3261445173041636\n",
            "torch.Size([80, 42])\n",
            "Epoch [7964/10000], train_Loss: 5.349752307814981e-10,test_Loss:5.218306541442871, r2_store:0.32614402263477216\n",
            "torch.Size([80, 42])\n",
            "Epoch [7965/10000], train_Loss: 4.880002513196757e-10,test_Loss:5.218320369720459, r2_store:0.32614345003479406\n",
            "torch.Size([80, 42])\n",
            "Epoch [7966/10000], train_Loss: 4.685405952109534e-10,test_Loss:5.218310356140137, r2_store:0.3261439458235351\n",
            "torch.Size([80, 42])\n",
            "Epoch [7967/10000], train_Loss: 4.4838718848971837e-10,test_Loss:5.218318462371826, r2_store:0.32614375491416114\n",
            "torch.Size([80, 42])\n",
            "Epoch [7968/10000], train_Loss: 4.160192745850111e-10,test_Loss:5.218319892883301, r2_store:0.326143705339058\n",
            "torch.Size([80, 42])\n",
            "Epoch [7969/10000], train_Loss: 3.9835917897690365e-10,test_Loss:5.218301773071289, r2_store:0.32614441793144777\n",
            "torch.Size([80, 42])\n",
            "Epoch [7970/10000], train_Loss: 3.8578734651295576e-10,test_Loss:5.218320846557617, r2_store:0.3261436572030342\n",
            "torch.Size([80, 42])\n",
            "Epoch [7971/10000], train_Loss: 3.564928907628939e-10,test_Loss:5.218322277069092, r2_store:0.32614350980866436\n",
            "torch.Size([80, 42])\n",
            "Epoch [7972/10000], train_Loss: 3.3348002137501e-10,test_Loss:5.218311786651611, r2_store:0.32614386746847757\n",
            "torch.Size([80, 42])\n",
            "Epoch [7973/10000], train_Loss: 3.274310822476423e-10,test_Loss:5.218327522277832, r2_store:0.3261432328668499\n",
            "torch.Size([80, 42])\n",
            "Epoch [7974/10000], train_Loss: 3.150601168844247e-10,test_Loss:5.218321800231934, r2_store:0.3261436751113975\n",
            "torch.Size([80, 42])\n",
            "Epoch [7975/10000], train_Loss: 2.8564400844643956e-10,test_Loss:5.218315601348877, r2_store:0.3261440710699077\n",
            "torch.Size([80, 42])\n",
            "Epoch [7976/10000], train_Loss: 2.739793947270641e-10,test_Loss:5.2183332443237305, r2_store:0.32614352632436316\n",
            "torch.Size([80, 42])\n",
            "Epoch [7977/10000], train_Loss: 2.7303054261906823e-10,test_Loss:5.218318939208984, r2_store:0.3261441424574425\n",
            "torch.Size([80, 42])\n",
            "Epoch [7978/10000], train_Loss: 2.548309896432954e-10,test_Loss:5.218323230743408, r2_store:0.32614391591445435\n",
            "torch.Size([80, 42])\n",
            "Epoch [7979/10000], train_Loss: 2.3359608691819744e-10,test_Loss:5.218331336975098, r2_store:0.3261434271500653\n",
            "torch.Size([80, 42])\n",
            "Epoch [7980/10000], train_Loss: 2.290466705190397e-10,test_Loss:5.218321800231934, r2_store:0.32614382463980385\n",
            "torch.Size([80, 42])\n",
            "Epoch [7981/10000], train_Loss: 2.0741459938466988e-10,test_Loss:5.218327522277832, r2_store:0.326143756768272\n",
            "torch.Size([80, 42])\n",
            "Epoch [7982/10000], train_Loss: 1.9650614468957883e-10,test_Loss:5.218331336975098, r2_store:0.3261437051149073\n",
            "torch.Size([80, 42])\n",
            "Epoch [7983/10000], train_Loss: 1.9072214640925012e-10,test_Loss:5.218321800231934, r2_store:0.3261440515719449\n",
            "torch.Size([80, 42])\n",
            "Epoch [7984/10000], train_Loss: 1.762690410300749e-10,test_Loss:5.218325614929199, r2_store:0.32614379035946717\n",
            "torch.Size([80, 42])\n",
            "Epoch [7985/10000], train_Loss: 1.6832384097664743e-10,test_Loss:5.218329429626465, r2_store:0.3261435180495762\n",
            "torch.Size([80, 42])\n",
            "Epoch [7986/10000], train_Loss: 1.6105274058819674e-10,test_Loss:5.218323707580566, r2_store:0.3261438004702115\n",
            "torch.Size([80, 42])\n",
            "Epoch [7987/10000], train_Loss: 1.5452081281175367e-10,test_Loss:5.218336582183838, r2_store:0.3261433065706669\n",
            "torch.Size([80, 42])\n",
            "Epoch [7988/10000], train_Loss: 1.4889253718841644e-10,test_Loss:5.218331813812256, r2_store:0.3261437339300519\n",
            "torch.Size([80, 42])\n",
            "Epoch [7989/10000], train_Loss: 1.324144960346274e-10,test_Loss:5.218325614929199, r2_store:0.3261441361260259\n",
            "torch.Size([80, 42])\n",
            "Epoch [7990/10000], train_Loss: 1.2680646810370177e-10,test_Loss:5.21833610534668, r2_store:0.3261436250526949\n",
            "torch.Size([80, 42])\n",
            "Epoch [7991/10000], train_Loss: 1.29308397323058e-10,test_Loss:5.21832799911499, r2_store:0.32614381833785966\n",
            "torch.Size([80, 42])\n",
            "Epoch [7992/10000], train_Loss: 1.127517731958072e-10,test_Loss:5.218330383300781, r2_store:0.32614380501444995\n",
            "torch.Size([80, 42])\n",
            "Epoch [7993/10000], train_Loss: 1.0727500138196788e-10,test_Loss:5.218342304229736, r2_store:0.3261433141041059\n",
            "torch.Size([80, 42])\n",
            "Epoch [7994/10000], train_Loss: 1.0842646919195786e-10,test_Loss:5.218329906463623, r2_store:0.32614381588676\n",
            "torch.Size([80, 42])\n",
            "Epoch [7995/10000], train_Loss: 9.967050795811616e-11,test_Loss:5.2183356285095215, r2_store:0.32614373155725973\n",
            "torch.Size([80, 42])\n",
            "Epoch [7996/10000], train_Loss: 8.871613860206295e-11,test_Loss:5.218338966369629, r2_store:0.3261435438625018\n",
            "torch.Size([80, 42])\n",
            "Epoch [7997/10000], train_Loss: 8.869669582134421e-11,test_Loss:5.218329429626465, r2_store:0.3261439555395983\n",
            "torch.Size([80, 42])\n",
            "Epoch [7998/10000], train_Loss: 8.486557290243724e-11,test_Loss:5.2183380126953125, r2_store:0.32614351738386593\n",
            "torch.Size([80, 42])\n",
            "Epoch [7999/10000], train_Loss: 7.681739272458188e-11,test_Loss:5.218339920043945, r2_store:0.32614341042662665\n",
            "torch.Size([80, 42])\n",
            "Epoch [8000/10000], train_Loss: 7.488672876254654e-11,test_Loss:5.218331813812256, r2_store:0.3261437561222984\n",
            "torch.Size([80, 42])\n",
            "Epoch [8001/10000], train_Loss: 7.7133376075178e-11,test_Loss:5.2183427810668945, r2_store:0.3261434142101548\n",
            "torch.Size([80, 42])\n",
            "Epoch [8002/10000], train_Loss: 6.934434276795187e-11,test_Loss:5.218340873718262, r2_store:0.32614363109594724\n",
            "torch.Size([80, 42])\n",
            "Epoch [8003/10000], train_Loss: 5.961708210433514e-11,test_Loss:5.218334197998047, r2_store:0.3261439432671911\n",
            "torch.Size([80, 42])\n",
            "Epoch [8004/10000], train_Loss: 6.579219807845149e-11,test_Loss:5.218345642089844, r2_store:0.3261435692971625\n",
            "torch.Size([80, 42])\n",
            "Epoch [8005/10000], train_Loss: 6.22718127063493e-11,test_Loss:5.218338966369629, r2_store:0.3261437490461121\n",
            "torch.Size([80, 42])\n",
            "Epoch [8006/10000], train_Loss: 5.3272504463297565e-11,test_Loss:5.218337535858154, r2_store:0.3261436862079812\n",
            "torch.Size([80, 42])\n",
            "Epoch [8007/10000], train_Loss: 5.22881807296649e-11,test_Loss:5.218347549438477, r2_store:0.32614331652663375\n",
            "torch.Size([80, 42])\n",
            "Epoch [8008/10000], train_Loss: 5.32650208662222e-11,test_Loss:5.2183380126953125, r2_store:0.32614374800580126\n",
            "torch.Size([80, 42])\n",
            "Epoch [8009/10000], train_Loss: 4.7032412686665026e-11,test_Loss:5.218340873718262, r2_store:0.32614371043207113\n",
            "torch.Size([80, 42])\n",
            "Epoch [8010/10000], train_Loss: 4.309229015286853e-11,test_Loss:5.218344688415527, r2_store:0.3261434537657515\n",
            "torch.Size([80, 42])\n",
            "Epoch [8011/10000], train_Loss: 4.609912104824865e-11,test_Loss:5.218335151672363, r2_store:0.326143989426093\n",
            "torch.Size([80, 42])\n",
            "Epoch [8012/10000], train_Loss: 4.404940301405702e-11,test_Loss:5.218344688415527, r2_store:0.32614348919510283\n",
            "torch.Size([80, 42])\n",
            "Epoch [8013/10000], train_Loss: 3.6836936279094346e-11,test_Loss:5.218344688415527, r2_store:0.3261434213395875\n",
            "torch.Size([80, 42])\n",
            "Epoch [8014/10000], train_Loss: 3.510669532857946e-11,test_Loss:5.218337535858154, r2_store:0.32614377262813987\n",
            "torch.Size([80, 42])\n",
            "Epoch [8015/10000], train_Loss: 3.6852847162816005e-11,test_Loss:5.21834659576416, r2_store:0.3261434506232167\n",
            "torch.Size([80, 42])\n",
            "Epoch [8016/10000], train_Loss: 3.264803011271411e-11,test_Loss:5.218343257904053, r2_store:0.32614367399646127\n",
            "torch.Size([80, 42])\n",
            "Epoch [8017/10000], train_Loss: 2.9624386277404824e-11,test_Loss:5.218338966369629, r2_store:0.32614380446737434\n",
            "torch.Size([80, 42])\n",
            "Epoch [8018/10000], train_Loss: 2.741465908451257e-11,test_Loss:5.2183451652526855, r2_store:0.32614351025210475\n",
            "torch.Size([80, 42])\n",
            "Epoch [8019/10000], train_Loss: 2.87446923902257e-11,test_Loss:5.2183403968811035, r2_store:0.32614366594390787\n",
            "torch.Size([80, 42])\n",
            "Epoch [8020/10000], train_Loss: 2.5557181371205218e-11,test_Loss:5.218344211578369, r2_store:0.3261436037983265\n",
            "torch.Size([80, 42])\n",
            "Epoch [8021/10000], train_Loss: 2.340871420314361e-11,test_Loss:5.21834659576416, r2_store:0.32614348646085756\n",
            "torch.Size([80, 42])\n",
            "Epoch [8022/10000], train_Loss: 2.277627565716589e-11,test_Loss:5.218341827392578, r2_store:0.3261437815789233\n",
            "torch.Size([80, 42])\n",
            "Epoch [8023/10000], train_Loss: 2.1066835775851445e-11,test_Loss:5.2183427810668945, r2_store:0.32614371762621164\n",
            "torch.Size([80, 42])\n",
            "Epoch [8024/10000], train_Loss: 1.9521793903631846e-11,test_Loss:5.218344688415527, r2_store:0.3261435170087187\n",
            "torch.Size([80, 42])\n",
            "Epoch [8025/10000], train_Loss: 1.8790653061317997e-11,test_Loss:5.218342304229736, r2_store:0.3261435928102403\n",
            "torch.Size([80, 42])\n",
            "Epoch [8026/10000], train_Loss: 1.861674356340437e-11,test_Loss:5.218344688415527, r2_store:0.3261433746868325\n",
            "torch.Size([80, 42])\n",
            "Epoch [8027/10000], train_Loss: 1.7195975546280273e-11,test_Loss:5.218347072601318, r2_store:0.3261434134106739\n",
            "torch.Size([80, 42])\n",
            "Epoch [8028/10000], train_Loss: 1.605606446408725e-11,test_Loss:5.218344688415527, r2_store:0.3261435345374629\n",
            "torch.Size([80, 42])\n",
            "Epoch [8029/10000], train_Loss: 1.489457515657655e-11,test_Loss:5.218347549438477, r2_store:0.32614355016862795\n",
            "torch.Size([80, 42])\n",
            "Epoch [8030/10000], train_Loss: 1.4203425761916133e-11,test_Loss:5.218346118927002, r2_store:0.32614362922223894\n",
            "torch.Size([80, 42])\n",
            "Epoch [8031/10000], train_Loss: 1.4179222032617567e-11,test_Loss:5.218344688415527, r2_store:0.32614360664656405\n",
            "torch.Size([80, 42])\n",
            "Epoch [8032/10000], train_Loss: 1.3070144792848293e-11,test_Loss:5.218348503112793, r2_store:0.32614346986645704\n",
            "torch.Size([80, 42])\n",
            "Epoch [8033/10000], train_Loss: 1.178540858653987e-11,test_Loss:5.218347549438477, r2_store:0.3261434468264841\n",
            "torch.Size([80, 42])\n",
            "Epoch [8034/10000], train_Loss: 1.1296898312640469e-11,test_Loss:5.218348026275635, r2_store:0.3261434596599716\n",
            "torch.Size([80, 42])\n",
            "Epoch [8035/10000], train_Loss: 1.0888857523982942e-11,test_Loss:5.218348503112793, r2_store:0.3261435440633922\n",
            "torch.Size([80, 42])\n",
            "Epoch [8036/10000], train_Loss: 1.0024333793601237e-11,test_Loss:5.21834659576416, r2_store:0.32614359898818146\n",
            "torch.Size([80, 42])\n",
            "Epoch [8037/10000], train_Loss: 9.646761688075767e-12,test_Loss:5.21834659576416, r2_store:0.3261436436479873\n",
            "torch.Size([80, 42])\n",
            "Epoch [8038/10000], train_Loss: 9.17601411520863e-12,test_Loss:5.21834659576416, r2_store:0.32614360829227396\n",
            "torch.Size([80, 42])\n",
            "Epoch [8039/10000], train_Loss: 8.647634691660855e-12,test_Loss:5.218348503112793, r2_store:0.32614344493224345\n",
            "torch.Size([80, 42])\n",
            "Epoch [8040/10000], train_Loss: 8.14027924928018e-12,test_Loss:5.218348026275635, r2_store:0.3261434724571787\n",
            "torch.Size([80, 42])\n",
            "Epoch [8041/10000], train_Loss: 8.126553249776514e-12,test_Loss:5.218348503112793, r2_store:0.3261434481034303\n",
            "torch.Size([80, 42])\n",
            "Epoch [8042/10000], train_Loss: 7.453210791596998e-12,test_Loss:5.218348979949951, r2_store:0.32614347915178366\n",
            "torch.Size([80, 42])\n",
            "Epoch [8043/10000], train_Loss: 6.915724069800344e-12,test_Loss:5.218348026275635, r2_store:0.32614353016654485\n",
            "torch.Size([80, 42])\n",
            "Epoch [8044/10000], train_Loss: 6.9705929396646216e-12,test_Loss:5.218347549438477, r2_store:0.32614356407180844\n",
            "torch.Size([80, 42])\n",
            "Epoch [8045/10000], train_Loss: 6.427276679626948e-12,test_Loss:5.218348979949951, r2_store:0.326143414490885\n",
            "torch.Size([80, 42])\n",
            "Epoch [8046/10000], train_Loss: 5.89516413115887e-12,test_Loss:5.218350887298584, r2_store:0.3261433890087464\n",
            "torch.Size([80, 42])\n",
            "Epoch [8047/10000], train_Loss: 5.746508303927644e-12,test_Loss:5.218348503112793, r2_store:0.3261433978745335\n",
            "torch.Size([80, 42])\n",
            "Epoch [8048/10000], train_Loss: 5.537200472444104e-12,test_Loss:5.218350410461426, r2_store:0.32614338613289007\n",
            "torch.Size([80, 42])\n",
            "Epoch [8049/10000], train_Loss: 4.773443359334939e-12,test_Loss:5.218349456787109, r2_store:0.3261434106453972\n",
            "torch.Size([80, 42])\n",
            "Epoch [8050/10000], train_Loss: 4.848842247856533e-12,test_Loss:5.21834659576416, r2_store:0.3261435380656088\n",
            "torch.Size([80, 42])\n",
            "Epoch [8051/10000], train_Loss: 4.905408110961185e-12,test_Loss:5.218350410461426, r2_store:0.3261434341679995\n",
            "torch.Size([80, 42])\n",
            "Epoch [8052/10000], train_Loss: 4.779926454645533e-12,test_Loss:5.218349456787109, r2_store:0.3261434383883274\n",
            "torch.Size([80, 42])\n",
            "Epoch [8053/10000], train_Loss: 4.065877842740484e-12,test_Loss:5.218349456787109, r2_store:0.3261434398542177\n",
            "torch.Size([80, 42])\n",
            "Epoch [8054/10000], train_Loss: 3.938102014627853e-12,test_Loss:5.218351364135742, r2_store:0.3261433574202487\n",
            "torch.Size([80, 42])\n",
            "Epoch [8055/10000], train_Loss: 3.679801689054907e-12,test_Loss:5.218350410461426, r2_store:0.32614342774864513\n",
            "torch.Size([80, 42])\n",
            "Epoch [8056/10000], train_Loss: 3.6064061893076316e-12,test_Loss:5.218350410461426, r2_store:0.3261434305945966\n",
            "torch.Size([80, 42])\n",
            "Epoch [8057/10000], train_Loss: 3.378963775446664e-12,test_Loss:5.218350887298584, r2_store:0.3261434316032603\n",
            "torch.Size([80, 42])\n",
            "Epoch [8058/10000], train_Loss: 3.3140066212078434e-12,test_Loss:5.218349933624268, r2_store:0.32614346092498614\n",
            "torch.Size([80, 42])\n",
            "Epoch [8059/10000], train_Loss: 2.796294445994718e-12,test_Loss:5.2183518409729, r2_store:0.32614341564638016\n",
            "torch.Size([80, 42])\n",
            "Epoch [8060/10000], train_Loss: 2.929743253554662e-12,test_Loss:5.2183518409729, r2_store:0.3261433757731885\n",
            "torch.Size([80, 42])\n",
            "Epoch [8061/10000], train_Loss: 2.903742133894549e-12,test_Loss:5.218350410461426, r2_store:0.3261433717437925\n",
            "torch.Size([80, 42])\n",
            "Epoch [8062/10000], train_Loss: 2.674397595742173e-12,test_Loss:5.218350410461426, r2_store:0.3261433870225974\n",
            "torch.Size([80, 42])\n",
            "Epoch [8063/10000], train_Loss: 2.4382624825430854e-12,test_Loss:5.218349456787109, r2_store:0.32614340017888377\n",
            "torch.Size([80, 42])\n",
            "Epoch [8064/10000], train_Loss: 2.1444183234686776e-12,test_Loss:5.218350887298584, r2_store:0.32614333638775506\n",
            "torch.Size([80, 42])\n",
            "Epoch [8065/10000], train_Loss: 2.3837483636296453e-12,test_Loss:5.218348503112793, r2_store:0.3261434247390721\n",
            "torch.Size([80, 42])\n",
            "Epoch [8066/10000], train_Loss: 2.1435184356655146e-12,test_Loss:5.218350410461426, r2_store:0.3261433725183721\n",
            "torch.Size([80, 42])\n",
            "Epoch [8067/10000], train_Loss: 2.133626175043757e-12,test_Loss:5.218350410461426, r2_store:0.32614334893204355\n",
            "torch.Size([80, 42])\n",
            "Epoch [8068/10000], train_Loss: 2.021136296520565e-12,test_Loss:5.218350410461426, r2_store:0.3261433421743819\n",
            "torch.Size([80, 42])\n",
            "Epoch [8069/10000], train_Loss: 1.894011640232729e-12,test_Loss:5.218349933624268, r2_store:0.3261433809925328\n",
            "torch.Size([80, 42])\n",
            "Epoch [8070/10000], train_Loss: 1.762441971878137e-12,test_Loss:5.218350410461426, r2_store:0.3261433977803406\n",
            "torch.Size([80, 42])\n",
            "Epoch [8071/10000], train_Loss: 1.70444040825668e-12,test_Loss:5.218350410461426, r2_store:0.3261433553562677\n",
            "torch.Size([80, 42])\n",
            "Epoch [8072/10000], train_Loss: 1.5536627973739003e-12,test_Loss:5.218349456787109, r2_store:0.32614340013277665\n",
            "torch.Size([80, 42])\n",
            "Epoch [8073/10000], train_Loss: 1.6588012430665544e-12,test_Loss:5.218349456787109, r2_store:0.3261433804318089\n",
            "torch.Size([80, 42])\n",
            "Epoch [8074/10000], train_Loss: 1.461544643990842e-12,test_Loss:5.218350410461426, r2_store:0.3261433472172137\n",
            "torch.Size([80, 42])\n",
            "Epoch [8075/10000], train_Loss: 1.4798893447492967e-12,test_Loss:5.218348503112793, r2_store:0.32614339389205926\n",
            "torch.Size([80, 42])\n",
            "Epoch [8076/10000], train_Loss: 1.4122958445078604e-12,test_Loss:5.218349456787109, r2_store:0.3261433640587692\n",
            "torch.Size([80, 42])\n",
            "Epoch [8077/10000], train_Loss: 1.3138894269446033e-12,test_Loss:5.218350410461426, r2_store:0.3261433626235479\n",
            "torch.Size([80, 42])\n",
            "Epoch [8078/10000], train_Loss: 1.2811886968000508e-12,test_Loss:5.218350410461426, r2_store:0.3261434274066318\n",
            "torch.Size([80, 42])\n",
            "Epoch [8079/10000], train_Loss: 1.3684316266943108e-12,test_Loss:5.218352317810059, r2_store:0.3261433930275721\n",
            "torch.Size([80, 42])\n",
            "Epoch [8080/10000], train_Loss: 1.1174984548834033e-12,test_Loss:5.218352317810059, r2_store:0.32614332648166\n",
            "torch.Size([80, 42])\n",
            "Epoch [8081/10000], train_Loss: 1.0945389559979812e-12,test_Loss:5.2183518409729, r2_store:0.32614332873733154\n",
            "torch.Size([80, 42])\n",
            "Epoch [8082/10000], train_Loss: 1.0724405304779472e-12,test_Loss:5.218352317810059, r2_store:0.3261432946870175\n",
            "torch.Size([80, 42])\n",
            "Epoch [8083/10000], train_Loss: 1.026973428172595e-12,test_Loss:5.218352317810059, r2_store:0.32614323892713204\n",
            "torch.Size([80, 42])\n",
            "Epoch [8084/10000], train_Loss: 1.0686448470922927e-12,test_Loss:5.218350887298584, r2_store:0.32614329486569005\n",
            "torch.Size([80, 42])\n",
            "Epoch [8085/10000], train_Loss: 1.0223108167298212e-12,test_Loss:5.218352317810059, r2_store:0.3261433037994429\n",
            "torch.Size([80, 42])\n",
            "Epoch [8086/10000], train_Loss: 1.0538280317828885e-12,test_Loss:5.218352794647217, r2_store:0.3261432825839812\n",
            "torch.Size([80, 42])\n",
            "Epoch [8087/10000], train_Loss: 1.1655322974118976e-12,test_Loss:5.218352317810059, r2_store:0.32614340015928367\n",
            "torch.Size([80, 42])\n",
            "Epoch [8088/10000], train_Loss: 1.0336533061774955e-12,test_Loss:5.218352317810059, r2_store:0.3261433285488221\n",
            "torch.Size([80, 42])\n",
            "Epoch [8089/10000], train_Loss: 9.117665390051544e-13,test_Loss:5.218354225158691, r2_store:0.32614331935440266\n",
            "torch.Size([80, 42])\n",
            "Epoch [8090/10000], train_Loss: 1.0716824563189453e-12,test_Loss:5.218352794647217, r2_store:0.32614329034568434\n",
            "torch.Size([80, 42])\n",
            "Epoch [8091/10000], train_Loss: 9.12277631909264e-13,test_Loss:5.218352317810059, r2_store:0.326143356655751\n",
            "torch.Size([80, 42])\n",
            "Epoch [8092/10000], train_Loss: 9.351448651898076e-13,test_Loss:5.218353271484375, r2_store:0.3261432119420087\n",
            "torch.Size([80, 42])\n",
            "Epoch [8093/10000], train_Loss: 7.110867342001448e-13,test_Loss:5.218354225158691, r2_store:0.32614323272198464\n",
            "torch.Size([80, 42])\n",
            "Epoch [8094/10000], train_Loss: 6.785233724708462e-13,test_Loss:5.218352794647217, r2_store:0.3261432517872003\n",
            "torch.Size([80, 42])\n",
            "Epoch [8095/10000], train_Loss: 7.672149590978727e-13,test_Loss:5.218352794647217, r2_store:0.3261432428449439\n",
            "torch.Size([80, 42])\n",
            "Epoch [8096/10000], train_Loss: 7.32085995557713e-13,test_Loss:5.218352794647217, r2_store:0.3261432621696142\n",
            "torch.Size([80, 42])\n",
            "Epoch [8097/10000], train_Loss: 7.317164452472213e-13,test_Loss:5.218354225158691, r2_store:0.32614328298136674\n",
            "torch.Size([80, 42])\n",
            "Epoch [8098/10000], train_Loss: 8.0502314883657e-13,test_Loss:5.218354225158691, r2_store:0.3261432702425795\n",
            "torch.Size([80, 42])\n",
            "Epoch [8099/10000], train_Loss: 6.803818576248122e-13,test_Loss:5.21835470199585, r2_store:0.3261433219358002\n",
            "torch.Size([80, 42])\n",
            "Epoch [8100/10000], train_Loss: 7.072914844953593e-13,test_Loss:5.218354225158691, r2_store:0.32614325396702826\n",
            "torch.Size([80, 42])\n",
            "Epoch [8101/10000], train_Loss: 6.293501960893955e-13,test_Loss:5.218354225158691, r2_store:0.3261432484933453\n",
            "torch.Size([80, 42])\n",
            "Epoch [8102/10000], train_Loss: 5.00832448430133e-13,test_Loss:5.218354225158691, r2_store:0.32614322551874464\n",
            "torch.Size([80, 42])\n",
            "Epoch [8103/10000], train_Loss: 5.396155527623292e-13,test_Loss:5.218353748321533, r2_store:0.32614320600704894\n",
            "torch.Size([80, 42])\n",
            "Epoch [8104/10000], train_Loss: 4.5341516457207687e-13,test_Loss:5.218354225158691, r2_store:0.32614325495449936\n",
            "torch.Size([80, 42])\n",
            "Epoch [8105/10000], train_Loss: 4.623025595153207e-13,test_Loss:5.218354225158691, r2_store:0.32614327880834304\n",
            "torch.Size([80, 42])\n",
            "Epoch [8106/10000], train_Loss: 5.285939871577106e-13,test_Loss:5.21835470199585, r2_store:0.326143303408406\n",
            "torch.Size([80, 42])\n",
            "Epoch [8107/10000], train_Loss: 4.73457210936612e-13,test_Loss:5.218354225158691, r2_store:0.32614324991251675\n",
            "torch.Size([80, 42])\n",
            "Epoch [8108/10000], train_Loss: 5.015524670928806e-13,test_Loss:5.218354225158691, r2_store:0.3261432030052115\n",
            "torch.Size([80, 42])\n",
            "Epoch [8109/10000], train_Loss: 4.3993359844819724e-13,test_Loss:5.218353748321533, r2_store:0.32614317979242513\n",
            "torch.Size([80, 42])\n",
            "Epoch [8110/10000], train_Loss: 3.7689686441244596e-13,test_Loss:5.218353748321533, r2_store:0.32614325032625\n",
            "torch.Size([80, 42])\n",
            "Epoch [8111/10000], train_Loss: 3.595462415208889e-13,test_Loss:5.218354225158691, r2_store:0.32614325500494734\n",
            "torch.Size([80, 42])\n",
            "Epoch [8112/10000], train_Loss: 3.7749019405133866e-13,test_Loss:5.21835470199585, r2_store:0.3261432751877451\n",
            "torch.Size([80, 42])\n",
            "Epoch [8113/10000], train_Loss: 4.602058751440596e-13,test_Loss:5.21835470199585, r2_store:0.3261431813097224\n",
            "torch.Size([80, 42])\n",
            "Epoch [8114/10000], train_Loss: 3.909556597729569e-13,test_Loss:5.21835470199585, r2_store:0.32614320127300456\n",
            "torch.Size([80, 42])\n",
            "Epoch [8115/10000], train_Loss: 3.721838917787601e-13,test_Loss:5.21835470199585, r2_store:0.32614323301412307\n",
            "torch.Size([80, 42])\n",
            "Epoch [8116/10000], train_Loss: 4.0266081484732763e-13,test_Loss:5.218354225158691, r2_store:0.32614322385385686\n",
            "torch.Size([80, 42])\n",
            "Epoch [8117/10000], train_Loss: 3.785075009497818e-13,test_Loss:5.218354225158691, r2_store:0.3261432226180162\n",
            "torch.Size([80, 42])\n",
            "Epoch [8118/10000], train_Loss: 3.6839772226716916e-13,test_Loss:5.218355178833008, r2_store:0.3261432262234957\n",
            "torch.Size([80, 42])\n",
            "Epoch [8119/10000], train_Loss: 3.664105423153291e-13,test_Loss:5.218354225158691, r2_store:0.32614328177586427\n",
            "torch.Size([80, 42])\n",
            "Epoch [8120/10000], train_Loss: 3.0492584368949083e-13,test_Loss:5.218354225158691, r2_store:0.32614328960603445\n",
            "torch.Size([80, 42])\n",
            "Epoch [8121/10000], train_Loss: 3.7438338562102713e-13,test_Loss:5.218353748321533, r2_store:0.3261432809888116\n",
            "torch.Size([80, 42])\n",
            "Epoch [8122/10000], train_Loss: 3.517542160325071e-13,test_Loss:5.21835470199585, r2_store:0.32614321406902924\n",
            "torch.Size([80, 42])\n",
            "Epoch [8123/10000], train_Loss: 3.4005328934660906e-13,test_Loss:5.21835470199585, r2_store:0.3261432669474176\n",
            "torch.Size([80, 42])\n",
            "Epoch [8124/10000], train_Loss: 1.963537839266838e-13,test_Loss:5.218354225158691, r2_store:0.32614326782747294\n",
            "torch.Size([80, 42])\n",
            "Epoch [8125/10000], train_Loss: 2.647268797402458e-13,test_Loss:5.218354225158691, r2_store:0.3261433052701822\n",
            "torch.Size([80, 42])\n",
            "Epoch [8126/10000], train_Loss: 2.568918927407793e-13,test_Loss:5.218354225158691, r2_store:0.3261432934778544\n",
            "torch.Size([80, 42])\n",
            "Epoch [8127/10000], train_Loss: 3.0277760550492805e-13,test_Loss:5.218354225158691, r2_store:0.32614330709389106\n",
            "torch.Size([80, 42])\n",
            "Epoch [8128/10000], train_Loss: 2.9675900951008083e-13,test_Loss:5.218354225158691, r2_store:0.3261432728240443\n",
            "torch.Size([80, 42])\n",
            "Epoch [8129/10000], train_Loss: 2.9679969419660335e-13,test_Loss:5.218354225158691, r2_store:0.32614330884720977\n",
            "torch.Size([80, 42])\n",
            "Epoch [8130/10000], train_Loss: 2.998380623647767e-13,test_Loss:5.218354225158691, r2_store:0.32614330631995114\n",
            "torch.Size([80, 42])\n",
            "Epoch [8131/10000], train_Loss: 2.652157193947652e-13,test_Loss:5.218353271484375, r2_store:0.32614332628898923\n",
            "torch.Size([80, 42])\n",
            "Epoch [8132/10000], train_Loss: 2.436390932752941e-13,test_Loss:5.218353271484375, r2_store:0.3261432928882769\n",
            "torch.Size([80, 42])\n",
            "Epoch [8133/10000], train_Loss: 2.324374145847713e-13,test_Loss:5.218353271484375, r2_store:0.3261432399896206\n",
            "torch.Size([80, 42])\n",
            "Epoch [8134/10000], train_Loss: 2.721541796178034e-13,test_Loss:5.218354225158691, r2_store:0.32614329493344696\n",
            "torch.Size([80, 42])\n",
            "Epoch [8135/10000], train_Loss: 2.4476427828989955e-13,test_Loss:5.21835470199585, r2_store:0.3261432591799074\n",
            "torch.Size([80, 42])\n",
            "Epoch [8136/10000], train_Loss: 1.7526792192058827e-13,test_Loss:5.21835470199585, r2_store:0.3261432436523545\n",
            "torch.Size([80, 42])\n",
            "Epoch [8137/10000], train_Loss: 2.710297264396644e-13,test_Loss:5.218355178833008, r2_store:0.3261432868638059\n",
            "torch.Size([80, 42])\n",
            "Epoch [8138/10000], train_Loss: 2.1506768262992415e-13,test_Loss:5.218355655670166, r2_store:0.3261432565513306\n",
            "torch.Size([80, 42])\n",
            "Epoch [8139/10000], train_Loss: 2.395533044933368e-13,test_Loss:5.218355655670166, r2_store:0.32614324555206087\n",
            "torch.Size([80, 42])\n",
            "Epoch [8140/10000], train_Loss: 2.1446920303071215e-13,test_Loss:5.218355655670166, r2_store:0.3261432770227194\n",
            "torch.Size([80, 42])\n",
            "Epoch [8141/10000], train_Loss: 2.3080509400398574e-13,test_Loss:5.218355655670166, r2_store:0.3261432307833423\n",
            "torch.Size([80, 42])\n",
            "Epoch [8142/10000], train_Loss: 2.1654184521879838e-13,test_Loss:5.218355655670166, r2_store:0.3261432373978175\n",
            "torch.Size([80, 42])\n",
            "Epoch [8143/10000], train_Loss: 2.523539916528955e-13,test_Loss:5.218354225158691, r2_store:0.32614322824836517\n",
            "torch.Size([80, 42])\n",
            "Epoch [8144/10000], train_Loss: 2.3885936089283744e-13,test_Loss:5.218355178833008, r2_store:0.3261432394220657\n",
            "torch.Size([80, 42])\n",
            "Epoch [8145/10000], train_Loss: 2.407681801326611e-13,test_Loss:5.21835470199585, r2_store:0.3261432120453014\n",
            "torch.Size([80, 42])\n",
            "Epoch [8146/10000], train_Loss: 2.916298658724864e-13,test_Loss:5.218354225158691, r2_store:0.32614320502080596\n",
            "torch.Size([80, 42])\n",
            "Epoch [8147/10000], train_Loss: 2.2113379378498055e-13,test_Loss:5.218354225158691, r2_store:0.32614319950173454\n",
            "torch.Size([80, 42])\n",
            "Epoch [8148/10000], train_Loss: 2.086136845951339e-13,test_Loss:5.218356132507324, r2_store:0.3261431685025399\n",
            "torch.Size([80, 42])\n",
            "Epoch [8149/10000], train_Loss: 2.1916856892713332e-13,test_Loss:5.218355178833008, r2_store:0.3261431760382413\n",
            "torch.Size([80, 42])\n",
            "Epoch [8150/10000], train_Loss: 2.451368914715285e-13,test_Loss:5.21835470199585, r2_store:0.3261431853368232\n",
            "torch.Size([80, 42])\n",
            "Epoch [8151/10000], train_Loss: 2.445118760241449e-13,test_Loss:5.218355178833008, r2_store:0.3261431855321114\n",
            "torch.Size([80, 42])\n",
            "Epoch [8152/10000], train_Loss: 1.5444954614297207e-13,test_Loss:5.218357086181641, r2_store:0.3261431365605726\n",
            "torch.Size([80, 42])\n",
            "Epoch [8153/10000], train_Loss: 2.304481204386949e-13,test_Loss:5.218356132507324, r2_store:0.32614315980188047\n",
            "torch.Size([80, 42])\n",
            "Epoch [8154/10000], train_Loss: 1.464292689922278e-13,test_Loss:5.218355178833008, r2_store:0.32614318034033274\n",
            "torch.Size([80, 42])\n",
            "Epoch [8155/10000], train_Loss: 2.2044359068197628e-13,test_Loss:5.218356132507324, r2_store:0.32614323811093116\n",
            "torch.Size([80, 42])\n",
            "Epoch [8156/10000], train_Loss: 1.3356109024743185e-13,test_Loss:5.218356132507324, r2_store:0.32614312232990605\n",
            "torch.Size([80, 42])\n",
            "Epoch [8157/10000], train_Loss: 1.3867947317846435e-13,test_Loss:5.218356132507324, r2_store:0.3261431639072805\n",
            "torch.Size([80, 42])\n",
            "Epoch [8158/10000], train_Loss: 1.465417143100417e-13,test_Loss:5.218355655670166, r2_store:0.32614324155300045\n",
            "torch.Size([80, 42])\n",
            "Epoch [8159/10000], train_Loss: 1.6447971728106997e-13,test_Loss:5.218356132507324, r2_store:0.3261432059416035\n",
            "torch.Size([80, 42])\n",
            "Epoch [8160/10000], train_Loss: 1.6282630896802958e-13,test_Loss:5.218356609344482, r2_store:0.3261431758265311\n",
            "torch.Size([80, 42])\n",
            "Epoch [8161/10000], train_Loss: 1.6885660079381248e-13,test_Loss:5.218356132507324, r2_store:0.32614318799236086\n",
            "torch.Size([80, 42])\n",
            "Epoch [8162/10000], train_Loss: 1.462343294416149e-13,test_Loss:5.218354225158691, r2_store:0.32614320191528734\n",
            "torch.Size([80, 42])\n",
            "Epoch [8163/10000], train_Loss: 2.3483553426503767e-13,test_Loss:5.218355655670166, r2_store:0.32614325558054724\n",
            "torch.Size([80, 42])\n",
            "Epoch [8164/10000], train_Loss: 2.0849012620505203e-13,test_Loss:5.218355655670166, r2_store:0.326143190777474\n",
            "torch.Size([80, 42])\n",
            "Epoch [8165/10000], train_Loss: 1.9042077214082714e-13,test_Loss:5.218354225158691, r2_store:0.3261432793374318\n",
            "torch.Size([80, 42])\n",
            "Epoch [8166/10000], train_Loss: 1.9208644549094378e-13,test_Loss:5.218354225158691, r2_store:0.32614326077566635\n",
            "torch.Size([80, 42])\n",
            "Epoch [8167/10000], train_Loss: 1.9096088100557795e-13,test_Loss:5.218356132507324, r2_store:0.32614320980975153\n",
            "torch.Size([80, 42])\n",
            "Epoch [8168/10000], train_Loss: 1.7517154989998146e-13,test_Loss:5.218356132507324, r2_store:0.3261432127854803\n",
            "torch.Size([80, 42])\n",
            "Epoch [8169/10000], train_Loss: 9.30228116757803e-14,test_Loss:5.218355178833008, r2_store:0.32614322472363566\n",
            "torch.Size([80, 42])\n",
            "Epoch [8170/10000], train_Loss: 2.30818836266522e-13,test_Loss:5.218355655670166, r2_store:0.32614317196719744\n",
            "torch.Size([80, 42])\n",
            "Epoch [8171/10000], train_Loss: 1.7487165957907197e-13,test_Loss:5.218356132507324, r2_store:0.326143191214184\n",
            "torch.Size([80, 42])\n",
            "Epoch [8172/10000], train_Loss: 1.837553953399837e-13,test_Loss:5.218356132507324, r2_store:0.32614319515775236\n",
            "torch.Size([80, 42])\n",
            "Epoch [8173/10000], train_Loss: 1.4832384452601044e-13,test_Loss:5.218356132507324, r2_store:0.3261432486335649\n",
            "torch.Size([80, 42])\n",
            "Epoch [8174/10000], train_Loss: 1.7059179860823975e-13,test_Loss:5.218356132507324, r2_store:0.32614324341879497\n",
            "torch.Size([80, 42])\n",
            "Epoch [8175/10000], train_Loss: 1.7090156872144602e-13,test_Loss:5.218356609344482, r2_store:0.3261431869253758\n",
            "torch.Size([80, 42])\n",
            "Epoch [8176/10000], train_Loss: 1.0923246085859512e-13,test_Loss:5.218356609344482, r2_store:0.32614317337201526\n",
            "torch.Size([80, 42])\n",
            "Epoch [8177/10000], train_Loss: 1.401639627930315e-13,test_Loss:5.218356132507324, r2_store:0.3261431384337957\n",
            "torch.Size([80, 42])\n",
            "Epoch [8178/10000], train_Loss: 1.3622002831281677e-13,test_Loss:5.218356132507324, r2_store:0.3261431513387305\n",
            "torch.Size([80, 42])\n",
            "Epoch [8179/10000], train_Loss: 1.6289863880546152e-13,test_Loss:5.218357086181641, r2_store:0.32614314151739154\n",
            "torch.Size([80, 42])\n",
            "Epoch [8180/10000], train_Loss: 1.4538843490664172e-13,test_Loss:5.218357086181641, r2_store:0.3261431947124158\n",
            "torch.Size([80, 42])\n",
            "Epoch [8181/10000], train_Loss: 1.525747844038916e-13,test_Loss:5.218357563018799, r2_store:0.32614319582176665\n",
            "torch.Size([80, 42])\n",
            "Epoch [8182/10000], train_Loss: 1.2657652432700867e-13,test_Loss:5.218357563018799, r2_store:0.32614317793728265\n",
            "torch.Size([80, 42])\n",
            "Epoch [8183/10000], train_Loss: 1.6184141971454374e-13,test_Loss:5.218357086181641, r2_store:0.3261431313390508\n",
            "torch.Size([80, 42])\n",
            "Epoch [8184/10000], train_Loss: 2.0979016592502508e-13,test_Loss:5.218357086181641, r2_store:0.3261431578461761\n",
            "torch.Size([80, 42])\n",
            "Epoch [8185/10000], train_Loss: 1.8598902799815686e-13,test_Loss:5.218357563018799, r2_store:0.3261431530255844\n",
            "torch.Size([80, 42])\n",
            "Epoch [8186/10000], train_Loss: 1.4823428942656314e-13,test_Loss:5.218357086181641, r2_store:0.3261431653838186\n",
            "torch.Size([80, 42])\n",
            "Epoch [8187/10000], train_Loss: 1.1136612330020154e-13,test_Loss:5.218357086181641, r2_store:0.3261431969254297\n",
            "torch.Size([80, 42])\n",
            "Epoch [8188/10000], train_Loss: 1.1994073269294692e-13,test_Loss:5.218356609344482, r2_store:0.3261431934358324\n",
            "torch.Size([80, 42])\n",
            "Epoch [8189/10000], train_Loss: 1.3108502998349092e-13,test_Loss:5.218357086181641, r2_store:0.32614316149988287\n",
            "torch.Size([80, 42])\n",
            "Epoch [8190/10000], train_Loss: 1.3061874173415922e-13,test_Loss:5.218357086181641, r2_store:0.3261431589775433\n",
            "torch.Size([80, 42])\n",
            "Epoch [8191/10000], train_Loss: 1.3690754801544414e-13,test_Loss:5.218356132507324, r2_store:0.32614314144450673\n",
            "torch.Size([80, 42])\n",
            "Epoch [8192/10000], train_Loss: 1.1302039897497992e-13,test_Loss:5.218357086181641, r2_store:0.3261431046178457\n",
            "torch.Size([80, 42])\n",
            "Epoch [8193/10000], train_Loss: 8.157880024717984e-14,test_Loss:5.218356132507324, r2_store:0.3261431409254175\n",
            "torch.Size([80, 42])\n",
            "Epoch [8194/10000], train_Loss: 1.308520620416781e-13,test_Loss:5.218356132507324, r2_store:0.3261431466743696\n",
            "torch.Size([80, 42])\n",
            "Epoch [8195/10000], train_Loss: 1.0462256197019473e-13,test_Loss:5.218356132507324, r2_store:0.3261431415856956\n",
            "torch.Size([80, 42])\n",
            "Epoch [8196/10000], train_Loss: 1.3493698346189742e-13,test_Loss:5.218356609344482, r2_store:0.3261431693959075\n",
            "torch.Size([80, 42])\n",
            "Epoch [8197/10000], train_Loss: 1.3237913369656962e-13,test_Loss:5.218357086181641, r2_store:0.3261431476804032\n",
            "torch.Size([80, 42])\n",
            "Epoch [8198/10000], train_Loss: 1.0289920228823829e-13,test_Loss:5.218356132507324, r2_store:0.3261432008435088\n",
            "torch.Size([80, 42])\n",
            "Epoch [8199/10000], train_Loss: 1.576491487267212e-13,test_Loss:5.218356609344482, r2_store:0.3261431849407662\n",
            "torch.Size([80, 42])\n",
            "Epoch [8200/10000], train_Loss: 1.6321467018621388e-13,test_Loss:5.218357563018799, r2_store:0.32614315589012244\n",
            "torch.Size([80, 42])\n",
            "Epoch [8201/10000], train_Loss: 1.4884321802421246e-13,test_Loss:5.218358039855957, r2_store:0.326143155591199\n",
            "torch.Size([80, 42])\n",
            "Epoch [8202/10000], train_Loss: 1.06019834296249e-13,test_Loss:5.218357086181641, r2_store:0.32614316793083287\n",
            "torch.Size([80, 42])\n",
            "Epoch [8203/10000], train_Loss: 8.281365908779578e-14,test_Loss:5.218357086181641, r2_store:0.32614313645818394\n",
            "torch.Size([80, 42])\n",
            "Epoch [8204/10000], train_Loss: 1.0169773009827132e-13,test_Loss:5.218356132507324, r2_store:0.3261431337057882\n",
            "torch.Size([80, 42])\n",
            "Epoch [8205/10000], train_Loss: 1.4342372504482642e-13,test_Loss:5.218356609344482, r2_store:0.32614311689258846\n",
            "torch.Size([80, 42])\n",
            "Epoch [8206/10000], train_Loss: 1.2610493703955894e-13,test_Loss:5.218357086181641, r2_store:0.32614310727107554\n",
            "torch.Size([80, 42])\n",
            "Epoch [8207/10000], train_Loss: 1.109416784784642e-13,test_Loss:5.218357086181641, r2_store:0.3261431150960107\n",
            "torch.Size([80, 42])\n",
            "Epoch [8208/10000], train_Loss: 9.464365326606466e-14,test_Loss:5.218356132507324, r2_store:0.3261431683955268\n",
            "torch.Size([80, 42])\n",
            "Epoch [8209/10000], train_Loss: 1.3211372100474517e-13,test_Loss:5.218356132507324, r2_store:0.3261431616470134\n",
            "torch.Size([80, 42])\n",
            "Epoch [8210/10000], train_Loss: 1.2331021620459737e-13,test_Loss:5.218356132507324, r2_store:0.3261431861507075\n",
            "torch.Size([80, 42])\n",
            "Epoch [8211/10000], train_Loss: 1.153307863707015e-13,test_Loss:5.218357086181641, r2_store:0.3261431891035669\n",
            "torch.Size([80, 42])\n",
            "Epoch [8212/10000], train_Loss: 9.445538833507613e-14,test_Loss:5.218356609344482, r2_store:0.32614320977499156\n",
            "torch.Size([80, 42])\n",
            "Epoch [8213/10000], train_Loss: 8.667524163674667e-14,test_Loss:5.218357086181641, r2_store:0.3261431393908166\n",
            "torch.Size([80, 42])\n",
            "Epoch [8214/10000], train_Loss: 1.1533681724528594e-13,test_Loss:5.218357086181641, r2_store:0.3261431178618359\n",
            "torch.Size([80, 42])\n",
            "Epoch [8215/10000], train_Loss: 1.1171476206129141e-13,test_Loss:5.218357563018799, r2_store:0.3261431727799803\n",
            "torch.Size([80, 42])\n",
            "Epoch [8216/10000], train_Loss: 1.0524250877242194e-13,test_Loss:5.218356609344482, r2_store:0.326143179556742\n",
            "torch.Size([80, 42])\n",
            "Epoch [8217/10000], train_Loss: 1.0491720068683125e-13,test_Loss:5.218358039855957, r2_store:0.32614312125938116\n",
            "torch.Size([80, 42])\n",
            "Epoch [8218/10000], train_Loss: 2.0387572110137225e-13,test_Loss:5.218357563018799, r2_store:0.3261431494168935\n",
            "torch.Size([80, 42])\n",
            "Epoch [8219/10000], train_Loss: 1.2782678561473748e-13,test_Loss:5.218356609344482, r2_store:0.3261431596826778\n",
            "torch.Size([80, 42])\n",
            "Epoch [8220/10000], train_Loss: 2.6318796317661985e-13,test_Loss:5.218357563018799, r2_store:0.3261431169584582\n",
            "torch.Size([80, 42])\n",
            "Epoch [8221/10000], train_Loss: 1.5591235171408951e-13,test_Loss:5.218357563018799, r2_store:0.3261430986561563\n",
            "torch.Size([80, 42])\n",
            "Epoch [8222/10000], train_Loss: 3.6132549860110053e-13,test_Loss:5.218355655670166, r2_store:0.3261431962512643\n",
            "torch.Size([80, 42])\n",
            "Epoch [8223/10000], train_Loss: 4.0792434534420163e-13,test_Loss:5.218356132507324, r2_store:0.326143171477534\n",
            "torch.Size([80, 42])\n",
            "Epoch [8224/10000], train_Loss: 1.8388581130880655e-13,test_Loss:5.218358039855957, r2_store:0.3261430585088002\n",
            "torch.Size([80, 42])\n",
            "Epoch [8225/10000], train_Loss: 5.287514133131554e-13,test_Loss:5.218356132507324, r2_store:0.3261431732603155\n",
            "torch.Size([80, 42])\n",
            "Epoch [8226/10000], train_Loss: 3.8103152360732806e-13,test_Loss:5.218356609344482, r2_store:0.32614312081385133\n",
            "torch.Size([80, 42])\n",
            "Epoch [8227/10000], train_Loss: 1.8338633292046963e-13,test_Loss:5.218358039855957, r2_store:0.3261430519255969\n",
            "torch.Size([80, 42])\n",
            "Epoch [8228/10000], train_Loss: 1.2184162099387885e-12,test_Loss:5.218353748321533, r2_store:0.3261433442741839\n",
            "torch.Size([80, 42])\n",
            "Epoch [8229/10000], train_Loss: 2.062601174926404e-12,test_Loss:5.21835994720459, r2_store:0.32614308644120626\n",
            "torch.Size([80, 42])\n",
            "Epoch [8230/10000], train_Loss: 1.4608658250106488e-12,test_Loss:5.218356609344482, r2_store:0.32614322324166556\n",
            "torch.Size([80, 42])\n",
            "Epoch [8231/10000], train_Loss: 2.0177839976133483e-13,test_Loss:5.218356132507324, r2_store:0.32614322975953436\n",
            "torch.Size([80, 42])\n",
            "Epoch [8232/10000], train_Loss: 3.8407412016397413e-13,test_Loss:5.218358039855957, r2_store:0.3261430886989205\n",
            "torch.Size([80, 42])\n",
            "Epoch [8233/10000], train_Loss: 4.637324053403946e-13,test_Loss:5.218357086181641, r2_store:0.32614316543194366\n",
            "torch.Size([80, 42])\n",
            "Epoch [8234/10000], train_Loss: 1.5703952895018691e-13,test_Loss:5.218355655670166, r2_store:0.3261432404187251\n",
            "torch.Size([80, 42])\n",
            "Epoch [8235/10000], train_Loss: 2.2404925408437554e-13,test_Loss:5.218357086181641, r2_store:0.32614324481864443\n",
            "torch.Size([80, 42])\n",
            "Epoch [8236/10000], train_Loss: 1.8652501689465223e-13,test_Loss:5.218357563018799, r2_store:0.3261432223888223\n",
            "torch.Size([80, 42])\n",
            "Epoch [8237/10000], train_Loss: 1.7961417672195806e-13,test_Loss:5.218356609344482, r2_store:0.32614324834991015\n",
            "torch.Size([80, 42])\n",
            "Epoch [8238/10000], train_Loss: 2.458894090943964e-13,test_Loss:5.218357086181641, r2_store:0.32614316989120073\n",
            "torch.Size([80, 42])\n",
            "Epoch [8239/10000], train_Loss: 1.0324358555580115e-13,test_Loss:5.218357086181641, r2_store:0.32614315434198926\n",
            "torch.Size([80, 42])\n",
            "Epoch [8240/10000], train_Loss: 1.53103915721646e-13,test_Loss:5.218357086181641, r2_store:0.3261432084789899\n",
            "torch.Size([80, 42])\n",
            "Epoch [8241/10000], train_Loss: 1.2820578203665695e-13,test_Loss:5.218357086181641, r2_store:0.32614320654238493\n",
            "torch.Size([80, 42])\n",
            "Epoch [8242/10000], train_Loss: 1.300899898871652e-13,test_Loss:5.218358039855957, r2_store:0.32614320719056544\n",
            "torch.Size([80, 42])\n",
            "Epoch [8243/10000], train_Loss: 1.464456539975595e-13,test_Loss:5.218358039855957, r2_store:0.32614323325877637\n",
            "torch.Size([80, 42])\n",
            "Epoch [8244/10000], train_Loss: 9.660172238957349e-14,test_Loss:5.218357086181641, r2_store:0.3261432391528106\n",
            "torch.Size([80, 42])\n",
            "Epoch [8245/10000], train_Loss: 1.5191190319563397e-13,test_Loss:5.218358039855957, r2_store:0.3261431583391652\n",
            "torch.Size([80, 42])\n",
            "Epoch [8246/10000], train_Loss: 1.324994801377155e-13,test_Loss:5.218358039855957, r2_store:0.3261431357671022\n",
            "torch.Size([80, 42])\n",
            "Epoch [8247/10000], train_Loss: 1.2340189905080817e-13,test_Loss:5.218359470367432, r2_store:0.32614313371282055\n",
            "torch.Size([80, 42])\n",
            "Epoch [8248/10000], train_Loss: 1.0742730489898822e-13,test_Loss:5.218358039855957, r2_store:0.32614312791071476\n",
            "torch.Size([80, 42])\n",
            "Epoch [8249/10000], train_Loss: 1.1398893710445196e-13,test_Loss:5.218358039855957, r2_store:0.3261431243486471\n",
            "torch.Size([80, 42])\n",
            "Epoch [8250/10000], train_Loss: 8.69594787887909e-14,test_Loss:5.218357563018799, r2_store:0.32614312589864547\n",
            "torch.Size([80, 42])\n",
            "Epoch [8251/10000], train_Loss: 1.0599468080584734e-13,test_Loss:5.218358039855957, r2_store:0.32614311292503484\n",
            "torch.Size([80, 42])\n",
            "Epoch [8252/10000], train_Loss: 1.2523519005679107e-13,test_Loss:5.218358516693115, r2_store:0.32614311154405806\n",
            "torch.Size([80, 42])\n",
            "Epoch [8253/10000], train_Loss: 1.1539844058626458e-13,test_Loss:5.218358039855957, r2_store:0.32614309761836047\n",
            "torch.Size([80, 42])\n",
            "Epoch [8254/10000], train_Loss: 1.0923922356964599e-13,test_Loss:5.218358039855957, r2_store:0.32614308344230536\n",
            "torch.Size([80, 42])\n",
            "Epoch [8255/10000], train_Loss: 9.523965952907068e-14,test_Loss:5.218358516693115, r2_store:0.3261431288044425\n",
            "torch.Size([80, 42])\n",
            "Epoch [8256/10000], train_Loss: 1.015645900714901e-13,test_Loss:5.218358039855957, r2_store:0.32614314594515503\n",
            "torch.Size([80, 42])\n",
            "Epoch [8257/10000], train_Loss: 9.973493114278503e-14,test_Loss:5.218358039855957, r2_store:0.3261431233676123\n",
            "torch.Size([80, 42])\n",
            "Epoch [8258/10000], train_Loss: 1.1807902203751774e-13,test_Loss:5.218358039855957, r2_store:0.326143135401769\n",
            "torch.Size([80, 42])\n",
            "Epoch [8259/10000], train_Loss: 1.0251196592980794e-13,test_Loss:5.218357086181641, r2_store:0.32614315662825955\n",
            "torch.Size([80, 42])\n",
            "Epoch [8260/10000], train_Loss: 1.0663904926200979e-13,test_Loss:5.218358516693115, r2_store:0.32614317427887396\n",
            "torch.Size([80, 42])\n",
            "Epoch [8261/10000], train_Loss: 6.301990179702344e-14,test_Loss:5.218357563018799, r2_store:0.32614316663585596\n",
            "torch.Size([80, 42])\n",
            "Epoch [8262/10000], train_Loss: 7.25503844826135e-14,test_Loss:5.218357563018799, r2_store:0.32614320700140054\n",
            "torch.Size([80, 42])\n",
            "Epoch [8263/10000], train_Loss: 6.896358619801549e-14,test_Loss:5.218358516693115, r2_store:0.32614323304172044\n",
            "torch.Size([80, 42])\n",
            "Epoch [8264/10000], train_Loss: 7.490683691813854e-14,test_Loss:5.218358039855957, r2_store:0.3261431903522406\n",
            "torch.Size([80, 42])\n",
            "Epoch [8265/10000], train_Loss: 7.398496013966485e-14,test_Loss:5.218358039855957, r2_store:0.3261431685955426\n",
            "torch.Size([80, 42])\n",
            "Epoch [8266/10000], train_Loss: 9.135717220698156e-14,test_Loss:5.218357086181641, r2_store:0.32614317004077376\n",
            "torch.Size([80, 42])\n",
            "Epoch [8267/10000], train_Loss: 1.1073581559096352e-13,test_Loss:5.218358039855957, r2_store:0.3261431774124631\n",
            "torch.Size([80, 42])\n",
            "Epoch [8268/10000], train_Loss: 1.19562305477168e-13,test_Loss:5.218358039855957, r2_store:0.32614320560906407\n",
            "torch.Size([80, 42])\n",
            "Epoch [8269/10000], train_Loss: 9.328367071848032e-14,test_Loss:5.218358516693115, r2_store:0.3261432328754478\n",
            "torch.Size([80, 42])\n",
            "Epoch [8270/10000], train_Loss: 9.16092288832937e-14,test_Loss:5.218358039855957, r2_store:0.3261432031092011\n",
            "torch.Size([80, 42])\n",
            "Epoch [8271/10000], train_Loss: 9.048352209639274e-14,test_Loss:5.218357563018799, r2_store:0.32614322196039824\n",
            "torch.Size([80, 42])\n",
            "Epoch [8272/10000], train_Loss: 1.0670643920329334e-13,test_Loss:5.218358039855957, r2_store:0.32614316951573197\n",
            "torch.Size([80, 42])\n",
            "Epoch [8273/10000], train_Loss: 1.3036742367057708e-13,test_Loss:5.218356609344482, r2_store:0.3261431911551682\n",
            "torch.Size([80, 42])\n",
            "Epoch [8274/10000], train_Loss: 1.0516773948010191e-13,test_Loss:5.218357086181641, r2_store:0.32614314475448436\n",
            "torch.Size([80, 42])\n",
            "Epoch [8275/10000], train_Loss: 1.1239659647877681e-13,test_Loss:5.218357086181641, r2_store:0.32614317666319037\n",
            "torch.Size([80, 42])\n",
            "Epoch [8276/10000], train_Loss: 1.4884195763918695e-13,test_Loss:5.218355655670166, r2_store:0.326143233306054\n",
            "torch.Size([80, 42])\n",
            "Epoch [8277/10000], train_Loss: 1.1628957345688473e-13,test_Loss:5.218356609344482, r2_store:0.3261432174698059\n",
            "torch.Size([80, 42])\n",
            "Epoch [8278/10000], train_Loss: 1.308351891453688e-13,test_Loss:5.218357086181641, r2_store:0.32614319971403316\n",
            "torch.Size([80, 42])\n",
            "Epoch [8279/10000], train_Loss: 1.72323608290878e-13,test_Loss:5.218356132507324, r2_store:0.3261431810662644\n",
            "torch.Size([80, 42])\n",
            "Epoch [8280/10000], train_Loss: 1.3023791572107368e-13,test_Loss:5.218356132507324, r2_store:0.32614318327462966\n",
            "torch.Size([80, 42])\n",
            "Epoch [8281/10000], train_Loss: 1.4931441228837466e-13,test_Loss:5.218356132507324, r2_store:0.3261431681967155\n",
            "torch.Size([80, 42])\n",
            "Epoch [8282/10000], train_Loss: 1.1359749946260322e-13,test_Loss:5.218356132507324, r2_store:0.32614315401271277\n",
            "torch.Size([80, 42])\n",
            "Epoch [8283/10000], train_Loss: 8.612425009268954e-14,test_Loss:5.218356609344482, r2_store:0.3261431081938768\n",
            "torch.Size([80, 42])\n",
            "Epoch [8284/10000], train_Loss: 1.037253169098272e-13,test_Loss:5.218357086181641, r2_store:0.3261431455629521\n",
            "torch.Size([80, 42])\n",
            "Epoch [8285/10000], train_Loss: 1.1650706441268532e-13,test_Loss:5.218357086181641, r2_store:0.32614313425452524\n",
            "torch.Size([80, 42])\n",
            "Epoch [8286/10000], train_Loss: 8.640666442983128e-14,test_Loss:5.218357086181641, r2_store:0.32614312210004637\n",
            "torch.Size([80, 42])\n",
            "Epoch [8287/10000], train_Loss: 1.4263603861398855e-13,test_Loss:5.218357086181641, r2_store:0.32614309830748567\n",
            "torch.Size([80, 42])\n",
            "Epoch [8288/10000], train_Loss: 1.2044054989446273e-13,test_Loss:5.218357086181641, r2_store:0.326143159797613\n",
            "torch.Size([80, 42])\n",
            "Epoch [8289/10000], train_Loss: 1.5750240196267529e-13,test_Loss:5.218357086181641, r2_store:0.3261431358179323\n",
            "torch.Size([80, 42])\n",
            "Epoch [8290/10000], train_Loss: 1.4733570266600715e-13,test_Loss:5.218357086181641, r2_store:0.3261430824661684\n",
            "torch.Size([80, 42])\n",
            "Epoch [8291/10000], train_Loss: 1.205422074006604e-13,test_Loss:5.218356609344482, r2_store:0.32614315137040484\n",
            "torch.Size([80, 42])\n",
            "Epoch [8292/10000], train_Loss: 7.912771729078755e-14,test_Loss:5.218357086181641, r2_store:0.3261431362385344\n",
            "torch.Size([80, 42])\n",
            "Epoch [8293/10000], train_Loss: 1.137446934600453e-13,test_Loss:5.218357086181641, r2_store:0.32614317117823677\n",
            "torch.Size([80, 42])\n",
            "Epoch [8294/10000], train_Loss: 1.1541974515895392e-13,test_Loss:5.218357086181641, r2_store:0.3261431705589679\n",
            "torch.Size([80, 42])\n",
            "Epoch [8295/10000], train_Loss: 9.616608995666881e-14,test_Loss:5.218357563018799, r2_store:0.3261431776559165\n",
            "torch.Size([80, 42])\n",
            "Epoch [8296/10000], train_Loss: 1.507009306841306e-13,test_Loss:5.218357086181641, r2_store:0.32614322385356775\n",
            "torch.Size([80, 42])\n",
            "Epoch [8297/10000], train_Loss: 9.468645214682353e-14,test_Loss:5.218356132507324, r2_store:0.326143177977972\n",
            "torch.Size([80, 42])\n",
            "Epoch [8298/10000], train_Loss: 1.2842859913562987e-13,test_Loss:5.218355655670166, r2_store:0.3261431949395488\n",
            "torch.Size([80, 42])\n",
            "Epoch [8299/10000], train_Loss: 1.207546703688861e-13,test_Loss:5.218355655670166, r2_store:0.3261431679439395\n",
            "torch.Size([80, 42])\n",
            "Epoch [8300/10000], train_Loss: 1.7598209944413162e-13,test_Loss:5.218355655670166, r2_store:0.32614312795613587\n",
            "torch.Size([80, 42])\n",
            "Epoch [8301/10000], train_Loss: 1.313162225442463e-13,test_Loss:5.218356132507324, r2_store:0.3261431089625749\n",
            "torch.Size([80, 42])\n",
            "Epoch [8302/10000], train_Loss: 1.837492831502363e-13,test_Loss:5.218358039855957, r2_store:0.32614309930205\n",
            "torch.Size([80, 42])\n",
            "Epoch [8303/10000], train_Loss: 2.2878969769060675e-13,test_Loss:5.218356132507324, r2_store:0.3261431723103905\n",
            "torch.Size([80, 42])\n",
            "Epoch [8304/10000], train_Loss: 1.1326074626782923e-13,test_Loss:5.218356132507324, r2_store:0.32614322247743666\n",
            "torch.Size([80, 42])\n",
            "Epoch [8305/10000], train_Loss: 1.5427420354662685e-13,test_Loss:5.218357563018799, r2_store:0.3261431640295481\n",
            "torch.Size([80, 42])\n",
            "Epoch [8306/10000], train_Loss: 2.8238874997046914e-13,test_Loss:5.218356132507324, r2_store:0.3261431779839943\n",
            "torch.Size([80, 42])\n",
            "Epoch [8307/10000], train_Loss: 1.929378559044695e-13,test_Loss:5.218358039855957, r2_store:0.3261431667157394\n",
            "torch.Size([80, 42])\n",
            "Epoch [8308/10000], train_Loss: 2.928185580293452e-13,test_Loss:5.218357086181641, r2_store:0.3261431090128877\n",
            "torch.Size([80, 42])\n",
            "Epoch [8309/10000], train_Loss: 1.5580427031001987e-13,test_Loss:5.218356609344482, r2_store:0.32614317993018827\n",
            "torch.Size([80, 42])\n",
            "Epoch [8310/10000], train_Loss: 1.5404027337538595e-13,test_Loss:5.218356132507324, r2_store:0.3261431680100615\n",
            "torch.Size([80, 42])\n",
            "Epoch [8311/10000], train_Loss: 2.283489424024371e-13,test_Loss:5.218356609344482, r2_store:0.3261432019353887\n",
            "torch.Size([80, 42])\n",
            "Epoch [8312/10000], train_Loss: 1.9711034020264417e-13,test_Loss:5.218356609344482, r2_store:0.32614317113129654\n",
            "torch.Size([80, 42])\n",
            "Epoch [8313/10000], train_Loss: 1.4640589088288358e-13,test_Loss:5.218356609344482, r2_store:0.3261431701928874\n",
            "torch.Size([80, 42])\n",
            "Epoch [8314/10000], train_Loss: 1.9531854703481316e-13,test_Loss:5.218357086181641, r2_store:0.32614312513634114\n",
            "torch.Size([80, 42])\n",
            "Epoch [8315/10000], train_Loss: 1.6502562662744358e-13,test_Loss:5.218356132507324, r2_store:0.32614312341420326\n",
            "torch.Size([80, 42])\n",
            "Epoch [8316/10000], train_Loss: 1.1517704650264304e-13,test_Loss:5.218356609344482, r2_store:0.32614315853768083\n",
            "torch.Size([80, 42])\n",
            "Epoch [8317/10000], train_Loss: 1.21058504475198e-13,test_Loss:5.218357086181641, r2_store:0.32614315876287614\n",
            "torch.Size([80, 42])\n",
            "Epoch [8318/10000], train_Loss: 1.2320392373411232e-13,test_Loss:5.218357563018799, r2_store:0.3261431723970287\n",
            "torch.Size([80, 42])\n",
            "Epoch [8319/10000], train_Loss: 1.2301452716710626e-13,test_Loss:5.218358039855957, r2_store:0.32614318979549994\n",
            "torch.Size([80, 42])\n",
            "Epoch [8320/10000], train_Loss: 1.6138656979813176e-13,test_Loss:5.218357086181641, r2_store:0.3261431547937208\n",
            "torch.Size([80, 42])\n",
            "Epoch [8321/10000], train_Loss: 1.9277435821685868e-13,test_Loss:5.218356609344482, r2_store:0.32614314243311593\n",
            "torch.Size([80, 42])\n",
            "Epoch [8322/10000], train_Loss: 1.882456863999682e-13,test_Loss:5.218357086181641, r2_store:0.32614310224751486\n",
            "torch.Size([80, 42])\n",
            "Epoch [8323/10000], train_Loss: 2.3593556578924146e-13,test_Loss:5.218358039855957, r2_store:0.3261431264267617\n",
            "torch.Size([80, 42])\n",
            "Epoch [8324/10000], train_Loss: 1.4563992915307689e-13,test_Loss:5.218357086181641, r2_store:0.32614322606903146\n",
            "torch.Size([80, 42])\n",
            "Epoch [8325/10000], train_Loss: 1.9224999738866322e-13,test_Loss:5.218357563018799, r2_store:0.3261431888707431\n",
            "torch.Size([80, 42])\n",
            "Epoch [8326/10000], train_Loss: 1.1693437559391617e-13,test_Loss:5.218357563018799, r2_store:0.3261431642636592\n",
            "torch.Size([80, 42])\n",
            "Epoch [8327/10000], train_Loss: 2.4128732323790147e-13,test_Loss:5.218357563018799, r2_store:0.32614320951371345\n",
            "torch.Size([80, 42])\n",
            "Epoch [8328/10000], train_Loss: 1.2325549109994116e-13,test_Loss:5.218356132507324, r2_store:0.3261432110130317\n",
            "torch.Size([80, 42])\n",
            "Epoch [8329/10000], train_Loss: 1.8858196525629173e-13,test_Loss:5.218356609344482, r2_store:0.3261431663326436\n",
            "torch.Size([80, 42])\n",
            "Epoch [8330/10000], train_Loss: 1.6056860702162723e-13,test_Loss:5.218357563018799, r2_store:0.3261431627207839\n",
            "torch.Size([80, 42])\n",
            "Epoch [8331/10000], train_Loss: 1.8646603629646902e-13,test_Loss:5.218357086181641, r2_store:0.3261432138737501\n",
            "torch.Size([80, 42])\n",
            "Epoch [8332/10000], train_Loss: 1.1528130609405468e-13,test_Loss:5.218356132507324, r2_store:0.3261432635491237\n",
            "torch.Size([80, 42])\n",
            "Epoch [8333/10000], train_Loss: 1.7399280529805522e-13,test_Loss:5.218357563018799, r2_store:0.3261431367186042\n",
            "torch.Size([80, 42])\n",
            "Epoch [8334/10000], train_Loss: 1.7701061428253284e-13,test_Loss:5.218357086181641, r2_store:0.3261431063970881\n",
            "torch.Size([80, 42])\n",
            "Epoch [8335/10000], train_Loss: 1.516807106348786e-13,test_Loss:5.218356132507324, r2_store:0.32614320635396676\n",
            "torch.Size([80, 42])\n",
            "Epoch [8336/10000], train_Loss: 3.597457347206262e-13,test_Loss:5.218357563018799, r2_store:0.3261431564453712\n",
            "torch.Size([80, 42])\n",
            "Epoch [8337/10000], train_Loss: 2.542226412022286e-13,test_Loss:5.218357563018799, r2_store:0.3261431245310724\n",
            "torch.Size([80, 42])\n",
            "Epoch [8338/10000], train_Loss: 1.7992027410030503e-13,test_Loss:5.218356132507324, r2_store:0.3261431906534813\n",
            "torch.Size([80, 42])\n",
            "Epoch [8339/10000], train_Loss: 1.7336978207216358e-13,test_Loss:5.218355655670166, r2_store:0.3261431791258579\n",
            "torch.Size([80, 42])\n",
            "Epoch [8340/10000], train_Loss: 2.4891010476715825e-13,test_Loss:5.218358039855957, r2_store:0.32614312125005507\n",
            "torch.Size([80, 42])\n",
            "Epoch [8341/10000], train_Loss: 3.506925652652093e-13,test_Loss:5.218356132507324, r2_store:0.3261432492798527\n",
            "torch.Size([80, 42])\n",
            "Epoch [8342/10000], train_Loss: 3.1608288035556154e-13,test_Loss:5.218356132507324, r2_store:0.32614319392493896\n",
            "torch.Size([80, 42])\n",
            "Epoch [8343/10000], train_Loss: 1.5131537516033244e-13,test_Loss:5.218358516693115, r2_store:0.3261431006198183\n",
            "torch.Size([80, 42])\n",
            "Epoch [8344/10000], train_Loss: 5.67829529056485e-13,test_Loss:5.218355178833008, r2_store:0.32614325069705674\n",
            "torch.Size([80, 42])\n",
            "Epoch [8345/10000], train_Loss: 6.231961019280419e-13,test_Loss:5.218358039855957, r2_store:0.3261431687018026\n",
            "torch.Size([80, 42])\n",
            "Epoch [8346/10000], train_Loss: 2.7947227323153745e-13,test_Loss:5.218358039855957, r2_store:0.3261431475012935\n",
            "torch.Size([80, 42])\n",
            "Epoch [8347/10000], train_Loss: 2.4196709089499557e-13,test_Loss:5.218355178833008, r2_store:0.3261432972193703\n",
            "torch.Size([80, 42])\n",
            "Epoch [8348/10000], train_Loss: 6.574547221742388e-13,test_Loss:5.21835994720459, r2_store:0.3261430067183506\n",
            "torch.Size([80, 42])\n",
            "Epoch [8349/10000], train_Loss: 1.0246181073730876e-12,test_Loss:5.218354225158691, r2_store:0.32614316610328464\n",
            "torch.Size([80, 42])\n",
            "Epoch [8350/10000], train_Loss: 7.978093012617204e-13,test_Loss:5.218357086181641, r2_store:0.3261430877849384\n",
            "torch.Size([80, 42])\n",
            "Epoch [8351/10000], train_Loss: 3.4365961682283896e-13,test_Loss:5.218356132507324, r2_store:0.32614319007933135\n",
            "torch.Size([80, 42])\n",
            "Epoch [8352/10000], train_Loss: 2.0935952082211384e-13,test_Loss:5.218355655670166, r2_store:0.32614330328635766\n",
            "torch.Size([80, 42])\n",
            "Epoch [8353/10000], train_Loss: 3.405893731107945e-13,test_Loss:5.218357563018799, r2_store:0.3261432258677276\n",
            "torch.Size([80, 42])\n",
            "Epoch [8354/10000], train_Loss: 2.71758689770335e-13,test_Loss:5.218357563018799, r2_store:0.32614314252678267\n",
            "torch.Size([80, 42])\n",
            "Epoch [8355/10000], train_Loss: 2.4412335217563474e-13,test_Loss:5.218355655670166, r2_store:0.3261432096269167\n",
            "torch.Size([80, 42])\n",
            "Epoch [8356/10000], train_Loss: 5.779411237777365e-13,test_Loss:5.218358516693115, r2_store:0.326143107724569\n",
            "torch.Size([80, 42])\n",
            "Epoch [8357/10000], train_Loss: 6.364378967414763e-13,test_Loss:5.218356132507324, r2_store:0.32614320728922064\n",
            "torch.Size([80, 42])\n",
            "Epoch [8358/10000], train_Loss: 2.602292025529612e-13,test_Loss:5.218356132507324, r2_store:0.3261431834105252\n",
            "torch.Size([80, 42])\n",
            "Epoch [8359/10000], train_Loss: 3.3920687981560393e-13,test_Loss:5.218358516693115, r2_store:0.32614314086028884\n",
            "torch.Size([80, 42])\n",
            "Epoch [8360/10000], train_Loss: 2.9565637590066307e-13,test_Loss:5.218357086181641, r2_store:0.3261430847034431\n",
            "torch.Size([80, 42])\n",
            "Epoch [8361/10000], train_Loss: 2.5903742041991085e-13,test_Loss:5.218356132507324, r2_store:0.32614312000791523\n",
            "torch.Size([80, 42])\n",
            "Epoch [8362/10000], train_Loss: 3.1252393251426924e-13,test_Loss:5.218358039855957, r2_store:0.32614317779467394\n",
            "torch.Size([80, 42])\n",
            "Epoch [8363/10000], train_Loss: 4.756069127941076e-13,test_Loss:5.218356132507324, r2_store:0.3261431937214343\n",
            "torch.Size([80, 42])\n",
            "Epoch [8364/10000], train_Loss: 3.747736984031219e-13,test_Loss:5.218356609344482, r2_store:0.3261431812240977\n",
            "torch.Size([80, 42])\n",
            "Epoch [8365/10000], train_Loss: 1.816476656590904e-13,test_Loss:5.218358039855957, r2_store:0.3261430758010996\n",
            "torch.Size([80, 42])\n",
            "Epoch [8366/10000], train_Loss: 4.716050141552464e-13,test_Loss:5.218356132507324, r2_store:0.3261432801784677\n",
            "torch.Size([80, 42])\n",
            "Epoch [8367/10000], train_Loss: 7.213451841056595e-13,test_Loss:5.218359470367432, r2_store:0.3261431117333117\n",
            "torch.Size([80, 42])\n",
            "Epoch [8368/10000], train_Loss: 1.2058680876753103e-12,test_Loss:5.21835470199585, r2_store:0.32614326032708674\n",
            "torch.Size([80, 42])\n",
            "Epoch [8369/10000], train_Loss: 1.3635154203633926e-12,test_Loss:5.21835994720459, r2_store:0.32614311790966666\n",
            "torch.Size([80, 42])\n",
            "Epoch [8370/10000], train_Loss: 1.4036793645824663e-12,test_Loss:5.218355655670166, r2_store:0.32614324864971134\n",
            "torch.Size([80, 42])\n",
            "Epoch [8371/10000], train_Loss: 6.590786401881876e-13,test_Loss:5.218357086181641, r2_store:0.3261432343890678\n",
            "torch.Size([80, 42])\n",
            "Epoch [8372/10000], train_Loss: 1.9885734226822438e-13,test_Loss:5.218358516693115, r2_store:0.3261431146718792\n",
            "torch.Size([80, 42])\n",
            "Epoch [8373/10000], train_Loss: 9.3967552922819e-13,test_Loss:5.218355655670166, r2_store:0.3261431840729728\n",
            "torch.Size([80, 42])\n",
            "Epoch [8374/10000], train_Loss: 1.2149851437437409e-12,test_Loss:5.218358516693115, r2_store:0.3261430878238677\n",
            "torch.Size([80, 42])\n",
            "Epoch [8375/10000], train_Loss: 8.169854766662543e-13,test_Loss:5.218357086181641, r2_store:0.3261431717994825\n",
            "torch.Size([80, 42])\n",
            "Epoch [8376/10000], train_Loss: 2.141645828778252e-13,test_Loss:5.218355655670166, r2_store:0.32614322818888664\n",
            "torch.Size([80, 42])\n",
            "Epoch [8377/10000], train_Loss: 1.2456534284957521e-12,test_Loss:5.2183613777160645, r2_store:0.3261429943317733\n",
            "torch.Size([80, 42])\n",
            "Epoch [8378/10000], train_Loss: 3.716862321395675e-12,test_Loss:5.218350887298584, r2_store:0.3261434824202687\n",
            "torch.Size([80, 42])\n",
            "Epoch [8379/10000], train_Loss: 7.132137762322355e-12,test_Loss:5.2183637619018555, r2_store:0.3261428755725061\n",
            "torch.Size([80, 42])\n",
            "Epoch [8380/10000], train_Loss: 1.108583884412706e-11,test_Loss:5.218348503112793, r2_store:0.3261435291814948\n",
            "torch.Size([80, 42])\n",
            "Epoch [8381/10000], train_Loss: 1.2511795419167804e-11,test_Loss:5.2183637619018555, r2_store:0.3261428245307889\n",
            "torch.Size([80, 42])\n",
            "Epoch [8382/10000], train_Loss: 1.29007568516748e-11,test_Loss:5.218348503112793, r2_store:0.3261434976590134\n",
            "torch.Size([80, 42])\n",
            "Epoch [8383/10000], train_Loss: 1.2536289714648596e-11,test_Loss:5.218364238739014, r2_store:0.3261428585667211\n",
            "torch.Size([80, 42])\n",
            "Epoch [8384/10000], train_Loss: 1.4057886799090369e-11,test_Loss:5.218347549438477, r2_store:0.3261435192509827\n",
            "torch.Size([80, 42])\n",
            "Epoch [8385/10000], train_Loss: 1.7825662820825094e-11,test_Loss:5.218367576599121, r2_store:0.32614269374616256\n",
            "torch.Size([80, 42])\n",
            "Epoch [8386/10000], train_Loss: 2.5921367483028313e-11,test_Loss:5.218343734741211, r2_store:0.32614373435834865\n",
            "torch.Size([80, 42])\n",
            "Epoch [8387/10000], train_Loss: 3.840949433508989e-11,test_Loss:5.218372821807861, r2_store:0.32614252352704354\n",
            "torch.Size([80, 42])\n",
            "Epoch [8388/10000], train_Loss: 5.084663246002208e-11,test_Loss:5.218338966369629, r2_store:0.32614391569844137\n",
            "torch.Size([80, 42])\n",
            "Epoch [8389/10000], train_Loss: 6.066495222833979e-11,test_Loss:5.2183756828308105, r2_store:0.32614245676246045\n",
            "torch.Size([80, 42])\n",
            "Epoch [8390/10000], train_Loss: 6.926878515223223e-11,test_Loss:5.218338966369629, r2_store:0.32614391367827955\n",
            "torch.Size([80, 42])\n",
            "Epoch [8391/10000], train_Loss: 7.6144889005203e-11,test_Loss:5.218377590179443, r2_store:0.32614228518209987\n",
            "torch.Size([80, 42])\n",
            "Epoch [8392/10000], train_Loss: 7.879635138818841e-11,test_Loss:5.2183380126953125, r2_store:0.32614399919960857\n",
            "torch.Size([80, 42])\n",
            "Epoch [8393/10000], train_Loss: 7.746862873414528e-11,test_Loss:5.218376159667969, r2_store:0.32614237111220756\n",
            "torch.Size([80, 42])\n",
            "Epoch [8394/10000], train_Loss: 7.436724847043052e-11,test_Loss:5.218339920043945, r2_store:0.32614391618078165\n",
            "torch.Size([80, 42])\n",
            "Epoch [8395/10000], train_Loss: 7.198258655805034e-11,test_Loss:5.218376159667969, r2_store:0.3261424408861059\n",
            "torch.Size([80, 42])\n",
            "Epoch [8396/10000], train_Loss: 6.757459869444205e-11,test_Loss:5.218339920043945, r2_store:0.3261439008475707\n",
            "torch.Size([80, 42])\n",
            "Epoch [8397/10000], train_Loss: 6.024175602803439e-11,test_Loss:5.218371868133545, r2_store:0.326142552861833\n",
            "torch.Size([80, 42])\n",
            "Epoch [8398/10000], train_Loss: 4.817980042703951e-11,test_Loss:5.218344211578369, r2_store:0.32614374520740186\n",
            "torch.Size([80, 42])\n",
            "Epoch [8399/10000], train_Loss: 3.514805113624675e-11,test_Loss:5.218369483947754, r2_store:0.3261426748442017\n",
            "torch.Size([80, 42])\n",
            "Epoch [8400/10000], train_Loss: 2.5004762149727355e-11,test_Loss:5.21834659576416, r2_store:0.32614353956228126\n",
            "torch.Size([80, 42])\n",
            "Epoch [8401/10000], train_Loss: 1.7917150402224635e-11,test_Loss:5.218364238739014, r2_store:0.3261429267377137\n",
            "torch.Size([80, 42])\n",
            "Epoch [8402/10000], train_Loss: 1.2648403158177501e-11,test_Loss:5.218350410461426, r2_store:0.3261434424553904\n",
            "torch.Size([80, 42])\n",
            "Epoch [8403/10000], train_Loss: 8.240225342348584e-12,test_Loss:5.218361854553223, r2_store:0.32614303170211745\n",
            "torch.Size([80, 42])\n",
            "Epoch [8404/10000], train_Loss: 5.544974635701694e-12,test_Loss:5.218352794647217, r2_store:0.3261432810478694\n",
            "torch.Size([80, 42])\n",
            "Epoch [8405/10000], train_Loss: 4.092261252086615e-12,test_Loss:5.218360424041748, r2_store:0.32614298773843964\n",
            "torch.Size([80, 42])\n",
            "Epoch [8406/10000], train_Loss: 3.784555134556111e-12,test_Loss:5.218351364135742, r2_store:0.32614333925539263\n",
            "torch.Size([80, 42])\n",
            "Epoch [8407/10000], train_Loss: 4.35128235526383e-12,test_Loss:5.218361854553223, r2_store:0.3261430221877356\n",
            "torch.Size([80, 42])\n",
            "Epoch [8408/10000], train_Loss: 5.561030368833597e-12,test_Loss:5.218350410461426, r2_store:0.3261434705929074\n",
            "torch.Size([80, 42])\n",
            "Epoch [8409/10000], train_Loss: 8.038793589126847e-12,test_Loss:5.218364238739014, r2_store:0.3261429409827563\n",
            "torch.Size([80, 42])\n",
            "Epoch [8410/10000], train_Loss: 1.1976655778234147e-11,test_Loss:5.218348503112793, r2_store:0.3261435357876691\n",
            "torch.Size([80, 42])\n",
            "Epoch [8411/10000], train_Loss: 1.8103296639537803e-11,test_Loss:5.218369483947754, r2_store:0.3261426953791602\n",
            "torch.Size([80, 42])\n",
            "Epoch [8412/10000], train_Loss: 2.7665791532682782e-11,test_Loss:5.218343734741211, r2_store:0.326143813043407\n",
            "torch.Size([80, 42])\n",
            "Epoch [8413/10000], train_Loss: 4.471194595123684e-11,test_Loss:5.218376159667969, r2_store:0.3261424646155472\n",
            "torch.Size([80, 42])\n",
            "Epoch [8414/10000], train_Loss: 6.995561768752268e-11,test_Loss:5.218335151672363, r2_store:0.3261441700070167\n",
            "torch.Size([80, 42])\n",
            "Epoch [8415/10000], train_Loss: 1.084373563164931e-10,test_Loss:5.218387603759766, r2_store:0.32614193321221707\n",
            "torch.Size([80, 42])\n",
            "Epoch [8416/10000], train_Loss: 1.6663395663307767e-10,test_Loss:5.218324184417725, r2_store:0.32614463940983973\n",
            "torch.Size([80, 42])\n",
            "Epoch [8417/10000], train_Loss: 2.407635479872994e-10,test_Loss:5.2183990478515625, r2_store:0.32614143718225286\n",
            "torch.Size([80, 42])\n",
            "Epoch [8418/10000], train_Loss: 3.3502445262456604e-10,test_Loss:5.218311786651611, r2_store:0.3261450672509735\n",
            "torch.Size([80, 42])\n",
            "Epoch [8419/10000], train_Loss: 4.5876752396978304e-10,test_Loss:5.218411922454834, r2_store:0.32614076825889937\n",
            "torch.Size([80, 42])\n",
            "Epoch [8420/10000], train_Loss: 6.033596955390408e-10,test_Loss:5.218296051025391, r2_store:0.32614579698604085\n",
            "torch.Size([80, 42])\n",
            "Epoch [8421/10000], train_Loss: 7.677969371400195e-10,test_Loss:5.218426704406738, r2_store:0.32614018400628864\n",
            "torch.Size([80, 42])\n",
            "Epoch [8422/10000], train_Loss: 9.779008713906023e-10,test_Loss:5.2182769775390625, r2_store:0.32614651704553044\n",
            "torch.Size([80, 42])\n",
            "Epoch [8423/10000], train_Loss: 1.246892145090328e-09,test_Loss:5.218445777893066, r2_store:0.326139380763635\n",
            "torch.Size([80, 42])\n",
            "Epoch [8424/10000], train_Loss: 1.5653969231976816e-09,test_Loss:5.218257427215576, r2_store:0.3261472693119578\n",
            "torch.Size([80, 42])\n",
            "Epoch [8425/10000], train_Loss: 1.905298585569426e-09,test_Loss:5.218463897705078, r2_store:0.3261384900804313\n",
            "torch.Size([80, 42])\n",
            "Epoch [8426/10000], train_Loss: 2.2904678154134217e-09,test_Loss:5.218235969543457, r2_store:0.3261480169671612\n",
            "torch.Size([80, 42])\n",
            "Epoch [8427/10000], train_Loss: 2.8286868403171184e-09,test_Loss:5.218493938446045, r2_store:0.3261373927467758\n",
            "torch.Size([80, 42])\n",
            "Epoch [8428/10000], train_Loss: 3.635725276396329e-09,test_Loss:5.218203067779541, r2_store:0.32614965686867514\n",
            "torch.Size([80, 42])\n",
            "Epoch [8429/10000], train_Loss: 4.783637486127645e-09,test_Loss:5.218535900115967, r2_store:0.32613576077191\n",
            "torch.Size([80, 42])\n",
            "Epoch [8430/10000], train_Loss: 6.2761835728508686e-09,test_Loss:5.2181549072265625, r2_store:0.3261517606901414\n",
            "torch.Size([80, 42])\n",
            "Epoch [8431/10000], train_Loss: 8.210059299074146e-09,test_Loss:5.218591213226318, r2_store:0.32613322038152126\n",
            "torch.Size([80, 42])\n",
            "Epoch [8432/10000], train_Loss: 1.0836505914824102e-08,test_Loss:5.218088626861572, r2_store:0.3261542649476996\n",
            "torch.Size([80, 42])\n",
            "Epoch [8433/10000], train_Loss: 1.4382772306476e-08,test_Loss:5.2186713218688965, r2_store:0.3261298004849571\n",
            "torch.Size([80, 42])\n",
            "Epoch [8434/10000], train_Loss: 1.9240655291241637e-08,test_Loss:5.2179975509643555, r2_store:0.32615827554974297\n",
            "torch.Size([80, 42])\n",
            "Epoch [8435/10000], train_Loss: 2.596652493025431e-08,test_Loss:5.218781471252441, r2_store:0.3261253200385673\n",
            "torch.Size([80, 42])\n",
            "Epoch [8436/10000], train_Loss: 3.517950375453438e-08,test_Loss:5.217865943908691, r2_store:0.3261638548137358\n",
            "torch.Size([80, 42])\n",
            "Epoch [8437/10000], train_Loss: 4.808822495760978e-08,test_Loss:5.218939781188965, r2_store:0.32611871481035704\n",
            "torch.Size([80, 42])\n",
            "Epoch [8438/10000], train_Loss: 6.641012362251786e-08,test_Loss:5.21767520904541, r2_store:0.3261719599894498\n",
            "torch.Size([80, 42])\n",
            "Epoch [8439/10000], train_Loss: 9.263028033501541e-08,test_Loss:5.219171047210693, r2_store:0.3261084333063352\n",
            "torch.Size([80, 42])\n",
            "Epoch [8440/10000], train_Loss: 1.3123755593369424e-07,test_Loss:5.217382907867432, r2_store:0.3261831797788034\n",
            "torch.Size([80, 42])\n",
            "Epoch [8441/10000], train_Loss: 1.873471973112828e-07,test_Loss:5.2195281982421875, r2_store:0.32609317733871745\n",
            "torch.Size([80, 42])\n",
            "Epoch [8442/10000], train_Loss: 2.693579119750211e-07,test_Loss:5.216955661773682, r2_store:0.3262013632367208\n",
            "torch.Size([80, 42])\n",
            "Epoch [8443/10000], train_Loss: 3.916992739050329e-07,test_Loss:5.220066547393799, r2_store:0.326071002102418\n",
            "torch.Size([80, 42])\n",
            "Epoch [8444/10000], train_Loss: 5.729505119234091e-07,test_Loss:5.216294765472412, r2_store:0.32622970517053507\n",
            "torch.Size([80, 42])\n",
            "Epoch [8445/10000], train_Loss: 8.457940339212655e-07,test_Loss:5.220884323120117, r2_store:0.3260349397636444\n",
            "torch.Size([80, 42])\n",
            "Epoch [8446/10000], train_Loss: 1.264898514818924e-06,test_Loss:5.215262413024902, r2_store:0.3262702933195243\n",
            "torch.Size([80, 42])\n",
            "Epoch [8447/10000], train_Loss: 1.901866539810726e-06,test_Loss:5.222192764282227, r2_store:0.32597947335498223\n",
            "torch.Size([80, 42])\n",
            "Epoch [8448/10000], train_Loss: 2.873802486647037e-06,test_Loss:5.213672161102295, r2_store:0.3263380233537394\n",
            "torch.Size([80, 42])\n",
            "Epoch [8449/10000], train_Loss: 4.386432920000516e-06,test_Loss:5.224209308624268, r2_store:0.3258958226715949\n",
            "torch.Size([80, 42])\n",
            "Epoch [8450/10000], train_Loss: 6.727760592184495e-06,test_Loss:5.211110591888428, r2_store:0.3264463197309143\n",
            "torch.Size([80, 42])\n",
            "Epoch [8451/10000], train_Loss: 1.0436086085974239e-05,test_Loss:5.227442741394043, r2_store:0.32575235230212696\n",
            "torch.Size([80, 42])\n",
            "Epoch [8452/10000], train_Loss: 1.6362424503313377e-05,test_Loss:5.206938743591309, r2_store:0.3266101606249726\n",
            "torch.Size([80, 42])\n",
            "Epoch [8453/10000], train_Loss: 2.5875251594698057e-05,test_Loss:5.232829570770264, r2_store:0.32552280645119946\n",
            "torch.Size([80, 42])\n",
            "Epoch [8454/10000], train_Loss: 4.092546441825107e-05,test_Loss:5.200266361236572, r2_store:0.32689169816261154\n",
            "torch.Size([80, 42])\n",
            "Epoch [8455/10000], train_Loss: 6.551801925525069e-05,test_Loss:5.241482734680176, r2_store:0.32515923213363385\n",
            "torch.Size([80, 42])\n",
            "Epoch [8456/10000], train_Loss: 0.00010474528971826658,test_Loss:5.189114570617676, r2_store:0.3273451519898928\n",
            "torch.Size([80, 42])\n",
            "Epoch [8457/10000], train_Loss: 0.00017038569785654545,test_Loss:5.255849838256836, r2_store:0.3245120340118558\n",
            "torch.Size([80, 42])\n",
            "Epoch [8458/10000], train_Loss: 0.000277994986390695,test_Loss:5.1699724197387695, r2_store:0.3280493655001778\n",
            "torch.Size([80, 42])\n",
            "Epoch [8459/10000], train_Loss: 0.0004698835837189108,test_Loss:5.281702041625977, r2_store:0.32336352371344323\n",
            "torch.Size([80, 42])\n",
            "Epoch [8460/10000], train_Loss: 0.000774052576161921,test_Loss:5.1372575759887695, r2_store:0.32943515825138336\n",
            "torch.Size([80, 42])\n",
            "Epoch [8461/10000], train_Loss: 0.0013386390637606382,test_Loss:5.325455188751221, r2_store:0.3215018843398514\n",
            "torch.Size([80, 42])\n",
            "Epoch [8462/10000], train_Loss: 0.0022417528089135885,test_Loss:5.0796027183532715, r2_store:0.33167159753157704\n",
            "torch.Size([80, 42])\n",
            "Epoch [8463/10000], train_Loss: 0.004052974283695221,test_Loss:5.407446384429932, r2_store:0.31790397309148666\n",
            "torch.Size([80, 42])\n",
            "Epoch [8464/10000], train_Loss: 0.0067035430110991,test_Loss:4.981334209442139, r2_store:0.3352133619133746\n",
            "torch.Size([80, 42])\n",
            "Epoch [8465/10000], train_Loss: 0.012294980697333813,test_Loss:5.52347993850708, r2_store:0.31199586380469113\n",
            "torch.Size([80, 42])\n",
            "Epoch [8466/10000], train_Loss: 0.01987447403371334,test_Loss:4.830014228820801, r2_store:0.33882160929134264\n",
            "torch.Size([80, 42])\n",
            "Epoch [8467/10000], train_Loss: 0.03696946054697037,test_Loss:5.708495140075684, r2_store:0.30178881282355363\n",
            "torch.Size([80, 42])\n",
            "Epoch [8468/10000], train_Loss: 0.048017196357250214,test_Loss:4.6829328536987305, r2_store:0.3401503047775736\n",
            "torch.Size([80, 42])\n",
            "Epoch [8469/10000], train_Loss: 0.07896332442760468,test_Loss:5.697784900665283, r2_store:0.30318736836488225\n",
            "torch.Size([80, 42])\n",
            "Epoch [8470/10000], train_Loss: 0.05858384817838669,test_Loss:4.753983974456787, r2_store:0.33939545797530846\n",
            "torch.Size([80, 42])\n",
            "Epoch [8471/10000], train_Loss: 0.033487334847450256,test_Loss:5.112325191497803, r2_store:0.3236629900061012\n",
            "torch.Size([80, 42])\n",
            "Epoch [8472/10000], train_Loss: 0.0016733345109969378,test_Loss:5.304726600646973, r2_store:0.31535740796255896\n",
            "torch.Size([80, 42])\n",
            "Epoch [8473/10000], train_Loss: 0.0165999922901392,test_Loss:4.6096038818359375, r2_store:0.3418965758654189\n",
            "torch.Size([80, 42])\n",
            "Epoch [8474/10000], train_Loss: 0.04157999902963638,test_Loss:5.266144752502441, r2_store:0.31696966690559103\n",
            "torch.Size([80, 42])\n",
            "Epoch [8475/10000], train_Loss: 0.01685372181236744,test_Loss:5.022704601287842, r2_store:0.32523114737343795\n",
            "torch.Size([80, 42])\n",
            "Epoch [8476/10000], train_Loss: 0.000868950504809618,test_Loss:4.76626443862915, r2_store:0.33292786920967377\n",
            "torch.Size([80, 42])\n",
            "Epoch [8477/10000], train_Loss: 0.01693577505648136,test_Loss:5.318819522857666, r2_store:0.31007278534440885\n",
            "torch.Size([80, 42])\n",
            "Epoch [8478/10000], train_Loss: 0.019991783425211906,test_Loss:4.853554725646973, r2_store:0.3318789400683634\n",
            "torch.Size([80, 42])\n",
            "Epoch [8479/10000], train_Loss: 0.006264267954975367,test_Loss:4.9078898429870605, r2_store:0.3286664776214667\n",
            "torch.Size([80, 42])\n",
            "Epoch [8480/10000], train_Loss: 0.0016473407158628106,test_Loss:5.1701765060424805, r2_store:0.3139053106845754\n",
            "torch.Size([80, 42])\n",
            "Epoch [8481/10000], train_Loss: 0.011346101760864258,test_Loss:4.725496768951416, r2_store:0.3290176094988564\n",
            "torch.Size([80, 42])\n",
            "Epoch [8482/10000], train_Loss: 0.009733420796692371,test_Loss:4.929241180419922, r2_store:0.3190288969454196\n",
            "torch.Size([80, 42])\n",
            "Epoch [8483/10000], train_Loss: 0.0006438913987949491,test_Loss:5.076135635375977, r2_store:0.3122111276848336\n",
            "torch.Size([80, 42])\n",
            "Epoch [8484/10000], train_Loss: 0.00652772281318903,test_Loss:4.702149391174316, r2_store:0.32822971503647214\n",
            "torch.Size([80, 42])\n",
            "Epoch [8485/10000], train_Loss: 0.00944907870143652,test_Loss:4.932986736297607, r2_store:0.31883034323405246\n",
            "torch.Size([80, 42])\n",
            "Epoch [8486/10000], train_Loss: 0.0011388586135581136,test_Loss:4.97642707824707, r2_store:0.3153235877299846\n",
            "torch.Size([80, 42])\n",
            "Epoch [8487/10000], train_Loss: 0.0034453286789357662,test_Loss:4.673422813415527, r2_store:0.3261466610532485\n",
            "torch.Size([80, 42])\n",
            "Epoch [8488/10000], train_Loss: 0.00774576747789979,test_Loss:4.930944919586182, r2_store:0.3139644404497077\n",
            "torch.Size([80, 42])\n",
            "Epoch [8489/10000], train_Loss: 0.001800560625270009,test_Loss:4.928576469421387, r2_store:0.31418669769042606\n",
            "torch.Size([80, 42])\n",
            "Epoch [8490/10000], train_Loss: 0.0015318725490942597,test_Loss:4.702922821044922, r2_store:0.32384557813005654\n",
            "torch.Size([80, 42])\n",
            "Epoch [8491/10000], train_Loss: 0.005720313638448715,test_Loss:4.940155029296875, r2_store:0.31354714238519554\n",
            "torch.Size([80, 42])\n",
            "Epoch [8492/10000], train_Loss: 0.002034577541053295,test_Loss:4.882311820983887, r2_store:0.31531178007123417\n",
            "torch.Size([80, 42])\n",
            "Epoch [8493/10000], train_Loss: 0.0006282144458964467,test_Loss:4.709201335906982, r2_store:0.3218685691403551\n",
            "torch.Size([80, 42])\n",
            "Epoch [8494/10000], train_Loss: 0.0037931669503450394,test_Loss:4.919450283050537, r2_store:0.31342068008414004\n",
            "torch.Size([80, 42])\n",
            "Epoch [8495/10000], train_Loss: 0.0018791041802614927,test_Loss:4.8588762283325195, r2_store:0.31673290576821944\n",
            "torch.Size([80, 42])\n",
            "Epoch [8496/10000], train_Loss: 0.00026868030545301735,test_Loss:4.743172645568848, r2_store:0.3216545540561012\n",
            "torch.Size([80, 42])\n",
            "Epoch [8497/10000], train_Loss: 0.0024376383516937494,test_Loss:4.9214558601379395, r2_store:0.3134638358886309\n",
            "torch.Size([80, 42])\n",
            "Epoch [8498/10000], train_Loss: 0.001611103885807097,test_Loss:4.8350348472595215, r2_store:0.3163828217926161\n",
            "torch.Size([80, 42])\n",
            "Epoch [8499/10000], train_Loss: 0.0001223143917741254,test_Loss:4.7481279373168945, r2_store:0.3196798487267336\n",
            "torch.Size([80, 42])\n",
            "Epoch [8500/10000], train_Loss: 0.001481069135479629,test_Loss:4.899045944213867, r2_store:0.3137585662105876\n",
            "torch.Size([80, 42])\n",
            "Epoch [8501/10000], train_Loss: 0.0013210922479629517,test_Loss:4.82114315032959, r2_store:0.31773285316948363\n",
            "torch.Size([80, 42])\n",
            "Epoch [8502/10000], train_Loss: 9.819403931032866e-05,test_Loss:4.7745256423950195, r2_store:0.31959360941656045\n",
            "torch.Size([80, 42])\n",
            "Epoch [8503/10000], train_Loss: 0.0008774774032644928,test_Loss:4.898210525512695, r2_store:0.3136901611782491\n",
            "torch.Size([80, 42])\n",
            "Epoch [8504/10000], train_Loss: 0.0010876087471842766,test_Loss:4.809126853942871, r2_store:0.3168350372584119\n",
            "torch.Size([80, 42])\n",
            "Epoch [8505/10000], train_Loss: 0.00013886952365282923,test_Loss:4.783670425415039, r2_store:0.3180523624547543\n",
            "torch.Size([80, 42])\n",
            "Epoch [8506/10000], train_Loss: 0.00047293328680098057,test_Loss:4.8893303871154785, r2_store:0.314460506237906\n",
            "torch.Size([80, 42])\n",
            "Epoch [8507/10000], train_Loss: 0.0008323510992340744,test_Loss:4.812075614929199, r2_store:0.318429549884122\n",
            "torch.Size([80, 42])\n",
            "Epoch [8508/10000], train_Loss: 0.00018683739472180605,test_Loss:4.8098530769348145, r2_store:0.3184468573947481\n",
            "torch.Size([80, 42])\n",
            "Epoch [8509/10000], train_Loss: 0.00023979353136382997,test_Loss:4.887594223022461, r2_store:0.3145167050181623\n",
            "torch.Size([80, 42])\n",
            "Epoch [8510/10000], train_Loss: 0.0006226735422387719,test_Loss:4.805574417114258, r2_store:0.3174183522078746\n",
            "torch.Size([80, 42])\n",
            "Epoch [8511/10000], train_Loss: 0.0002134673559339717,test_Loss:4.813549518585205, r2_store:0.3171949716891367\n",
            "torch.Size([80, 42])\n",
            "Epoch [8512/10000], train_Loss: 0.00011305876250844449,test_Loss:4.875678539276123, r2_store:0.31514764871096423\n",
            "torch.Size([80, 42])\n",
            "Epoch [8513/10000], train_Loss: 0.0004427723470143974,test_Loss:4.804434776306152, r2_store:0.3185319937749449\n",
            "torch.Size([80, 42])\n",
            "Epoch [8514/10000], train_Loss: 0.00021600013133138418,test_Loss:4.821881294250488, r2_store:0.3176648157206866\n",
            "torch.Size([80, 42])\n",
            "Epoch [8515/10000], train_Loss: 4.684639134211466e-05,test_Loss:4.862938404083252, r2_store:0.3153844509526875\n",
            "torch.Size([80, 42])\n",
            "Epoch [8516/10000], train_Loss: 0.00030305859399959445,test_Loss:4.795908451080322, r2_store:0.31784160672312567\n",
            "torch.Size([80, 42])\n",
            "Epoch [8517/10000], train_Loss: 0.00021097937133163214,test_Loss:4.822119235992432, r2_store:0.3168747235518258\n",
            "torch.Size([80, 42])\n",
            "Epoch [8518/10000], train_Loss: 2.1756412024842575e-05,test_Loss:4.853458881378174, r2_store:0.3159851421024308\n",
            "torch.Size([80, 42])\n",
            "Epoch [8519/10000], train_Loss: 0.00019392641843296587,test_Loss:4.798467636108398, r2_store:0.3186415687588533\n",
            "torch.Size([80, 42])\n",
            "Epoch [8520/10000], train_Loss: 0.00018937060667667538,test_Loss:4.828804016113281, r2_store:0.31739768374032573\n",
            "torch.Size([80, 42])\n",
            "Epoch [8521/10000], train_Loss: 1.867564787971787e-05,test_Loss:4.8452043533325195, r2_store:0.31653946214573503\n",
            "torch.Size([80, 42])\n",
            "Epoch [8522/10000], train_Loss: 0.0001141875036410056,test_Loss:4.798773765563965, r2_store:0.31844172011803007\n",
            "torch.Size([80, 42])\n",
            "Epoch [8523/10000], train_Loss: 0.00016009937098715454,test_Loss:4.832870960235596, r2_store:0.31719595669432077\n",
            "torch.Size([80, 42])\n",
            "Epoch [8524/10000], train_Loss: 2.6208366762148216e-05,test_Loss:4.839907646179199, r2_store:0.3171062586323672\n",
            "torch.Size([80, 42])\n",
            "Epoch [8525/10000], train_Loss: 5.987673648633063e-05,test_Loss:4.801793098449707, r2_store:0.3187439639828722\n",
            "torch.Size([80, 42])\n",
            "Epoch [8526/10000], train_Loss: 0.00012501966557465494,test_Loss:4.832965850830078, r2_store:0.3173004460787169\n",
            "torch.Size([80, 42])\n",
            "Epoch [8527/10000], train_Loss: 3.502921390463598e-05,test_Loss:4.829499244689941, r2_store:0.31730486607256536\n",
            "torch.Size([80, 42])\n",
            "Epoch [8528/10000], train_Loss: 2.739800220297184e-05,test_Loss:4.801076889038086, r2_store:0.3185085514809298\n",
            "torch.Size([80, 42])\n",
            "Epoch [8529/10000], train_Loss: 9.057785791810602e-05,test_Loss:4.8327412605285645, r2_store:0.3173223109824552\n",
            "torch.Size([80, 42])\n",
            "Epoch [8530/10000], train_Loss: 4.0721606637816876e-05,test_Loss:4.824575424194336, r2_store:0.317774954473665\n",
            "torch.Size([80, 42])\n",
            "Epoch [8531/10000], train_Loss: 1.0659116014721803e-05,test_Loss:4.8046464920043945, r2_store:0.3185818234116984\n",
            "torch.Size([80, 42])\n",
            "Epoch [8532/10000], train_Loss: 6.0048991144867614e-05,test_Loss:4.8321661949157715, r2_store:0.31731968163438773\n",
            "torch.Size([80, 42])\n",
            "Epoch [8533/10000], train_Loss: 4.204684591968544e-05,test_Loss:4.819379806518555, r2_store:0.3178063103354646\n",
            "torch.Size([80, 42])\n",
            "Epoch [8534/10000], train_Loss: 5.501428404386388e-06,test_Loss:4.8076252937316895, r2_store:0.318352937570371\n",
            "torch.Size([80, 42])\n",
            "Epoch [8535/10000], train_Loss: 3.580980410333723e-05,test_Loss:4.832310676574707, r2_store:0.3174033846100943\n",
            "torch.Size([80, 42])\n",
            "Epoch [8536/10000], train_Loss: 3.833121445495635e-05,test_Loss:4.817904949188232, r2_store:0.3180305945989744\n",
            "torch.Size([80, 42])\n",
            "Epoch [8537/10000], train_Loss: 5.801487986900611e-06,test_Loss:4.812849998474121, r2_store:0.3181672065044071\n",
            "torch.Size([80, 42])\n",
            "Epoch [8538/10000], train_Loss: 1.875134876172524e-05,test_Loss:4.8329033851623535, r2_store:0.31724278115004423\n",
            "torch.Size([80, 42])\n",
            "Epoch [8539/10000], train_Loss: 3.183630178682506e-05,test_Loss:4.817532539367676, r2_store:0.31790424444764187\n",
            "torch.Size([80, 42])\n",
            "Epoch [8540/10000], train_Loss: 8.461282959615346e-06,test_Loss:4.817709922790527, r2_store:0.3179979235058955\n",
            "torch.Size([80, 42])\n",
            "Epoch [8541/10000], train_Loss: 8.456330760964192e-06,test_Loss:4.8327836990356445, r2_store:0.3174581508252672\n",
            "torch.Size([80, 42])\n",
            "Epoch [8542/10000], train_Loss: 2.3841168513172306e-05,test_Loss:4.817150592803955, r2_store:0.31812877780794313\n",
            "torch.Size([80, 42])\n",
            "Epoch [8543/10000], train_Loss: 1.0622041372698732e-05,test_Loss:4.820666790008545, r2_store:0.31792076613978804\n",
            "torch.Size([80, 42])\n",
            "Epoch [8544/10000], train_Loss: 3.180391558998963e-06,test_Loss:4.830546855926514, r2_store:0.31746294767644667\n",
            "torch.Size([80, 42])\n",
            "Epoch [8545/10000], train_Loss: 1.5963203622959554e-05,test_Loss:4.815959453582764, r2_store:0.3181253067919666\n",
            "torch.Size([80, 42])\n",
            "Epoch [8546/10000], train_Loss: 1.15721850306727e-05,test_Loss:4.822205543518066, r2_store:0.3179736783175855\n",
            "torch.Size([80, 42])\n",
            "Epoch [8547/10000], train_Loss: 1.7718432445690269e-06,test_Loss:4.827901363372803, r2_store:0.31781971019958133\n",
            "torch.Size([80, 42])\n",
            "Epoch [8548/10000], train_Loss: 9.599873010301962e-06,test_Loss:4.815589904785156, r2_store:0.31833371996707527\n",
            "torch.Size([80, 42])\n",
            "Epoch [8549/10000], train_Loss: 1.0969343748001847e-05,test_Loss:4.8236212730407715, r2_store:0.31792883874589517\n",
            "torch.Size([80, 42])\n",
            "Epoch [8550/10000], train_Loss: 2.174887868022779e-06,test_Loss:4.825753211975098, r2_store:0.31777985135840525\n",
            "torch.Size([80, 42])\n",
            "Epoch [8551/10000], train_Loss: 4.92557728648535e-06,test_Loss:4.816082954406738, r2_store:0.3181883953714286\n",
            "torch.Size([80, 42])\n",
            "Epoch [8552/10000], train_Loss: 9.029527063830756e-06,test_Loss:4.824742317199707, r2_store:0.3178751499612401\n",
            "torch.Size([80, 42])\n",
            "Epoch [8553/10000], train_Loss: 3.2052143978944514e-06,test_Loss:4.823876857757568, r2_store:0.31795174808744764\n",
            "torch.Size([80, 42])\n",
            "Epoch [8554/10000], train_Loss: 2.2426406758313533e-06,test_Loss:4.816887378692627, r2_store:0.31824134262706494\n",
            "torch.Size([80, 42])\n",
            "Epoch [8555/10000], train_Loss: 6.493597084045177e-06,test_Loss:4.8251237869262695, r2_store:0.3178680359190881\n",
            "torch.Size([80, 42])\n",
            "Epoch [8556/10000], train_Loss: 3.915723482350586e-06,test_Loss:4.822030067443848, r2_store:0.31798830535474454\n",
            "torch.Size([80, 42])\n",
            "Epoch [8557/10000], train_Loss: 1.1454774266894674e-06,test_Loss:4.817824363708496, r2_store:0.3181894473728806\n",
            "torch.Size([80, 42])\n",
            "Epoch [8558/10000], train_Loss: 4.078160600329284e-06,test_Loss:4.8251423835754395, r2_store:0.3179155666764856\n",
            "torch.Size([80, 42])\n",
            "Epoch [8559/10000], train_Loss: 3.983926035289187e-06,test_Loss:4.82063102722168, r2_store:0.3181118412770323\n",
            "torch.Size([80, 42])\n",
            "Epoch [8560/10000], train_Loss: 1.0502473060114426e-06,test_Loss:4.81871223449707, r2_store:0.3181691053400162\n",
            "torch.Size([80, 42])\n",
            "Epoch [8561/10000], train_Loss: 2.2525641725223977e-06,test_Loss:4.824549674987793, r2_store:0.3179020100191531\n",
            "torch.Size([80, 42])\n",
            "Epoch [8562/10000], train_Loss: 3.4758445508487057e-06,test_Loss:4.819708824157715, r2_store:0.3181137478412538\n",
            "torch.Size([80, 42])\n",
            "Epoch [8563/10000], train_Loss: 1.3564100527219125e-06,test_Loss:4.820324420928955, r2_store:0.31812317944831436\n",
            "torch.Size([80, 42])\n",
            "Epoch [8564/10000], train_Loss: 1.1311660728097195e-06,test_Loss:4.824825286865234, r2_store:0.3179659843719769\n",
            "torch.Size([80, 42])\n",
            "Epoch [8565/10000], train_Loss: 2.6178684038313804e-06,test_Loss:4.819997787475586, r2_store:0.31817510539918026\n",
            "torch.Size([80, 42])\n",
            "Epoch [8566/10000], train_Loss: 1.653272533985728e-06,test_Loss:4.821788787841797, r2_store:0.3180910591544891\n",
            "torch.Size([80, 42])\n",
            "Epoch [8567/10000], train_Loss: 6.795693252570345e-07,test_Loss:4.824334144592285, r2_store:0.3179871812125835\n",
            "torch.Size([80, 42])\n",
            "Epoch [8568/10000], train_Loss: 1.7211632439284585e-06,test_Loss:4.820194721221924, r2_store:0.31818859331080895\n",
            "torch.Size([80, 42])\n",
            "Epoch [8569/10000], train_Loss: 1.6958392734522931e-06,test_Loss:4.823190212249756, r2_store:0.3180981373529621\n",
            "torch.Size([80, 42])\n",
            "Epoch [8570/10000], train_Loss: 6.364793989632744e-07,test_Loss:4.8242106437683105, r2_store:0.31807181457519307\n",
            "torch.Size([80, 42])\n",
            "Epoch [8571/10000], train_Loss: 9.96595190372318e-07,test_Loss:4.820714473724365, r2_store:0.31821056034579054\n",
            "torch.Size([80, 42])\n",
            "Epoch [8572/10000], train_Loss: 1.4656704934168374e-06,test_Loss:4.823719024658203, r2_store:0.3180714847966788\n",
            "torch.Size([80, 42])\n",
            "Epoch [8573/10000], train_Loss: 7.709294322921778e-07,test_Loss:4.823367595672607, r2_store:0.31809191479160803\n",
            "torch.Size([80, 42])\n",
            "Epoch [8574/10000], train_Loss: 5.975254566692456e-07,test_Loss:4.821278095245361, r2_store:0.318204979741766\n",
            "torch.Size([80, 42])\n",
            "Epoch [8575/10000], train_Loss: 1.106092099689704e-06,test_Loss:4.82456111907959, r2_store:0.3180922033738889\n",
            "torch.Size([80, 42])\n",
            "Epoch [8576/10000], train_Loss: 8.591776463617862e-07,test_Loss:4.823356628417969, r2_store:0.3181489890369724\n",
            "torch.Size([80, 42])\n",
            "Epoch [8577/10000], train_Loss: 4.392531991470605e-07,test_Loss:4.822150230407715, r2_store:0.31818995564400343\n",
            "torch.Size([80, 42])\n",
            "Epoch [8578/10000], train_Loss: 7.37819846108323e-07,test_Loss:4.82470703125, r2_store:0.3180761637694455\n",
            "torch.Size([80, 42])\n",
            "Epoch [8579/10000], train_Loss: 8.329963634423621e-07,test_Loss:4.822936058044434, r2_store:0.31816051886356744\n",
            "torch.Size([80, 42])\n",
            "Epoch [8580/10000], train_Loss: 4.4564072254615894e-07,test_Loss:4.822902202606201, r2_store:0.3181819181155954\n",
            "torch.Size([80, 42])\n",
            "Epoch [8581/10000], train_Loss: 4.752638176341861e-07,test_Loss:4.824905872344971, r2_store:0.31811090016580545\n",
            "torch.Size([80, 42])\n",
            "Epoch [8582/10000], train_Loss: 6.959120923966111e-07,test_Loss:4.8229217529296875, r2_store:0.3181924379647204\n",
            "torch.Size([80, 42])\n",
            "Epoch [8583/10000], train_Loss: 4.855174324802647e-07,test_Loss:4.823472499847412, r2_store:0.31816074312418197\n",
            "torch.Size([80, 42])\n",
            "Epoch [8584/10000], train_Loss: 3.4230004075652687e-07,test_Loss:4.824608325958252, r2_store:0.31811298558422796\n",
            "torch.Size([80, 42])\n",
            "Epoch [8585/10000], train_Loss: 5.183252369533875e-07,test_Loss:4.822884559631348, r2_store:0.318197859323488\n",
            "torch.Size([80, 42])\n",
            "Epoch [8586/10000], train_Loss: 4.916109901387244e-07,test_Loss:4.824109077453613, r2_store:0.31816078476424015\n",
            "torch.Size([80, 42])\n",
            "Epoch [8587/10000], train_Loss: 3.0878169354764395e-07,test_Loss:4.824555397033691, r2_store:0.31814683940005806\n",
            "torch.Size([80, 42])\n",
            "Epoch [8588/10000], train_Loss: 3.6371042710925394e-07,test_Loss:4.823146820068359, r2_store:0.3182010384940167\n",
            "torch.Size([80, 42])\n",
            "Epoch [8589/10000], train_Loss: 4.3886697653761075e-07,test_Loss:4.824450492858887, r2_store:0.31814044446914225\n",
            "torch.Size([80, 42])\n",
            "Epoch [8590/10000], train_Loss: 3.168511284457054e-07,test_Loss:4.824234485626221, r2_store:0.3181511960658251\n",
            "torch.Size([80, 42])\n",
            "Epoch [8591/10000], train_Loss: 2.699376295822731e-07,test_Loss:4.823385238647461, r2_store:0.3181948579995997\n",
            "torch.Size([80, 42])\n",
            "Epoch [8592/10000], train_Loss: 3.526728278302471e-07,test_Loss:4.824700355529785, r2_store:0.31814688890334997\n",
            "torch.Size([80, 42])\n",
            "Epoch [8593/10000], train_Loss: 3.1866142080616555e-07,test_Loss:4.824060916900635, r2_store:0.3181755073251473\n",
            "torch.Size([80, 42])\n",
            "Epoch [8594/10000], train_Loss: 2.3273449301086657e-07,test_Loss:4.8236918449401855, r2_store:0.31819006172429987\n",
            "torch.Size([80, 42])\n",
            "Epoch [8595/10000], train_Loss: 2.6794160135068523e-07,test_Loss:4.82473087310791, r2_store:0.318149322784572\n",
            "torch.Size([80, 42])\n",
            "Epoch [8596/10000], train_Loss: 2.938569991783879e-07,test_Loss:4.823884010314941, r2_store:0.3181928379288167\n",
            "torch.Size([80, 42])\n",
            "Epoch [8597/10000], train_Loss: 2.2697449253428204e-07,test_Loss:4.823998928070068, r2_store:0.3181971084317339\n",
            "torch.Size([80, 42])\n",
            "Epoch [8598/10000], train_Loss: 2.0998470517952228e-07,test_Loss:4.824705123901367, r2_store:0.31817274569855813\n",
            "torch.Size([80, 42])\n",
            "Epoch [8599/10000], train_Loss: 2.478619194334897e-07,test_Loss:4.82385778427124, r2_store:0.3182090748803468\n",
            "torch.Size([80, 42])\n",
            "Epoch [8600/10000], train_Loss: 2.2353499673499755e-07,test_Loss:4.824319839477539, r2_store:0.3181904487575493\n",
            "torch.Size([80, 42])\n",
            "Epoch [8601/10000], train_Loss: 1.8315488148346049e-07,test_Loss:4.824670791625977, r2_store:0.31818035511789566\n",
            "torch.Size([80, 42])\n",
            "Epoch [8602/10000], train_Loss: 2.0069732897809445e-07,test_Loss:4.8239970207214355, r2_store:0.3182164920419077\n",
            "torch.Size([80, 42])\n",
            "Epoch [8603/10000], train_Loss: 2.0857325466749899e-07,test_Loss:4.8246283531188965, r2_store:0.31819697037965267\n",
            "torch.Size([80, 42])\n",
            "Epoch [8604/10000], train_Loss: 1.7495291615432507e-07,test_Loss:4.82460880279541, r2_store:0.3182007057320998\n",
            "torch.Size([80, 42])\n",
            "Epoch [8605/10000], train_Loss: 1.6666858471126034e-07,test_Loss:4.8241424560546875, r2_store:0.3182202208648989\n",
            "torch.Size([80, 42])\n",
            "Epoch [8606/10000], train_Loss: 1.8316895022962854e-07,test_Loss:4.824775695800781, r2_store:0.3181948577174103\n",
            "torch.Size([80, 42])\n",
            "Epoch [8607/10000], train_Loss: 1.6993524809549854e-07,test_Loss:4.824516296386719, r2_store:0.3182100076758546\n",
            "torch.Size([80, 42])\n",
            "Epoch [8608/10000], train_Loss: 1.489791117137429e-07,test_Loss:4.824343204498291, r2_store:0.3182234557665541\n",
            "torch.Size([80, 42])\n",
            "Epoch [8609/10000], train_Loss: 1.5648619466901437e-07,test_Loss:4.824883460998535, r2_store:0.31820544929028727\n",
            "torch.Size([80, 42])\n",
            "Epoch [8610/10000], train_Loss: 1.5942167408411478e-07,test_Loss:4.824502944946289, r2_store:0.3182233785258286\n",
            "torch.Size([80, 42])\n",
            "Epoch [8611/10000], train_Loss: 1.4162819184093678e-07,test_Loss:4.824571132659912, r2_store:0.3182211991656879\n",
            "torch.Size([80, 42])\n",
            "Epoch [8612/10000], train_Loss: 1.365985156098759e-07,test_Loss:4.824930667877197, r2_store:0.3182077924104464\n",
            "torch.Size([80, 42])\n",
            "Epoch [8613/10000], train_Loss: 1.4379224921867717e-07,test_Loss:4.824534893035889, r2_store:0.31822798862842794\n",
            "torch.Size([80, 42])\n",
            "Epoch [8614/10000], train_Loss: 1.3654678809871257e-07,test_Loss:4.824775218963623, r2_store:0.3182219794305252\n",
            "torch.Size([80, 42])\n",
            "Epoch [8615/10000], train_Loss: 1.2543092964278912e-07,test_Loss:4.824930191040039, r2_store:0.31821839302737764\n",
            "torch.Size([80, 42])\n",
            "Epoch [8616/10000], train_Loss: 1.2753550038269168e-07,test_Loss:4.82460880279541, r2_store:0.3182334138527725\n",
            "torch.Size([80, 42])\n",
            "Epoch [8617/10000], train_Loss: 1.2853664088652295e-07,test_Loss:4.824935436248779, r2_store:0.3182215349817913\n",
            "torch.Size([80, 42])\n",
            "Epoch [8618/10000], train_Loss: 1.198110766154059e-07,test_Loss:4.824917793273926, r2_store:0.3182255746724698\n",
            "torch.Size([80, 42])\n",
            "Epoch [8619/10000], train_Loss: 1.1550064016319084e-07,test_Loss:4.8247504234313965, r2_store:0.318236646133245\n",
            "torch.Size([80, 42])\n",
            "Epoch [8620/10000], train_Loss: 1.17872808402808e-07,test_Loss:4.825080394744873, r2_store:0.31822611407704604\n",
            "torch.Size([80, 42])\n",
            "Epoch [8621/10000], train_Loss: 1.1474363503793938e-07,test_Loss:4.824942111968994, r2_store:0.31823384137165966\n",
            "torch.Size([80, 42])\n",
            "Epoch [8622/10000], train_Loss: 1.0920335569153394e-07,test_Loss:4.8249101638793945, r2_store:0.31823630908149747\n",
            "torch.Size([80, 42])\n",
            "Epoch [8623/10000], train_Loss: 1.0936095407032553e-07,test_Loss:4.825144290924072, r2_store:0.3182279701444026\n",
            "torch.Size([80, 42])\n",
            "Epoch [8624/10000], train_Loss: 1.1040596348266263e-07,test_Loss:4.824950695037842, r2_store:0.3182384348212458\n",
            "torch.Size([80, 42])\n",
            "Epoch [8625/10000], train_Loss: 1.0677895545541105e-07,test_Loss:4.825033664703369, r2_store:0.31823721260799176\n",
            "torch.Size([80, 42])\n",
            "Epoch [8626/10000], train_Loss: 1.0421574359043007e-07,test_Loss:4.825169563293457, r2_store:0.31823299145934825\n",
            "torch.Size([80, 42])\n",
            "Epoch [8627/10000], train_Loss: 1.0513743120554864e-07,test_Loss:4.8249831199646, r2_store:0.318241221715134\n",
            "torch.Size([80, 42])\n",
            "Epoch [8628/10000], train_Loss: 1.0414269269176657e-07,test_Loss:4.825130462646484, r2_store:0.3182356513982082\n",
            "torch.Size([80, 42])\n",
            "Epoch [8629/10000], train_Loss: 1.010618930763485e-07,test_Loss:4.82515811920166, r2_store:0.3182360162337968\n",
            "torch.Size([80, 42])\n",
            "Epoch [8630/10000], train_Loss: 1.0027567753922995e-07,test_Loss:4.825035572052002, r2_store:0.3182432429592893\n",
            "torch.Size([80, 42])\n",
            "Epoch [8631/10000], train_Loss: 1.005749581395321e-07,test_Loss:4.825209617614746, r2_store:0.3182374744624944\n",
            "torch.Size([80, 42])\n",
            "Epoch [8632/10000], train_Loss: 9.874089812456077e-08,test_Loss:4.825157165527344, r2_store:0.31824020511165385\n",
            "torch.Size([80, 42])\n",
            "Epoch [8633/10000], train_Loss: 9.675824230725993e-08,test_Loss:4.825107574462891, r2_store:0.318242487422697\n",
            "torch.Size([80, 42])\n",
            "Epoch [8634/10000], train_Loss: 9.66473407970625e-08,test_Loss:4.825254440307617, r2_store:0.31823706563916887\n",
            "torch.Size([80, 42])\n",
            "Epoch [8635/10000], train_Loss: 9.615126828066423e-08,test_Loss:4.82515811920166, r2_store:0.3182428052735592\n",
            "torch.Size([80, 42])\n",
            "Epoch [8636/10000], train_Loss: 9.430834779777797e-08,test_Loss:4.825186729431152, r2_store:0.3182432760884709\n",
            "torch.Size([80, 42])\n",
            "Epoch [8637/10000], train_Loss: 9.321223615188501e-08,test_Loss:4.825273036956787, r2_store:0.31824031671380404\n",
            "torch.Size([80, 42])\n",
            "Epoch [8638/10000], train_Loss: 9.299218817204746e-08,test_Loss:4.825167655944824, r2_store:0.31824461010357763\n",
            "torch.Size([80, 42])\n",
            "Epoch [8639/10000], train_Loss: 9.197607653277373e-08,test_Loss:4.825235366821289, r2_store:0.318241726980087\n",
            "torch.Size([80, 42])\n",
            "Epoch [8640/10000], train_Loss: 9.055427341309041e-08,test_Loss:4.8252668380737305, r2_store:0.31824100685998247\n",
            "torch.Size([80, 42])\n",
            "Epoch [8641/10000], train_Loss: 8.991992217488587e-08,test_Loss:4.82519006729126, r2_store:0.3182453618686768\n",
            "torch.Size([80, 42])\n",
            "Epoch [8642/10000], train_Loss: 8.944208929051456e-08,test_Loss:4.825284004211426, r2_store:0.3182422098360074\n",
            "torch.Size([80, 42])\n",
            "Epoch [8643/10000], train_Loss: 8.831104025830427e-08,test_Loss:4.825254440307617, r2_store:0.3182437733254284\n",
            "torch.Size([80, 42])\n",
            "Epoch [8644/10000], train_Loss: 8.72206626922889e-08,test_Loss:4.8252177238464355, r2_store:0.31824500239077824\n",
            "torch.Size([80, 42])\n",
            "Epoch [8645/10000], train_Loss: 8.668632034414259e-08,test_Loss:4.825297832489014, r2_store:0.3182416917959342\n",
            "torch.Size([80, 42])\n",
            "Epoch [8646/10000], train_Loss: 8.599182876878331e-08,test_Loss:4.825246810913086, r2_store:0.31824437095551017\n",
            "torch.Size([80, 42])\n",
            "Epoch [8647/10000], train_Loss: 8.492047243180423e-08,test_Loss:4.825257301330566, r2_store:0.3182445538369444\n",
            "torch.Size([80, 42])\n",
            "Epoch [8648/10000], train_Loss: 8.414910723786306e-08,test_Loss:4.825308799743652, r2_store:0.3182427457149517\n",
            "torch.Size([80, 42])\n",
            "Epoch [8649/10000], train_Loss: 8.360647996141779e-08,test_Loss:4.825246334075928, r2_store:0.31824535106862895\n",
            "torch.Size([80, 42])\n",
            "Epoch [8650/10000], train_Loss: 8.278389174165568e-08,test_Loss:4.825278282165527, r2_store:0.31824380923890594\n",
            "torch.Size([80, 42])\n",
            "Epoch [8651/10000], train_Loss: 8.188128930441962e-08,test_Loss:4.825299263000488, r2_store:0.31824312939154975\n",
            "torch.Size([80, 42])\n",
            "Epoch [8652/10000], train_Loss: 8.125463324404336e-08,test_Loss:4.825252532958984, r2_store:0.31824529648733135\n",
            "torch.Size([80, 42])\n",
            "Epoch [8653/10000], train_Loss: 8.064626655368556e-08,test_Loss:4.825304985046387, r2_store:0.3182433526310757\n",
            "torch.Size([80, 42])\n",
            "Epoch [8654/10000], train_Loss: 7.98163313220357e-08,test_Loss:4.825290203094482, r2_store:0.3182439791162126\n",
            "torch.Size([80, 42])\n",
            "Epoch [8655/10000], train_Loss: 7.904996124352692e-08,test_Loss:4.8252644538879395, r2_store:0.3182451855418891\n",
            "torch.Size([80, 42])\n",
            "Epoch [8656/10000], train_Loss: 7.847258842730298e-08,test_Loss:4.825308799743652, r2_store:0.318243474918222\n",
            "torch.Size([80, 42])\n",
            "Epoch [8657/10000], train_Loss: 7.780509747590258e-08,test_Loss:4.825279712677002, r2_store:0.3182450445445961\n",
            "torch.Size([80, 42])\n",
            "Epoch [8658/10000], train_Loss: 7.704436910671575e-08,test_Loss:4.825281143188477, r2_store:0.3182451841347117\n",
            "torch.Size([80, 42])\n",
            "Epoch [8659/10000], train_Loss: 7.63838912121173e-08,test_Loss:4.825311660766602, r2_store:0.31824391952118747\n",
            "torch.Size([80, 42])\n",
            "Epoch [8660/10000], train_Loss: 7.580443650567759e-08,test_Loss:4.825275897979736, r2_store:0.3182453786657662\n",
            "torch.Size([80, 42])\n",
            "Epoch [8661/10000], train_Loss: 7.514428546073759e-08,test_Loss:4.825295448303223, r2_store:0.318244322494444\n",
            "torch.Size([80, 42])\n",
            "Epoch [8662/10000], train_Loss: 7.445156313679036e-08,test_Loss:4.825300216674805, r2_store:0.31824431671790776\n",
            "torch.Size([80, 42])\n",
            "Epoch [8663/10000], train_Loss: 7.384148403843938e-08,test_Loss:4.825278282165527, r2_store:0.3182454291522313\n",
            "torch.Size([80, 42])\n",
            "Epoch [8664/10000], train_Loss: 7.325633077925886e-08,test_Loss:4.8253045082092285, r2_store:0.3182443854292638\n",
            "torch.Size([80, 42])\n",
            "Epoch [8665/10000], train_Loss: 7.262710255417915e-08,test_Loss:4.825294494628906, r2_store:0.31824471030492274\n",
            "torch.Size([80, 42])\n",
            "Epoch [8666/10000], train_Loss: 7.200235785376208e-08,test_Loss:4.825287818908691, r2_store:0.3182449068730665\n",
            "torch.Size([80, 42])\n",
            "Epoch [8667/10000], train_Loss: 7.142259761394598e-08,test_Loss:4.825305938720703, r2_store:0.3182442199540966\n",
            "torch.Size([80, 42])\n",
            "Epoch [8668/10000], train_Loss: 7.0845700861355e-08,test_Loss:4.825293064117432, r2_store:0.31824481534270976\n",
            "torch.Size([80, 42])\n",
            "Epoch [8669/10000], train_Loss: 7.025299453289335e-08,test_Loss:4.825296401977539, r2_store:0.31824492783789926\n",
            "torch.Size([80, 42])\n",
            "Epoch [8670/10000], train_Loss: 6.96791602194935e-08,test_Loss:4.825308799743652, r2_store:0.3182444387646648\n",
            "torch.Size([80, 42])\n",
            "Epoch [8671/10000], train_Loss: 6.913193573154786e-08,test_Loss:4.825294017791748, r2_store:0.3182450087531965\n",
            "torch.Size([80, 42])\n",
            "Epoch [8672/10000], train_Loss: 6.856903667085135e-08,test_Loss:4.825306415557861, r2_store:0.31824443561356164\n",
            "torch.Size([80, 42])\n",
            "Epoch [8673/10000], train_Loss: 6.800633656212085e-08,test_Loss:4.825309753417969, r2_store:0.3182443059881507\n",
            "torch.Size([80, 42])\n",
            "Epoch [8674/10000], train_Loss: 6.746250846845214e-08,test_Loss:4.825299263000488, r2_store:0.3182448485492896\n",
            "torch.Size([80, 42])\n",
            "Epoch [8675/10000], train_Loss: 6.693449705608145e-08,test_Loss:4.825314044952393, r2_store:0.31824427418404955\n",
            "torch.Size([80, 42])\n",
            "Epoch [8676/10000], train_Loss: 6.639939442720788e-08,test_Loss:4.825308799743652, r2_store:0.31824457488286073\n",
            "torch.Size([80, 42])\n",
            "Epoch [8677/10000], train_Loss: 6.586459733171068e-08,test_Loss:4.82530403137207, r2_store:0.31824465583192263\n",
            "torch.Size([80, 42])\n",
            "Epoch [8678/10000], train_Loss: 6.535268681773232e-08,test_Loss:4.825315475463867, r2_store:0.318244004436692\n",
            "torch.Size([80, 42])\n",
            "Epoch [8679/10000], train_Loss: 6.484396664063752e-08,test_Loss:4.825308799743652, r2_store:0.3182443679103495\n",
            "torch.Size([80, 42])\n",
            "Epoch [8680/10000], train_Loss: 6.433033661323861e-08,test_Loss:4.825310707092285, r2_store:0.31824428050794773\n",
            "torch.Size([80, 42])\n",
            "Epoch [8681/10000], train_Loss: 6.382860107123633e-08,test_Loss:4.825318813323975, r2_store:0.31824399534084247\n",
            "torch.Size([80, 42])\n",
            "Epoch [8682/10000], train_Loss: 6.333784341450155e-08,test_Loss:4.825308799743652, r2_store:0.31824440323267467\n",
            "torch.Size([80, 42])\n",
            "Epoch [8683/10000], train_Loss: 6.284878395490523e-08,test_Loss:4.825319290161133, r2_store:0.3182438533485811\n",
            "torch.Size([80, 42])\n",
            "Epoch [8684/10000], train_Loss: 6.236056293573711e-08,test_Loss:4.825315475463867, r2_store:0.3182439965367704\n",
            "torch.Size([80, 42])\n",
            "Epoch [8685/10000], train_Loss: 6.187615753106002e-08,test_Loss:4.825313568115234, r2_store:0.31824395952664475\n",
            "torch.Size([80, 42])\n",
            "Epoch [8686/10000], train_Loss: 6.140363240092483e-08,test_Loss:4.825325012207031, r2_store:0.3182435124194265\n",
            "torch.Size([80, 42])\n",
            "Epoch [8687/10000], train_Loss: 6.09433996601183e-08,test_Loss:4.825316429138184, r2_store:0.3182437622154264\n",
            "torch.Size([80, 42])\n",
            "Epoch [8688/10000], train_Loss: 6.047293510391683e-08,test_Loss:4.825316429138184, r2_store:0.31824376056331893\n",
            "torch.Size([80, 42])\n",
            "Epoch [8689/10000], train_Loss: 6.001193497695567e-08,test_Loss:4.825325965881348, r2_store:0.3182432725053783\n",
            "torch.Size([80, 42])\n",
            "Epoch [8690/10000], train_Loss: 5.956550808150496e-08,test_Loss:4.825314998626709, r2_store:0.31824375824645146\n",
            "torch.Size([80, 42])\n",
            "Epoch [8691/10000], train_Loss: 5.9119827255926793e-08,test_Loss:4.825325965881348, r2_store:0.31824329272890406\n",
            "torch.Size([80, 42])\n",
            "Epoch [8692/10000], train_Loss: 5.867233454637244e-08,test_Loss:4.825322151184082, r2_store:0.3182433904967119\n",
            "torch.Size([80, 42])\n",
            "Epoch [8693/10000], train_Loss: 5.8229080224236895e-08,test_Loss:4.825320720672607, r2_store:0.3182433895095522\n",
            "torch.Size([80, 42])\n",
            "Epoch [8694/10000], train_Loss: 5.779713774245465e-08,test_Loss:4.825327396392822, r2_store:0.3182429092904705\n",
            "torch.Size([80, 42])\n",
            "Epoch [8695/10000], train_Loss: 5.737149422202492e-08,test_Loss:4.825324058532715, r2_store:0.31824316287946686\n",
            "torch.Size([80, 42])\n",
            "Epoch [8696/10000], train_Loss: 5.694457172467082e-08,test_Loss:4.825327396392822, r2_store:0.318242951292686\n",
            "torch.Size([80, 42])\n",
            "Epoch [8697/10000], train_Loss: 5.65210882541578e-08,test_Loss:4.825329780578613, r2_store:0.31824290140342615\n",
            "torch.Size([80, 42])\n",
            "Epoch [8698/10000], train_Loss: 5.610714381987236e-08,test_Loss:4.825325012207031, r2_store:0.3182429241355148\n",
            "torch.Size([80, 42])\n",
            "Epoch [8699/10000], train_Loss: 5.569702210550531e-08,test_Loss:4.8253302574157715, r2_store:0.3182425793998285\n",
            "torch.Size([80, 42])\n",
            "Epoch [8700/10000], train_Loss: 5.52902115202869e-08,test_Loss:4.825329780578613, r2_store:0.31824265081075875\n",
            "torch.Size([80, 42])\n",
            "Epoch [8701/10000], train_Loss: 5.488767484962409e-08,test_Loss:4.825329780578613, r2_store:0.3182426365305543\n",
            "torch.Size([80, 42])\n",
            "Epoch [8702/10000], train_Loss: 5.449008000368849e-08,test_Loss:4.825335502624512, r2_store:0.31824236552118024\n",
            "torch.Size([80, 42])\n",
            "Epoch [8703/10000], train_Loss: 5.40976614615829e-08,test_Loss:4.825331211090088, r2_store:0.3182423106208556\n",
            "torch.Size([80, 42])\n",
            "Epoch [8704/10000], train_Loss: 5.370653255454272e-08,test_Loss:4.825333595275879, r2_store:0.31824219383241603\n",
            "torch.Size([80, 42])\n",
            "Epoch [8705/10000], train_Loss: 5.33206545583198e-08,test_Loss:4.8253374099731445, r2_store:0.31824189270505954\n",
            "torch.Size([80, 42])\n",
            "Epoch [8706/10000], train_Loss: 5.294127802812909e-08,test_Loss:4.8253326416015625, r2_store:0.3182421003258761\n",
            "torch.Size([80, 42])\n",
            "Epoch [8707/10000], train_Loss: 5.256245572127227e-08,test_Loss:4.825339317321777, r2_store:0.31824178226583555\n",
            "torch.Size([80, 42])\n",
            "Epoch [8708/10000], train_Loss: 5.2189609078823196e-08,test_Loss:4.8253350257873535, r2_store:0.31824189882790765\n",
            "torch.Size([80, 42])\n",
            "Epoch [8709/10000], train_Loss: 5.182081252996795e-08,test_Loss:4.825339317321777, r2_store:0.3182416822692785\n",
            "torch.Size([80, 42])\n",
            "Epoch [8710/10000], train_Loss: 5.1452825999831475e-08,test_Loss:4.825339317321777, r2_store:0.31824152621680524\n",
            "torch.Size([80, 42])\n",
            "Epoch [8711/10000], train_Loss: 5.1090211172777344e-08,test_Loss:4.8253374099731445, r2_store:0.3182415147775113\n",
            "torch.Size([80, 42])\n",
            "Epoch [8712/10000], train_Loss: 5.073023956470024e-08,test_Loss:4.825339317321777, r2_store:0.31824127894057797\n",
            "torch.Size([80, 42])\n",
            "Epoch [8713/10000], train_Loss: 5.0377146010305296e-08,test_Loss:4.825339317321777, r2_store:0.3182412608154228\n",
            "torch.Size([80, 42])\n",
            "Epoch [8714/10000], train_Loss: 5.002520353514228e-08,test_Loss:4.825340747833252, r2_store:0.3182411053421589\n",
            "torch.Size([80, 42])\n",
            "Epoch [8715/10000], train_Loss: 4.967784050791124e-08,test_Loss:4.82534122467041, r2_store:0.31824099674346296\n",
            "torch.Size([80, 42])\n",
            "Epoch [8716/10000], train_Loss: 4.9334431651004707e-08,test_Loss:4.825340747833252, r2_store:0.3182407800149287\n",
            "torch.Size([80, 42])\n",
            "Epoch [8717/10000], train_Loss: 4.899224137489e-08,test_Loss:4.82534122467041, r2_store:0.3182407050875412\n",
            "torch.Size([80, 42])\n",
            "Epoch [8718/10000], train_Loss: 4.865598768333257e-08,test_Loss:4.82534122467041, r2_store:0.318240577504204\n",
            "torch.Size([80, 42])\n",
            "Epoch [8719/10000], train_Loss: 4.8321702195153193e-08,test_Loss:4.825342178344727, r2_store:0.318240488769183\n",
            "torch.Size([80, 42])\n",
            "Epoch [8720/10000], train_Loss: 4.7991782992085064e-08,test_Loss:4.825345039367676, r2_store:0.3182402681340386\n",
            "torch.Size([80, 42])\n",
            "Epoch [8721/10000], train_Loss: 4.7664791225088265e-08,test_Loss:4.825343608856201, r2_store:0.3182401864904233\n",
            "torch.Size([80, 42])\n",
            "Epoch [8722/10000], train_Loss: 4.734028280495295e-08,test_Loss:4.825344085693359, r2_store:0.31824011041279443\n",
            "torch.Size([80, 42])\n",
            "Epoch [8723/10000], train_Loss: 4.701808364870885e-08,test_Loss:4.825346946716309, r2_store:0.3182398721192241\n",
            "torch.Size([80, 42])\n",
            "Epoch [8724/10000], train_Loss: 4.67018601568725e-08,test_Loss:4.825345039367676, r2_store:0.31823971884089397\n",
            "torch.Size([80, 42])\n",
            "Epoch [8725/10000], train_Loss: 4.638612693952382e-08,test_Loss:4.825347423553467, r2_store:0.31823956876639303\n",
            "torch.Size([80, 42])\n",
            "Epoch [8726/10000], train_Loss: 4.6074582371602446e-08,test_Loss:4.825347900390625, r2_store:0.3182394507632742\n",
            "torch.Size([80, 42])\n",
            "Epoch [8727/10000], train_Loss: 4.576503087605488e-08,test_Loss:4.825347423553467, r2_store:0.3182392962897578\n",
            "torch.Size([80, 42])\n",
            "Epoch [8728/10000], train_Loss: 4.5461632680598996e-08,test_Loss:4.825350761413574, r2_store:0.3182390696425613\n",
            "torch.Size([80, 42])\n",
            "Epoch [8729/10000], train_Loss: 4.515925411396893e-08,test_Loss:4.825346946716309, r2_store:0.31823912166096235\n",
            "torch.Size([80, 42])\n",
            "Epoch [8730/10000], train_Loss: 4.485881888172116e-08,test_Loss:4.825350284576416, r2_store:0.31823889117345716\n",
            "torch.Size([80, 42])\n",
            "Epoch [8731/10000], train_Loss: 4.456136437624991e-08,test_Loss:4.825352191925049, r2_store:0.3182387034413563\n",
            "torch.Size([80, 42])\n",
            "Epoch [8732/10000], train_Loss: 4.426895117148888e-08,test_Loss:4.825347900390625, r2_store:0.3182386671159507\n",
            "torch.Size([80, 42])\n",
            "Epoch [8733/10000], train_Loss: 4.397937303224353e-08,test_Loss:4.825353145599365, r2_store:0.3182383864966476\n",
            "torch.Size([80, 42])\n",
            "Epoch [8734/10000], train_Loss: 4.368970252244253e-08,test_Loss:4.825349807739258, r2_store:0.3182383637373881\n",
            "torch.Size([80, 42])\n",
            "Epoch [8735/10000], train_Loss: 4.340368775501702e-08,test_Loss:4.825351238250732, r2_store:0.31823817054162984\n",
            "torch.Size([80, 42])\n",
            "Epoch [8736/10000], train_Loss: 4.312039081355579e-08,test_Loss:4.8253560066223145, r2_store:0.3182378240475159\n",
            "torch.Size([80, 42])\n",
            "Epoch [8737/10000], train_Loss: 4.2841179492825177e-08,test_Loss:4.825351238250732, r2_store:0.31823803894076386\n",
            "torch.Size([80, 42])\n",
            "Epoch [8738/10000], train_Loss: 4.256388663748112e-08,test_Loss:4.825355529785156, r2_store:0.3182376223857333\n",
            "torch.Size([80, 42])\n",
            "Epoch [8739/10000], train_Loss: 4.2287702228804847e-08,test_Loss:4.82535457611084, r2_store:0.3182375401682772\n",
            "torch.Size([80, 42])\n",
            "Epoch [8740/10000], train_Loss: 4.2015901868808214e-08,test_Loss:4.825355529785156, r2_store:0.31823738204360086\n",
            "torch.Size([80, 42])\n",
            "Epoch [8741/10000], train_Loss: 4.174467704842755e-08,test_Loss:4.8253560066223145, r2_store:0.3182373237562449\n",
            "torch.Size([80, 42])\n",
            "Epoch [8742/10000], train_Loss: 4.1476258871853133e-08,test_Loss:4.825356483459473, r2_store:0.31823719456189137\n",
            "torch.Size([80, 42])\n",
            "Epoch [8743/10000], train_Loss: 4.121196184314613e-08,test_Loss:4.8253560066223145, r2_store:0.31823702315074676\n",
            "torch.Size([80, 42])\n",
            "Epoch [8744/10000], train_Loss: 4.095038974583076e-08,test_Loss:4.825356483459473, r2_store:0.3182368574787181\n",
            "torch.Size([80, 42])\n",
            "Epoch [8745/10000], train_Loss: 4.068976267035396e-08,test_Loss:4.8253560066223145, r2_store:0.3182367034976178\n",
            "torch.Size([80, 42])\n",
            "Epoch [8746/10000], train_Loss: 4.043311463419741e-08,test_Loss:4.8253583908081055, r2_store:0.31823643034801263\n",
            "torch.Size([80, 42])\n",
            "Epoch [8747/10000], train_Loss: 4.0177663862550617e-08,test_Loss:4.825357437133789, r2_store:0.31823630240007006\n",
            "torch.Size([80, 42])\n",
            "Epoch [8748/10000], train_Loss: 3.992473551761577e-08,test_Loss:4.825355052947998, r2_store:0.3182362239793708\n",
            "torch.Size([80, 42])\n",
            "Epoch [8749/10000], train_Loss: 3.967432959939288e-08,test_Loss:4.82535982131958, r2_store:0.3182360099448456\n",
            "torch.Size([80, 42])\n",
            "Epoch [8750/10000], train_Loss: 3.9427259679314375e-08,test_Loss:4.825360298156738, r2_store:0.31823587900863404\n",
            "torch.Size([80, 42])\n",
            "Epoch [8751/10000], train_Loss: 3.9180239497227376e-08,test_Loss:4.8253583908081055, r2_store:0.31823571410727436\n",
            "torch.Size([80, 42])\n",
            "Epoch [8752/10000], train_Loss: 3.893632793960933e-08,test_Loss:4.8253607749938965, r2_store:0.31823537547985614\n",
            "torch.Size([80, 42])\n",
            "Epoch [8753/10000], train_Loss: 3.8695180393233386e-08,test_Loss:4.825357913970947, r2_store:0.31823536645462613\n",
            "torch.Size([80, 42])\n",
            "Epoch [8754/10000], train_Loss: 3.845543261604689e-08,test_Loss:4.825361728668213, r2_store:0.31823519348401985\n",
            "torch.Size([80, 42])\n",
            "Epoch [8755/10000], train_Loss: 3.821715210960974e-08,test_Loss:4.825363636016846, r2_store:0.31823501824463263\n",
            "torch.Size([80, 42])\n",
            "Epoch [8756/10000], train_Loss: 3.798128744847418e-08,test_Loss:4.825358867645264, r2_store:0.31823507919457783\n",
            "torch.Size([80, 42])\n",
            "Epoch [8757/10000], train_Loss: 3.775090817725868e-08,test_Loss:4.8253631591796875, r2_store:0.318234666547594\n",
            "torch.Size([80, 42])\n",
            "Epoch [8758/10000], train_Loss: 3.751913624228109e-08,test_Loss:4.825360298156738, r2_store:0.3182346262539235\n",
            "torch.Size([80, 42])\n",
            "Epoch [8759/10000], train_Loss: 3.729027753252012e-08,test_Loss:4.825361728668213, r2_store:0.3182344883163939\n",
            "torch.Size([80, 42])\n",
            "Epoch [8760/10000], train_Loss: 3.706222173605056e-08,test_Loss:4.825364112854004, r2_store:0.3182342739253894\n",
            "torch.Size([80, 42])\n",
            "Epoch [8761/10000], train_Loss: 3.683810945176447e-08,test_Loss:4.825360298156738, r2_store:0.3182343026504052\n",
            "torch.Size([80, 42])\n",
            "Epoch [8762/10000], train_Loss: 3.661587655301446e-08,test_Loss:4.825363636016846, r2_store:0.31823400069268803\n",
            "torch.Size([80, 42])\n",
            "Epoch [8763/10000], train_Loss: 3.639400603105969e-08,test_Loss:4.8253607749938965, r2_store:0.3182338107195716\n",
            "torch.Size([80, 42])\n",
            "Epoch [8764/10000], train_Loss: 3.6173748441115094e-08,test_Loss:4.825364112854004, r2_store:0.31823366222572713\n",
            "torch.Size([80, 42])\n",
            "Epoch [8765/10000], train_Loss: 3.5955874722048975e-08,test_Loss:4.8253631591796875, r2_store:0.3182335470616716\n",
            "torch.Size([80, 42])\n",
            "Epoch [8766/10000], train_Loss: 3.5740811199502787e-08,test_Loss:4.82536506652832, r2_store:0.31823330812745787\n",
            "torch.Size([80, 42])\n",
            "Epoch [8767/10000], train_Loss: 3.552609229018344e-08,test_Loss:4.825362205505371, r2_store:0.3182332919777834\n",
            "torch.Size([80, 42])\n",
            "Epoch [8768/10000], train_Loss: 3.531470582629481e-08,test_Loss:4.825366020202637, r2_store:0.3182330156016214\n",
            "torch.Size([80, 42])\n",
            "Epoch [8769/10000], train_Loss: 3.510614376978083e-08,test_Loss:4.825364589691162, r2_store:0.3182329504316451\n",
            "torch.Size([80, 42])\n",
            "Epoch [8770/10000], train_Loss: 3.489575206572226e-08,test_Loss:4.825364589691162, r2_store:0.31823270954047556\n",
            "torch.Size([80, 42])\n",
            "Epoch [8771/10000], train_Loss: 3.4689840333612665e-08,test_Loss:4.825364112854004, r2_store:0.31823263475596153\n",
            "torch.Size([80, 42])\n",
            "Epoch [8772/10000], train_Loss: 3.4485854172316976e-08,test_Loss:4.82536506652832, r2_store:0.31823234418032886\n",
            "torch.Size([80, 42])\n",
            "Epoch [8773/10000], train_Loss: 3.428286277085135e-08,test_Loss:4.825364112854004, r2_store:0.31823220415176756\n",
            "torch.Size([80, 42])\n",
            "Epoch [8774/10000], train_Loss: 3.408193549603311e-08,test_Loss:4.825364112854004, r2_store:0.31823208639172373\n",
            "torch.Size([80, 42])\n",
            "Epoch [8775/10000], train_Loss: 3.388242220125903e-08,test_Loss:4.825366020202637, r2_store:0.3182318471142106\n",
            "torch.Size([80, 42])\n",
            "Epoch [8776/10000], train_Loss: 3.368386813917823e-08,test_Loss:4.825363636016846, r2_store:0.31823177805449676\n",
            "torch.Size([80, 42])\n",
            "Epoch [8777/10000], train_Loss: 3.348952049009313e-08,test_Loss:4.825368881225586, r2_store:0.3182314293158761\n",
            "torch.Size([80, 42])\n",
            "Epoch [8778/10000], train_Loss: 3.3293162005065824e-08,test_Loss:4.825367450714111, r2_store:0.3182313336206761\n",
            "torch.Size([80, 42])\n",
            "Epoch [8779/10000], train_Loss: 3.310027096858903e-08,test_Loss:4.825364589691162, r2_store:0.31823120133710314\n",
            "torch.Size([80, 42])\n",
            "Epoch [8780/10000], train_Loss: 3.290799099886499e-08,test_Loss:4.825369834899902, r2_store:0.3182308916692095\n",
            "torch.Size([80, 42])\n",
            "Epoch [8781/10000], train_Loss: 3.2720073761538515e-08,test_Loss:4.825366020202637, r2_store:0.31823089071568944\n",
            "torch.Size([80, 42])\n",
            "Epoch [8782/10000], train_Loss: 3.253088465271503e-08,test_Loss:4.825366973876953, r2_store:0.3182306744376827\n",
            "torch.Size([80, 42])\n",
            "Epoch [8783/10000], train_Loss: 3.234321965805975e-08,test_Loss:4.825369834899902, r2_store:0.31823045489343027\n",
            "torch.Size([80, 42])\n",
            "Epoch [8784/10000], train_Loss: 3.2159935159370434e-08,test_Loss:4.825366020202637, r2_store:0.3182303944299989\n",
            "torch.Size([80, 42])\n",
            "Epoch [8785/10000], train_Loss: 3.197467890458938e-08,test_Loss:4.825368404388428, r2_store:0.31823014030983876\n",
            "torch.Size([80, 42])\n",
            "Epoch [8786/10000], train_Loss: 3.179167862299437e-08,test_Loss:4.8253679275512695, r2_store:0.31823006785451313\n",
            "torch.Size([80, 42])\n",
            "Epoch [8787/10000], train_Loss: 3.1611502748774e-08,test_Loss:4.825366973876953, r2_store:0.31822988476695\n",
            "torch.Size([80, 42])\n",
            "Epoch [8788/10000], train_Loss: 3.1431294900130524e-08,test_Loss:4.825367450714111, r2_store:0.3182296920854757\n",
            "torch.Size([80, 42])\n",
            "Epoch [8789/10000], train_Loss: 3.125401448755838e-08,test_Loss:4.825369358062744, r2_store:0.3182294468861411\n",
            "torch.Size([80, 42])\n",
            "Epoch [8790/10000], train_Loss: 3.107690105252914e-08,test_Loss:4.825366973876953, r2_store:0.31822922738840254\n",
            "torch.Size([80, 42])\n",
            "Epoch [8791/10000], train_Loss: 3.0901837533292564e-08,test_Loss:4.825371742248535, r2_store:0.3182288356321312\n",
            "torch.Size([80, 42])\n",
            "Epoch [8792/10000], train_Loss: 3.072985776952919e-08,test_Loss:4.825366497039795, r2_store:0.31822896952807855\n",
            "torch.Size([80, 42])\n",
            "Epoch [8793/10000], train_Loss: 3.055608388535802e-08,test_Loss:4.825369834899902, r2_store:0.31822877071130196\n",
            "torch.Size([80, 42])\n",
            "Epoch [8794/10000], train_Loss: 3.0384850191467194e-08,test_Loss:4.825371742248535, r2_store:0.3182284424273196\n",
            "torch.Size([80, 42])\n",
            "Epoch [8795/10000], train_Loss: 3.021580141648883e-08,test_Loss:4.825366020202637, r2_store:0.3182284909037727\n",
            "torch.Size([80, 42])\n",
            "Epoch [8796/10000], train_Loss: 3.005009574508222e-08,test_Loss:4.825375080108643, r2_store:0.318228013218566\n",
            "torch.Size([80, 42])\n",
            "Epoch [8797/10000], train_Loss: 2.988182856711319e-08,test_Loss:4.825369834899902, r2_store:0.3182280513317449\n",
            "torch.Size([80, 42])\n",
            "Epoch [8798/10000], train_Loss: 2.971412449426225e-08,test_Loss:4.8253703117370605, r2_store:0.3182278425243502\n",
            "torch.Size([80, 42])\n",
            "Epoch [8799/10000], train_Loss: 2.9548312241445274e-08,test_Loss:4.825372219085693, r2_store:0.3182275860232734\n",
            "torch.Size([80, 42])\n",
            "Epoch [8800/10000], train_Loss: 2.938595500268093e-08,test_Loss:4.8253679275512695, r2_store:0.3182274705197352\n",
            "torch.Size([80, 42])\n",
            "Epoch [8801/10000], train_Loss: 2.9224157316320998e-08,test_Loss:4.82537317276001, r2_store:0.31822711574417484\n",
            "torch.Size([80, 42])\n",
            "Epoch [8802/10000], train_Loss: 2.906409157787948e-08,test_Loss:4.8253679275512695, r2_store:0.3182271492313453\n",
            "torch.Size([80, 42])\n",
            "Epoch [8803/10000], train_Loss: 2.890335260019583e-08,test_Loss:4.825375080108643, r2_store:0.3182268341396063\n",
            "torch.Size([80, 42])\n",
            "Epoch [8804/10000], train_Loss: 2.8745825275677817e-08,test_Loss:4.825368881225586, r2_store:0.3182267756599736\n",
            "torch.Size([80, 42])\n",
            "Epoch [8805/10000], train_Loss: 2.8588223344172548e-08,test_Loss:4.825372695922852, r2_store:0.31822641103508953\n",
            "torch.Size([80, 42])\n",
            "Epoch [8806/10000], train_Loss: 2.8431944798512632e-08,test_Loss:4.825371742248535, r2_store:0.3182262407838362\n",
            "torch.Size([80, 42])\n",
            "Epoch [8807/10000], train_Loss: 2.827458445153752e-08,test_Loss:4.825369834899902, r2_store:0.31822611688580127\n",
            "torch.Size([80, 42])\n",
            "Epoch [8808/10000], train_Loss: 2.8122070006020294e-08,test_Loss:4.825376033782959, r2_store:0.3182257340465612\n",
            "torch.Size([80, 42])\n",
            "Epoch [8809/10000], train_Loss: 2.7973442229267675e-08,test_Loss:4.8253679275512695, r2_store:0.3182260427101601\n",
            "torch.Size([80, 42])\n",
            "Epoch [8810/10000], train_Loss: 2.7824190951264427e-08,test_Loss:4.825376510620117, r2_store:0.3182253451346019\n",
            "torch.Size([80, 42])\n",
            "Epoch [8811/10000], train_Loss: 2.7671344327018232e-08,test_Loss:4.825370788574219, r2_store:0.3182253836529241\n",
            "torch.Size([80, 42])\n",
            "Epoch [8812/10000], train_Loss: 2.75188476450694e-08,test_Loss:4.825370788574219, r2_store:0.3182252989815947\n",
            "torch.Size([80, 42])\n",
            "Epoch [8813/10000], train_Loss: 2.7371664046427213e-08,test_Loss:4.825377941131592, r2_store:0.3182248429699829\n",
            "torch.Size([80, 42])\n",
            "Epoch [8814/10000], train_Loss: 2.722861935922083e-08,test_Loss:4.8253679275512695, r2_store:0.31822504998873724\n",
            "torch.Size([80, 42])\n",
            "Epoch [8815/10000], train_Loss: 2.7085334863841126e-08,test_Loss:4.825379371643066, r2_store:0.31822443119663624\n",
            "torch.Size([80, 42])\n",
            "Epoch [8816/10000], train_Loss: 2.6938959507560867e-08,test_Loss:4.825372219085693, r2_store:0.3182245397375567\n",
            "torch.Size([80, 42])\n",
            "Epoch [8817/10000], train_Loss: 2.6790408114152342e-08,test_Loss:4.825372695922852, r2_store:0.3182242853652416\n",
            "torch.Size([80, 42])\n",
            "Epoch [8818/10000], train_Loss: 2.664694775944554e-08,test_Loss:4.825378894805908, r2_store:0.3182238025502031\n",
            "torch.Size([80, 42])\n",
            "Epoch [8819/10000], train_Loss: 2.6508336858910297e-08,test_Loss:4.825368404388428, r2_store:0.31822417917469537\n",
            "torch.Size([80, 42])\n",
            "Epoch [8820/10000], train_Loss: 2.637193574628327e-08,test_Loss:4.825381278991699, r2_store:0.31822338734718236\n",
            "torch.Size([80, 42])\n",
            "Epoch [8821/10000], train_Loss: 2.623057149264696e-08,test_Loss:4.825373649597168, r2_store:0.3182235404658912\n",
            "torch.Size([80, 42])\n",
            "Epoch [8822/10000], train_Loss: 2.608597604591978e-08,test_Loss:4.825373649597168, r2_store:0.3182233724654314\n",
            "torch.Size([80, 42])\n",
            "Epoch [8823/10000], train_Loss: 2.5947944237714182e-08,test_Loss:4.825381278991699, r2_store:0.3182228299034241\n",
            "torch.Size([80, 42])\n",
            "Epoch [8824/10000], train_Loss: 2.5817280757678418e-08,test_Loss:4.825368881225586, r2_store:0.31822300369007817\n",
            "torch.Size([80, 42])\n",
            "Epoch [8825/10000], train_Loss: 2.5684832039019057e-08,test_Loss:4.825379848480225, r2_store:0.31822231858364913\n",
            "torch.Size([80, 42])\n",
            "Epoch [8826/10000], train_Loss: 2.5546853521518642e-08,test_Loss:4.825372695922852, r2_store:0.31822251122362477\n",
            "torch.Size([80, 42])\n",
            "Epoch [8827/10000], train_Loss: 2.5408169790352986e-08,test_Loss:4.825374126434326, r2_store:0.3182222185294665\n",
            "torch.Size([80, 42])\n",
            "Epoch [8828/10000], train_Loss: 2.5273646286905205e-08,test_Loss:4.825379371643066, r2_store:0.31822187596662854\n",
            "torch.Size([80, 42])\n",
            "Epoch [8829/10000], train_Loss: 2.514337360537411e-08,test_Loss:4.82537317276001, r2_store:0.31822200666308753\n",
            "torch.Size([80, 42])\n",
            "Epoch [8830/10000], train_Loss: 2.501358586926017e-08,test_Loss:4.825381278991699, r2_store:0.31822137482656176\n",
            "torch.Size([80, 42])\n",
            "Epoch [8831/10000], train_Loss: 2.4882174542995017e-08,test_Loss:4.825375556945801, r2_store:0.31822148488165414\n",
            "torch.Size([80, 42])\n",
            "Epoch [8832/10000], train_Loss: 2.4751111382670388e-08,test_Loss:4.825376510620117, r2_store:0.31822121427402494\n",
            "torch.Size([80, 42])\n",
            "Epoch [8833/10000], train_Loss: 2.4621831684612516e-08,test_Loss:4.825379371643066, r2_store:0.3182208459111582\n",
            "torch.Size([80, 42])\n",
            "Epoch [8834/10000], train_Loss: 2.4496552342156974e-08,test_Loss:4.825374603271484, r2_store:0.3182208720651071\n",
            "torch.Size([80, 42])\n",
            "Epoch [8835/10000], train_Loss: 2.4369402495949544e-08,test_Loss:4.825380802154541, r2_store:0.3182203809279476\n",
            "torch.Size([80, 42])\n",
            "Epoch [8836/10000], train_Loss: 2.4244110718996126e-08,test_Loss:4.825375556945801, r2_store:0.31822043642888576\n",
            "torch.Size([80, 42])\n",
            "Epoch [8837/10000], train_Loss: 2.4118074648527e-08,test_Loss:4.825379848480225, r2_store:0.3182200849838318\n",
            "torch.Size([80, 42])\n",
            "Epoch [8838/10000], train_Loss: 2.3992953401830164e-08,test_Loss:4.825378894805908, r2_store:0.31821992055920045\n",
            "torch.Size([80, 42])\n",
            "Epoch [8839/10000], train_Loss: 2.386978259494299e-08,test_Loss:4.825377464294434, r2_store:0.318219839227578\n",
            "torch.Size([80, 42])\n",
            "Epoch [8840/10000], train_Loss: 2.3747059429979345e-08,test_Loss:4.825381278991699, r2_store:0.31821961112694197\n",
            "torch.Size([80, 42])\n",
            "Epoch [8841/10000], train_Loss: 2.3625409184546697e-08,test_Loss:4.825377464294434, r2_store:0.31821941411548627\n",
            "torch.Size([80, 42])\n",
            "Epoch [8842/10000], train_Loss: 2.3505368318410547e-08,test_Loss:4.825380802154541, r2_store:0.3182190370057534\n",
            "torch.Size([80, 42])\n",
            "Epoch [8843/10000], train_Loss: 2.3385039682466413e-08,test_Loss:4.82537841796875, r2_store:0.3182188979288716\n",
            "torch.Size([80, 42])\n",
            "Epoch [8844/10000], train_Loss: 2.326616410641691e-08,test_Loss:4.825381278991699, r2_store:0.3182186676260732\n",
            "torch.Size([80, 42])\n",
            "Epoch [8845/10000], train_Loss: 2.3147519456756527e-08,test_Loss:4.825377941131592, r2_store:0.31821857641942897\n",
            "torch.Size([80, 42])\n",
            "Epoch [8846/10000], train_Loss: 2.3029043560995888e-08,test_Loss:4.825381278991699, r2_store:0.3182182541108127\n",
            "torch.Size([80, 42])\n",
            "Epoch [8847/10000], train_Loss: 2.2911788022383917e-08,test_Loss:4.825379848480225, r2_store:0.3182180842834582\n",
            "torch.Size([80, 42])\n",
            "Epoch [8848/10000], train_Loss: 2.2795720866497504e-08,test_Loss:4.825377464294434, r2_store:0.3182179166483059\n",
            "torch.Size([80, 42])\n",
            "Epoch [8849/10000], train_Loss: 2.268211929390418e-08,test_Loss:4.825384616851807, r2_store:0.31821749588217274\n",
            "torch.Size([80, 42])\n",
            "Epoch [8850/10000], train_Loss: 2.2569107471781535e-08,test_Loss:4.825376510620117, r2_store:0.318217659958664\n",
            "torch.Size([80, 42])\n",
            "Epoch [8851/10000], train_Loss: 2.2454713644037838e-08,test_Loss:4.825383186340332, r2_store:0.3182171841758211\n",
            "torch.Size([80, 42])\n",
            "Epoch [8852/10000], train_Loss: 2.2340836736134406e-08,test_Loss:4.82537841796875, r2_store:0.31821715736695855\n",
            "torch.Size([80, 42])\n",
            "Epoch [8853/10000], train_Loss: 2.222759576397948e-08,test_Loss:4.825381755828857, r2_store:0.31821681997469564\n",
            "torch.Size([80, 42])\n",
            "Epoch [8854/10000], train_Loss: 2.2114488018587508e-08,test_Loss:4.825382709503174, r2_store:0.31821652253905053\n",
            "torch.Size([80, 42])\n",
            "Epoch [8855/10000], train_Loss: 2.2004412514320393e-08,test_Loss:4.825380802154541, r2_store:0.31821647175929557\n",
            "torch.Size([80, 42])\n",
            "Epoch [8856/10000], train_Loss: 2.189353054404819e-08,test_Loss:4.825383186340332, r2_store:0.31821616304326683\n",
            "torch.Size([80, 42])\n",
            "Epoch [8857/10000], train_Loss: 2.1783845838285743e-08,test_Loss:4.825381278991699, r2_store:0.31821602376284264\n",
            "torch.Size([80, 42])\n",
            "Epoch [8858/10000], train_Loss: 2.1674994243880974e-08,test_Loss:4.825382232666016, r2_store:0.3182158161971891\n",
            "torch.Size([80, 42])\n",
            "Epoch [8859/10000], train_Loss: 2.1566670227457507e-08,test_Loss:4.825384140014648, r2_store:0.3182154720225112\n",
            "torch.Size([80, 42])\n",
            "Epoch [8860/10000], train_Loss: 2.1459374721644053e-08,test_Loss:4.825381278991699, r2_store:0.3182154224024861\n",
            "torch.Size([80, 42])\n",
            "Epoch [8861/10000], train_Loss: 2.1353130819079524e-08,test_Loss:4.8253865242004395, r2_store:0.31821507646891456\n",
            "torch.Size([80, 42])\n",
            "Epoch [8862/10000], train_Loss: 2.1247632986387543e-08,test_Loss:4.825380325317383, r2_store:0.31821508501980666\n",
            "torch.Size([80, 42])\n",
            "Epoch [8863/10000], train_Loss: 2.114279418208298e-08,test_Loss:4.8253865242004395, r2_store:0.31821451353842833\n",
            "torch.Size([80, 42])\n",
            "Epoch [8864/10000], train_Loss: 2.1038134789819196e-08,test_Loss:4.825381278991699, r2_store:0.3182146049905844\n",
            "torch.Size([80, 42])\n",
            "Epoch [8865/10000], train_Loss: 2.0932674260620843e-08,test_Loss:4.825383186340332, r2_store:0.31821427801334345\n",
            "torch.Size([80, 42])\n",
            "Epoch [8866/10000], train_Loss: 2.082856909169095e-08,test_Loss:4.825384140014648, r2_store:0.31821406692720067\n",
            "torch.Size([80, 42])\n",
            "Epoch [8867/10000], train_Loss: 2.07247587979964e-08,test_Loss:4.825383186340332, r2_store:0.31821393720698754\n",
            "torch.Size([80, 42])\n",
            "Epoch [8868/10000], train_Loss: 2.0623245333695195e-08,test_Loss:4.825385093688965, r2_store:0.3182135800373239\n",
            "torch.Size([80, 42])\n",
            "Epoch [8869/10000], train_Loss: 2.05216963422572e-08,test_Loss:4.825382232666016, r2_store:0.3182133815299185\n",
            "torch.Size([80, 42])\n",
            "Epoch [8870/10000], train_Loss: 2.042075664121512e-08,test_Loss:4.825386047363281, r2_store:0.3182130941026907\n",
            "torch.Size([80, 42])\n",
            "Epoch [8871/10000], train_Loss: 2.0320229054959782e-08,test_Loss:4.825384140014648, r2_store:0.3182129797477288\n",
            "torch.Size([80, 42])\n",
            "Epoch [8872/10000], train_Loss: 2.0220499052925334e-08,test_Loss:4.8253865242004395, r2_store:0.3182126014269848\n",
            "torch.Size([80, 42])\n",
            "Epoch [8873/10000], train_Loss: 2.0121088795121977e-08,test_Loss:4.825382709503174, r2_store:0.3182126552886049\n",
            "torch.Size([80, 42])\n",
            "Epoch [8874/10000], train_Loss: 2.0022932645247238e-08,test_Loss:4.8253889083862305, r2_store:0.31821220000356865\n",
            "torch.Size([80, 42])\n",
            "Epoch [8875/10000], train_Loss: 1.992624731883552e-08,test_Loss:4.825381755828857, r2_store:0.31821223533637855\n",
            "torch.Size([80, 42])\n",
            "Epoch [8876/10000], train_Loss: 1.9831436048889373e-08,test_Loss:4.825392723083496, r2_store:0.31821165486889846\n",
            "torch.Size([80, 42])\n",
            "Epoch [8877/10000], train_Loss: 1.973763907869852e-08,test_Loss:4.825383186340332, r2_store:0.31821185196437307\n",
            "torch.Size([80, 42])\n",
            "Epoch [8878/10000], train_Loss: 1.9638877191141546e-08,test_Loss:4.825390338897705, r2_store:0.31821136390529725\n",
            "torch.Size([80, 42])\n",
            "Epoch [8879/10000], train_Loss: 1.9538708428967766e-08,test_Loss:4.825387477874756, r2_store:0.3182110845634678\n",
            "torch.Size([80, 42])\n",
            "Epoch [8880/10000], train_Loss: 1.9443641363636743e-08,test_Loss:4.825382232666016, r2_store:0.3182112718729253\n",
            "torch.Size([80, 42])\n",
            "Epoch [8881/10000], train_Loss: 1.935464943869647e-08,test_Loss:4.825395584106445, r2_store:0.31821042461706894\n",
            "torch.Size([80, 42])\n",
            "Epoch [8882/10000], train_Loss: 1.9267023532165695e-08,test_Loss:4.825381278991699, r2_store:0.31821076628517253\n",
            "torch.Size([80, 42])\n",
            "Epoch [8883/10000], train_Loss: 1.9173274523609507e-08,test_Loss:4.825394630432129, r2_store:0.3182100258984919\n",
            "torch.Size([80, 42])\n",
            "Epoch [8884/10000], train_Loss: 1.9074953172548703e-08,test_Loss:4.825385570526123, r2_store:0.31821020305659875\n",
            "torch.Size([80, 42])\n",
            "Epoch [8885/10000], train_Loss: 1.8977592830538015e-08,test_Loss:4.825388431549072, r2_store:0.31821000314830306\n",
            "torch.Size([80, 42])\n",
            "Epoch [8886/10000], train_Loss: 1.8882658991969947e-08,test_Loss:4.825392246246338, r2_store:0.31820958241451636\n",
            "torch.Size([80, 42])\n",
            "Epoch [8887/10000], train_Loss: 1.8792826850244637e-08,test_Loss:4.825385093688965, r2_store:0.3182096290375709\n",
            "torch.Size([80, 42])\n",
            "Epoch [8888/10000], train_Loss: 1.8705311077837905e-08,test_Loss:4.825395584106445, r2_store:0.3182090375985417\n",
            "torch.Size([80, 42])\n",
            "Epoch [8889/10000], train_Loss: 1.8615825325696278e-08,test_Loss:4.825385093688965, r2_store:0.3182092068274187\n",
            "torch.Size([80, 42])\n",
            "Epoch [8890/10000], train_Loss: 1.8524817235743285e-08,test_Loss:4.825390815734863, r2_store:0.31820875713721086\n",
            "torch.Size([80, 42])\n",
            "Epoch [8891/10000], train_Loss: 1.8432979587146292e-08,test_Loss:4.825387954711914, r2_store:0.31820864748450073\n",
            "torch.Size([80, 42])\n",
            "Epoch [8892/10000], train_Loss: 1.834341567530373e-08,test_Loss:4.825385093688965, r2_store:0.31820849749524405\n",
            "torch.Size([80, 42])\n",
            "Epoch [8893/10000], train_Loss: 1.825565831836684e-08,test_Loss:4.825392723083496, r2_store:0.3182080215198042\n",
            "torch.Size([80, 42])\n",
            "Epoch [8894/10000], train_Loss: 1.8171325777416314e-08,test_Loss:4.82538366317749, r2_store:0.3182081395624272\n",
            "torch.Size([80, 42])\n",
            "Epoch [8895/10000], train_Loss: 1.8085192010630635e-08,test_Loss:4.825392246246338, r2_store:0.3182075562934302\n",
            "torch.Size([80, 42])\n",
            "Epoch [8896/10000], train_Loss: 1.7997102474964777e-08,test_Loss:4.825387477874756, r2_store:0.3182076340555793\n",
            "torch.Size([80, 42])\n",
            "Epoch [8897/10000], train_Loss: 1.790859194272798e-08,test_Loss:4.825390338897705, r2_store:0.31820729292084016\n",
            "torch.Size([80, 42])\n",
            "Epoch [8898/10000], train_Loss: 1.782195724331359e-08,test_Loss:4.825393199920654, r2_store:0.3182069149994239\n",
            "torch.Size([80, 42])\n",
            "Epoch [8899/10000], train_Loss: 1.7738177149340117e-08,test_Loss:4.825386047363281, r2_store:0.3182069874570336\n",
            "torch.Size([80, 42])\n",
            "Epoch [8900/10000], train_Loss: 1.765662815955693e-08,test_Loss:4.825395107269287, r2_store:0.3182063342638364\n",
            "torch.Size([80, 42])\n",
            "Epoch [8901/10000], train_Loss: 1.7574397048747414e-08,test_Loss:4.825385093688965, r2_store:0.31820654749818744\n",
            "torch.Size([80, 42])\n",
            "Epoch [8902/10000], train_Loss: 1.749091538272296e-08,test_Loss:4.825396537780762, r2_store:0.3182059299224045\n",
            "torch.Size([80, 42])\n",
            "Epoch [8903/10000], train_Loss: 1.7404206076321316e-08,test_Loss:4.825388431549072, r2_store:0.3182060788718193\n",
            "torch.Size([80, 42])\n",
            "Epoch [8904/10000], train_Loss: 1.7318077638606155e-08,test_Loss:4.825389862060547, r2_store:0.3182058664906462\n",
            "torch.Size([80, 42])\n",
            "Epoch [8905/10000], train_Loss: 1.72348393334687e-08,test_Loss:4.825394630432129, r2_store:0.3182054323646223\n",
            "torch.Size([80, 42])\n",
            "Epoch [8906/10000], train_Loss: 1.7156253306893632e-08,test_Loss:4.825384140014648, r2_store:0.3182055211622157\n",
            "torch.Size([80, 42])\n",
            "Epoch [8907/10000], train_Loss: 1.7078706449069614e-08,test_Loss:4.82539701461792, r2_store:0.31820486620708854\n",
            "torch.Size([80, 42])\n",
            "Epoch [8908/10000], train_Loss: 1.6998768614939763e-08,test_Loss:4.825385570526123, r2_store:0.31820499861087337\n",
            "torch.Size([80, 42])\n",
            "Epoch [8909/10000], train_Loss: 1.6915809197826093e-08,test_Loss:4.825395584106445, r2_store:0.3182043650568068\n",
            "torch.Size([80, 42])\n",
            "Epoch [8910/10000], train_Loss: 1.68313789572494e-08,test_Loss:4.825392246246338, r2_store:0.31820436480193026\n",
            "torch.Size([80, 42])\n",
            "Epoch [8911/10000], train_Loss: 1.674898086889698e-08,test_Loss:4.8253889083862305, r2_store:0.31820444082933097\n",
            "torch.Size([80, 42])\n",
            "Epoch [8912/10000], train_Loss: 1.6673142866352464e-08,test_Loss:4.8253984451293945, r2_store:0.3182037771039252\n",
            "torch.Size([80, 42])\n",
            "Epoch [8913/10000], train_Loss: 1.6599418728446835e-08,test_Loss:4.825387001037598, r2_store:0.31820404562872007\n",
            "torch.Size([80, 42])\n",
            "Epoch [8914/10000], train_Loss: 1.6523273416169104e-08,test_Loss:4.825400352478027, r2_store:0.31820318718571794\n",
            "torch.Size([80, 42])\n",
            "Epoch [8915/10000], train_Loss: 1.644524338928477e-08,test_Loss:4.8253889083862305, r2_store:0.3182035369323919\n",
            "torch.Size([80, 42])\n",
            "Epoch [8916/10000], train_Loss: 1.6364989363637505e-08,test_Loss:4.8253984451293945, r2_store:0.3182028693954616\n",
            "torch.Size([80, 42])\n",
            "Epoch [8917/10000], train_Loss: 1.628488988103527e-08,test_Loss:4.825392246246338, r2_store:0.31820305308347885\n",
            "torch.Size([80, 42])\n",
            "Epoch [8918/10000], train_Loss: 1.6204895203486558e-08,test_Loss:4.825397968292236, r2_store:0.31820256538834324\n",
            "torch.Size([80, 42])\n",
            "Epoch [8919/10000], train_Loss: 1.612746203250026e-08,test_Loss:4.825395107269287, r2_store:0.3182024742990115\n",
            "torch.Size([80, 42])\n",
            "Epoch [8920/10000], train_Loss: 1.605105204305346e-08,test_Loss:4.825396537780762, r2_store:0.31820211136217125\n",
            "torch.Size([80, 42])\n",
            "Epoch [8921/10000], train_Loss: 1.5974684686170804e-08,test_Loss:4.825398921966553, r2_store:0.3182018151177072\n",
            "torch.Size([80, 42])\n",
            "Epoch [8922/10000], train_Loss: 1.5900365468723976e-08,test_Loss:4.825395107269287, r2_store:0.3182017401906979\n",
            "torch.Size([80, 42])\n",
            "Epoch [8923/10000], train_Loss: 1.5825788679535435e-08,test_Loss:4.825399398803711, r2_store:0.3182014065614872\n",
            "torch.Size([80, 42])\n",
            "Epoch [8924/10000], train_Loss: 1.575151920008011e-08,test_Loss:4.825394630432129, r2_store:0.3182013332438266\n",
            "torch.Size([80, 42])\n",
            "Epoch [8925/10000], train_Loss: 1.5677954934290028e-08,test_Loss:4.8253984451293945, r2_store:0.3182009696430286\n",
            "torch.Size([80, 42])\n",
            "Epoch [8926/10000], train_Loss: 1.5603706771116777e-08,test_Loss:4.825394630432129, r2_store:0.31820086202372455\n",
            "torch.Size([80, 42])\n",
            "Epoch [8927/10000], train_Loss: 1.553098094575489e-08,test_Loss:4.8253984451293945, r2_store:0.3182004276000878\n",
            "torch.Size([80, 42])\n",
            "Epoch [8928/10000], train_Loss: 1.5457697344345434e-08,test_Loss:4.825394153594971, r2_store:0.31820052636090634\n",
            "torch.Size([80, 42])\n",
            "Epoch [8929/10000], train_Loss: 1.5385248630650494e-08,test_Loss:4.825398921966553, r2_store:0.3182000032100243\n",
            "torch.Size([80, 42])\n",
            "Epoch [8930/10000], train_Loss: 1.531322801895385e-08,test_Loss:4.825394630432129, r2_store:0.3181999545865656\n",
            "torch.Size([80, 42])\n",
            "Epoch [8931/10000], train_Loss: 1.5241516493347262e-08,test_Loss:4.8253984451293945, r2_store:0.3181995177878961\n",
            "torch.Size([80, 42])\n",
            "Epoch [8932/10000], train_Loss: 1.5169979050710936e-08,test_Loss:4.825397968292236, r2_store:0.3181994137304869\n",
            "torch.Size([80, 42])\n",
            "Epoch [8933/10000], train_Loss: 1.5098725825168913e-08,test_Loss:4.825398921966553, r2_store:0.3181991910760409\n",
            "torch.Size([80, 42])\n",
            "Epoch [8934/10000], train_Loss: 1.5027863398131558e-08,test_Loss:4.8253960609436035, r2_store:0.3181990278840139\n",
            "torch.Size([80, 42])\n",
            "Epoch [8935/10000], train_Loss: 1.4957759475464627e-08,test_Loss:4.825400352478027, r2_store:0.31819871583886594\n",
            "torch.Size([80, 42])\n",
            "Epoch [8936/10000], train_Loss: 1.4887828747589538e-08,test_Loss:4.8253984451293945, r2_store:0.318198542616728\n",
            "torch.Size([80, 42])\n",
            "Epoch [8937/10000], train_Loss: 1.4817651106113772e-08,test_Loss:4.8253984451293945, r2_store:0.3181984408014965\n",
            "torch.Size([80, 42])\n",
            "Epoch [8938/10000], train_Loss: 1.4748536614206387e-08,test_Loss:4.82540225982666, r2_store:0.31819807574380443\n",
            "torch.Size([80, 42])\n",
            "Epoch [8939/10000], train_Loss: 1.4680466620120569e-08,test_Loss:4.825397491455078, r2_store:0.31819809814914046\n",
            "torch.Size([80, 42])\n",
            "Epoch [8940/10000], train_Loss: 1.4613945609198709e-08,test_Loss:4.825403690338135, r2_store:0.3181974986010926\n",
            "torch.Size([80, 42])\n",
            "Epoch [8941/10000], train_Loss: 1.4546451154728857e-08,test_Loss:4.825396537780762, r2_store:0.3181975263516522\n",
            "torch.Size([80, 42])\n",
            "Epoch [8942/10000], train_Loss: 1.4478049870092491e-08,test_Loss:4.825403690338135, r2_store:0.318197064592042\n",
            "torch.Size([80, 42])\n",
            "Epoch [8943/10000], train_Loss: 1.4409214266208892e-08,test_Loss:4.825397968292236, r2_store:0.3181970290281698\n",
            "torch.Size([80, 42])\n",
            "Epoch [8944/10000], train_Loss: 1.4342011134260702e-08,test_Loss:4.82540225982666, r2_store:0.31819664867981556\n",
            "torch.Size([80, 42])\n",
            "Epoch [8945/10000], train_Loss: 1.4274116999501985e-08,test_Loss:4.82540225982666, r2_store:0.31819649790694726\n",
            "torch.Size([80, 42])\n",
            "Epoch [8946/10000], train_Loss: 1.4207863330284454e-08,test_Loss:4.825400352478027, r2_store:0.3181963269137764\n",
            "torch.Size([80, 42])\n",
            "Epoch [8947/10000], train_Loss: 1.4141862791916537e-08,test_Loss:4.82540225982666, r2_store:0.3181960347260585\n",
            "torch.Size([80, 42])\n",
            "Epoch [8948/10000], train_Loss: 1.4076716681188373e-08,test_Loss:4.825399875640869, r2_store:0.3181959059905256\n",
            "torch.Size([80, 42])\n",
            "Epoch [8949/10000], train_Loss: 1.4011007465342118e-08,test_Loss:4.825405120849609, r2_store:0.3181954067161611\n",
            "torch.Size([80, 42])\n",
            "Epoch [8950/10000], train_Loss: 1.3947001775704848e-08,test_Loss:4.825397968292236, r2_store:0.3181955343731\n",
            "torch.Size([80, 42])\n",
            "Epoch [8951/10000], train_Loss: 1.3882297977829694e-08,test_Loss:4.825406074523926, r2_store:0.31819501738890865\n",
            "torch.Size([80, 42])\n",
            "Epoch [8952/10000], train_Loss: 1.381972669634024e-08,test_Loss:4.8253984451293945, r2_store:0.3181951385530405\n",
            "torch.Size([80, 42])\n",
            "Epoch [8953/10000], train_Loss: 1.3756526584529638e-08,test_Loss:4.825406551361084, r2_store:0.31819451051744674\n",
            "torch.Size([80, 42])\n",
            "Epoch [8954/10000], train_Loss: 1.369224822411752e-08,test_Loss:4.825399875640869, r2_store:0.31819465215891707\n",
            "torch.Size([80, 42])\n",
            "Epoch [8955/10000], train_Loss: 1.3627404982230473e-08,test_Loss:4.825405597686768, r2_store:0.3181941857977417\n",
            "torch.Size([80, 42])\n",
            "Epoch [8956/10000], train_Loss: 1.3562304168601713e-08,test_Loss:4.825403213500977, r2_store:0.31819404683660935\n",
            "torch.Size([80, 42])\n",
            "Epoch [8957/10000], train_Loss: 1.3499082740509039e-08,test_Loss:4.8254008293151855, r2_store:0.3181938123587925\n",
            "torch.Size([80, 42])\n",
            "Epoch [8958/10000], train_Loss: 1.3437419177364518e-08,test_Loss:4.825407028198242, r2_store:0.31819342256412475\n",
            "torch.Size([80, 42])\n",
            "Epoch [8959/10000], train_Loss: 1.3376196150716169e-08,test_Loss:4.825400352478027, r2_store:0.3181934058222766\n",
            "torch.Size([80, 42])\n",
            "Epoch [8960/10000], train_Loss: 1.3315135660718624e-08,test_Loss:4.825406074523926, r2_store:0.31819299038779214\n",
            "torch.Size([80, 42])\n",
            "Epoch [8961/10000], train_Loss: 1.3252339670088986e-08,test_Loss:4.825403213500977, r2_store:0.31819301948328627\n",
            "torch.Size([80, 42])\n",
            "Epoch [8962/10000], train_Loss: 1.3189546343994607e-08,test_Loss:4.825404167175293, r2_store:0.31819277985973815\n",
            "torch.Size([80, 42])\n",
            "Epoch [8963/10000], train_Loss: 1.3127762876763427e-08,test_Loss:4.825407981872559, r2_store:0.31819244207172037\n",
            "torch.Size([80, 42])\n",
            "Epoch [8964/10000], train_Loss: 1.3068434334684298e-08,test_Loss:4.825401782989502, r2_store:0.31819233585815077\n",
            "torch.Size([80, 42])\n",
            "Epoch [8965/10000], train_Loss: 1.3010103216970492e-08,test_Loss:4.825411796569824, r2_store:0.3181917475434285\n",
            "torch.Size([80, 42])\n",
            "Epoch [8966/10000], train_Loss: 1.2954314954072288e-08,test_Loss:4.8254008293151855, r2_store:0.3181920641667194\n",
            "torch.Size([80, 42])\n",
            "Epoch [8967/10000], train_Loss: 1.2895084111619326e-08,test_Loss:4.825412750244141, r2_store:0.318191403011427\n",
            "torch.Size([80, 42])\n",
            "Epoch [8968/10000], train_Loss: 1.2833629270403435e-08,test_Loss:4.825403690338135, r2_store:0.3181915401751909\n",
            "torch.Size([80, 42])\n",
            "Epoch [8969/10000], train_Loss: 1.2770867030553745e-08,test_Loss:4.825409889221191, r2_store:0.31819097430252996\n",
            "torch.Size([80, 42])\n",
            "Epoch [8970/10000], train_Loss: 1.2709797658772004e-08,test_Loss:4.825407981872559, r2_store:0.3181908043240913\n",
            "torch.Size([80, 42])\n",
            "Epoch [8971/10000], train_Loss: 1.2651080183445629e-08,test_Loss:4.825407028198242, r2_store:0.31819070059641474\n",
            "torch.Size([80, 42])\n",
            "Epoch [8972/10000], train_Loss: 1.259323134661372e-08,test_Loss:4.825412750244141, r2_store:0.31819018132055643\n",
            "torch.Size([80, 42])\n",
            "Epoch [8973/10000], train_Loss: 1.253734183137567e-08,test_Loss:4.825403690338135, r2_store:0.31819032064080344\n",
            "torch.Size([80, 42])\n",
            "Epoch [8974/10000], train_Loss: 1.248174719137296e-08,test_Loss:4.82541561126709, r2_store:0.3181896682055254\n",
            "torch.Size([80, 42])\n",
            "Epoch [8975/10000], train_Loss: 1.2427650908364285e-08,test_Loss:4.825402736663818, r2_store:0.3181899864216621\n",
            "torch.Size([80, 42])\n",
            "Epoch [8976/10000], train_Loss: 1.237127111863856e-08,test_Loss:4.82541561126709, r2_store:0.31818921508922304\n",
            "torch.Size([80, 42])\n",
            "Epoch [8977/10000], train_Loss: 1.2314440134275628e-08,test_Loss:4.825403690338135, r2_store:0.3181894470563289\n",
            "torch.Size([80, 42])\n",
            "Epoch [8978/10000], train_Loss: 1.225578927233073e-08,test_Loss:4.825416564941406, r2_store:0.3181887543199994\n",
            "torch.Size([80, 42])\n",
            "Epoch [8979/10000], train_Loss: 1.2199225629672128e-08,test_Loss:4.825403690338135, r2_store:0.31818918922456974\n",
            "torch.Size([80, 42])\n",
            "Epoch [8980/10000], train_Loss: 1.2141827099299007e-08,test_Loss:4.825412273406982, r2_store:0.3181885433777165\n",
            "torch.Size([80, 42])\n",
            "Epoch [8981/10000], train_Loss: 1.208450850498366e-08,test_Loss:4.825406074523926, r2_store:0.31818866239817845\n",
            "torch.Size([80, 42])\n",
            "Epoch [8982/10000], train_Loss: 1.2027145501747327e-08,test_Loss:4.825413703918457, r2_store:0.3181880753960008\n",
            "torch.Size([80, 42])\n",
            "Epoch [8983/10000], train_Loss: 1.1969840230108275e-08,test_Loss:4.825409412384033, r2_store:0.3181881229513782\n",
            "torch.Size([80, 42])\n",
            "Epoch [8984/10000], train_Loss: 1.1913931174944992e-08,test_Loss:4.825411319732666, r2_store:0.3181877201364053\n",
            "torch.Size([80, 42])\n",
            "Epoch [8985/10000], train_Loss: 1.1858277915166582e-08,test_Loss:4.825413227081299, r2_store:0.3181874565267604\n",
            "torch.Size([80, 42])\n",
            "Epoch [8986/10000], train_Loss: 1.1804251798253063e-08,test_Loss:4.825408935546875, r2_store:0.3181874348739183\n",
            "torch.Size([80, 42])\n",
            "Epoch [8987/10000], train_Loss: 1.175156860711013e-08,test_Loss:4.8254194259643555, r2_store:0.3181869458833213\n",
            "torch.Size([80, 42])\n",
            "Epoch [8988/10000], train_Loss: 1.1703975566490499e-08,test_Loss:4.825403690338135, r2_store:0.3181872405305365\n",
            "torch.Size([80, 42])\n",
            "Epoch [8989/10000], train_Loss: 1.1655759912798658e-08,test_Loss:4.825421333312988, r2_store:0.3181862015044432\n",
            "torch.Size([80, 42])\n",
            "Epoch [8990/10000], train_Loss: 1.160658591459196e-08,test_Loss:4.8254008293151855, r2_store:0.3181867767088302\n",
            "torch.Size([80, 42])\n",
            "Epoch [8991/10000], train_Loss: 1.1555412626762518e-08,test_Loss:4.825421333312988, r2_store:0.3181858302387923\n",
            "torch.Size([80, 42])\n",
            "Epoch [8992/10000], train_Loss: 1.1498216601069089e-08,test_Loss:4.825405597686768, r2_store:0.31818638239290153\n",
            "torch.Size([80, 42])\n",
            "Epoch [8993/10000], train_Loss: 1.1436952718213433e-08,test_Loss:4.825413703918457, r2_store:0.3181857011084853\n",
            "torch.Size([80, 42])\n",
            "Epoch [8994/10000], train_Loss: 1.1376248387762189e-08,test_Loss:4.825413703918457, r2_store:0.3181853740324885\n",
            "torch.Size([80, 42])\n",
            "Epoch [8995/10000], train_Loss: 1.1323933790663432e-08,test_Loss:4.825407028198242, r2_store:0.3181854168264081\n",
            "torch.Size([80, 42])\n",
            "Epoch [8996/10000], train_Loss: 1.1279547962317338e-08,test_Loss:4.8254241943359375, r2_store:0.31818453078385334\n",
            "torch.Size([80, 42])\n",
            "Epoch [8997/10000], train_Loss: 1.1240879338458853e-08,test_Loss:4.82540225982666, r2_store:0.31818541438526804\n",
            "torch.Size([80, 42])\n",
            "Epoch [8998/10000], train_Loss: 1.1204950745025144e-08,test_Loss:4.8254289627075195, r2_store:0.3181840496421866\n",
            "torch.Size([80, 42])\n",
            "Epoch [8999/10000], train_Loss: 1.116939074563561e-08,test_Loss:4.82539701461792, r2_store:0.3181852107221548\n",
            "torch.Size([80, 42])\n",
            "Epoch [9000/10000], train_Loss: 1.1129364096973404e-08,test_Loss:4.825432777404785, r2_store:0.31818339941264695\n",
            "torch.Size([80, 42])\n",
            "Epoch [9001/10000], train_Loss: 1.1084223316970565e-08,test_Loss:4.825398921966553, r2_store:0.3181846891688578\n",
            "torch.Size([80, 42])\n",
            "Epoch [9002/10000], train_Loss: 1.1031660918092712e-08,test_Loss:4.825432300567627, r2_store:0.31818312850484765\n",
            "torch.Size([80, 42])\n",
            "Epoch [9003/10000], train_Loss: 1.0979281483969316e-08,test_Loss:4.825397968292236, r2_store:0.3181842989657454\n",
            "torch.Size([80, 42])\n",
            "Epoch [9004/10000], train_Loss: 1.0929727345398987e-08,test_Loss:4.825432777404785, r2_store:0.3181826198207749\n",
            "torch.Size([80, 42])\n",
            "Epoch [9005/10000], train_Loss: 1.0880946810232217e-08,test_Loss:4.825398921966553, r2_store:0.31818382053144467\n",
            "torch.Size([80, 42])\n",
            "Epoch [9006/10000], train_Loss: 1.0831938901390004e-08,test_Loss:4.82543420791626, r2_store:0.3181821021830247\n",
            "torch.Size([80, 42])\n",
            "Epoch [9007/10000], train_Loss: 1.0780254910969234e-08,test_Loss:4.825401306152344, r2_store:0.31818343817362316\n",
            "torch.Size([80, 42])\n",
            "Epoch [9008/10000], train_Loss: 1.0725311305748164e-08,test_Loss:4.825434684753418, r2_store:0.3181817820727385\n",
            "torch.Size([80, 42])\n",
            "Epoch [9009/10000], train_Loss: 1.0665723415570483e-08,test_Loss:4.825406074523926, r2_store:0.31818278907341535\n",
            "torch.Size([80, 42])\n",
            "Epoch [9010/10000], train_Loss: 1.0603046440849084e-08,test_Loss:4.825429439544678, r2_store:0.3181815011526087\n",
            "torch.Size([80, 42])\n",
            "Epoch [9011/10000], train_Loss: 1.0542794193213467e-08,test_Loss:4.825409412384033, r2_store:0.3181821484431351\n",
            "torch.Size([80, 42])\n",
            "Epoch [9012/10000], train_Loss: 1.048807973802468e-08,test_Loss:4.825427055358887, r2_store:0.3181812916608834\n",
            "torch.Size([80, 42])\n",
            "Epoch [9013/10000], train_Loss: 1.043630692976194e-08,test_Loss:4.825412750244141, r2_store:0.31818169291442255\n",
            "torch.Size([80, 42])\n",
            "Epoch [9014/10000], train_Loss: 1.038480235138195e-08,test_Loss:4.825425624847412, r2_store:0.3181808655087205\n",
            "torch.Size([80, 42])\n",
            "Epoch [9015/10000], train_Loss: 1.0333723210464996e-08,test_Loss:4.825413703918457, r2_store:0.3181810947475545\n",
            "torch.Size([80, 42])\n",
            "Epoch [9016/10000], train_Loss: 1.028353668885984e-08,test_Loss:4.825422763824463, r2_store:0.31818058547234385\n",
            "torch.Size([80, 42])\n",
            "Epoch [9017/10000], train_Loss: 1.0233176972462843e-08,test_Loss:4.8254170417785645, r2_store:0.3181806194220008\n",
            "torch.Size([80, 42])\n",
            "Epoch [9018/10000], train_Loss: 1.0185208232371679e-08,test_Loss:4.825423240661621, r2_store:0.318180186858277\n",
            "torch.Size([80, 42])\n",
            "Epoch [9019/10000], train_Loss: 1.013781680825332e-08,test_Loss:4.825417995452881, r2_store:0.3181799910065011\n",
            "torch.Size([80, 42])\n",
            "Epoch [9020/10000], train_Loss: 1.0091119051480746e-08,test_Loss:4.825423240661621, r2_store:0.3181796093718803\n",
            "torch.Size([80, 42])\n",
            "Epoch [9021/10000], train_Loss: 1.0045268616920566e-08,test_Loss:4.82541561126709, r2_store:0.3181797916383088\n",
            "torch.Size([80, 42])\n",
            "Epoch [9022/10000], train_Loss: 1.0000021255507363e-08,test_Loss:4.825424671173096, r2_store:0.3181792768699485\n",
            "torch.Size([80, 42])\n",
            "Epoch [9023/10000], train_Loss: 9.954495006070374e-09,test_Loss:4.825418949127197, r2_store:0.3181792497776622\n",
            "torch.Size([80, 42])\n",
            "Epoch [9024/10000], train_Loss: 9.907775933015728e-09,test_Loss:4.8254241943359375, r2_store:0.3181788189890389\n",
            "torch.Size([80, 42])\n",
            "Epoch [9025/10000], train_Loss: 9.860218419532885e-09,test_Loss:4.8254241943359375, r2_store:0.31817863012014924\n",
            "torch.Size([80, 42])\n",
            "Epoch [9026/10000], train_Loss: 9.815445345395801e-09,test_Loss:4.825418472290039, r2_store:0.3181786653740255\n",
            "torch.Size([80, 42])\n",
            "Epoch [9027/10000], train_Loss: 9.7735703974422e-09,test_Loss:4.825430870056152, r2_store:0.3181779748993181\n",
            "torch.Size([80, 42])\n",
            "Epoch [9028/10000], train_Loss: 9.735225958706906e-09,test_Loss:4.825414180755615, r2_store:0.3181784100010333\n",
            "torch.Size([80, 42])\n",
            "Epoch [9029/10000], train_Loss: 9.696847769191663e-09,test_Loss:4.825433254241943, r2_store:0.31817744299660455\n",
            "torch.Size([80, 42])\n",
            "Epoch [9030/10000], train_Loss: 9.656692334658601e-09,test_Loss:4.825413703918457, r2_store:0.31817797749439736\n",
            "torch.Size([80, 42])\n",
            "Epoch [9031/10000], train_Loss: 9.612413087722871e-09,test_Loss:4.825432777404785, r2_store:0.31817712816506494\n",
            "torch.Size([80, 42])\n",
            "Epoch [9032/10000], train_Loss: 9.564280034624062e-09,test_Loss:4.825417518615723, r2_store:0.31817746943075975\n",
            "torch.Size([80, 42])\n",
            "Epoch [9033/10000], train_Loss: 9.514382171005309e-09,test_Loss:4.8254289627075195, r2_store:0.3181766393211446\n",
            "torch.Size([80, 42])\n",
            "Epoch [9034/10000], train_Loss: 9.464791617119772e-09,test_Loss:4.825421333312988, r2_store:0.318176783350373\n",
            "torch.Size([80, 42])\n",
            "Epoch [9035/10000], train_Loss: 9.417485458129704e-09,test_Loss:4.825424671173096, r2_store:0.3181765117079608\n",
            "torch.Size([80, 42])\n",
            "Epoch [9036/10000], train_Loss: 9.372118192629841e-09,test_Loss:4.825427055358887, r2_store:0.3181762907165996\n",
            "torch.Size([80, 42])\n",
            "Epoch [9037/10000], train_Loss: 9.328777750283734e-09,test_Loss:4.825420379638672, r2_store:0.3181762858189674\n",
            "torch.Size([80, 42])\n",
            "Epoch [9038/10000], train_Loss: 9.28907262220946e-09,test_Loss:4.825432777404785, r2_store:0.31817543523026726\n",
            "torch.Size([80, 42])\n",
            "Epoch [9039/10000], train_Loss: 9.256172717186928e-09,test_Loss:4.825413703918457, r2_store:0.31817620722659135\n",
            "torch.Size([80, 42])\n",
            "Epoch [9040/10000], train_Loss: 9.230388897663033e-09,test_Loss:4.825440883636475, r2_store:0.3181748783393432\n",
            "torch.Size([80, 42])\n",
            "Epoch [9041/10000], train_Loss: 9.206797102478959e-09,test_Loss:4.825408458709717, r2_store:0.31817617478127946\n",
            "torch.Size([80, 42])\n",
            "Epoch [9042/10000], train_Loss: 9.182075544345025e-09,test_Loss:4.825446605682373, r2_store:0.31817428113987434\n",
            "torch.Size([80, 42])\n",
            "Epoch [9043/10000], train_Loss: 9.164266678851618e-09,test_Loss:4.82540225982666, r2_store:0.3181758130385708\n",
            "torch.Size([80, 42])\n",
            "Epoch [9044/10000], train_Loss: 9.158593883284993e-09,test_Loss:4.825455665588379, r2_store:0.31817335992373685\n",
            "torch.Size([80, 42])\n",
            "Epoch [9045/10000], train_Loss: 9.177949955585518e-09,test_Loss:4.825392246246338, r2_store:0.3181758509208773\n",
            "torch.Size([80, 42])\n",
            "Epoch [9046/10000], train_Loss: 9.22838250261293e-09,test_Loss:4.825469970703125, r2_store:0.31817249040526485\n",
            "torch.Size([80, 42])\n",
            "Epoch [9047/10000], train_Loss: 9.318299909466532e-09,test_Loss:4.825376987457275, r2_store:0.31817617636145146\n",
            "torch.Size([80, 42])\n",
            "Epoch [9048/10000], train_Loss: 9.47484046776026e-09,test_Loss:4.825491428375244, r2_store:0.31817103804775837\n",
            "torch.Size([80, 42])\n",
            "Epoch [9049/10000], train_Loss: 9.736501382917595e-09,test_Loss:4.825349807739258, r2_store:0.31817680764758227\n",
            "torch.Size([80, 42])\n",
            "Epoch [9050/10000], train_Loss: 1.0167724440179882e-08,test_Loss:4.825525760650635, r2_store:0.31816933462111296\n",
            "torch.Size([80, 42])\n",
            "Epoch [9051/10000], train_Loss: 1.083775380550378e-08,test_Loss:4.825310707092285, r2_store:0.31817817630572987\n",
            "torch.Size([80, 42])\n",
            "Epoch [9052/10000], train_Loss: 1.18256462400268e-08,test_Loss:4.825571537017822, r2_store:0.3181669932314922\n",
            "torch.Size([80, 42])\n",
            "Epoch [9053/10000], train_Loss: 1.3256199693501003e-08,test_Loss:4.82525634765625, r2_store:0.31817999198829927\n",
            "torch.Size([80, 42])\n",
            "Epoch [9054/10000], train_Loss: 1.5316260260078707e-08,test_Loss:4.825638771057129, r2_store:0.31816370633867186\n",
            "torch.Size([80, 42])\n",
            "Epoch [9055/10000], train_Loss: 1.839287833149683e-08,test_Loss:4.825174808502197, r2_store:0.3181829229494584\n",
            "torch.Size([80, 42])\n",
            "Epoch [9056/10000], train_Loss: 2.316395075752098e-08,test_Loss:4.825744152069092, r2_store:0.3181589504119615\n",
            "torch.Size([80, 42])\n",
            "Epoch [9057/10000], train_Loss: 3.055951580677174e-08,test_Loss:4.825045585632324, r2_store:0.3181880735051307\n",
            "torch.Size([80, 42])\n",
            "Epoch [9058/10000], train_Loss: 4.190069802234575e-08,test_Loss:4.825905799865723, r2_store:0.31815178896570373\n",
            "torch.Size([80, 42])\n",
            "Epoch [9059/10000], train_Loss: 5.929248203528914e-08,test_Loss:4.824843406677246, r2_store:0.31819616944134754\n",
            "torch.Size([80, 42])\n",
            "Epoch [9060/10000], train_Loss: 8.620399682968127e-08,test_Loss:4.826159954071045, r2_store:0.3181405975269893\n",
            "torch.Size([80, 42])\n",
            "Epoch [9061/10000], train_Loss: 1.2820326844575902e-07,test_Loss:4.824522018432617, r2_store:0.31820910889758114\n",
            "torch.Size([80, 42])\n",
            "Epoch [9062/10000], train_Loss: 1.9453537447589042e-07,test_Loss:4.826570987701416, r2_store:0.31812300071562105\n",
            "torch.Size([80, 42])\n",
            "Epoch [9063/10000], train_Loss: 2.9979995019857597e-07,test_Loss:4.82400369644165, r2_store:0.318230568652101\n",
            "torch.Size([80, 42])\n",
            "Epoch [9064/10000], train_Loss: 4.674336082644004e-07,test_Loss:4.8272318840026855, r2_store:0.318094973095312\n",
            "torch.Size([80, 42])\n",
            "Epoch [9065/10000], train_Loss: 7.356824198723189e-07,test_Loss:4.823159217834473, r2_store:0.31826533129772905\n",
            "torch.Size([80, 42])\n",
            "Epoch [9066/10000], train_Loss: 1.1700506092893193e-06,test_Loss:4.828313827514648, r2_store:0.3180487177570893\n",
            "torch.Size([80, 42])\n",
            "Epoch [9067/10000], train_Loss: 1.875564294095966e-06,test_Loss:4.821765899658203, r2_store:0.31832322481070985\n",
            "torch.Size([80, 42])\n",
            "Epoch [9068/10000], train_Loss: 3.0337052976392442e-06,test_Loss:4.8301167488098145, r2_store:0.31797254126022434\n",
            "torch.Size([80, 42])\n",
            "Epoch [9069/10000], train_Loss: 4.939235168421874e-06,test_Loss:4.819427967071533, r2_store:0.3184214032980669\n",
            "torch.Size([80, 42])\n",
            "Epoch [9070/10000], train_Loss: 8.130840797093697e-06,test_Loss:4.8331708908081055, r2_store:0.3178442182712229\n",
            "torch.Size([80, 42])\n",
            "Epoch [9071/10000], train_Loss: 1.3442641829897184e-05,test_Loss:4.815459728240967, r2_store:0.3185876397491667\n",
            "torch.Size([80, 42])\n",
            "Epoch [9072/10000], train_Loss: 2.2469099349109456e-05,test_Loss:4.838400840759277, r2_store:0.31762343739924825\n",
            "torch.Size([80, 42])\n",
            "Epoch [9073/10000], train_Loss: 3.7660403904737905e-05,test_Loss:4.808558940887451, r2_store:0.3188694525199752\n",
            "torch.Size([80, 42])\n",
            "Epoch [9074/10000], train_Loss: 6.508138903882354e-05,test_Loss:4.847935199737549, r2_store:0.31721672846648186\n",
            "torch.Size([80, 42])\n",
            "Epoch [9075/10000], train_Loss: 0.00011145519965793937,test_Loss:4.796408176422119, r2_store:0.3193766514577182\n",
            "torch.Size([80, 42])\n",
            "Epoch [9076/10000], train_Loss: 0.00019641368999145925,test_Loss:4.865050315856934, r2_store:0.3164983038263136\n",
            "torch.Size([80, 42])\n",
            "Epoch [9077/10000], train_Loss: 0.00033922604052349925,test_Loss:4.7748517990112305, r2_store:0.32026267318147705\n",
            "torch.Size([80, 42])\n",
            "Epoch [9078/10000], train_Loss: 0.0006048573413863778,test_Loss:4.89540958404541, r2_store:0.31520734463691613\n",
            "torch.Size([80, 42])\n",
            "Epoch [9079/10000], train_Loss: 0.0010429753456264734,test_Loss:4.737128734588623, r2_store:0.3217616557103\n",
            "torch.Size([80, 42])\n",
            "Epoch [9080/10000], train_Loss: 0.001874545938335359,test_Loss:4.949078559875488, r2_store:0.31268731372249137\n",
            "torch.Size([80, 42])\n",
            "Epoch [9081/10000], train_Loss: 0.0032648216001689434,test_Loss:4.668644905090332, r2_store:0.3243456014318489\n",
            "torch.Size([80, 42])\n",
            "Epoch [9082/10000], train_Loss: 0.006051274016499519,test_Loss:5.045873641967773, r2_store:0.30837270924365756\n",
            "torch.Size([80, 42])\n",
            "Epoch [9083/10000], train_Loss: 0.010166415013372898,test_Loss:4.547208309173584, r2_store:0.32898529810185184\n",
            "torch.Size([80, 42])\n",
            "Epoch [9084/10000], train_Loss: 0.019774386659264565,test_Loss:5.1981611251831055, r2_store:0.30107033480750134\n",
            "torch.Size([80, 42])\n",
            "Epoch [9085/10000], train_Loss: 0.030428484082221985,test_Loss:4.370902061462402, r2_store:0.33269542952900044\n",
            "torch.Size([80, 42])\n",
            "Epoch [9086/10000], train_Loss: 0.05688320845365524,test_Loss:5.358855247497559, r2_store:0.28936473739341717\n",
            "torch.Size([80, 42])\n",
            "Epoch [9087/10000], train_Loss: 0.06828165054321289,test_Loss:4.279296875, r2_store:0.3324095815232817\n",
            "torch.Size([80, 42])\n",
            "Epoch [9088/10000], train_Loss: 0.09356901049613953,test_Loss:5.20637845993042, r2_store:0.30596597878609644\n",
            "torch.Size([80, 42])\n",
            "Epoch [9089/10000], train_Loss: 0.034388624131679535,test_Loss:4.741560935974121, r2_store:0.3286676390573988\n",
            "torch.Size([80, 42])\n",
            "Epoch [9090/10000], train_Loss: 0.0006819552509114146,test_Loss:4.4294514656066895, r2_store:0.34074065950176147\n",
            "torch.Size([80, 42])\n",
            "Epoch [9091/10000], train_Loss: 0.02415870875120163,test_Loss:5.095614433288574, r2_store:0.30980723365669793\n",
            "torch.Size([80, 42])\n",
            "Epoch [9092/10000], train_Loss: 0.04164169728755951,test_Loss:4.371001243591309, r2_store:0.3377845533550833\n",
            "torch.Size([80, 42])\n",
            "Epoch [9093/10000], train_Loss: 0.024614332243800163,test_Loss:4.6532087326049805, r2_store:0.32862562140951757\n",
            "torch.Size([80, 42])\n",
            "Epoch [9094/10000], train_Loss: 0.0011849121656268835,test_Loss:5.032727241516113, r2_store:0.3118495228687621\n",
            "torch.Size([80, 42])\n",
            "Epoch [9095/10000], train_Loss: 0.025934990495443344,test_Loss:4.311354637145996, r2_store:0.33848732439678997\n",
            "torch.Size([80, 42])\n",
            "Epoch [9096/10000], train_Loss: 0.033658020198345184,test_Loss:4.6587233543396, r2_store:0.3283343162569725\n",
            "torch.Size([80, 42])\n",
            "Epoch [9097/10000], train_Loss: 0.0020092111080884933,test_Loss:4.867127418518066, r2_store:0.32060528321502824\n",
            "torch.Size([80, 42])\n",
            "Epoch [9098/10000], train_Loss: 0.018669214099645615,test_Loss:4.293112277984619, r2_store:0.3438601896647302\n",
            "torch.Size([80, 42])\n",
            "Epoch [9099/10000], train_Loss: 0.032943472266197205,test_Loss:4.711732864379883, r2_store:0.3267515342773476\n",
            "torch.Size([80, 42])\n",
            "Epoch [9100/10000], train_Loss: 0.003040019888430834,test_Loss:4.850560188293457, r2_store:0.31802144391568654\n",
            "torch.Size([80, 42])\n",
            "Epoch [9101/10000], train_Loss: 0.013407510705292225,test_Loss:4.339330196380615, r2_store:0.33641299393880275\n",
            "torch.Size([80, 42])\n",
            "Epoch [9102/10000], train_Loss: 0.026385527104139328,test_Loss:4.708287239074707, r2_store:0.32407931525064704\n",
            "torch.Size([80, 42])\n",
            "Epoch [9103/10000], train_Loss: 0.0021675582975149155,test_Loss:4.866452693939209, r2_store:0.3177174289812228\n",
            "torch.Size([80, 42])\n",
            "Epoch [9104/10000], train_Loss: 0.013308705762028694,test_Loss:4.333197116851807, r2_store:0.3379033962173802\n",
            "torch.Size([80, 42])\n",
            "Epoch [9105/10000], train_Loss: 0.022544873878359795,test_Loss:4.610742092132568, r2_store:0.3287582806205034\n",
            "torch.Size([80, 42])\n",
            "Epoch [9106/10000], train_Loss: 0.0009991626720875502,test_Loss:4.8192596435546875, r2_store:0.3202715991400573\n",
            "torch.Size([80, 42])\n",
            "Epoch [9107/10000], train_Loss: 0.01512160338461399,test_Loss:4.347289085388184, r2_store:0.3399901788406574\n",
            "torch.Size([80, 42])\n",
            "Epoch [9108/10000], train_Loss: 0.017456531524658203,test_Loss:4.539768218994141, r2_store:0.3298639352006971\n",
            "torch.Size([80, 42])\n",
            "Epoch [9109/10000], train_Loss: 0.00042525242315605283,test_Loss:4.783792018890381, r2_store:0.3169583142886101\n",
            "torch.Size([80, 42])\n",
            "Epoch [9110/10000], train_Loss: 0.015234148129820824,test_Loss:4.348849296569824, r2_store:0.3340403822920176\n",
            "torch.Size([80, 42])\n",
            "Epoch [9111/10000], train_Loss: 0.011492976918816566,test_Loss:4.485331058502197, r2_store:0.3296722971202004\n",
            "torch.Size([80, 42])\n",
            "Epoch [9112/10000], train_Loss: 0.0019336852710694075,test_Loss:4.79849910736084, r2_store:0.31607972571796483\n",
            "torch.Size([80, 42])\n",
            "Epoch [9113/10000], train_Loss: 0.014950955286622047,test_Loss:4.394180774688721, r2_store:0.3316348888816859\n",
            "torch.Size([80, 42])\n",
            "Epoch [9114/10000], train_Loss: 0.006702615413814783,test_Loss:4.448952674865723, r2_store:0.33141906869969084\n",
            "torch.Size([80, 42])\n",
            "Epoch [9115/10000], train_Loss: 0.002963020233437419,test_Loss:4.7802276611328125, r2_store:0.3210825261762834\n",
            "torch.Size([80, 42])\n",
            "Epoch [9116/10000], train_Loss: 0.012207802385091782,test_Loss:4.478972434997559, r2_store:0.3355699176269651\n",
            "torch.Size([80, 42])\n",
            "Epoch [9117/10000], train_Loss: 0.0023585213348269463,test_Loss:4.420880317687988, r2_store:0.3374208029884178\n",
            "torch.Size([80, 42])\n",
            "Epoch [9118/10000], train_Loss: 0.00472638476639986,test_Loss:4.694954872131348, r2_store:0.3250161922217196\n",
            "torch.Size([80, 42])\n",
            "Epoch [9119/10000], train_Loss: 0.007382075302302837,test_Loss:4.504578590393066, r2_store:0.33109450176457\n",
            "torch.Size([80, 42])\n",
            "Epoch [9120/10000], train_Loss: 0.000364340259693563,test_Loss:4.392770767211914, r2_store:0.3343648750408016\n",
            "torch.Size([80, 42])\n",
            "Epoch [9121/10000], train_Loss: 0.0053693694062530994,test_Loss:4.647192001342773, r2_store:0.3248082813268023\n",
            "torch.Size([80, 42])\n",
            "Epoch [9122/10000], train_Loss: 0.0033634721767157316,test_Loss:4.583887577056885, r2_store:0.32719823075792287\n",
            "torch.Size([80, 42])\n",
            "Epoch [9123/10000], train_Loss: 0.0008186160703189671,test_Loss:4.409730434417725, r2_store:0.333040265346509\n",
            "torch.Size([80, 42])\n",
            "Epoch [9124/10000], train_Loss: 0.004486612044274807,test_Loss:4.5820817947387695, r2_store:0.3267003924111984\n",
            "torch.Size([80, 42])\n",
            "Epoch [9125/10000], train_Loss: 0.0006929034716449678,test_Loss:4.635777473449707, r2_store:0.32479204436515763\n",
            "torch.Size([80, 42])\n",
            "Epoch [9126/10000], train_Loss: 0.002069579903036356,test_Loss:4.462038040161133, r2_store:0.3319963764936522\n",
            "torch.Size([80, 42])\n",
            "Epoch [9127/10000], train_Loss: 0.002851732075214386,test_Loss:4.5540571212768555, r2_store:0.3290754385655338\n",
            "torch.Size([80, 42])\n",
            "Epoch [9128/10000], train_Loss: 0.00017429790750611573,test_Loss:4.660350799560547, r2_store:0.3251774077575186\n",
            "torch.Size([80, 42])\n",
            "Epoch [9129/10000], train_Loss: 0.002535215113312006,test_Loss:4.503432273864746, r2_store:0.33164956938486956\n",
            "torch.Size([80, 42])\n",
            "Epoch [9130/10000], train_Loss: 0.001061482005752623,test_Loss:4.520009517669678, r2_store:0.33083752479443107\n",
            "torch.Size([80, 42])\n",
            "Epoch [9131/10000], train_Loss: 0.0006390956696122885,test_Loss:4.6494879722595215, r2_store:0.3251998201498284\n",
            "torch.Size([80, 42])\n",
            "Epoch [9132/10000], train_Loss: 0.0020306087099015713,test_Loss:4.537505149841309, r2_store:0.3292414718785396\n",
            "torch.Size([80, 42])\n",
            "Epoch [9133/10000], train_Loss: 0.00022776956029701978,test_Loss:4.4995245933532715, r2_store:0.3305791112423152\n",
            "torch.Size([80, 42])\n",
            "Epoch [9134/10000], train_Loss: 0.0011024270206689835,test_Loss:4.632083415985107, r2_store:0.325743878518885\n",
            "torch.Size([80, 42])\n",
            "Epoch [9135/10000], train_Loss: 0.0010303808376193047,test_Loss:4.590283393859863, r2_store:0.32767712986153863\n",
            "torch.Size([80, 42])\n",
            "Epoch [9136/10000], train_Loss: 0.0001230528869200498,test_Loss:4.513974189758301, r2_store:0.3306459940676567\n",
            "torch.Size([80, 42])\n",
            "Epoch [9137/10000], train_Loss: 0.001143567031249404,test_Loss:4.60526180267334, r2_store:0.32729811700348466\n",
            "torch.Size([80, 42])\n",
            "Epoch [9138/10000], train_Loss: 0.00033492041984573007,test_Loss:4.604090690612793, r2_store:0.3277543225544862\n",
            "torch.Size([80, 42])\n",
            "Epoch [9139/10000], train_Loss: 0.0003835742245428264,test_Loss:4.515839576721191, r2_store:0.331723781159585\n",
            "torch.Size([80, 42])\n",
            "Epoch [9140/10000], train_Loss: 0.000777774432208389,test_Loss:4.577334880828857, r2_store:0.3296642216689767\n",
            "torch.Size([80, 42])\n",
            "Epoch [9141/10000], train_Loss: 5.0183247367385775e-05,test_Loss:4.615447521209717, r2_store:0.32791424433555527\n",
            "torch.Size([80, 42])\n",
            "Epoch [9142/10000], train_Loss: 0.000551337085198611,test_Loss:4.529468059539795, r2_store:0.3306124118931233\n",
            "torch.Size([80, 42])\n",
            "Epoch [9143/10000], train_Loss: 0.0003852943191304803,test_Loss:4.548619270324707, r2_store:0.3294359186648017\n",
            "torch.Size([80, 42])\n",
            "Epoch [9144/10000], train_Loss: 9.405364107806236e-05,test_Loss:4.6090006828308105, r2_store:0.32705271954452975\n",
            "torch.Size([80, 42])\n",
            "Epoch [9145/10000], train_Loss: 0.0004938492784276605,test_Loss:4.552369117736816, r2_store:0.3294931804386866\n",
            "torch.Size([80, 42])\n",
            "Epoch [9146/10000], train_Loss: 9.933201363310218e-05,test_Loss:4.546579837799072, r2_store:0.32992620395370087\n",
            "torch.Size([80, 42])\n",
            "Epoch [9147/10000], train_Loss: 0.000208246085094288,test_Loss:4.609353065490723, r2_store:0.32755152736463733\n",
            "torch.Size([80, 42])\n",
            "Epoch [9148/10000], train_Loss: 0.0003209887072443962,test_Loss:4.574629783630371, r2_store:0.328897885043523\n",
            "torch.Size([80, 42])\n",
            "Epoch [9149/10000], train_Loss: 2.553640297264792e-05,test_Loss:4.545575141906738, r2_store:0.3301027624767312\n",
            "torch.Size([80, 42])\n",
            "Epoch [9150/10000], train_Loss: 0.00025424599880352616,test_Loss:4.5992865562438965, r2_store:0.3282104767469177\n",
            "torch.Size([80, 42])\n",
            "Epoch [9151/10000], train_Loss: 0.00013642251724377275,test_Loss:4.587998867034912, r2_store:0.3287835347387499\n",
            "torch.Size([80, 42])\n",
            "Epoch [9152/10000], train_Loss: 4.786535646417178e-05,test_Loss:4.546006202697754, r2_store:0.3303807541184607\n",
            "torch.Size([80, 42])\n",
            "Epoch [9153/10000], train_Loss: 0.0002175412664655596,test_Loss:4.582700252532959, r2_store:0.32890060405665245\n",
            "torch.Size([80, 42])\n",
            "Epoch [9154/10000], train_Loss: 3.999975524493493e-05,test_Loss:4.59250545501709, r2_store:0.32840915041193264\n",
            "torch.Size([80, 42])\n",
            "Epoch [9155/10000], train_Loss: 0.00010032546560978517,test_Loss:4.552465915679932, r2_store:0.3298729615240683\n",
            "torch.Size([80, 42])\n",
            "Epoch [9156/10000], train_Loss: 0.00013425729412119836,test_Loss:4.574423789978027, r2_store:0.329072184808492\n",
            "torch.Size([80, 42])\n",
            "Epoch [9157/10000], train_Loss: 7.83466202847194e-06,test_Loss:4.596155166625977, r2_store:0.32834447928268495\n",
            "torch.Size([80, 42])\n",
            "Epoch [9158/10000], train_Loss: 0.00011583136802073568,test_Loss:4.560561656951904, r2_store:0.3298054095968903\n",
            "torch.Size([80, 42])\n",
            "Epoch [9159/10000], train_Loss: 5.957078610663302e-05,test_Loss:4.565743446350098, r2_store:0.32966536678718483\n",
            "torch.Size([80, 42])\n",
            "Epoch [9160/10000], train_Loss: 2.7732152375392616e-05,test_Loss:4.593404293060303, r2_store:0.32855810332837987\n",
            "torch.Size([80, 42])\n",
            "Epoch [9161/10000], train_Loss: 9.59416211117059e-05,test_Loss:4.567383289337158, r2_store:0.3294348247900173\n",
            "torch.Size([80, 42])\n",
            "Epoch [9162/10000], train_Loss: 1.2957434591953643e-05,test_Loss:4.559091567993164, r2_store:0.32965298193153636\n",
            "torch.Size([80, 42])\n",
            "Epoch [9163/10000], train_Loss: 4.516512490226887e-05,test_Loss:4.585916519165039, r2_store:0.32863237818060576\n",
            "torch.Size([80, 42])\n",
            "Epoch [9164/10000], train_Loss: 5.791499279439449e-05,test_Loss:4.572635173797607, r2_store:0.3292204076589288\n",
            "torch.Size([80, 42])\n",
            "Epoch [9165/10000], train_Loss: 5.587626674241619e-06,test_Loss:4.558062553405762, r2_store:0.329827505675218\n",
            "torch.Size([80, 42])\n",
            "Epoch [9166/10000], train_Loss: 5.2163086365908384e-05,test_Loss:4.58070707321167, r2_store:0.3289602940966869\n",
            "torch.Size([80, 42])\n",
            "Epoch [9167/10000], train_Loss: 2.305425914528314e-05,test_Loss:4.577343463897705, r2_store:0.3290452011695051\n",
            "torch.Size([80, 42])\n",
            "Epoch [9168/10000], train_Loss: 1.1216273378522601e-05,test_Loss:4.559469699859619, r2_store:0.3297176808354847\n",
            "torch.Size([80, 42])\n",
            "Epoch [9169/10000], train_Loss: 4.150134918745607e-05,test_Loss:4.576757907867432, r2_store:0.3291294307612328\n",
            "torch.Size([80, 42])\n",
            "Epoch [9170/10000], train_Loss: 6.344084340526024e-06,test_Loss:4.5827956199646, r2_store:0.3289496443860439\n",
            "torch.Size([80, 42])\n",
            "Epoch [9171/10000], train_Loss: 2.107838008669205e-05,test_Loss:4.564790725708008, r2_store:0.3296063584750306\n",
            "torch.Size([80, 42])\n",
            "Epoch [9172/10000], train_Loss: 2.463654709572438e-05,test_Loss:4.572851181030273, r2_store:0.32923237638696623\n",
            "torch.Size([80, 42])\n",
            "Epoch [9173/10000], train_Loss: 1.7204574760398827e-06,test_Loss:4.58232307434082, r2_store:0.32882592513979403\n",
            "torch.Size([80, 42])\n",
            "Epoch [9174/10000], train_Loss: 2.2583004465559497e-05,test_Loss:4.567525386810303, r2_store:0.3294148502274896\n",
            "torch.Size([80, 42])\n",
            "Epoch [9175/10000], train_Loss: 1.0919129636022262e-05,test_Loss:4.570621967315674, r2_store:0.32937844854876985\n",
            "torch.Size([80, 42])\n",
            "Epoch [9176/10000], train_Loss: 5.375627097237157e-06,test_Loss:4.583165168762207, r2_store:0.3289701186914452\n",
            "torch.Size([80, 42])\n",
            "Epoch [9177/10000], train_Loss: 1.8321054085390642e-05,test_Loss:4.572256088256836, r2_store:0.32939317819542957\n",
            "torch.Size([80, 42])\n",
            "Epoch [9178/10000], train_Loss: 3.0797586987318937e-06,test_Loss:4.5694780349731445, r2_store:0.329473384150905\n",
            "torch.Size([80, 42])\n",
            "Epoch [9179/10000], train_Loss: 8.478818017465528e-06,test_Loss:4.581416130065918, r2_store:0.32899690676707627\n",
            "torch.Size([80, 42])\n",
            "Epoch [9180/10000], train_Loss: 1.1370305401214864e-05,test_Loss:4.575101852416992, r2_store:0.32921916334279133\n",
            "torch.Size([80, 42])\n",
            "Epoch [9181/10000], train_Loss: 1.2404772178342682e-06,test_Loss:4.568938255310059, r2_store:0.3294337367220962\n",
            "torch.Size([80, 42])\n",
            "Epoch [9182/10000], train_Loss: 9.542850420984905e-06,test_Loss:4.578627109527588, r2_store:0.32904581367799135\n",
            "torch.Size([80, 42])\n",
            "Epoch [9183/10000], train_Loss: 5.456227427202975e-06,test_Loss:4.575996398925781, r2_store:0.3291217272198683\n",
            "torch.Size([80, 42])\n",
            "Epoch [9184/10000], train_Loss: 1.9031491547139012e-06,test_Loss:4.568265914916992, r2_store:0.32939843417307946\n",
            "torch.Size([80, 42])\n",
            "Epoch [9185/10000], train_Loss: 7.931213986012153e-06,test_Loss:4.5756120681762695, r2_store:0.32912815128524553\n",
            "torch.Size([80, 42])\n",
            "Epoch [9186/10000], train_Loss: 1.9871138192684157e-06,test_Loss:4.576366424560547, r2_store:0.32912555129936605\n",
            "torch.Size([80, 42])\n",
            "Epoch [9187/10000], train_Loss: 3.333654149173526e-06,test_Loss:4.56861686706543, r2_store:0.3294573251934575\n",
            "torch.Size([80, 42])\n",
            "Epoch [9188/10000], train_Loss: 5.4804390856588725e-06,test_Loss:4.57363224029541, r2_store:0.3293100031231422\n",
            "torch.Size([80, 42])\n",
            "Epoch [9189/10000], train_Loss: 6.548936539729766e-07,test_Loss:4.5772809982299805, r2_store:0.32919176333942013\n",
            "torch.Size([80, 42])\n",
            "Epoch [9190/10000], train_Loss: 3.809832605838892e-06,test_Loss:4.570727348327637, r2_store:0.32942528479765976\n",
            "torch.Size([80, 42])\n",
            "Epoch [9191/10000], train_Loss: 2.9924162845418323e-06,test_Loss:4.572867393493652, r2_store:0.32931430260645955\n",
            "torch.Size([80, 42])\n",
            "Epoch [9192/10000], train_Loss: 7.520627605117625e-07,test_Loss:4.577070236206055, r2_store:0.32913413114080026\n",
            "torch.Size([80, 42])\n",
            "Epoch [9193/10000], train_Loss: 3.5878431390301557e-06,test_Loss:4.571595191955566, r2_store:0.32934252464405644\n",
            "torch.Size([80, 42])\n",
            "Epoch [9194/10000], train_Loss: 1.3065678103885148e-06,test_Loss:4.571764945983887, r2_store:0.32934940089852505\n",
            "torch.Size([80, 42])\n",
            "Epoch [9195/10000], train_Loss: 1.141437905971543e-06,test_Loss:4.576544284820557, r2_store:0.3291729162610688\n",
            "torch.Size([80, 42])\n",
            "Epoch [9196/10000], train_Loss: 2.654179752425989e-06,test_Loss:4.5726823806762695, r2_store:0.32930578689581247\n",
            "torch.Size([80, 42])\n",
            "Epoch [9197/10000], train_Loss: 5.253729113974259e-07,test_Loss:4.571169853210449, r2_store:0.3293524417351541\n",
            "torch.Size([80, 42])\n",
            "Epoch [9198/10000], train_Loss: 1.5447789110112353e-06,test_Loss:4.575728416442871, r2_store:0.3291909331543409\n",
            "torch.Size([80, 42])\n",
            "Epoch [9199/10000], train_Loss: 1.6803782045826665e-06,test_Loss:4.573828220367432, r2_store:0.3292882161189312\n",
            "torch.Size([80, 42])\n",
            "Epoch [9200/10000], train_Loss: 3.1556928092868475e-07,test_Loss:4.57166051864624, r2_store:0.3293911019097775\n",
            "torch.Size([80, 42])\n",
            "Epoch [9201/10000], train_Loss: 1.5176965462160297e-06,test_Loss:4.575449466705322, r2_store:0.32925148670600224\n",
            "torch.Size([80, 42])\n",
            "Epoch [9202/10000], train_Loss: 9.064768278221891e-07,test_Loss:4.574638843536377, r2_store:0.32926985192138647\n",
            "torch.Size([80, 42])\n",
            "Epoch [9203/10000], train_Loss: 4.5553503014161834e-07,test_Loss:4.571897983551025, r2_store:0.32936065314723295\n",
            "torch.Size([80, 42])\n",
            "Epoch [9204/10000], train_Loss: 1.2776554285665043e-06,test_Loss:4.5748610496521, r2_store:0.3292456685453513\n",
            "torch.Size([80, 42])\n",
            "Epoch [9205/10000], train_Loss: 4.410736949012062e-07,test_Loss:4.575173377990723, r2_store:0.3292343125424734\n",
            "torch.Size([80, 42])\n",
            "Epoch [9206/10000], train_Loss: 5.750671334681101e-07,test_Loss:4.572278022766113, r2_store:0.3293405604523808\n",
            "torch.Size([80, 42])\n",
            "Epoch [9207/10000], train_Loss: 9.235610605173861e-07,test_Loss:4.574075222015381, r2_store:0.3292672888489695\n",
            "torch.Size([80, 42])\n",
            "Epoch [9208/10000], train_Loss: 2.6582193868307513e-07,test_Loss:4.575054168701172, r2_store:0.32922676188558164\n",
            "torch.Size([80, 42])\n",
            "Epoch [9209/10000], train_Loss: 6.402302688002237e-07,test_Loss:4.572580337524414, r2_store:0.3293230024359717\n",
            "torch.Size([80, 42])\n",
            "Epoch [9210/10000], train_Loss: 6.023282139722141e-07,test_Loss:4.573714733123779, r2_store:0.32929111253440135\n",
            "torch.Size([80, 42])\n",
            "Epoch [9211/10000], train_Loss: 2.1508408565296122e-07,test_Loss:4.575186729431152, r2_store:0.3292501957141687\n",
            "torch.Size([80, 42])\n",
            "Epoch [9212/10000], train_Loss: 5.886825533707452e-07,test_Loss:4.573110103607178, r2_store:0.32934092706225515\n",
            "torch.Size([80, 42])\n",
            "Epoch [9213/10000], train_Loss: 3.705556537170196e-07,test_Loss:4.57349157333374, r2_store:0.329332744710377\n",
            "torch.Size([80, 42])\n",
            "Epoch [9214/10000], train_Loss: 2.4830245592966094e-07,test_Loss:4.575116157531738, r2_store:0.3292687595394762\n",
            "torch.Size([80, 42])\n",
            "Epoch [9215/10000], train_Loss: 4.962950583831116e-07,test_Loss:4.573505401611328, r2_store:0.32931963227699823\n",
            "torch.Size([80, 42])\n",
            "Epoch [9216/10000], train_Loss: 2.2502779017941066e-07,test_Loss:4.573278903961182, r2_store:0.3293186246996366\n",
            "torch.Size([80, 42])\n",
            "Epoch [9217/10000], train_Loss: 2.671636138984468e-07,test_Loss:4.574858665466309, r2_store:0.32925565971799153\n",
            "torch.Size([80, 42])\n",
            "Epoch [9218/10000], train_Loss: 3.767411271837773e-07,test_Loss:4.573822975158691, r2_store:0.32929700556680863\n",
            "torch.Size([80, 42])\n",
            "Epoch [9219/10000], train_Loss: 1.6559421567308164e-07,test_Loss:4.573296546936035, r2_store:0.32932103727686846\n",
            "torch.Size([80, 42])\n",
            "Epoch [9220/10000], train_Loss: 2.802193534989783e-07,test_Loss:4.5746941566467285, r2_store:0.32927152863886944\n",
            "torch.Size([80, 42])\n",
            "Epoch [9221/10000], train_Loss: 2.677004999895871e-07,test_Loss:4.574016571044922, r2_store:0.32930038680660334\n",
            "torch.Size([80, 42])\n",
            "Epoch [9222/10000], train_Loss: 1.3795212794320832e-07,test_Loss:4.573239326477051, r2_store:0.3293353990556682\n",
            "torch.Size([80, 42])\n",
            "Epoch [9223/10000], train_Loss: 2.55787654168671e-07,test_Loss:4.574486255645752, r2_store:0.32929519508933436\n",
            "torch.Size([80, 42])\n",
            "Epoch [9224/10000], train_Loss: 1.910627531742648e-07,test_Loss:4.574284076690674, r2_store:0.3293050581044271\n",
            "torch.Size([80, 42])\n",
            "Epoch [9225/10000], train_Loss: 1.4258687031087902e-07,test_Loss:4.57341194152832, r2_store:0.3293325080778312\n",
            "torch.Size([80, 42])\n",
            "Epoch [9226/10000], train_Loss: 2.199832636051724e-07,test_Loss:4.574288368225098, r2_store:0.32929015823689967\n",
            "torch.Size([80, 42])\n",
            "Epoch [9227/10000], train_Loss: 1.3722475955546543e-07,test_Loss:4.574288368225098, r2_store:0.3292832699443322\n",
            "torch.Size([80, 42])\n",
            "Epoch [9228/10000], train_Loss: 1.396786757368318e-07,test_Loss:4.5734477043151855, r2_store:0.3293143770566149\n",
            "torch.Size([80, 42])\n",
            "Epoch [9229/10000], train_Loss: 1.7990763012676325e-07,test_Loss:4.574152946472168, r2_store:0.3292921445589103\n",
            "torch.Size([80, 42])\n",
            "Epoch [9230/10000], train_Loss: 1.124383857131761e-07,test_Loss:4.574412822723389, r2_store:0.3292875043508333\n",
            "torch.Size([80, 42])\n",
            "Epoch [9231/10000], train_Loss: 1.364718400509446e-07,test_Loss:4.573634147644043, r2_store:0.3293205864816854\n",
            "torch.Size([80, 42])\n",
            "Epoch [9232/10000], train_Loss: 1.4201086173670774e-07,test_Loss:4.574079513549805, r2_store:0.3293070369113362\n",
            "torch.Size([80, 42])\n",
            "Epoch [9233/10000], train_Loss: 9.529487243753465e-08,test_Loss:4.574466705322266, r2_store:0.3292958841889114\n",
            "torch.Size([80, 42])\n",
            "Epoch [9234/10000], train_Loss: 1.265654816506867e-07,test_Loss:4.573807716369629, r2_store:0.3293235038230222\n",
            "torch.Size([80, 42])\n",
            "Epoch [9235/10000], train_Loss: 1.147302768345071e-07,test_Loss:4.574039936065674, r2_store:0.32931536000848727\n",
            "torch.Size([80, 42])\n",
            "Epoch [9236/10000], train_Loss: 8.868043721577124e-08,test_Loss:4.5744524002075195, r2_store:0.329297881766327\n",
            "torch.Size([80, 42])\n",
            "Epoch [9237/10000], train_Loss: 1.1329650817515358e-07,test_Loss:4.573894023895264, r2_store:0.32931552029961497\n",
            "torch.Size([80, 42])\n",
            "Epoch [9238/10000], train_Loss: 9.192132921498342e-08,test_Loss:4.573977947235107, r2_store:0.32930918872222026\n",
            "torch.Size([80, 42])\n",
            "Epoch [9239/10000], train_Loss: 8.291859643350108e-08,test_Loss:4.5744218826293945, r2_store:0.3292909771917929\n",
            "torch.Size([80, 42])\n",
            "Epoch [9240/10000], train_Loss: 1.0002290906641065e-07,test_Loss:4.5739850997924805, r2_store:0.3293087799794465\n",
            "torch.Size([80, 42])\n",
            "Epoch [9241/10000], train_Loss: 7.89452414551306e-08,test_Loss:4.573955059051514, r2_store:0.3293135613186351\n",
            "torch.Size([80, 42])\n",
            "Epoch [9242/10000], train_Loss: 7.935294377148239e-08,test_Loss:4.574408054351807, r2_store:0.32930110602516915\n",
            "torch.Size([80, 42])\n",
            "Epoch [9243/10000], train_Loss: 8.602278711578037e-08,test_Loss:4.574121475219727, r2_store:0.32931551680891247\n",
            "torch.Size([80, 42])\n",
            "Epoch [9244/10000], train_Loss: 6.82104968063868e-08,test_Loss:4.574030876159668, r2_store:0.32932055871864363\n",
            "torch.Size([80, 42])\n",
            "Epoch [9245/10000], train_Loss: 7.337543905805433e-08,test_Loss:4.57442045211792, r2_store:0.3293063850388678\n",
            "torch.Size([80, 42])\n",
            "Epoch [9246/10000], train_Loss: 7.422531922429698e-08,test_Loss:4.574209690093994, r2_store:0.3293151060541548\n",
            "torch.Size([80, 42])\n",
            "Epoch [9247/10000], train_Loss: 6.196544433123563e-08,test_Loss:4.574060440063477, r2_store:0.3293215276685263\n",
            "torch.Size([80, 42])\n",
            "Epoch [9248/10000], train_Loss: 6.72444713245568e-08,test_Loss:4.574401378631592, r2_store:0.32930876159809597\n",
            "torch.Size([80, 42])\n",
            "Epoch [9249/10000], train_Loss: 6.404324182085475e-08,test_Loss:4.574270248413086, r2_store:0.32931245520908325\n",
            "torch.Size([80, 42])\n",
            "Epoch [9250/10000], train_Loss: 5.656482215954384e-08,test_Loss:4.57407808303833, r2_store:0.32931783027405526\n",
            "torch.Size([80, 42])\n",
            "Epoch [9251/10000], train_Loss: 6.131666907549516e-08,test_Loss:4.5743560791015625, r2_store:0.3293068797947809\n",
            "torch.Size([80, 42])\n",
            "Epoch [9252/10000], train_Loss: 5.663569169200855e-08,test_Loss:4.574309349060059, r2_store:0.32931051118897736\n",
            "torch.Size([80, 42])\n",
            "Epoch [9253/10000], train_Loss: 5.216465837065698e-08,test_Loss:4.574134349822998, r2_store:0.3293199356664098\n",
            "torch.Size([80, 42])\n",
            "Epoch [9254/10000], train_Loss: 5.5241478946754796e-08,test_Loss:4.574371337890625, r2_store:0.32931294176382964\n",
            "torch.Size([80, 42])\n",
            "Epoch [9255/10000], train_Loss: 5.0231811599132925e-08,test_Loss:4.574347019195557, r2_store:0.3293145349700991\n",
            "torch.Size([80, 42])\n",
            "Epoch [9256/10000], train_Loss: 4.8174342737183906e-08,test_Loss:4.5741496086120605, r2_store:0.329321718356694\n",
            "torch.Size([80, 42])\n",
            "Epoch [9257/10000], train_Loss: 4.9781515798486e-08,test_Loss:4.574326515197754, r2_store:0.3293151853239813\n",
            "torch.Size([80, 42])\n",
            "Epoch [9258/10000], train_Loss: 4.499676009572795e-08,test_Loss:4.574353218078613, r2_store:0.3293148766774684\n",
            "torch.Size([80, 42])\n",
            "Epoch [9259/10000], train_Loss: 4.427780453397645e-08,test_Loss:4.574179172515869, r2_store:0.32932221773272785\n",
            "torch.Size([80, 42])\n",
            "Epoch [9260/10000], train_Loss: 4.464684266736185e-08,test_Loss:4.574309349060059, r2_store:0.3293172974282521\n",
            "torch.Size([80, 42])\n",
            "Epoch [9261/10000], train_Loss: 4.0940797418898e-08,test_Loss:4.5743584632873535, r2_store:0.32931516452166176\n",
            "torch.Size([80, 42])\n",
            "Epoch [9262/10000], train_Loss: 4.094292904710528e-08,test_Loss:4.574202537536621, r2_store:0.3293210327977474\n",
            "torch.Size([80, 42])\n",
            "Epoch [9263/10000], train_Loss: 4.028818167967074e-08,test_Loss:4.574305534362793, r2_store:0.3293176530249692\n",
            "torch.Size([80, 42])\n",
            "Epoch [9264/10000], train_Loss: 3.726082198340919e-08,test_Loss:4.574377536773682, r2_store:0.329315846531707\n",
            "torch.Size([80, 42])\n",
            "Epoch [9265/10000], train_Loss: 3.747267740550342e-08,test_Loss:4.574244499206543, r2_store:0.32932179728271094\n",
            "torch.Size([80, 42])\n",
            "Epoch [9266/10000], train_Loss: 3.6280287218914964e-08,test_Loss:4.574310779571533, r2_store:0.3293198574326741\n",
            "torch.Size([80, 42])\n",
            "Epoch [9267/10000], train_Loss: 3.413063254242843e-08,test_Loss:4.574379920959473, r2_store:0.32931755995742684\n",
            "torch.Size([80, 42])\n",
            "Epoch [9268/10000], train_Loss: 3.4128397885524464e-08,test_Loss:4.574261665344238, r2_store:0.3293224730367261\n",
            "torch.Size([80, 42])\n",
            "Epoch [9269/10000], train_Loss: 3.2753153078601827e-08,test_Loss:4.574301242828369, r2_store:0.3293212891794658\n",
            "torch.Size([80, 42])\n",
            "Epoch [9270/10000], train_Loss: 3.1219933305237646e-08,test_Loss:4.574372291564941, r2_store:0.3293192304621706\n",
            "torch.Size([80, 42])\n",
            "Epoch [9271/10000], train_Loss: 3.113817115263373e-08,test_Loss:4.574277877807617, r2_store:0.329323158391296\n",
            "torch.Size([80, 42])\n",
            "Epoch [9272/10000], train_Loss: 2.987024316780662e-08,test_Loss:4.574306488037109, r2_store:0.32932206366077754\n",
            "torch.Size([80, 42])\n",
            "Epoch [9273/10000], train_Loss: 2.8718488920276286e-08,test_Loss:4.57437801361084, r2_store:0.329318898644947\n",
            "torch.Size([80, 42])\n",
            "Epoch [9274/10000], train_Loss: 2.8635232851570436e-08,test_Loss:4.574298858642578, r2_store:0.3293216767505289\n",
            "torch.Size([80, 42])\n",
            "Epoch [9275/10000], train_Loss: 2.7400892221862705e-08,test_Loss:4.574317932128906, r2_store:0.3293211369819129\n",
            "torch.Size([80, 42])\n",
            "Epoch [9276/10000], train_Loss: 2.6453928825276307e-08,test_Loss:4.574393272399902, r2_store:0.32931872838933585\n",
            "torch.Size([80, 42])\n",
            "Epoch [9277/10000], train_Loss: 2.611567673227455e-08,test_Loss:4.5743327140808105, r2_store:0.32932104623230385\n",
            "torch.Size([80, 42])\n",
            "Epoch [9278/10000], train_Loss: 2.4991891223180573e-08,test_Loss:4.574341773986816, r2_store:0.3293203837603216\n",
            "torch.Size([80, 42])\n",
            "Epoch [9279/10000], train_Loss: 2.42490418855823e-08,test_Loss:4.574408054351807, r2_store:0.3293170507843116\n",
            "torch.Size([80, 42])\n",
            "Epoch [9280/10000], train_Loss: 2.3786986602658544e-08,test_Loss:4.57435941696167, r2_store:0.32931833966818935\n",
            "torch.Size([80, 42])\n",
            "Epoch [9281/10000], train_Loss: 2.2805163979455756e-08,test_Loss:4.574358940124512, r2_store:0.32931815222367244\n",
            "torch.Size([80, 42])\n",
            "Epoch [9282/10000], train_Loss: 2.2267219179639142e-08,test_Loss:4.574414253234863, r2_store:0.32931589757522084\n",
            "torch.Size([80, 42])\n",
            "Epoch [9283/10000], train_Loss: 2.180022917741553e-08,test_Loss:4.574377059936523, r2_store:0.329317250637172\n",
            "torch.Size([80, 42])\n",
            "Epoch [9284/10000], train_Loss: 2.0974749048718877e-08,test_Loss:4.57436990737915, r2_store:0.32931749444785763\n",
            "torch.Size([80, 42])\n",
            "Epoch [9285/10000], train_Loss: 2.044934355183159e-08,test_Loss:4.574418067932129, r2_store:0.3293155831995308\n",
            "torch.Size([80, 42])\n",
            "Epoch [9286/10000], train_Loss: 1.991138098844658e-08,test_Loss:4.5743937492370605, r2_store:0.32931648732053187\n",
            "torch.Size([80, 42])\n",
            "Epoch [9287/10000], train_Loss: 1.9238939330534777e-08,test_Loss:4.574379920959473, r2_store:0.3293171189889662\n",
            "torch.Size([80, 42])\n",
            "Epoch [9288/10000], train_Loss: 1.8793254952242933e-08,test_Loss:4.57442569732666, r2_store:0.3293154425821875\n",
            "torch.Size([80, 42])\n",
            "Epoch [9289/10000], train_Loss: 1.825474349459455e-08,test_Loss:4.574404239654541, r2_store:0.3293162714003195\n",
            "torch.Size([80, 42])\n",
            "Epoch [9290/10000], train_Loss: 1.7615054304087607e-08,test_Loss:4.574387073516846, r2_store:0.32931704125241634\n",
            "torch.Size([80, 42])\n",
            "Epoch [9291/10000], train_Loss: 1.7242115291082882e-08,test_Loss:4.574433326721191, r2_store:0.3293153269268123\n",
            "torch.Size([80, 42])\n",
            "Epoch [9292/10000], train_Loss: 1.6758257004312327e-08,test_Loss:4.574416160583496, r2_store:0.3293160483089993\n",
            "torch.Size([80, 42])\n",
            "Epoch [9293/10000], train_Loss: 1.6187332363415408e-08,test_Loss:4.574399471282959, r2_store:0.32931654797234144\n",
            "torch.Size([80, 42])\n",
            "Epoch [9294/10000], train_Loss: 1.5792654295410102e-08,test_Loss:4.57443904876709, r2_store:0.3293152268941447\n",
            "torch.Size([80, 42])\n",
            "Epoch [9295/10000], train_Loss: 1.5322964230790603e-08,test_Loss:4.574431896209717, r2_store:0.3293155030820504\n",
            "torch.Size([80, 42])\n",
            "Epoch [9296/10000], train_Loss: 1.4820241922564037e-08,test_Loss:4.5744171142578125, r2_store:0.3293160630244022\n",
            "torch.Size([80, 42])\n",
            "Epoch [9297/10000], train_Loss: 1.449176778578476e-08,test_Loss:4.574446678161621, r2_store:0.3293146432843378\n",
            "torch.Size([80, 42])\n",
            "Epoch [9298/10000], train_Loss: 1.4056531938422268e-08,test_Loss:4.574441432952881, r2_store:0.3293146950257083\n",
            "torch.Size([80, 42])\n",
            "Epoch [9299/10000], train_Loss: 1.36450974963509e-08,test_Loss:4.5744242668151855, r2_store:0.32931527576039554\n",
            "torch.Size([80, 42])\n",
            "Epoch [9300/10000], train_Loss: 1.3304550350312638e-08,test_Loss:4.5744547843933105, r2_store:0.3293141826592063\n",
            "torch.Size([80, 42])\n",
            "Epoch [9301/10000], train_Loss: 1.2904062707264075e-08,test_Loss:4.57444953918457, r2_store:0.3293141293602938\n",
            "torch.Size([80, 42])\n",
            "Epoch [9302/10000], train_Loss: 1.2533472038001037e-08,test_Loss:4.574439525604248, r2_store:0.3293143739272265\n",
            "torch.Size([80, 42])\n",
            "Epoch [9303/10000], train_Loss: 1.2190033871206651e-08,test_Loss:4.574461460113525, r2_store:0.3293134770315266\n",
            "torch.Size([80, 42])\n",
            "Epoch [9304/10000], train_Loss: 1.1809600408696497e-08,test_Loss:4.57445764541626, r2_store:0.32931355151646313\n",
            "torch.Size([80, 42])\n",
            "Epoch [9305/10000], train_Loss: 1.146486283687409e-08,test_Loss:4.5744524002075195, r2_store:0.32931379512682624\n",
            "torch.Size([80, 42])\n",
            "Epoch [9306/10000], train_Loss: 1.1184908110806191e-08,test_Loss:4.574470043182373, r2_store:0.32931315821610607\n",
            "torch.Size([80, 42])\n",
            "Epoch [9307/10000], train_Loss: 1.0864910748864531e-08,test_Loss:4.574467658996582, r2_store:0.3293133979487408\n",
            "torch.Size([80, 42])\n",
            "Epoch [9308/10000], train_Loss: 1.0514829007490789e-08,test_Loss:4.574465751647949, r2_store:0.32931347043287484\n",
            "torch.Size([80, 42])\n",
            "Epoch [9309/10000], train_Loss: 1.0230209568362625e-08,test_Loss:4.574477195739746, r2_store:0.3293128299076665\n",
            "torch.Size([80, 42])\n",
            "Epoch [9310/10000], train_Loss: 9.937838996165738e-09,test_Loss:4.57447624206543, r2_store:0.329312791486564\n",
            "torch.Size([80, 42])\n",
            "Epoch [9311/10000], train_Loss: 9.640917397746307e-09,test_Loss:4.5744733810424805, r2_store:0.3293125875321046\n",
            "torch.Size([80, 42])\n",
            "Epoch [9312/10000], train_Loss: 9.38210487078095e-09,test_Loss:4.574484348297119, r2_store:0.3293121267596897\n",
            "torch.Size([80, 42])\n",
            "Epoch [9313/10000], train_Loss: 9.108939380553238e-09,test_Loss:4.5744829177856445, r2_store:0.329312102302308\n",
            "torch.Size([80, 42])\n",
            "Epoch [9314/10000], train_Loss: 8.846297916420554e-09,test_Loss:4.57448148727417, r2_store:0.32931214703248857\n",
            "torch.Size([80, 42])\n",
            "Epoch [9315/10000], train_Loss: 8.609793766822804e-09,test_Loss:4.574490070343018, r2_store:0.32931180406944305\n",
            "torch.Size([80, 42])\n",
            "Epoch [9316/10000], train_Loss: 8.344374080593298e-09,test_Loss:4.574492454528809, r2_store:0.3293118516831365\n",
            "torch.Size([80, 42])\n",
            "Epoch [9317/10000], train_Loss: 8.109240390297145e-09,test_Loss:4.574487686157227, r2_store:0.32931201466223814\n",
            "torch.Size([80, 42])\n",
            "Epoch [9318/10000], train_Loss: 7.886027830750209e-09,test_Loss:4.574497222900391, r2_store:0.3293115818071515\n",
            "torch.Size([80, 42])\n",
            "Epoch [9319/10000], train_Loss: 7.687262382205517e-09,test_Loss:4.574501037597656, r2_store:0.329311479802306\n",
            "torch.Size([80, 42])\n",
            "Epoch [9320/10000], train_Loss: 7.44002992547621e-09,test_Loss:4.574495792388916, r2_store:0.32931157688007806\n",
            "torch.Size([80, 42])\n",
            "Epoch [9321/10000], train_Loss: 7.243686095392832e-09,test_Loss:4.5745038986206055, r2_store:0.32931124553219426\n",
            "torch.Size([80, 42])\n",
            "Epoch [9322/10000], train_Loss: 7.022872949846715e-09,test_Loss:4.574505805969238, r2_store:0.32931125123232363\n",
            "torch.Size([80, 42])\n",
            "Epoch [9323/10000], train_Loss: 6.836831545342648e-09,test_Loss:4.5745038986206055, r2_store:0.329311321204785\n",
            "torch.Size([80, 42])\n",
            "Epoch [9324/10000], train_Loss: 6.644182981574431e-09,test_Loss:4.574512481689453, r2_store:0.3293108665797493\n",
            "torch.Size([80, 42])\n",
            "Epoch [9325/10000], train_Loss: 6.442879119106237e-09,test_Loss:4.574512481689453, r2_store:0.3293106191430152\n",
            "torch.Size([80, 42])\n",
            "Epoch [9326/10000], train_Loss: 6.2489022845113595e-09,test_Loss:4.574510097503662, r2_store:0.3293106494893887\n",
            "torch.Size([80, 42])\n",
            "Epoch [9327/10000], train_Loss: 6.0633942311483224e-09,test_Loss:4.574519157409668, r2_store:0.32931030967304586\n",
            "torch.Size([80, 42])\n",
            "Epoch [9328/10000], train_Loss: 5.900663957447705e-09,test_Loss:4.574521064758301, r2_store:0.3293103302031357\n",
            "torch.Size([80, 42])\n",
            "Epoch [9329/10000], train_Loss: 5.730992569397131e-09,test_Loss:4.574520111083984, r2_store:0.32931037373550553\n",
            "torch.Size([80, 42])\n",
            "Epoch [9330/10000], train_Loss: 5.577990069838279e-09,test_Loss:4.574524879455566, r2_store:0.32931019012332086\n",
            "torch.Size([80, 42])\n",
            "Epoch [9331/10000], train_Loss: 5.419122039995727e-09,test_Loss:4.574525833129883, r2_store:0.32931004645327144\n",
            "torch.Size([80, 42])\n",
            "Epoch [9332/10000], train_Loss: 5.23796916951369e-09,test_Loss:4.574525833129883, r2_store:0.3293099700113965\n",
            "torch.Size([80, 42])\n",
            "Epoch [9333/10000], train_Loss: 5.087877674725405e-09,test_Loss:4.574526786804199, r2_store:0.3293098530369455\n",
            "torch.Size([80, 42])\n",
            "Epoch [9334/10000], train_Loss: 4.958138344335339e-09,test_Loss:4.574527263641357, r2_store:0.3293098740472694\n",
            "torch.Size([80, 42])\n",
            "Epoch [9335/10000], train_Loss: 4.822713339791562e-09,test_Loss:4.574530601501465, r2_store:0.3293098777568326\n",
            "torch.Size([80, 42])\n",
            "Epoch [9336/10000], train_Loss: 4.675198006509618e-09,test_Loss:4.574533939361572, r2_store:0.3293096496802247\n",
            "torch.Size([80, 42])\n",
            "Epoch [9337/10000], train_Loss: 4.540722020607291e-09,test_Loss:4.57453727722168, r2_store:0.3293094896223261\n",
            "torch.Size([80, 42])\n",
            "Epoch [9338/10000], train_Loss: 4.405370734872349e-09,test_Loss:4.574535846710205, r2_store:0.32930934481460905\n",
            "torch.Size([80, 42])\n",
            "Epoch [9339/10000], train_Loss: 4.282623145002162e-09,test_Loss:4.5745391845703125, r2_store:0.3293091469584889\n",
            "torch.Size([80, 42])\n",
            "Epoch [9340/10000], train_Loss: 4.148143162296947e-09,test_Loss:4.574545860290527, r2_store:0.32930891007723284\n",
            "torch.Size([80, 42])\n",
            "Epoch [9341/10000], train_Loss: 4.0468757234179975e-09,test_Loss:4.574542045593262, r2_store:0.3293091576078333\n",
            "torch.Size([80, 42])\n",
            "Epoch [9342/10000], train_Loss: 3.925713532026975e-09,test_Loss:4.574544429779053, r2_store:0.32930906362958456\n",
            "torch.Size([80, 42])\n",
            "Epoch [9343/10000], train_Loss: 3.810755266897559e-09,test_Loss:4.574554920196533, r2_store:0.3293086592653762\n",
            "torch.Size([80, 42])\n",
            "Epoch [9344/10000], train_Loss: 3.709456519729315e-09,test_Loss:4.5745463371276855, r2_store:0.3293089934047231\n",
            "torch.Size([80, 42])\n",
            "Epoch [9345/10000], train_Loss: 3.5887020022329352e-09,test_Loss:4.574548721313477, r2_store:0.3293088070593875\n",
            "torch.Size([80, 42])\n",
            "Epoch [9346/10000], train_Loss: 3.485979949147122e-09,test_Loss:4.574558258056641, r2_store:0.3293084782075568\n",
            "torch.Size([80, 42])\n",
            "Epoch [9347/10000], train_Loss: 3.397336190147371e-09,test_Loss:4.574551105499268, r2_store:0.32930876234783524\n",
            "torch.Size([80, 42])\n",
            "Epoch [9348/10000], train_Loss: 3.290383743248526e-09,test_Loss:4.574553966522217, r2_store:0.3293083573731569\n",
            "torch.Size([80, 42])\n",
            "Epoch [9349/10000], train_Loss: 3.190562036792244e-09,test_Loss:4.574559688568115, r2_store:0.32930799552046486\n",
            "torch.Size([80, 42])\n",
            "Epoch [9350/10000], train_Loss: 3.113723057168727e-09,test_Loss:4.574556350708008, r2_store:0.3293082879487603\n",
            "torch.Size([80, 42])\n",
            "Epoch [9351/10000], train_Loss: 3.0072786483259506e-09,test_Loss:4.574559688568115, r2_store:0.3293082434968784\n",
            "torch.Size([80, 42])\n",
            "Epoch [9352/10000], train_Loss: 2.9241133958635146e-09,test_Loss:4.5745673179626465, r2_store:0.3293082089834436\n",
            "torch.Size([80, 42])\n",
            "Epoch [9353/10000], train_Loss: 2.845834456977059e-09,test_Loss:4.574563980102539, r2_store:0.32930849904359527\n",
            "torch.Size([80, 42])\n",
            "Epoch [9354/10000], train_Loss: 2.7569957428141834e-09,test_Loss:4.574564456939697, r2_store:0.32930854093497164\n",
            "torch.Size([80, 42])\n",
            "Epoch [9355/10000], train_Loss: 2.680481392403067e-09,test_Loss:4.574573993682861, r2_store:0.3293081797455112\n",
            "torch.Size([80, 42])\n",
            "Epoch [9356/10000], train_Loss: 2.607013049882312e-09,test_Loss:4.574568748474121, r2_store:0.3293083140099875\n",
            "torch.Size([80, 42])\n",
            "Epoch [9357/10000], train_Loss: 2.519516595356208e-09,test_Loss:4.574570655822754, r2_store:0.3293079416135455\n",
            "torch.Size([80, 42])\n",
            "Epoch [9358/10000], train_Loss: 2.4453097324794726e-09,test_Loss:4.574576377868652, r2_store:0.32930753976631155\n",
            "torch.Size([80, 42])\n",
            "Epoch [9359/10000], train_Loss: 2.3682138472480574e-09,test_Loss:4.5745744705200195, r2_store:0.32930761269134046\n",
            "torch.Size([80, 42])\n",
            "Epoch [9360/10000], train_Loss: 2.305796886759026e-09,test_Loss:4.574575901031494, r2_store:0.3293075918503139\n",
            "torch.Size([80, 42])\n",
            "Epoch [9361/10000], train_Loss: 2.232900309095953e-09,test_Loss:4.574582099914551, r2_store:0.32930734015329277\n",
            "torch.Size([80, 42])\n",
            "Epoch [9362/10000], train_Loss: 2.176454794167171e-09,test_Loss:4.574578762054443, r2_store:0.329307522748685\n",
            "torch.Size([80, 42])\n",
            "Epoch [9363/10000], train_Loss: 2.103442309220327e-09,test_Loss:4.574579238891602, r2_store:0.32930747909455327\n",
            "torch.Size([80, 42])\n",
            "Epoch [9364/10000], train_Loss: 2.0404153922015666e-09,test_Loss:4.574583053588867, r2_store:0.329307302312307\n",
            "torch.Size([80, 42])\n",
            "Epoch [9365/10000], train_Loss: 1.9836907672043935e-09,test_Loss:4.574582576751709, r2_store:0.32930733697846426\n",
            "torch.Size([80, 42])\n",
            "Epoch [9366/10000], train_Loss: 1.9241341853160066e-09,test_Loss:4.574583053588867, r2_store:0.32930741515482187\n",
            "torch.Size([80, 42])\n",
            "Epoch [9367/10000], train_Loss: 1.870971377826436e-09,test_Loss:4.574592113494873, r2_store:0.32930731026177307\n",
            "torch.Size([80, 42])\n",
            "Epoch [9368/10000], train_Loss: 1.8140904334273955e-09,test_Loss:4.574587821960449, r2_store:0.3293073659036101\n",
            "torch.Size([80, 42])\n",
            "Epoch [9369/10000], train_Loss: 1.7553147824145299e-09,test_Loss:4.574587345123291, r2_store:0.32930714200361744\n",
            "torch.Size([80, 42])\n",
            "Epoch [9370/10000], train_Loss: 1.7147840924991442e-09,test_Loss:4.574597358703613, r2_store:0.3293067851342275\n",
            "torch.Size([80, 42])\n",
            "Epoch [9371/10000], train_Loss: 1.6633437960322794e-09,test_Loss:4.574589729309082, r2_store:0.32930702516820154\n",
            "torch.Size([80, 42])\n",
            "Epoch [9372/10000], train_Loss: 1.6137275959948738e-09,test_Loss:4.5745954513549805, r2_store:0.32930672620252044\n",
            "torch.Size([80, 42])\n",
            "Epoch [9373/10000], train_Loss: 1.5506363970629877e-09,test_Loss:4.574601173400879, r2_store:0.32930646924704476\n",
            "torch.Size([80, 42])\n",
            "Epoch [9374/10000], train_Loss: 1.5191877755782457e-09,test_Loss:4.574594020843506, r2_store:0.3293068186385678\n",
            "torch.Size([80, 42])\n",
            "Epoch [9375/10000], train_Loss: 1.4742007614643171e-09,test_Loss:4.574599266052246, r2_store:0.32930674370274915\n",
            "torch.Size([80, 42])\n",
            "Epoch [9376/10000], train_Loss: 1.4274765813837575e-09,test_Loss:4.574606895446777, r2_store:0.3293065215941189\n",
            "torch.Size([80, 42])\n",
            "Epoch [9377/10000], train_Loss: 1.3846483959412126e-09,test_Loss:4.574597358703613, r2_store:0.3293070410065694\n",
            "torch.Size([80, 42])\n",
            "Epoch [9378/10000], train_Loss: 1.3347472016533857e-09,test_Loss:4.574602127075195, r2_store:0.3293068506194733\n",
            "torch.Size([80, 42])\n",
            "Epoch [9379/10000], train_Loss: 1.297139951006443e-09,test_Loss:4.574610710144043, r2_store:0.3293065207995397\n",
            "torch.Size([80, 42])\n",
            "Epoch [9380/10000], train_Loss: 1.269948701754231e-09,test_Loss:4.574599266052246, r2_store:0.3293068138053207\n",
            "torch.Size([80, 42])\n",
            "Epoch [9381/10000], train_Loss: 1.2395118265118299e-09,test_Loss:4.574605941772461, r2_store:0.3293065122930243\n",
            "torch.Size([80, 42])\n",
            "Epoch [9382/10000], train_Loss: 1.1766749796748854e-09,test_Loss:4.574614524841309, r2_store:0.32930621439871477\n",
            "torch.Size([80, 42])\n",
            "Epoch [9383/10000], train_Loss: 1.1591803072974471e-09,test_Loss:4.574601650238037, r2_store:0.3293066483020167\n",
            "torch.Size([80, 42])\n",
            "Epoch [9384/10000], train_Loss: 1.1251559683955747e-09,test_Loss:4.574611663818359, r2_store:0.3293063904710023\n",
            "torch.Size([80, 42])\n",
            "Epoch [9385/10000], train_Loss: 1.0847984732720306e-09,test_Loss:4.574615955352783, r2_store:0.32930628757532066\n",
            "torch.Size([80, 42])\n",
            "Epoch [9386/10000], train_Loss: 1.0596297173037783e-09,test_Loss:4.5746073722839355, r2_store:0.3293066154623939\n",
            "torch.Size([80, 42])\n",
            "Epoch [9387/10000], train_Loss: 1.028338969533138e-09,test_Loss:4.574618339538574, r2_store:0.32930622262248466\n",
            "torch.Size([80, 42])\n",
            "Epoch [9388/10000], train_Loss: 9.910765541576438e-10,test_Loss:4.574618339538574, r2_store:0.32930613163943945\n",
            "torch.Size([80, 42])\n",
            "Epoch [9389/10000], train_Loss: 9.637287634589597e-10,test_Loss:4.574611663818359, r2_store:0.3293064839858314\n",
            "torch.Size([80, 42])\n",
            "Epoch [9390/10000], train_Loss: 9.347934648573641e-10,test_Loss:4.574623107910156, r2_store:0.3293060081836132\n",
            "torch.Size([80, 42])\n",
            "Epoch [9391/10000], train_Loss: 9.07969421870547e-10,test_Loss:4.574619293212891, r2_store:0.32930619959575436\n",
            "torch.Size([80, 42])\n",
            "Epoch [9392/10000], train_Loss: 8.763116343679656e-10,test_Loss:4.574617862701416, r2_store:0.32930632486792866\n",
            "torch.Size([80, 42])\n",
            "Epoch [9393/10000], train_Loss: 8.516614080633644e-10,test_Loss:4.574625492095947, r2_store:0.3293059594885389\n",
            "torch.Size([80, 42])\n",
            "Epoch [9394/10000], train_Loss: 8.266192175199194e-10,test_Loss:4.57462215423584, r2_store:0.329306075501258\n",
            "torch.Size([80, 42])\n",
            "Epoch [9395/10000], train_Loss: 7.986759031908264e-10,test_Loss:4.574622631072998, r2_store:0.32930620901059193\n",
            "torch.Size([80, 42])\n",
            "Epoch [9396/10000], train_Loss: 7.736482565690039e-10,test_Loss:4.5746283531188965, r2_store:0.3293058581870476\n",
            "torch.Size([80, 42])\n",
            "Epoch [9397/10000], train_Loss: 7.541035573765953e-10,test_Loss:4.574624061584473, r2_store:0.3293060199568698\n",
            "torch.Size([80, 42])\n",
            "Epoch [9398/10000], train_Loss: 7.299835180774039e-10,test_Loss:4.5746259689331055, r2_store:0.3293059324658234\n",
            "torch.Size([80, 42])\n",
            "Epoch [9399/10000], train_Loss: 7.016854319807919e-10,test_Loss:4.574632167816162, r2_store:0.32930561662189406\n",
            "torch.Size([80, 42])\n",
            "Epoch [9400/10000], train_Loss: 6.947513120358906e-10,test_Loss:4.574627876281738, r2_store:0.3293057974025686\n",
            "torch.Size([80, 42])\n",
            "Epoch [9401/10000], train_Loss: 6.669925722846415e-10,test_Loss:4.574629306793213, r2_store:0.3293058189807323\n",
            "torch.Size([80, 42])\n",
            "Epoch [9402/10000], train_Loss: 6.404126673409394e-10,test_Loss:4.574633598327637, r2_store:0.3293056461168672\n",
            "torch.Size([80, 42])\n",
            "Epoch [9403/10000], train_Loss: 6.273855879257439e-10,test_Loss:4.574630260467529, r2_store:0.3293057786888055\n",
            "torch.Size([80, 42])\n",
            "Epoch [9404/10000], train_Loss: 6.083886727736854e-10,test_Loss:4.574633598327637, r2_store:0.32930562306796096\n",
            "torch.Size([80, 42])\n",
            "Epoch [9405/10000], train_Loss: 5.876313879937811e-10,test_Loss:4.574633598327637, r2_store:0.32930575070513957\n",
            "torch.Size([80, 42])\n",
            "Epoch [9406/10000], train_Loss: 5.714649309318531e-10,test_Loss:4.574635028839111, r2_store:0.3293057083420664\n",
            "torch.Size([80, 42])\n",
            "Epoch [9407/10000], train_Loss: 5.54134016450547e-10,test_Loss:4.574637413024902, r2_store:0.3293056620863206\n",
            "torch.Size([80, 42])\n",
            "Epoch [9408/10000], train_Loss: 5.397483571201178e-10,test_Loss:4.574636936187744, r2_store:0.32930563216957753\n",
            "torch.Size([80, 42])\n",
            "Epoch [9409/10000], train_Loss: 5.253594226317659e-10,test_Loss:4.574637413024902, r2_store:0.32930565419366553\n",
            "torch.Size([80, 42])\n",
            "Epoch [9410/10000], train_Loss: 5.078747422615493e-10,test_Loss:4.574636936187744, r2_store:0.32930555961145525\n",
            "torch.Size([80, 42])\n",
            "Epoch [9411/10000], train_Loss: 4.89799645286837e-10,test_Loss:4.574639320373535, r2_store:0.3293054626214791\n",
            "torch.Size([80, 42])\n",
            "Epoch [9412/10000], train_Loss: 4.7424097981974e-10,test_Loss:4.574643135070801, r2_store:0.3293053214088384\n",
            "torch.Size([80, 42])\n",
            "Epoch [9413/10000], train_Loss: 4.6249820639943096e-10,test_Loss:4.57464075088501, r2_store:0.32930544578852894\n",
            "torch.Size([80, 42])\n",
            "Epoch [9414/10000], train_Loss: 4.4621378814113655e-10,test_Loss:4.574643611907959, r2_store:0.32930529368518047\n",
            "torch.Size([80, 42])\n",
            "Epoch [9415/10000], train_Loss: 4.322338598150566e-10,test_Loss:4.574643135070801, r2_store:0.3293053151655143\n",
            "torch.Size([80, 42])\n",
            "Epoch [9416/10000], train_Loss: 4.208504655878187e-10,test_Loss:4.574643611907959, r2_store:0.32930536851671577\n",
            "torch.Size([80, 42])\n",
            "Epoch [9417/10000], train_Loss: 4.0541628387735784e-10,test_Loss:4.574644088745117, r2_store:0.3293053215497319\n",
            "torch.Size([80, 42])\n",
            "Epoch [9418/10000], train_Loss: 3.8945585645322467e-10,test_Loss:4.574645042419434, r2_store:0.32930536032094115\n",
            "torch.Size([80, 42])\n",
            "Epoch [9419/10000], train_Loss: 3.822421545951471e-10,test_Loss:4.574644088745117, r2_store:0.32930531941322894\n",
            "torch.Size([80, 42])\n",
            "Epoch [9420/10000], train_Loss: 3.661987657554988e-10,test_Loss:4.574646949768066, r2_store:0.32930519607007447\n",
            "torch.Size([80, 42])\n",
            "Epoch [9421/10000], train_Loss: 3.5771213768853727e-10,test_Loss:4.574647903442383, r2_store:0.3293051586465694\n",
            "torch.Size([80, 42])\n",
            "Epoch [9422/10000], train_Loss: 3.4947042482080803e-10,test_Loss:4.574645042419434, r2_store:0.3293052230734935\n",
            "torch.Size([80, 42])\n",
            "Epoch [9423/10000], train_Loss: 3.4015984473612093e-10,test_Loss:4.574652194976807, r2_store:0.32930499391765433\n",
            "torch.Size([80, 42])\n",
            "Epoch [9424/10000], train_Loss: 3.268772197362324e-10,test_Loss:4.574649810791016, r2_store:0.3293051582736465\n",
            "torch.Size([80, 42])\n",
            "Epoch [9425/10000], train_Loss: 3.180907204303196e-10,test_Loss:4.574646949768066, r2_store:0.3293052781733624\n",
            "torch.Size([80, 42])\n",
            "Epoch [9426/10000], train_Loss: 3.1124164356910455e-10,test_Loss:4.574654579162598, r2_store:0.3293049532565612\n",
            "torch.Size([80, 42])\n",
            "Epoch [9427/10000], train_Loss: 3.0101415804395515e-10,test_Loss:4.574649810791016, r2_store:0.32930512840182047\n",
            "torch.Size([80, 42])\n",
            "Epoch [9428/10000], train_Loss: 2.890375161435088e-10,test_Loss:4.574652671813965, r2_store:0.32930512649105936\n",
            "torch.Size([80, 42])\n",
            "Epoch [9429/10000], train_Loss: 2.8172916777258195e-10,test_Loss:4.574655055999756, r2_store:0.3293050419090069\n",
            "torch.Size([80, 42])\n",
            "Epoch [9430/10000], train_Loss: 2.723661018944057e-10,test_Loss:4.574650764465332, r2_store:0.32930511630029935\n",
            "torch.Size([80, 42])\n",
            "Epoch [9431/10000], train_Loss: 2.6380705953066297e-10,test_Loss:4.574653625488281, r2_store:0.32930508673574366\n",
            "torch.Size([80, 42])\n",
            "Epoch [9432/10000], train_Loss: 2.578324220792183e-10,test_Loss:4.574657917022705, r2_store:0.3293048678149493\n",
            "torch.Size([80, 42])\n",
            "Epoch [9433/10000], train_Loss: 2.4812946142205305e-10,test_Loss:4.574653148651123, r2_store:0.3293050062738384\n",
            "torch.Size([80, 42])\n",
            "Epoch [9434/10000], train_Loss: 2.402673893175944e-10,test_Loss:4.574658393859863, r2_store:0.3293049668513428\n",
            "torch.Size([80, 42])\n",
            "Epoch [9435/10000], train_Loss: 2.3305884999658133e-10,test_Loss:4.574657440185547, r2_store:0.3293049902365648\n",
            "torch.Size([80, 42])\n",
            "Epoch [9436/10000], train_Loss: 2.232660445411483e-10,test_Loss:4.574655532836914, r2_store:0.32930485783292773\n",
            "torch.Size([80, 42])\n",
            "Epoch [9437/10000], train_Loss: 2.181382852128877e-10,test_Loss:4.57465934753418, r2_store:0.32930473749129385\n",
            "torch.Size([80, 42])\n",
            "Epoch [9438/10000], train_Loss: 2.080703109808013e-10,test_Loss:4.574661731719971, r2_store:0.3293047595825872\n",
            "torch.Size([80, 42])\n",
            "Epoch [9439/10000], train_Loss: 2.046372793440554e-10,test_Loss:4.574657917022705, r2_store:0.3293049375275008\n",
            "torch.Size([80, 42])\n",
            "Epoch [9440/10000], train_Loss: 2.0230513098074e-10,test_Loss:4.574662208557129, r2_store:0.32930473911220626\n",
            "torch.Size([80, 42])\n",
            "Epoch [9441/10000], train_Loss: 1.9422397024015936e-10,test_Loss:4.574659824371338, r2_store:0.3293048990548755\n",
            "torch.Size([80, 42])\n",
            "Epoch [9442/10000], train_Loss: 1.870953392213437e-10,test_Loss:4.574660778045654, r2_store:0.32930473265755356\n",
            "torch.Size([80, 42])\n",
            "Epoch [9443/10000], train_Loss: 1.807775318329874e-10,test_Loss:4.574662208557129, r2_store:0.3293046085686605\n",
            "torch.Size([80, 42])\n",
            "Epoch [9444/10000], train_Loss: 1.76855960432043e-10,test_Loss:4.574661731719971, r2_store:0.32930466699793537\n",
            "torch.Size([80, 42])\n",
            "Epoch [9445/10000], train_Loss: 1.684876960172943e-10,test_Loss:4.5746636390686035, r2_store:0.32930462696280405\n",
            "torch.Size([80, 42])\n",
            "Epoch [9446/10000], train_Loss: 1.6532955560144558e-10,test_Loss:4.574663162231445, r2_store:0.32930478282172804\n",
            "torch.Size([80, 42])\n",
            "Epoch [9447/10000], train_Loss: 1.6043416595223903e-10,test_Loss:4.574662208557129, r2_store:0.3293047013841762\n",
            "torch.Size([80, 42])\n",
            "Epoch [9448/10000], train_Loss: 1.5499328209767071e-10,test_Loss:4.57466459274292, r2_store:0.32930463169482704\n",
            "torch.Size([80, 42])\n",
            "Epoch [9449/10000], train_Loss: 1.5111760454100676e-10,test_Loss:4.574663162231445, r2_store:0.3293047354313329\n",
            "torch.Size([80, 42])\n",
            "Epoch [9450/10000], train_Loss: 1.4506101875255695e-10,test_Loss:4.5746660232543945, r2_store:0.32930465839220147\n",
            "torch.Size([80, 42])\n",
            "Epoch [9451/10000], train_Loss: 1.416351896876833e-10,test_Loss:4.5746660232543945, r2_store:0.32930478977939026\n",
            "torch.Size([80, 42])\n",
            "Epoch [9452/10000], train_Loss: 1.3581205604573654e-10,test_Loss:4.574665069580078, r2_store:0.32930474320014835\n",
            "torch.Size([80, 42])\n",
            "Epoch [9453/10000], train_Loss: 1.3206416515920694e-10,test_Loss:4.574669361114502, r2_store:0.32930461680045864\n",
            "torch.Size([80, 42])\n",
            "Epoch [9454/10000], train_Loss: 1.2739534427375077e-10,test_Loss:4.574666500091553, r2_store:0.3293045988125286\n",
            "torch.Size([80, 42])\n",
            "Epoch [9455/10000], train_Loss: 1.2565894158544921e-10,test_Loss:4.57466983795166, r2_store:0.3293045079078355\n",
            "torch.Size([80, 42])\n",
            "Epoch [9456/10000], train_Loss: 1.1875724015286693e-10,test_Loss:4.574670791625977, r2_store:0.329304483643563\n",
            "torch.Size([80, 42])\n",
            "Epoch [9457/10000], train_Loss: 1.1614485068145441e-10,test_Loss:4.57466983795166, r2_store:0.3293045771506795\n",
            "torch.Size([80, 42])\n",
            "Epoch [9458/10000], train_Loss: 1.1411146333406563e-10,test_Loss:4.574671745300293, r2_store:0.32930450128687416\n",
            "torch.Size([80, 42])\n",
            "Epoch [9459/10000], train_Loss: 1.081482473019868e-10,test_Loss:4.57466983795166, r2_store:0.32930451173004527\n",
            "torch.Size([80, 42])\n",
            "Epoch [9460/10000], train_Loss: 1.0470997680034344e-10,test_Loss:4.57466983795166, r2_store:0.3293045010835687\n",
            "torch.Size([80, 42])\n",
            "Epoch [9461/10000], train_Loss: 1.0320762300342068e-10,test_Loss:4.574673175811768, r2_store:0.32930439194768624\n",
            "torch.Size([80, 42])\n",
            "Epoch [9462/10000], train_Loss: 1.0111713549809664e-10,test_Loss:4.574671268463135, r2_store:0.3293044209747551\n",
            "torch.Size([80, 42])\n",
            "Epoch [9463/10000], train_Loss: 9.634219810816802e-11,test_Loss:4.574673175811768, r2_store:0.32930444838150497\n",
            "torch.Size([80, 42])\n",
            "Epoch [9464/10000], train_Loss: 9.265530009905376e-11,test_Loss:4.574674606323242, r2_store:0.3293043984185783\n",
            "torch.Size([80, 42])\n",
            "Epoch [9465/10000], train_Loss: 9.046522558842085e-11,test_Loss:4.574673175811768, r2_store:0.32930453241190394\n",
            "torch.Size([80, 42])\n",
            "Epoch [9466/10000], train_Loss: 8.756272096288598e-11,test_Loss:4.574674129486084, r2_store:0.3293044083988178\n",
            "torch.Size([80, 42])\n",
            "Epoch [9467/10000], train_Loss: 8.533822259959578e-11,test_Loss:4.574674129486084, r2_store:0.3293043977001412\n",
            "torch.Size([80, 42])\n",
            "Epoch [9468/10000], train_Loss: 8.274093910021207e-11,test_Loss:4.574674606323242, r2_store:0.329304400213424\n",
            "torch.Size([80, 42])\n",
            "Epoch [9469/10000], train_Loss: 7.835938148348376e-11,test_Loss:4.574675559997559, r2_store:0.3293044632185944\n",
            "torch.Size([80, 42])\n",
            "Epoch [9470/10000], train_Loss: 7.620494513194132e-11,test_Loss:4.574675559997559, r2_store:0.32930437515727595\n",
            "torch.Size([80, 42])\n",
            "Epoch [9471/10000], train_Loss: 7.52461079556177e-11,test_Loss:4.574676990509033, r2_store:0.32930433306589524\n",
            "torch.Size([80, 42])\n",
            "Epoch [9472/10000], train_Loss: 7.295034021304048e-11,test_Loss:4.574673652648926, r2_store:0.32930428827731406\n",
            "torch.Size([80, 42])\n",
            "Epoch [9473/10000], train_Loss: 7.083077180336517e-11,test_Loss:4.574676513671875, r2_store:0.3293042419850539\n",
            "torch.Size([80, 42])\n",
            "Epoch [9474/10000], train_Loss: 6.78263417652758e-11,test_Loss:4.574676990509033, r2_store:0.32930429451896626\n",
            "torch.Size([80, 42])\n",
            "Epoch [9475/10000], train_Loss: 6.538263680466727e-11,test_Loss:4.57467794418335, r2_store:0.3293044156234223\n",
            "torch.Size([80, 42])\n",
            "Epoch [9476/10000], train_Loss: 6.342277397708429e-11,test_Loss:4.574679374694824, r2_store:0.3293043297056547\n",
            "torch.Size([80, 42])\n",
            "Epoch [9477/10000], train_Loss: 6.187939050050772e-11,test_Loss:4.574679374694824, r2_store:0.3293043822847834\n",
            "torch.Size([80, 42])\n",
            "Epoch [9478/10000], train_Loss: 6.032504357156299e-11,test_Loss:4.574676990509033, r2_store:0.3293043185784692\n",
            "torch.Size([80, 42])\n",
            "Epoch [9479/10000], train_Loss: 5.7813632353687083e-11,test_Loss:4.574679851531982, r2_store:0.3293043039938218\n",
            "torch.Size([80, 42])\n",
            "Epoch [9480/10000], train_Loss: 5.555707630056084e-11,test_Loss:4.574678421020508, r2_store:0.3293042862140928\n",
            "torch.Size([80, 42])\n",
            "Epoch [9481/10000], train_Loss: 5.409509992726491e-11,test_Loss:4.574677467346191, r2_store:0.32930433105882406\n",
            "torch.Size([80, 42])\n",
            "Epoch [9482/10000], train_Loss: 5.218727186506733e-11,test_Loss:4.574679374694824, r2_store:0.32930427460115896\n",
            "torch.Size([80, 42])\n",
            "Epoch [9483/10000], train_Loss: 5.0302949305969236e-11,test_Loss:4.574680805206299, r2_store:0.3293041391194099\n",
            "torch.Size([80, 42])\n",
            "Epoch [9484/10000], train_Loss: 4.942473166846817e-11,test_Loss:4.574677467346191, r2_store:0.32930422914641955\n",
            "torch.Size([80, 42])\n",
            "Epoch [9485/10000], train_Loss: 4.817595281036979e-11,test_Loss:4.574680328369141, r2_store:0.3293041227651252\n",
            "torch.Size([80, 42])\n",
            "Epoch [9486/10000], train_Loss: 4.659821487007498e-11,test_Loss:4.574681758880615, r2_store:0.3293041497903523\n",
            "torch.Size([80, 42])\n",
            "Epoch [9487/10000], train_Loss: 4.4622854022957625e-11,test_Loss:4.574681282043457, r2_store:0.3293042202321501\n",
            "torch.Size([80, 42])\n",
            "Epoch [9488/10000], train_Loss: 4.4713299035548104e-11,test_Loss:4.574682712554932, r2_store:0.329304206151393\n",
            "torch.Size([80, 42])\n",
            "Epoch [9489/10000], train_Loss: 4.20115990606984e-11,test_Loss:4.5746846199035645, r2_store:0.3293039725008615\n",
            "torch.Size([80, 42])\n",
            "Epoch [9490/10000], train_Loss: 4.272318956943799e-11,test_Loss:4.574680805206299, r2_store:0.3293040578920413\n",
            "torch.Size([80, 42])\n",
            "Epoch [9491/10000], train_Loss: 4.00503727404633e-11,test_Loss:4.574681758880615, r2_store:0.3293041038683122\n",
            "torch.Size([80, 42])\n",
            "Epoch [9492/10000], train_Loss: 3.788366842449875e-11,test_Loss:4.5746846199035645, r2_store:0.32930399845577096\n",
            "torch.Size([80, 42])\n",
            "Epoch [9493/10000], train_Loss: 3.743768489661292e-11,test_Loss:4.574684143066406, r2_store:0.32930408812881273\n",
            "torch.Size([80, 42])\n",
            "Epoch [9494/10000], train_Loss: 3.613307916761066e-11,test_Loss:4.574682712554932, r2_store:0.3293040914803631\n",
            "torch.Size([80, 42])\n",
            "Epoch [9495/10000], train_Loss: 3.4877500193486455e-11,test_Loss:4.5746870040893555, r2_store:0.3293038830260687\n",
            "torch.Size([80, 42])\n",
            "Epoch [9496/10000], train_Loss: 3.4677233307078836e-11,test_Loss:4.574682712554932, r2_store:0.3293041091418839\n",
            "torch.Size([80, 42])\n",
            "Epoch [9497/10000], train_Loss: 3.331427494979167e-11,test_Loss:4.574684143066406, r2_store:0.32930408745018436\n",
            "torch.Size([80, 42])\n",
            "Epoch [9498/10000], train_Loss: 3.102850615332997e-11,test_Loss:4.574686527252197, r2_store:0.3293040106467441\n",
            "torch.Size([80, 42])\n",
            "Epoch [9499/10000], train_Loss: 2.961058481742995e-11,test_Loss:4.574684143066406, r2_store:0.32930412601851844\n",
            "torch.Size([80, 42])\n",
            "Epoch [9500/10000], train_Loss: 2.922590294773819e-11,test_Loss:4.574685573577881, r2_store:0.3293040265978675\n",
            "torch.Size([80, 42])\n",
            "Epoch [9501/10000], train_Loss: 2.7856906018031147e-11,test_Loss:4.574684143066406, r2_store:0.32930398964032903\n",
            "torch.Size([80, 42])\n",
            "Epoch [9502/10000], train_Loss: 2.8412022734514153e-11,test_Loss:4.574685096740723, r2_store:0.3293040200899702\n",
            "torch.Size([80, 42])\n",
            "Epoch [9503/10000], train_Loss: 2.790842210109723e-11,test_Loss:4.5746870040893555, r2_store:0.3293039878537469\n",
            "torch.Size([80, 42])\n",
            "Epoch [9504/10000], train_Loss: 2.7187238571535488e-11,test_Loss:4.574686050415039, r2_store:0.32930407027940745\n",
            "torch.Size([80, 42])\n",
            "Epoch [9505/10000], train_Loss: 2.6066315772510507e-11,test_Loss:4.5746870040893555, r2_store:0.32930400895943523\n",
            "torch.Size([80, 42])\n",
            "Epoch [9506/10000], train_Loss: 2.4392144554186146e-11,test_Loss:4.5746870040893555, r2_store:0.3293039875835332\n",
            "torch.Size([80, 42])\n",
            "Epoch [9507/10000], train_Loss: 2.3500789855801507e-11,test_Loss:4.574687480926514, r2_store:0.3293039501384498\n",
            "torch.Size([80, 42])\n",
            "Epoch [9508/10000], train_Loss: 2.2688824777294947e-11,test_Loss:4.574687957763672, r2_store:0.3293039572627019\n",
            "torch.Size([80, 42])\n",
            "Epoch [9509/10000], train_Loss: 2.1232907793100608e-11,test_Loss:4.5746870040893555, r2_store:0.32930400430464624\n",
            "torch.Size([80, 42])\n",
            "Epoch [9510/10000], train_Loss: 2.1223172524953426e-11,test_Loss:4.574687957763672, r2_store:0.3293039868824057\n",
            "torch.Size([80, 42])\n",
            "Epoch [9511/10000], train_Loss: 2.050805705811065e-11,test_Loss:4.574688911437988, r2_store:0.3293039429930211\n",
            "torch.Size([80, 42])\n",
            "Epoch [9512/10000], train_Loss: 1.947536229507385e-11,test_Loss:4.574688911437988, r2_store:0.32930393519250234\n",
            "torch.Size([80, 42])\n",
            "Epoch [9513/10000], train_Loss: 1.9728458450218866e-11,test_Loss:4.57468843460083, r2_store:0.3293038584267325\n",
            "torch.Size([80, 42])\n",
            "Epoch [9514/10000], train_Loss: 1.8722318834152318e-11,test_Loss:4.574687957763672, r2_store:0.3293038345827366\n",
            "torch.Size([80, 42])\n",
            "Epoch [9515/10000], train_Loss: 1.7624240608582475e-11,test_Loss:4.57468843460083, r2_store:0.3293038926092129\n",
            "torch.Size([80, 42])\n",
            "Epoch [9516/10000], train_Loss: 1.7275054650656152e-11,test_Loss:4.5746893882751465, r2_store:0.32930392326741953\n",
            "torch.Size([80, 42])\n",
            "Epoch [9517/10000], train_Loss: 1.668456692249798e-11,test_Loss:4.574688911437988, r2_store:0.32930383789079565\n",
            "torch.Size([80, 42])\n",
            "Epoch [9518/10000], train_Loss: 1.6926817586471188e-11,test_Loss:4.574688911437988, r2_store:0.32930387392087734\n",
            "torch.Size([80, 42])\n",
            "Epoch [9519/10000], train_Loss: 1.6127288740563905e-11,test_Loss:4.574687957763672, r2_store:0.3293038596174125\n",
            "torch.Size([80, 42])\n",
            "Epoch [9520/10000], train_Loss: 1.559055315403235e-11,test_Loss:4.57468843460083, r2_store:0.32930382816940096\n",
            "torch.Size([80, 42])\n",
            "Epoch [9521/10000], train_Loss: 1.523832102168221e-11,test_Loss:4.574688911437988, r2_store:0.3293038133859617\n",
            "torch.Size([80, 42])\n",
            "Epoch [9522/10000], train_Loss: 1.4839088291473956e-11,test_Loss:4.574688911437988, r2_store:0.32930377509523756\n",
            "torch.Size([80, 42])\n",
            "Epoch [9523/10000], train_Loss: 1.4456667633833131e-11,test_Loss:4.574687480926514, r2_store:0.32930384459814943\n",
            "torch.Size([80, 42])\n",
            "Epoch [9524/10000], train_Loss: 1.4099462916639105e-11,test_Loss:4.574688911437988, r2_store:0.32930386329275263\n",
            "torch.Size([80, 42])\n",
            "Epoch [9525/10000], train_Loss: 1.359316825766399e-11,test_Loss:4.574688911437988, r2_store:0.32930387590011867\n",
            "torch.Size([80, 42])\n",
            "Epoch [9526/10000], train_Loss: 1.3246584384951632e-11,test_Loss:4.574689865112305, r2_store:0.3293039255249087\n",
            "torch.Size([80, 42])\n",
            "Epoch [9527/10000], train_Loss: 1.2231269816420642e-11,test_Loss:4.574689865112305, r2_store:0.3293039425396609\n",
            "torch.Size([80, 42])\n",
            "Epoch [9528/10000], train_Loss: 1.1671058217088692e-11,test_Loss:4.574690818786621, r2_store:0.3293038594281438\n",
            "torch.Size([80, 42])\n",
            "Epoch [9529/10000], train_Loss: 1.1597597014689764e-11,test_Loss:4.574690341949463, r2_store:0.3293037838213192\n",
            "torch.Size([80, 42])\n",
            "Epoch [9530/10000], train_Loss: 1.1354733125967797e-11,test_Loss:4.574689865112305, r2_store:0.3293038311488722\n",
            "torch.Size([80, 42])\n",
            "Epoch [9531/10000], train_Loss: 1.0851593061633746e-11,test_Loss:4.5746893882751465, r2_store:0.32930379801397036\n",
            "torch.Size([80, 42])\n",
            "Epoch [9532/10000], train_Loss: 1.0371930744823565e-11,test_Loss:4.574690341949463, r2_store:0.32930377328982485\n",
            "torch.Size([80, 42])\n",
            "Epoch [9533/10000], train_Loss: 1.0502851192917273e-11,test_Loss:4.574688911437988, r2_store:0.3293038988542363\n",
            "torch.Size([80, 42])\n",
            "Epoch [9534/10000], train_Loss: 1.0325074996375694e-11,test_Loss:4.574690341949463, r2_store:0.32930382811186787\n",
            "torch.Size([80, 42])\n",
            "Epoch [9535/10000], train_Loss: 9.78699326442678e-12,test_Loss:4.5746917724609375, r2_store:0.3293037929651934\n",
            "torch.Size([80, 42])\n",
            "Epoch [9536/10000], train_Loss: 9.398716180331057e-12,test_Loss:4.574689865112305, r2_store:0.32930383884871606\n",
            "torch.Size([80, 42])\n",
            "Epoch [9537/10000], train_Loss: 9.156372708651883e-12,test_Loss:4.574690341949463, r2_store:0.3293038163067228\n",
            "torch.Size([80, 42])\n",
            "Epoch [9538/10000], train_Loss: 8.640343648891324e-12,test_Loss:4.574692249298096, r2_store:0.32930376684203255\n",
            "torch.Size([80, 42])\n",
            "Epoch [9539/10000], train_Loss: 8.780123329776846e-12,test_Loss:4.574688911437988, r2_store:0.32930388953636314\n",
            "torch.Size([80, 42])\n",
            "Epoch [9540/10000], train_Loss: 8.6730206350083e-12,test_Loss:4.574690818786621, r2_store:0.3293037527474991\n",
            "torch.Size([80, 42])\n",
            "Epoch [9541/10000], train_Loss: 8.183006355855227e-12,test_Loss:4.574690818786621, r2_store:0.32930374235158344\n",
            "torch.Size([80, 42])\n",
            "Epoch [9542/10000], train_Loss: 7.4346778733414e-12,test_Loss:4.574688911437988, r2_store:0.32930377307147685\n",
            "torch.Size([80, 42])\n",
            "Epoch [9543/10000], train_Loss: 7.704540130881732e-12,test_Loss:4.574690818786621, r2_store:0.32930372529550633\n",
            "torch.Size([80, 42])\n",
            "Epoch [9544/10000], train_Loss: 7.705475146835283e-12,test_Loss:4.574688911437988, r2_store:0.3293037956473276\n",
            "torch.Size([80, 42])\n",
            "Epoch [9545/10000], train_Loss: 7.0723197263811155e-12,test_Loss:4.574687957763672, r2_store:0.3293038839854199\n",
            "torch.Size([80, 42])\n",
            "Epoch [9546/10000], train_Loss: 7.109553831069482e-12,test_Loss:4.574690341949463, r2_store:0.32930373503022314\n",
            "torch.Size([80, 42])\n",
            "Epoch [9547/10000], train_Loss: 7.125004579389138e-12,test_Loss:4.574690341949463, r2_store:0.3293038158668552\n",
            "torch.Size([80, 42])\n",
            "Epoch [9548/10000], train_Loss: 6.367924850619877e-12,test_Loss:4.574689865112305, r2_store:0.32930382568314975\n",
            "torch.Size([80, 42])\n",
            "Epoch [9549/10000], train_Loss: 6.005945740739094e-12,test_Loss:4.574690341949463, r2_store:0.3293037783409327\n",
            "torch.Size([80, 42])\n",
            "Epoch [9550/10000], train_Loss: 6.456968206641767e-12,test_Loss:4.574690341949463, r2_store:0.3293037923317683\n",
            "torch.Size([80, 42])\n",
            "Epoch [9551/10000], train_Loss: 6.496345995865571e-12,test_Loss:4.574689865112305, r2_store:0.32930382429997407\n",
            "torch.Size([80, 42])\n",
            "Epoch [9552/10000], train_Loss: 5.2905423097993065e-12,test_Loss:4.574690818786621, r2_store:0.32930379517679276\n",
            "torch.Size([80, 42])\n",
            "Epoch [9553/10000], train_Loss: 5.277250858526372e-12,test_Loss:4.574690818786621, r2_store:0.32930374935530593\n",
            "torch.Size([80, 42])\n",
            "Epoch [9554/10000], train_Loss: 5.099340220915405e-12,test_Loss:4.574690818786621, r2_store:0.32930383369853644\n",
            "torch.Size([80, 42])\n",
            "Epoch [9555/10000], train_Loss: 5.08367740265081e-12,test_Loss:4.574690818786621, r2_store:0.3293038650182908\n",
            "torch.Size([80, 42])\n",
            "Epoch [9556/10000], train_Loss: 4.7746849876628694e-12,test_Loss:4.574690818786621, r2_store:0.32930384976306304\n",
            "torch.Size([80, 42])\n",
            "Epoch [9557/10000], train_Loss: 4.877882819886992e-12,test_Loss:4.574688911437988, r2_store:0.32930381237946105\n",
            "torch.Size([80, 42])\n",
            "Epoch [9558/10000], train_Loss: 4.99068061182717e-12,test_Loss:4.574690818786621, r2_store:0.32930384565322923\n",
            "torch.Size([80, 42])\n",
            "Epoch [9559/10000], train_Loss: 4.8157450249775025e-12,test_Loss:4.5746917724609375, r2_store:0.3293037680781724\n",
            "torch.Size([80, 42])\n",
            "Epoch [9560/10000], train_Loss: 4.297748788795186e-12,test_Loss:4.574690818786621, r2_store:0.32930385830081843\n",
            "torch.Size([80, 42])\n",
            "Epoch [9561/10000], train_Loss: 4.365383055038308e-12,test_Loss:4.574690341949463, r2_store:0.32930379498313533\n",
            "torch.Size([80, 42])\n",
            "Epoch [9562/10000], train_Loss: 4.403212603559803e-12,test_Loss:4.574691295623779, r2_store:0.32930380786687663\n",
            "torch.Size([80, 42])\n",
            "Epoch [9563/10000], train_Loss: 4.3048841401327476e-12,test_Loss:4.5746893882751465, r2_store:0.3293039008709473\n",
            "torch.Size([80, 42])\n",
            "Epoch [9564/10000], train_Loss: 4.12963413465306e-12,test_Loss:4.574690818786621, r2_store:0.3293038737938645\n",
            "torch.Size([80, 42])\n",
            "Epoch [9565/10000], train_Loss: 3.65178633859875e-12,test_Loss:4.574692249298096, r2_store:0.32930380322117936\n",
            "torch.Size([80, 42])\n",
            "Epoch [9566/10000], train_Loss: 3.684543555676489e-12,test_Loss:4.574690818786621, r2_store:0.32930375097069375\n",
            "torch.Size([80, 42])\n",
            "Epoch [9567/10000], train_Loss: 3.7920894722931475e-12,test_Loss:4.574690341949463, r2_store:0.32930373581497985\n",
            "torch.Size([80, 42])\n",
            "Epoch [9568/10000], train_Loss: 3.665180572237636e-12,test_Loss:4.574692249298096, r2_store:0.3293036507732061\n",
            "torch.Size([80, 42])\n",
            "Epoch [9569/10000], train_Loss: 3.668646549742638e-12,test_Loss:4.574690818786621, r2_store:0.32930378309481023\n",
            "torch.Size([80, 42])\n",
            "Epoch [9570/10000], train_Loss: 3.58065248458328e-12,test_Loss:4.574690818786621, r2_store:0.3293037498473813\n",
            "torch.Size([80, 42])\n",
            "Epoch [9571/10000], train_Loss: 3.4125666702189417e-12,test_Loss:4.5746917724609375, r2_store:0.32930372348403325\n",
            "torch.Size([80, 42])\n",
            "Epoch [9572/10000], train_Loss: 3.24679996430155e-12,test_Loss:4.574691295623779, r2_store:0.3293038047561918\n",
            "torch.Size([80, 42])\n",
            "Epoch [9573/10000], train_Loss: 2.9721988759057183e-12,test_Loss:4.574690818786621, r2_store:0.32930382556222204\n",
            "torch.Size([80, 42])\n",
            "Epoch [9574/10000], train_Loss: 3.020167449463429e-12,test_Loss:4.574693202972412, r2_store:0.32930373016440473\n",
            "torch.Size([80, 42])\n",
            "Epoch [9575/10000], train_Loss: 2.915557335489427e-12,test_Loss:4.574692249298096, r2_store:0.32930385922996686\n",
            "torch.Size([80, 42])\n",
            "Epoch [9576/10000], train_Loss: 2.65737367007024e-12,test_Loss:4.574692249298096, r2_store:0.32930382414334336\n",
            "torch.Size([80, 42])\n",
            "Epoch [9577/10000], train_Loss: 2.8877178426256478e-12,test_Loss:4.574692726135254, r2_store:0.3293038166823724\n",
            "torch.Size([80, 42])\n",
            "Epoch [9578/10000], train_Loss: 2.8221147207324604e-12,test_Loss:4.5746917724609375, r2_store:0.329303792387288\n",
            "torch.Size([80, 42])\n",
            "Epoch [9579/10000], train_Loss: 2.859883770772731e-12,test_Loss:4.574692726135254, r2_store:0.3293037653513464\n",
            "torch.Size([80, 42])\n",
            "Epoch [9580/10000], train_Loss: 2.6608396475752416e-12,test_Loss:4.574692726135254, r2_store:0.3293037802895241\n",
            "torch.Size([80, 42])\n",
            "Epoch [9581/10000], train_Loss: 2.5990958517352336e-12,test_Loss:4.5746917724609375, r2_store:0.3293038117075989\n",
            "torch.Size([80, 42])\n",
            "Epoch [9582/10000], train_Loss: 2.5334671426707756e-12,test_Loss:4.574692726135254, r2_store:0.3293038090620629\n",
            "torch.Size([80, 42])\n",
            "Epoch [9583/10000], train_Loss: 2.321237603172821e-12,test_Loss:4.57469367980957, r2_store:0.32930369135801674\n",
            "torch.Size([80, 42])\n",
            "Epoch [9584/10000], train_Loss: 2.600099389266086e-12,test_Loss:4.574692249298096, r2_store:0.3293038033676893\n",
            "torch.Size([80, 42])\n",
            "Epoch [9585/10000], train_Loss: 2.6146688980599464e-12,test_Loss:4.574692726135254, r2_store:0.32930373325686946\n",
            "torch.Size([80, 42])\n",
            "Epoch [9586/10000], train_Loss: 2.3149455442850186e-12,test_Loss:4.5746941566467285, r2_store:0.32930362846654293\n",
            "torch.Size([80, 42])\n",
            "Epoch [9587/10000], train_Loss: 2.3762387457021417e-12,test_Loss:4.574693202972412, r2_store:0.3293038377784745\n",
            "torch.Size([80, 42])\n",
            "Epoch [9588/10000], train_Loss: 2.2134780987281832e-12,test_Loss:4.57469367980957, r2_store:0.3293038673805583\n",
            "torch.Size([80, 42])\n",
            "Epoch [9589/10000], train_Loss: 2.1169038744162094e-12,test_Loss:4.574694633483887, r2_store:0.32930374628935166\n",
            "torch.Size([80, 42])\n",
            "Epoch [9590/10000], train_Loss: 2.447901690377785e-12,test_Loss:4.5746917724609375, r2_store:0.3293037728168392\n",
            "torch.Size([80, 42])\n",
            "Epoch [9591/10000], train_Loss: 2.1511063329898716e-12,test_Loss:4.574692726135254, r2_store:0.3293037432766748\n",
            "torch.Size([80, 42])\n",
            "Epoch [9592/10000], train_Loss: 1.8521566658852295e-12,test_Loss:4.574695110321045, r2_store:0.32930364557002134\n",
            "torch.Size([80, 42])\n",
            "Epoch [9593/10000], train_Loss: 2.073701019927876e-12,test_Loss:4.574693202972412, r2_store:0.32930371182835705\n",
            "torch.Size([80, 42])\n",
            "Epoch [9594/10000], train_Loss: 1.908471210926299e-12,test_Loss:4.574693202972412, r2_store:0.32930371080881293\n",
            "torch.Size([80, 42])\n",
            "Epoch [9595/10000], train_Loss: 1.697972274936066e-12,test_Loss:4.5746941566467285, r2_store:0.32930371396623836\n",
            "torch.Size([80, 42])\n",
            "Epoch [9596/10000], train_Loss: 1.6489656862184177e-12,test_Loss:4.57469367980957, r2_store:0.3293037070175294\n",
            "torch.Size([80, 42])\n",
            "Epoch [9597/10000], train_Loss: 1.6137493901932642e-12,test_Loss:4.57469367980957, r2_store:0.3293036364676748\n",
            "torch.Size([80, 42])\n",
            "Epoch [9598/10000], train_Loss: 1.6196259828085702e-12,test_Loss:4.57469367980957, r2_store:0.3293036483418037\n",
            "torch.Size([80, 42])\n",
            "Epoch [9599/10000], train_Loss: 1.5677591603396879e-12,test_Loss:4.5746941566467285, r2_store:0.3293036947479093\n",
            "torch.Size([80, 42])\n",
            "Epoch [9600/10000], train_Loss: 1.4272999015324528e-12,test_Loss:4.5746941566467285, r2_store:0.3293036863239196\n",
            "torch.Size([80, 42])\n",
            "Epoch [9601/10000], train_Loss: 1.4290992434579097e-12,test_Loss:4.574694633483887, r2_store:0.3293036854202628\n",
            "torch.Size([80, 42])\n",
            "Epoch [9602/10000], train_Loss: 1.374064056980373e-12,test_Loss:4.574694633483887, r2_store:0.32930364426196723\n",
            "torch.Size([80, 42])\n",
            "Epoch [9603/10000], train_Loss: 1.2233949747350592e-12,test_Loss:4.574694633483887, r2_store:0.32930373824429526\n",
            "torch.Size([80, 42])\n",
            "Epoch [9604/10000], train_Loss: 1.2862086612788759e-12,test_Loss:4.574695587158203, r2_store:0.3293036885209081\n",
            "torch.Size([80, 42])\n",
            "Epoch [9605/10000], train_Loss: 1.3222381089333934e-12,test_Loss:4.574695110321045, r2_store:0.3293036911802423\n",
            "torch.Size([80, 42])\n",
            "Epoch [9606/10000], train_Loss: 1.3918255653902478e-12,test_Loss:4.5746941566467285, r2_store:0.32930365270333595\n",
            "torch.Size([80, 42])\n",
            "Epoch [9607/10000], train_Loss: 1.4777630074486181e-12,test_Loss:4.574695110321045, r2_store:0.3293036402216465\n",
            "torch.Size([80, 42])\n",
            "Epoch [9608/10000], train_Loss: 1.2816108851260166e-12,test_Loss:4.574695587158203, r2_store:0.3293036548574194\n",
            "torch.Size([80, 42])\n",
            "Epoch [9609/10000], train_Loss: 1.226662543242496e-12,test_Loss:4.574696063995361, r2_store:0.3293037186425354\n",
            "torch.Size([80, 42])\n",
            "Epoch [9610/10000], train_Loss: 1.260078846820889e-12,test_Loss:4.574695587158203, r2_store:0.32930366006355005\n",
            "torch.Size([80, 42])\n",
            "Epoch [9611/10000], train_Loss: 1.2303824408962938e-12,test_Loss:4.5746965408325195, r2_store:0.32930368052458314\n",
            "torch.Size([80, 42])\n",
            "Epoch [9612/10000], train_Loss: 1.0101537661899584e-12,test_Loss:4.574695110321045, r2_store:0.3293037107561393\n",
            "torch.Size([80, 42])\n",
            "Epoch [9613/10000], train_Loss: 1.2319693876161608e-12,test_Loss:4.5746965408325195, r2_store:0.32930363621624015\n",
            "torch.Size([80, 42])\n",
            "Epoch [9614/10000], train_Loss: 1.4166570477466833e-12,test_Loss:4.574694633483887, r2_store:0.3293037384436466\n",
            "torch.Size([80, 42])\n",
            "Epoch [9615/10000], train_Loss: 1.2973733415702626e-12,test_Loss:4.5746965408325195, r2_store:0.329303682607881\n",
            "torch.Size([80, 42])\n",
            "Epoch [9616/10000], train_Loss: 9.655283300311068e-13,test_Loss:4.574695587158203, r2_store:0.3293036317937188\n",
            "torch.Size([80, 42])\n",
            "Epoch [9617/10000], train_Loss: 9.080555860192796e-13,test_Loss:4.574694633483887, r2_store:0.32930368333855\n",
            "torch.Size([80, 42])\n",
            "Epoch [9618/10000], train_Loss: 1.0036020408818458e-12,test_Loss:4.574694633483887, r2_store:0.3293036352748576\n",
            "torch.Size([80, 42])\n",
            "Epoch [9619/10000], train_Loss: 9.983319509618283e-13,test_Loss:4.574695110321045, r2_store:0.32930357847253255\n",
            "torch.Size([80, 42])\n",
            "Epoch [9620/10000], train_Loss: 9.342914896598442e-13,test_Loss:4.574695110321045, r2_store:0.3293035695047477\n",
            "torch.Size([80, 42])\n",
            "Epoch [9621/10000], train_Loss: 1.0739909395846015e-12,test_Loss:4.574694633483887, r2_store:0.32930365363889436\n",
            "torch.Size([80, 42])\n",
            "Epoch [9622/10000], train_Loss: 9.469980138607226e-13,test_Loss:4.574695110321045, r2_store:0.3293036416609507\n",
            "torch.Size([80, 42])\n",
            "Epoch [9623/10000], train_Loss: 9.765771091102549e-13,test_Loss:4.574695110321045, r2_store:0.3293036272927161\n",
            "torch.Size([80, 42])\n",
            "Epoch [9624/10000], train_Loss: 7.195778803543995e-13,test_Loss:4.5746965408325195, r2_store:0.3293036312994352\n",
            "torch.Size([80, 42])\n",
            "Epoch [9625/10000], train_Loss: 9.645943982797278e-13,test_Loss:4.574696063995361, r2_store:0.3293036396947914\n",
            "torch.Size([80, 42])\n",
            "Epoch [9626/10000], train_Loss: 7.137179844525499e-13,test_Loss:4.574694633483887, r2_store:0.3293036441077589\n",
            "torch.Size([80, 42])\n",
            "Epoch [9627/10000], train_Loss: 7.339094609815078e-13,test_Loss:4.574696063995361, r2_store:0.3293036573010042\n",
            "torch.Size([80, 42])\n",
            "Epoch [9628/10000], train_Loss: 7.918686322980206e-13,test_Loss:4.574696063995361, r2_store:0.32930361791524465\n",
            "torch.Size([80, 42])\n",
            "Epoch [9629/10000], train_Loss: 7.540419569122825e-13,test_Loss:4.5746965408325195, r2_store:0.32930364109002375\n",
            "torch.Size([80, 42])\n",
            "Epoch [9630/10000], train_Loss: 7.222437708662155e-13,test_Loss:4.574695110321045, r2_store:0.3293035674538801\n",
            "torch.Size([80, 42])\n",
            "Epoch [9631/10000], train_Loss: 6.804452834519026e-13,test_Loss:4.574696063995361, r2_store:0.3293034800490926\n",
            "torch.Size([80, 42])\n",
            "Epoch [9632/10000], train_Loss: 6.509015331931933e-13,test_Loss:4.574696063995361, r2_store:0.32930349628720534\n",
            "torch.Size([80, 42])\n",
            "Epoch [9633/10000], train_Loss: 5.594275043208086e-13,test_Loss:4.5746965408325195, r2_store:0.329303551870188\n",
            "torch.Size([80, 42])\n",
            "Epoch [9634/10000], train_Loss: 6.856536280581971e-13,test_Loss:4.5746965408325195, r2_store:0.3293035348481278\n",
            "torch.Size([80, 42])\n",
            "Epoch [9635/10000], train_Loss: 5.20063863935355e-13,test_Loss:4.574696063995361, r2_store:0.3293035495503288\n",
            "torch.Size([80, 42])\n",
            "Epoch [9636/10000], train_Loss: 6.017873916200345e-13,test_Loss:4.574696063995361, r2_store:0.3293035570218086\n",
            "torch.Size([80, 42])\n",
            "Epoch [9637/10000], train_Loss: 5.926189985787367e-13,test_Loss:4.5746965408325195, r2_store:0.32930351478294295\n",
            "torch.Size([80, 42])\n",
            "Epoch [9638/10000], train_Loss: 4.994588184877025e-13,test_Loss:4.574695110321045, r2_store:0.32930353120747746\n",
            "torch.Size([80, 42])\n",
            "Epoch [9639/10000], train_Loss: 6.088553055824675e-13,test_Loss:4.574695110321045, r2_store:0.32930355839564895\n",
            "torch.Size([80, 42])\n",
            "Epoch [9640/10000], train_Loss: 6.160544080077712e-13,test_Loss:4.574695587158203, r2_store:0.3293035389006268\n",
            "torch.Size([80, 42])\n",
            "Epoch [9641/10000], train_Loss: 6.128625168119739e-13,test_Loss:4.574695587158203, r2_store:0.3293034903300829\n",
            "torch.Size([80, 42])\n",
            "Epoch [9642/10000], train_Loss: 6.030405124909932e-13,test_Loss:4.5746965408325195, r2_store:0.32930350728900093\n",
            "torch.Size([80, 42])\n",
            "Epoch [9643/10000], train_Loss: 6.030592691885772e-13,test_Loss:4.5746965408325195, r2_store:0.3293034953610412\n",
            "torch.Size([80, 42])\n",
            "Epoch [9644/10000], train_Loss: 5.054602569831701e-13,test_Loss:4.574696063995361, r2_store:0.32930348646087726\n",
            "torch.Size([80, 42])\n",
            "Epoch [9645/10000], train_Loss: 5.614536613407495e-13,test_Loss:4.5746965408325195, r2_store:0.32930352142517294\n",
            "torch.Size([80, 42])\n",
            "Epoch [9646/10000], train_Loss: 4.79963291333263e-13,test_Loss:4.5746965408325195, r2_store:0.32930352676366537\n",
            "torch.Size([80, 42])\n",
            "Epoch [9647/10000], train_Loss: 5.232015992326366e-13,test_Loss:4.5746965408325195, r2_store:0.32930352531725426\n",
            "torch.Size([80, 42])\n",
            "Epoch [9648/10000], train_Loss: 4.716345586644466e-13,test_Loss:4.5746965408325195, r2_store:0.3293036059841091\n",
            "torch.Size([80, 42])\n",
            "Epoch [9649/10000], train_Loss: 5.433181573914758e-13,test_Loss:4.574695587158203, r2_store:0.3293035907452979\n",
            "torch.Size([80, 42])\n",
            "Epoch [9650/10000], train_Loss: 5.364916952528553e-13,test_Loss:4.574696063995361, r2_store:0.3293035078742027\n",
            "torch.Size([80, 42])\n",
            "Epoch [9651/10000], train_Loss: 5.443354100798103e-13,test_Loss:4.5746965408325195, r2_store:0.3293035781479252\n",
            "torch.Size([80, 42])\n",
            "Epoch [9652/10000], train_Loss: 4.937675160236743e-13,test_Loss:4.5746965408325195, r2_store:0.32930363755883696\n",
            "torch.Size([80, 42])\n",
            "Epoch [9653/10000], train_Loss: 5.70678216054582e-13,test_Loss:4.5746965408325195, r2_store:0.32930360015718096\n",
            "torch.Size([80, 42])\n",
            "Epoch [9654/10000], train_Loss: 5.34435017941759e-13,test_Loss:4.5746965408325195, r2_store:0.32930357926399667\n",
            "torch.Size([80, 42])\n",
            "Epoch [9655/10000], train_Loss: 4.59415166499666e-13,test_Loss:4.5746965408325195, r2_store:0.32930358525688463\n",
            "torch.Size([80, 42])\n",
            "Epoch [9656/10000], train_Loss: 4.663783465322369e-13,test_Loss:4.574696063995361, r2_store:0.32930355923417165\n",
            "torch.Size([80, 42])\n",
            "Epoch [9657/10000], train_Loss: 5.311064088520112e-13,test_Loss:4.5746965408325195, r2_store:0.32930355471653294\n",
            "torch.Size([80, 42])\n",
            "Epoch [9658/10000], train_Loss: 5.089671631201831e-13,test_Loss:4.5746965408325195, r2_store:0.329303523365458\n",
            "torch.Size([80, 42])\n",
            "Epoch [9659/10000], train_Loss: 4.512827557392324e-13,test_Loss:4.574696063995361, r2_store:0.32930361754180804\n",
            "torch.Size([80, 42])\n",
            "Epoch [9660/10000], train_Loss: 5.051264853443704e-13,test_Loss:4.574696063995361, r2_store:0.32930359491031536\n",
            "torch.Size([80, 42])\n",
            "Epoch [9661/10000], train_Loss: 4.5288564023103495e-13,test_Loss:4.574694633483887, r2_store:0.32930363131183926\n",
            "torch.Size([80, 42])\n",
            "Epoch [9662/10000], train_Loss: 4.383493622337614e-13,test_Loss:4.574695110321045, r2_store:0.32930365119615757\n",
            "torch.Size([80, 42])\n",
            "Epoch [9663/10000], train_Loss: 4.465677773315274e-13,test_Loss:4.5746965408325195, r2_store:0.32930358681545857\n",
            "torch.Size([80, 42])\n",
            "Epoch [9664/10000], train_Loss: 4.981279061108679e-13,test_Loss:4.574695587158203, r2_store:0.3293035383689167\n",
            "torch.Size([80, 42])\n",
            "Epoch [9665/10000], train_Loss: 4.919321785860908e-13,test_Loss:4.574695587158203, r2_store:0.3293035448238265\n",
            "torch.Size([80, 42])\n",
            "Epoch [9666/10000], train_Loss: 3.946669380194834e-13,test_Loss:4.574696063995361, r2_store:0.32930355294540803\n",
            "torch.Size([80, 42])\n",
            "Epoch [9667/10000], train_Loss: 4.420956602104592e-13,test_Loss:4.5746965408325195, r2_store:0.32930350997413793\n",
            "torch.Size([80, 42])\n",
            "Epoch [9668/10000], train_Loss: 3.714438424808758e-13,test_Loss:4.574697017669678, r2_store:0.32930347001642646\n",
            "torch.Size([80, 42])\n",
            "Epoch [9669/10000], train_Loss: 4.379684006954043e-13,test_Loss:4.5746965408325195, r2_store:0.3293035056327078\n",
            "torch.Size([80, 42])\n",
            "Epoch [9670/10000], train_Loss: 3.382773119779692e-13,test_Loss:4.5746965408325195, r2_store:0.3293035702488044\n",
            "torch.Size([80, 42])\n",
            "Epoch [9671/10000], train_Loss: 4.1740498861117525e-13,test_Loss:4.574697017669678, r2_store:0.3293034950000625\n",
            "torch.Size([80, 42])\n",
            "Epoch [9672/10000], train_Loss: 3.6982846255903534e-13,test_Loss:4.574697494506836, r2_store:0.3293034536471374\n",
            "torch.Size([80, 42])\n",
            "Epoch [9673/10000], train_Loss: 3.162123340949563e-13,test_Loss:4.5746965408325195, r2_store:0.3293034947878247\n",
            "torch.Size([80, 42])\n",
            "Epoch [9674/10000], train_Loss: 4.0668786697659054e-13,test_Loss:4.5746965408325195, r2_store:0.3293035190764181\n",
            "torch.Size([80, 42])\n",
            "Epoch [9675/10000], train_Loss: 3.2858091247867094e-13,test_Loss:4.5746965408325195, r2_store:0.32930348643779694\n",
            "torch.Size([80, 42])\n",
            "Epoch [9676/10000], train_Loss: 3.6123672954822827e-13,test_Loss:4.5746965408325195, r2_store:0.32930348800687237\n",
            "torch.Size([80, 42])\n",
            "Epoch [9677/10000], train_Loss: 3.5084297121158736e-13,test_Loss:4.5746965408325195, r2_store:0.329303506764005\n",
            "torch.Size([80, 42])\n",
            "Epoch [9678/10000], train_Loss: 3.471313405993548e-13,test_Loss:4.574696063995361, r2_store:0.3293035484432143\n",
            "torch.Size([80, 42])\n",
            "Epoch [9679/10000], train_Loss: 3.3340273901047435e-13,test_Loss:4.574697017669678, r2_store:0.32930350817611886\n",
            "torch.Size([80, 42])\n",
            "Epoch [9680/10000], train_Loss: 4.462819003236973e-13,test_Loss:4.574695587158203, r2_store:0.32930351544697645\n",
            "torch.Size([80, 42])\n",
            "Epoch [9681/10000], train_Loss: 3.4974315652781807e-13,test_Loss:4.574694633483887, r2_store:0.32930354996766864\n",
            "torch.Size([80, 42])\n",
            "Epoch [9682/10000], train_Loss: 5.132942682006814e-13,test_Loss:4.5746965408325195, r2_store:0.3293035389639578\n",
            "torch.Size([80, 42])\n",
            "Epoch [9683/10000], train_Loss: 3.4580254241675656e-13,test_Loss:4.5746965408325195, r2_store:0.3293034722859328\n",
            "torch.Size([80, 42])\n",
            "Epoch [9684/10000], train_Loss: 3.232136780439987e-13,test_Loss:4.574695110321045, r2_store:0.3293035488138889\n",
            "torch.Size([80, 42])\n",
            "Epoch [9685/10000], train_Loss: 3.0238103145528716e-13,test_Loss:4.574696063995361, r2_store:0.3293035230274757\n",
            "torch.Size([80, 42])\n",
            "Epoch [9686/10000], train_Loss: 3.605650391973192e-13,test_Loss:4.5746965408325195, r2_store:0.32930340810943415\n",
            "torch.Size([80, 42])\n",
            "Epoch [9687/10000], train_Loss: 3.3167010262367957e-13,test_Loss:4.574697017669678, r2_store:0.3293034118259974\n",
            "torch.Size([80, 42])\n",
            "Epoch [9688/10000], train_Loss: 3.2409562230120703e-13,test_Loss:4.574695587158203, r2_store:0.3293034923588767\n",
            "torch.Size([80, 42])\n",
            "Epoch [9689/10000], train_Loss: 3.477586328713006e-13,test_Loss:4.5746965408325195, r2_store:0.3293035091739317\n",
            "torch.Size([80, 42])\n",
            "Epoch [9690/10000], train_Loss: 2.2405619297827944e-13,test_Loss:4.5746965408325195, r2_store:0.3293034797681764\n",
            "torch.Size([80, 42])\n",
            "Epoch [9691/10000], train_Loss: 3.3565441008229224e-13,test_Loss:4.574695587158203, r2_store:0.32930352076572\n",
            "torch.Size([80, 42])\n",
            "Epoch [9692/10000], train_Loss: 2.880418072028629e-13,test_Loss:4.574695587158203, r2_store:0.3293035329118721\n",
            "torch.Size([80, 42])\n",
            "Epoch [9693/10000], train_Loss: 2.7761403202306023e-13,test_Loss:4.5746965408325195, r2_store:0.32930348451339697\n",
            "torch.Size([80, 42])\n",
            "Epoch [9694/10000], train_Loss: 2.788741459980315e-13,test_Loss:4.5746965408325195, r2_store:0.32930347102491353\n",
            "torch.Size([80, 42])\n",
            "Epoch [9695/10000], train_Loss: 3.001002224500837e-13,test_Loss:4.5746965408325195, r2_store:0.3293034795952404\n",
            "torch.Size([80, 42])\n",
            "Epoch [9696/10000], train_Loss: 2.0543427527684732e-13,test_Loss:4.574695587158203, r2_store:0.3293034693612137\n",
            "torch.Size([80, 42])\n",
            "Epoch [9697/10000], train_Loss: 2.5582660989620365e-13,test_Loss:4.574695587158203, r2_store:0.3293034930458498\n",
            "torch.Size([80, 42])\n",
            "Epoch [9698/10000], train_Loss: 2.626239612064929e-13,test_Loss:4.574697494506836, r2_store:0.32930352074485936\n",
            "torch.Size([80, 42])\n",
            "Epoch [9699/10000], train_Loss: 2.809232067888662e-13,test_Loss:4.574697494506836, r2_store:0.32930345063565203\n",
            "torch.Size([80, 42])\n",
            "Epoch [9700/10000], train_Loss: 2.30449692531845e-13,test_Loss:4.574697494506836, r2_store:0.32930347896482004\n",
            "torch.Size([80, 42])\n",
            "Epoch [9701/10000], train_Loss: 2.3319817214415006e-13,test_Loss:4.574697017669678, r2_store:0.32930347938980686\n",
            "torch.Size([80, 42])\n",
            "Epoch [9702/10000], train_Loss: 2.1957574105301025e-13,test_Loss:4.574698448181152, r2_store:0.32930351340249775\n",
            "torch.Size([80, 42])\n",
            "Epoch [9703/10000], train_Loss: 2.6030566591117577e-13,test_Loss:4.5746965408325195, r2_store:0.3293034903049653\n",
            "torch.Size([80, 42])\n",
            "Epoch [9704/10000], train_Loss: 2.439957957900418e-13,test_Loss:4.5746965408325195, r2_store:0.3293034855129844\n",
            "torch.Size([80, 42])\n",
            "Epoch [9705/10000], train_Loss: 2.595971940015651e-13,test_Loss:4.5746965408325195, r2_store:0.3293034541807014\n",
            "torch.Size([80, 42])\n",
            "Epoch [9706/10000], train_Loss: 2.6295908809800816e-13,test_Loss:4.574697494506836, r2_store:0.3293034261635992\n",
            "torch.Size([80, 42])\n",
            "Epoch [9707/10000], train_Loss: 2.0759088892319255e-13,test_Loss:4.574697494506836, r2_store:0.32930344576585946\n",
            "torch.Size([80, 42])\n",
            "Epoch [9708/10000], train_Loss: 1.826282181038863e-13,test_Loss:4.574697494506836, r2_store:0.32930345902584435\n",
            "torch.Size([80, 42])\n",
            "Epoch [9709/10000], train_Loss: 1.8264694769641598e-13,test_Loss:4.574697017669678, r2_store:0.32930344470667117\n",
            "torch.Size([80, 42])\n",
            "Epoch [9710/10000], train_Loss: 1.7825949321249174e-13,test_Loss:4.574697017669678, r2_store:0.32930348235577056\n",
            "torch.Size([80, 42])\n",
            "Epoch [9711/10000], train_Loss: 1.8348794976908583e-13,test_Loss:4.574697017669678, r2_store:0.3293034735346243\n",
            "torch.Size([80, 42])\n",
            "Epoch [9712/10000], train_Loss: 1.8058471384918562e-13,test_Loss:4.5746965408325195, r2_store:0.3293034265624222\n",
            "torch.Size([80, 42])\n",
            "Epoch [9713/10000], train_Loss: 2.4146171715734577e-13,test_Loss:4.574697494506836, r2_store:0.32930340911746536\n",
            "torch.Size([80, 42])\n",
            "Epoch [9714/10000], train_Loss: 1.9993937603636491e-13,test_Loss:4.574697494506836, r2_store:0.32930340681605785\n",
            "torch.Size([80, 42])\n",
            "Epoch [9715/10000], train_Loss: 1.961278361939378e-13,test_Loss:4.574697017669678, r2_store:0.3293034917562151\n",
            "torch.Size([80, 42])\n",
            "Epoch [9716/10000], train_Loss: 2.065583760892803e-13,test_Loss:4.574697017669678, r2_store:0.32930342975140137\n",
            "torch.Size([80, 42])\n",
            "Epoch [9717/10000], train_Loss: 1.8421584245011113e-13,test_Loss:4.5746965408325195, r2_store:0.3293034382166209\n",
            "torch.Size([80, 42])\n",
            "Epoch [9718/10000], train_Loss: 2.1289705567049955e-13,test_Loss:4.574697017669678, r2_store:0.3293034666974328\n",
            "torch.Size([80, 42])\n",
            "Epoch [9719/10000], train_Loss: 1.8668538394849e-13,test_Loss:4.574696063995361, r2_store:0.329303449090807\n",
            "torch.Size([80, 42])\n",
            "Epoch [9720/10000], train_Loss: 1.7308307836017695e-13,test_Loss:4.574696063995361, r2_store:0.32930347161478524\n",
            "torch.Size([80, 42])\n",
            "Epoch [9721/10000], train_Loss: 1.9079945685462202e-13,test_Loss:4.574697017669678, r2_store:0.32930348856474756\n",
            "torch.Size([80, 42])\n",
            "Epoch [9722/10000], train_Loss: 2.2125287984110092e-13,test_Loss:4.574697971343994, r2_store:0.3293034684347702\n",
            "torch.Size([80, 42])\n",
            "Epoch [9723/10000], train_Loss: 2.482986147418764e-13,test_Loss:4.574697971343994, r2_store:0.3293035032966839\n",
            "torch.Size([80, 42])\n",
            "Epoch [9724/10000], train_Loss: 2.2720298136370137e-13,test_Loss:4.574697971343994, r2_store:0.3293034784653027\n",
            "torch.Size([80, 42])\n",
            "Epoch [9725/10000], train_Loss: 2.1917328520658363e-13,test_Loss:4.574698448181152, r2_store:0.32930346957253254\n",
            "torch.Size([80, 42])\n",
            "Epoch [9726/10000], train_Loss: 2.2337549019681158e-13,test_Loss:4.574698448181152, r2_store:0.32930346682821765\n",
            "torch.Size([80, 42])\n",
            "Epoch [9727/10000], train_Loss: 2.0160053639493858e-13,test_Loss:4.574698448181152, r2_store:0.32930349555732585\n",
            "torch.Size([80, 42])\n",
            "Epoch [9728/10000], train_Loss: 1.8516716209383138e-13,test_Loss:4.574697971343994, r2_store:0.3293034451983067\n",
            "torch.Size([80, 42])\n",
            "Epoch [9729/10000], train_Loss: 2.0005386778577938e-13,test_Loss:4.574698448181152, r2_store:0.3293034283180648\n",
            "torch.Size([80, 42])\n",
            "Epoch [9730/10000], train_Loss: 2.541009124033128e-13,test_Loss:4.574698448181152, r2_store:0.3293034730466934\n",
            "torch.Size([80, 42])\n",
            "Epoch [9731/10000], train_Loss: 1.7209497715775512e-13,test_Loss:4.574698448181152, r2_store:0.32930345104971226\n",
            "torch.Size([80, 42])\n",
            "Epoch [9732/10000], train_Loss: 2.1625825858805764e-13,test_Loss:4.574698448181152, r2_store:0.3293034899351688\n",
            "torch.Size([80, 42])\n",
            "Epoch [9733/10000], train_Loss: 1.995598104083049e-13,test_Loss:4.574698448181152, r2_store:0.3293034663904312\n",
            "torch.Size([80, 42])\n",
            "Epoch [9734/10000], train_Loss: 1.8408191637675486e-13,test_Loss:4.574698448181152, r2_store:0.32930350542093156\n",
            "torch.Size([80, 42])\n",
            "Epoch [9735/10000], train_Loss: 1.9690707940035745e-13,test_Loss:4.574698448181152, r2_store:0.3293034771756663\n",
            "torch.Size([80, 42])\n",
            "Epoch [9736/10000], train_Loss: 2.1805265384110262e-13,test_Loss:4.574698448181152, r2_store:0.3293034859037389\n",
            "torch.Size([80, 42])\n",
            "Epoch [9737/10000], train_Loss: 2.2194954749955864e-13,test_Loss:4.574698448181152, r2_store:0.32930347744906385\n",
            "torch.Size([80, 42])\n",
            "Epoch [9738/10000], train_Loss: 1.9401979480491993e-13,test_Loss:4.574698448181152, r2_store:0.32930346741399996\n",
            "torch.Size([80, 42])\n",
            "Epoch [9739/10000], train_Loss: 1.5424120314300183e-13,test_Loss:4.5746989250183105, r2_store:0.32930346261931975\n",
            "torch.Size([80, 42])\n",
            "Epoch [9740/10000], train_Loss: 1.6682350487996767e-13,test_Loss:4.574698448181152, r2_store:0.3293034723721172\n",
            "torch.Size([80, 42])\n",
            "Epoch [9741/10000], train_Loss: 1.6336793571582187e-13,test_Loss:4.5746989250183105, r2_store:0.3293034034536342\n",
            "torch.Size([80, 42])\n",
            "Epoch [9742/10000], train_Loss: 2.1266183800917882e-13,test_Loss:4.574698448181152, r2_store:0.3293035303485241\n",
            "torch.Size([80, 42])\n",
            "Epoch [9743/10000], train_Loss: 1.5729640354990304e-13,test_Loss:4.574697971343994, r2_store:0.32930347904470725\n",
            "torch.Size([80, 42])\n",
            "Epoch [9744/10000], train_Loss: 1.8270316357905936e-13,test_Loss:4.574698448181152, r2_store:0.3293034581509269\n",
            "torch.Size([80, 42])\n",
            "Epoch [9745/10000], train_Loss: 1.6415203072696338e-13,test_Loss:4.574698448181152, r2_store:0.3293034517537534\n",
            "torch.Size([80, 42])\n",
            "Epoch [9746/10000], train_Loss: 1.5155585120218973e-13,test_Loss:4.574697971343994, r2_store:0.3293034943085862\n",
            "torch.Size([80, 42])\n",
            "Epoch [9747/10000], train_Loss: 1.709604680044663e-13,test_Loss:4.574697971343994, r2_store:0.3293034973846516\n",
            "torch.Size([80, 42])\n",
            "Epoch [9748/10000], train_Loss: 1.8760271385410282e-13,test_Loss:4.574698448181152, r2_store:0.3293034810742127\n",
            "torch.Size([80, 42])\n",
            "Epoch [9749/10000], train_Loss: 2.313558958126627e-13,test_Loss:4.574698448181152, r2_store:0.32930353331768025\n",
            "torch.Size([80, 42])\n",
            "Epoch [9750/10000], train_Loss: 1.4764994511317492e-13,test_Loss:4.5746989250183105, r2_store:0.32930355079155016\n",
            "torch.Size([80, 42])\n",
            "Epoch [9751/10000], train_Loss: 2.8569090452720824e-13,test_Loss:4.574698448181152, r2_store:0.3293035646612055\n",
            "torch.Size([80, 42])\n",
            "Epoch [9752/10000], train_Loss: 1.36352734658729e-13,test_Loss:4.574700355529785, r2_store:0.3293034823106782\n",
            "torch.Size([80, 42])\n",
            "Epoch [9753/10000], train_Loss: 2.103865719875822e-13,test_Loss:4.574699878692627, r2_store:0.32930345848718623\n",
            "torch.Size([80, 42])\n",
            "Epoch [9754/10000], train_Loss: 1.943313538517108e-13,test_Loss:4.574698448181152, r2_store:0.32930346388720266\n",
            "torch.Size([80, 42])\n",
            "Epoch [9755/10000], train_Loss: 4.590474051227589e-13,test_Loss:4.574699401855469, r2_store:0.3293034645527704\n",
            "torch.Size([80, 42])\n",
            "Epoch [9756/10000], train_Loss: 1.9439242153907604e-13,test_Loss:4.574699401855469, r2_store:0.32930347675522653\n",
            "torch.Size([80, 42])\n",
            "Epoch [9757/10000], train_Loss: 1.5153018271575613e-13,test_Loss:4.574699401855469, r2_store:0.32930352095492244\n",
            "torch.Size([80, 42])\n",
            "Epoch [9758/10000], train_Loss: 2.1683418678208194e-13,test_Loss:4.574698448181152, r2_store:0.3293035159784775\n",
            "torch.Size([80, 42])\n",
            "Epoch [9759/10000], train_Loss: 1.7251200197087452e-13,test_Loss:4.574698448181152, r2_store:0.32930347150523165\n",
            "torch.Size([80, 42])\n",
            "Epoch [9760/10000], train_Loss: 2.64630683902492e-13,test_Loss:4.574697494506836, r2_store:0.32930349014229077\n",
            "torch.Size([80, 42])\n",
            "Epoch [9761/10000], train_Loss: 1.6705595782574856e-13,test_Loss:4.574697494506836, r2_store:0.32930356709396147\n",
            "torch.Size([80, 42])\n",
            "Epoch [9762/10000], train_Loss: 1.8623782529168798e-13,test_Loss:4.574698448181152, r2_store:0.32930350846504575\n",
            "torch.Size([80, 42])\n",
            "Epoch [9763/10000], train_Loss: 1.1649223794797658e-13,test_Loss:4.5746989250183105, r2_store:0.32930352567771926\n",
            "torch.Size([80, 42])\n",
            "Epoch [9764/10000], train_Loss: 1.3473041584298462e-13,test_Loss:4.574699401855469, r2_store:0.32930350945325615\n",
            "torch.Size([80, 42])\n",
            "Epoch [9765/10000], train_Loss: 2.66935074304947e-13,test_Loss:4.574699878692627, r2_store:0.32930346320464077\n",
            "torch.Size([80, 42])\n",
            "Epoch [9766/10000], train_Loss: 1.6316600306119644e-13,test_Loss:4.574699878692627, r2_store:0.3293034433773603\n",
            "torch.Size([80, 42])\n",
            "Epoch [9767/10000], train_Loss: 1.8254842082399136e-13,test_Loss:4.5746989250183105, r2_store:0.3293034822354596\n",
            "torch.Size([80, 42])\n",
            "Epoch [9768/10000], train_Loss: 2.343077175424174e-13,test_Loss:4.574699401855469, r2_store:0.3293035056803145\n",
            "torch.Size([80, 42])\n",
            "Epoch [9769/10000], train_Loss: 1.9899845118097337e-13,test_Loss:4.574700355529785, r2_store:0.32930347705306184\n",
            "torch.Size([80, 42])\n",
            "Epoch [9770/10000], train_Loss: 1.5484210864457476e-13,test_Loss:4.574700355529785, r2_store:0.32930349634672396\n",
            "torch.Size([80, 42])\n",
            "Epoch [9771/10000], train_Loss: 1.6378773879700825e-13,test_Loss:4.574699878692627, r2_store:0.32930346914421726\n",
            "torch.Size([80, 42])\n",
            "Epoch [9772/10000], train_Loss: 1.9591342166180165e-13,test_Loss:4.574700355529785, r2_store:0.3293034799289086\n",
            "torch.Size([80, 42])\n",
            "Epoch [9773/10000], train_Loss: 1.362750244680161e-13,test_Loss:4.574700355529785, r2_store:0.3293034278435458\n",
            "torch.Size([80, 42])\n",
            "Epoch [9774/10000], train_Loss: 1.5301857545814423e-13,test_Loss:4.574699401855469, r2_store:0.32930340268702196\n",
            "torch.Size([80, 42])\n",
            "Epoch [9775/10000], train_Loss: 1.9892351925832746e-13,test_Loss:4.5746989250183105, r2_store:0.3293034328461971\n",
            "torch.Size([80, 42])\n",
            "Epoch [9776/10000], train_Loss: 1.2601378274190722e-13,test_Loss:4.574699878692627, r2_store:0.3293035007409636\n",
            "torch.Size([80, 42])\n",
            "Epoch [9777/10000], train_Loss: 9.636041964355968e-14,test_Loss:4.574699401855469, r2_store:0.32930343306044796\n",
            "torch.Size([80, 42])\n",
            "Epoch [9778/10000], train_Loss: 1.7461795627071036e-13,test_Loss:4.574698448181152, r2_store:0.32930345798763516\n",
            "torch.Size([80, 42])\n",
            "Epoch [9779/10000], train_Loss: 1.1268555668653493e-13,test_Loss:4.574698448181152, r2_store:0.32930346124875254\n",
            "torch.Size([80, 42])\n",
            "Epoch [9780/10000], train_Loss: 1.452095415481816e-13,test_Loss:4.574698448181152, r2_store:0.32930343131625117\n",
            "torch.Size([80, 42])\n",
            "Epoch [9781/10000], train_Loss: 1.6588604947152807e-13,test_Loss:4.574698448181152, r2_store:0.32930354433194975\n",
            "torch.Size([80, 42])\n",
            "Epoch [9782/10000], train_Loss: 1.6476125748021014e-13,test_Loss:4.574699878692627, r2_store:0.32930342486834785\n",
            "torch.Size([80, 42])\n",
            "Epoch [9783/10000], train_Loss: 2.149135090809967e-13,test_Loss:4.574699878692627, r2_store:0.32930345088194657\n",
            "torch.Size([80, 42])\n",
            "Epoch [9784/10000], train_Loss: 1.7600226560453985e-13,test_Loss:4.574698448181152, r2_store:0.3293035036594564\n",
            "torch.Size([80, 42])\n",
            "Epoch [9785/10000], train_Loss: 2.6548901965739446e-13,test_Loss:4.574699878692627, r2_store:0.3293034032195403\n",
            "torch.Size([80, 42])\n",
            "Epoch [9786/10000], train_Loss: 2.7501959043441104e-13,test_Loss:4.5746989250183105, r2_store:0.3293034702408373\n",
            "torch.Size([80, 42])\n",
            "Epoch [9787/10000], train_Loss: 1.617199484136439e-13,test_Loss:4.5746989250183105, r2_store:0.32930353852035565\n",
            "torch.Size([80, 42])\n",
            "Epoch [9788/10000], train_Loss: 1.6906059343256563e-13,test_Loss:4.574699878692627, r2_store:0.3293035180104189\n",
            "torch.Size([80, 42])\n",
            "Epoch [9789/10000], train_Loss: 1.5930797805062402e-13,test_Loss:4.574699878692627, r2_store:0.3293034832968369\n",
            "torch.Size([80, 42])\n",
            "Epoch [9790/10000], train_Loss: 1.9729495272756414e-13,test_Loss:4.574699878692627, r2_store:0.3293034432852644\n",
            "torch.Size([80, 42])\n",
            "Epoch [9791/10000], train_Loss: 1.3783071906026123e-13,test_Loss:4.5746989250183105, r2_store:0.32930342532402623\n",
            "torch.Size([80, 42])\n",
            "Epoch [9792/10000], train_Loss: 1.851456542332347e-13,test_Loss:4.574699878692627, r2_store:0.3293034565981927\n",
            "torch.Size([80, 42])\n",
            "Epoch [9793/10000], train_Loss: 1.7037413146958613e-13,test_Loss:4.574700355529785, r2_store:0.3293034165651072\n",
            "torch.Size([80, 42])\n",
            "Epoch [9794/10000], train_Loss: 1.6359968393019064e-13,test_Loss:4.5746989250183105, r2_store:0.3293034283066455\n",
            "torch.Size([80, 42])\n",
            "Epoch [9795/10000], train_Loss: 1.636843465673346e-13,test_Loss:4.5746989250183105, r2_store:0.32930346766188734\n",
            "torch.Size([80, 42])\n",
            "Epoch [9796/10000], train_Loss: 1.3899089669998366e-13,test_Loss:4.5746989250183105, r2_store:0.3293034512098487\n",
            "torch.Size([80, 42])\n",
            "Epoch [9797/10000], train_Loss: 1.4855269249956782e-13,test_Loss:4.574699401855469, r2_store:0.3293033785112284\n",
            "torch.Size([80, 42])\n",
            "Epoch [9798/10000], train_Loss: 2.135340515518891e-13,test_Loss:4.574699401855469, r2_store:0.3293033854322085\n",
            "torch.Size([80, 42])\n",
            "Epoch [9799/10000], train_Loss: 1.7337589426191097e-13,test_Loss:4.5746989250183105, r2_store:0.329303473663502\n",
            "torch.Size([80, 42])\n",
            "Epoch [9800/10000], train_Loss: 1.6700113785340226e-13,test_Loss:4.5746989250183105, r2_store:0.3293034802112509\n",
            "torch.Size([80, 42])\n",
            "Epoch [9801/10000], train_Loss: 1.667541159409286e-13,test_Loss:4.5746989250183105, r2_store:0.32930344559465774\n",
            "torch.Size([80, 42])\n",
            "Epoch [9802/10000], train_Loss: 1.7915461052609577e-13,test_Loss:4.5746989250183105, r2_store:0.3293034877702028\n",
            "torch.Size([80, 42])\n",
            "Epoch [9803/10000], train_Loss: 1.8055487118438796e-13,test_Loss:4.574699878692627, r2_store:0.3293034623979092\n",
            "torch.Size([80, 42])\n",
            "Epoch [9804/10000], train_Loss: 2.0371967730369728e-13,test_Loss:4.5746989250183105, r2_store:0.32930347249042224\n",
            "torch.Size([80, 42])\n",
            "Epoch [9805/10000], train_Loss: 1.3234414107145265e-13,test_Loss:4.5746989250183105, r2_store:0.3293034775138769\n",
            "torch.Size([80, 42])\n",
            "Epoch [9806/10000], train_Loss: 1.4384257944911188e-13,test_Loss:4.5746989250183105, r2_store:0.3293034800607948\n",
            "torch.Size([80, 42])\n",
            "Epoch [9807/10000], train_Loss: 1.8118977997659547e-13,test_Loss:4.574698448181152, r2_store:0.32930346253913334\n",
            "torch.Size([80, 42])\n",
            "Epoch [9808/10000], train_Loss: 1.5587253438930498e-13,test_Loss:4.574699878692627, r2_store:0.3293034523253694\n",
            "torch.Size([80, 42])\n",
            "Epoch [9809/10000], train_Loss: 1.6273093983443232e-13,test_Loss:4.5746989250183105, r2_store:0.3293034538389462\n",
            "torch.Size([80, 42])\n",
            "Epoch [9810/10000], train_Loss: 1.637648350261145e-13,test_Loss:4.5746989250183105, r2_store:0.32930349485443755\n",
            "torch.Size([80, 42])\n",
            "Epoch [9811/10000], train_Loss: 2.0596302712384135e-13,test_Loss:4.574699878692627, r2_store:0.32930340720408935\n",
            "torch.Size([80, 42])\n",
            "Epoch [9812/10000], train_Loss: 2.0073457056724725e-13,test_Loss:4.5746989250183105, r2_store:0.32930344237137643\n",
            "torch.Size([80, 42])\n",
            "Epoch [9813/10000], train_Loss: 1.9459642773035635e-13,test_Loss:4.5746989250183105, r2_store:0.3293035066562171\n",
            "torch.Size([80, 42])\n",
            "Epoch [9814/10000], train_Loss: 1.8300777017941916e-13,test_Loss:4.574700355529785, r2_store:0.32930344187919425\n",
            "torch.Size([80, 42])\n",
            "Epoch [9815/10000], train_Loss: 1.5102849526549278e-13,test_Loss:4.574699878692627, r2_store:0.32930340940591596\n",
            "torch.Size([80, 42])\n",
            "Epoch [9816/10000], train_Loss: 2.4635225500183044e-13,test_Loss:4.574699401855469, r2_store:0.3293034416699461\n",
            "torch.Size([80, 42])\n",
            "Epoch [9817/10000], train_Loss: 1.3348211967169343e-13,test_Loss:4.574699401855469, r2_store:0.32930351984620276\n",
            "torch.Size([80, 42])\n",
            "Epoch [9818/10000], train_Loss: 2.4721473783004266e-13,test_Loss:4.5746989250183105, r2_store:0.32930351654682355\n",
            "torch.Size([80, 42])\n",
            "Epoch [9819/10000], train_Loss: 1.666250416722942e-13,test_Loss:4.574699401855469, r2_store:0.3293034558776443\n",
            "torch.Size([80, 42])\n",
            "Epoch [9820/10000], train_Loss: 2.8406096919120216e-13,test_Loss:4.574698448181152, r2_store:0.32930348516356023\n",
            "torch.Size([80, 42])\n",
            "Epoch [9821/10000], train_Loss: 2.6380078134956297e-13,test_Loss:4.5746989250183105, r2_store:0.3293034451208504\n",
            "torch.Size([80, 42])\n",
            "Epoch [9822/10000], train_Loss: 1.8096566183501556e-13,test_Loss:4.574699401855469, r2_store:0.32930334848222287\n",
            "torch.Size([80, 42])\n",
            "Epoch [9823/10000], train_Loss: 2.530919809666521e-13,test_Loss:4.574698448181152, r2_store:0.3293034622020996\n",
            "torch.Size([80, 42])\n",
            "Epoch [9824/10000], train_Loss: 2.176821277486557e-13,test_Loss:4.574697971343994, r2_store:0.32930354882808444\n",
            "torch.Size([80, 42])\n",
            "Epoch [9825/10000], train_Loss: 2.8041040626633484e-13,test_Loss:4.574699401855469, r2_store:0.32930350133799013\n",
            "torch.Size([80, 42])\n",
            "Epoch [9826/10000], train_Loss: 2.312906810519877e-13,test_Loss:4.574699401855469, r2_store:0.329303506232264\n",
            "torch.Size([80, 42])\n",
            "Epoch [9827/10000], train_Loss: 2.58429399841581e-13,test_Loss:4.5746989250183105, r2_store:0.32930352645841265\n",
            "torch.Size([80, 42])\n",
            "Epoch [9828/10000], train_Loss: 3.0496856125508676e-13,test_Loss:4.5746989250183105, r2_store:0.32930349445081497\n",
            "torch.Size([80, 42])\n",
            "Epoch [9829/10000], train_Loss: 1.641603519786372e-13,test_Loss:4.5746989250183105, r2_store:0.3293034843656597\n",
            "torch.Size([80, 42])\n",
            "Epoch [9830/10000], train_Loss: 2.339128782162525e-13,test_Loss:4.574698448181152, r2_store:0.3293035043839775\n",
            "torch.Size([80, 42])\n",
            "Epoch [9831/10000], train_Loss: 4.0559569591813727e-13,test_Loss:4.574700355529785, r2_store:0.329303449351238\n",
            "torch.Size([80, 42])\n",
            "Epoch [9832/10000], train_Loss: 3.3751959018467337e-13,test_Loss:4.574699401855469, r2_store:0.3293034518281682\n",
            "torch.Size([80, 42])\n",
            "Epoch [9833/10000], train_Loss: 2.0954349637825748e-13,test_Loss:4.5746989250183105, r2_store:0.32930346329832416\n",
            "torch.Size([80, 42])\n",
            "Epoch [9834/10000], train_Loss: 6.27685403653544e-13,test_Loss:4.57470178604126, r2_store:0.32930339943147613\n",
            "torch.Size([80, 42])\n",
            "Epoch [9835/10000], train_Loss: 9.92268116631334e-13,test_Loss:4.574698448181152, r2_store:0.32930350810049935\n",
            "torch.Size([80, 42])\n",
            "Epoch [9836/10000], train_Loss: 7.474229568593671e-13,test_Loss:4.574700355529785, r2_store:0.32930354772440107\n",
            "torch.Size([80, 42])\n",
            "Epoch [9837/10000], train_Loss: 3.178693473802202e-13,test_Loss:4.574699878692627, r2_store:0.3293034683821978\n",
            "torch.Size([80, 42])\n",
            "Epoch [9838/10000], train_Loss: 2.460726121564921e-13,test_Loss:4.574698448181152, r2_store:0.32930339917682117\n",
            "torch.Size([80, 42])\n",
            "Epoch [9839/10000], train_Loss: 4.459710324557914e-13,test_Loss:4.574700355529785, r2_store:0.3293034489463763\n",
            "torch.Size([80, 42])\n",
            "Epoch [9840/10000], train_Loss: 3.3925154894511034e-13,test_Loss:4.574699401855469, r2_store:0.3293034043359544\n",
            "torch.Size([80, 42])\n",
            "Epoch [9841/10000], train_Loss: 2.0143747238819676e-13,test_Loss:4.574698448181152, r2_store:0.32930348273107557\n",
            "torch.Size([80, 42])\n",
            "Epoch [9842/10000], train_Loss: 2.759091512118811e-13,test_Loss:4.574698448181152, r2_store:0.32930346228686536\n",
            "torch.Size([80, 42])\n",
            "Epoch [9843/10000], train_Loss: 2.617309038770166e-13,test_Loss:4.574699878692627, r2_store:0.3293034554147677\n",
            "torch.Size([80, 42])\n",
            "Epoch [9844/10000], train_Loss: 2.0589294700591732e-13,test_Loss:4.574699878692627, r2_store:0.3293034395135491\n",
            "torch.Size([80, 42])\n",
            "Epoch [9845/10000], train_Loss: 3.0772536211906565e-13,test_Loss:4.574699878692627, r2_store:0.32930347188592\n",
            "torch.Size([80, 42])\n",
            "Epoch [9846/10000], train_Loss: 1.827871214847912e-13,test_Loss:4.574700355529785, r2_store:0.32930345660230065\n",
            "torch.Size([80, 42])\n",
            "Epoch [9847/10000], train_Loss: 4.569643274887625e-13,test_Loss:4.574699878692627, r2_store:0.3293035221500744\n",
            "torch.Size([80, 42])\n",
            "Epoch [9848/10000], train_Loss: 2.4610104535846555e-13,test_Loss:4.5746989250183105, r2_store:0.32930350951041487\n",
            "torch.Size([80, 42])\n",
            "Epoch [9849/10000], train_Loss: 2.2000040949144567e-13,test_Loss:4.5746989250183105, r2_store:0.32930340526217194\n",
            "torch.Size([80, 42])\n",
            "Epoch [9850/10000], train_Loss: 1.9278398051113949e-13,test_Loss:4.5746989250183105, r2_store:0.3293033831535973\n",
            "torch.Size([80, 42])\n",
            "Epoch [9851/10000], train_Loss: 2.0550575130506843e-13,test_Loss:4.574698448181152, r2_store:0.32930349204587583\n",
            "torch.Size([80, 42])\n",
            "Epoch [9852/10000], train_Loss: 2.9191509235901303e-13,test_Loss:4.574699878692627, r2_store:0.32930351265684277\n",
            "torch.Size([80, 42])\n",
            "Epoch [9853/10000], train_Loss: 2.4537454858773733e-13,test_Loss:4.574699401855469, r2_store:0.3293035228616662\n",
            "torch.Size([80, 42])\n",
            "Epoch [9854/10000], train_Loss: 2.638347981927247e-13,test_Loss:4.5746965408325195, r2_store:0.32930353396120304\n",
            "torch.Size([80, 42])\n",
            "Epoch [9855/10000], train_Loss: 3.613172315595353e-13,test_Loss:4.574697494506836, r2_store:0.32930345746748757\n",
            "torch.Size([80, 42])\n",
            "Epoch [9856/10000], train_Loss: 1.8099619567869818e-13,test_Loss:4.574700355529785, r2_store:0.3293034596066178\n",
            "torch.Size([80, 42])\n",
            "Epoch [9857/10000], train_Loss: 9.958665836418135e-13,test_Loss:4.574696063995361, r2_store:0.32930359586121727\n",
            "torch.Size([80, 42])\n",
            "Epoch [9858/10000], train_Loss: 1.2912781737969836e-12,test_Loss:4.574699401855469, r2_store:0.32930355449454507\n",
            "torch.Size([80, 42])\n",
            "Epoch [9859/10000], train_Loss: 4.0175572287373673e-13,test_Loss:4.574699878692627, r2_store:0.3293035692251417\n",
            "torch.Size([80, 42])\n",
            "Epoch [9860/10000], train_Loss: 2.889161078347552e-13,test_Loss:4.5746965408325195, r2_store:0.3293035721109294\n",
            "torch.Size([80, 42])\n",
            "Epoch [9861/10000], train_Loss: 1.261320258308385e-12,test_Loss:4.574700832366943, r2_store:0.3293034294436098\n",
            "torch.Size([80, 42])\n",
            "Epoch [9862/10000], train_Loss: 1.9883782120810878e-12,test_Loss:4.574695110321045, r2_store:0.32930376600077593\n",
            "torch.Size([80, 42])\n",
            "Epoch [9863/10000], train_Loss: 2.716117695339415e-12,test_Loss:4.574703216552734, r2_store:0.32930345568450936\n",
            "torch.Size([80, 42])\n",
            "Epoch [9864/10000], train_Loss: 3.407118987983071e-12,test_Loss:4.574694633483887, r2_store:0.32930368999568904\n",
            "torch.Size([80, 42])\n",
            "Epoch [9865/10000], train_Loss: 3.8051046688525325e-12,test_Loss:4.574702262878418, r2_store:0.32930339341200143\n",
            "torch.Size([80, 42])\n",
            "Epoch [9866/10000], train_Loss: 3.2608347445839403e-12,test_Loss:4.574695110321045, r2_store:0.32930358448739716\n",
            "torch.Size([80, 42])\n",
            "Epoch [9867/10000], train_Loss: 2.473272888575684e-12,test_Loss:4.574700355529785, r2_store:0.32930339683287135\n",
            "torch.Size([80, 42])\n",
            "Epoch [9868/10000], train_Loss: 1.4399904879613956e-12,test_Loss:4.574697494506836, r2_store:0.3293034516233049\n",
            "torch.Size([80, 42])\n",
            "Epoch [9869/10000], train_Loss: 3.680986179928347e-13,test_Loss:4.574697494506836, r2_store:0.3293034597893668\n",
            "torch.Size([80, 42])\n",
            "Epoch [9870/10000], train_Loss: 4.151110065495761e-13,test_Loss:4.5746989250183105, r2_store:0.32930337422882017\n",
            "torch.Size([80, 42])\n",
            "Epoch [9871/10000], train_Loss: 5.620761018079734e-13,test_Loss:4.574697494506836, r2_store:0.3293035137107623\n",
            "torch.Size([80, 42])\n",
            "Epoch [9872/10000], train_Loss: 1.8036058215507855e-13,test_Loss:4.574697494506836, r2_store:0.32930352810795294\n",
            "torch.Size([80, 42])\n",
            "Epoch [9873/10000], train_Loss: 3.0028201604935523e-13,test_Loss:4.574698448181152, r2_store:0.3293034686064993\n",
            "torch.Size([80, 42])\n",
            "Epoch [9874/10000], train_Loss: 2.5891859186180644e-13,test_Loss:4.574698448181152, r2_store:0.32930341423377185\n",
            "torch.Size([80, 42])\n",
            "Epoch [9875/10000], train_Loss: 1.868442873293949e-13,test_Loss:4.574698448181152, r2_store:0.32930347717698694\n",
            "torch.Size([80, 42])\n",
            "Epoch [9876/10000], train_Loss: 2.4183503507038684e-13,test_Loss:4.574699401855469, r2_store:0.32930343221016356\n",
            "torch.Size([80, 42])\n",
            "Epoch [9877/10000], train_Loss: 2.939183727131145e-13,test_Loss:4.5746989250183105, r2_store:0.3293034162538867\n",
            "torch.Size([80, 42])\n",
            "Epoch [9878/10000], train_Loss: 1.739115850028089e-13,test_Loss:4.574698448181152, r2_store:0.3293035328516961\n",
            "torch.Size([80, 42])\n",
            "Epoch [9879/10000], train_Loss: 3.604693041454887e-13,test_Loss:4.574699401855469, r2_store:0.32930339171194034\n",
            "torch.Size([80, 42])\n",
            "Epoch [9880/10000], train_Loss: 2.3347643263171847e-13,test_Loss:4.574700355529785, r2_store:0.32930341947194486\n",
            "torch.Size([80, 42])\n",
            "Epoch [9881/10000], train_Loss: 2.480113282712221e-13,test_Loss:4.574698448181152, r2_store:0.32930349377554924\n",
            "torch.Size([80, 42])\n",
            "Epoch [9882/10000], train_Loss: 3.901705347697515e-13,test_Loss:4.5746989250183105, r2_store:0.32930338834939454\n",
            "torch.Size([80, 42])\n",
            "Epoch [9883/10000], train_Loss: 3.011549343234776e-13,test_Loss:4.5746989250183105, r2_store:0.3293034635694798\n",
            "torch.Size([80, 42])\n",
            "Epoch [9884/10000], train_Loss: 2.6513096188993113e-13,test_Loss:4.574696063995361, r2_store:0.3293035394197934\n",
            "torch.Size([80, 42])\n",
            "Epoch [9885/10000], train_Loss: 8.102740483781345e-13,test_Loss:4.574700355529785, r2_store:0.32930338506992496\n",
            "torch.Size([80, 42])\n",
            "Epoch [9886/10000], train_Loss: 1.0509975051711806e-12,test_Loss:4.5746965408325195, r2_store:0.3293035442324763\n",
            "torch.Size([80, 42])\n",
            "Epoch [9887/10000], train_Loss: 5.517010459588079e-13,test_Loss:4.574697017669678, r2_store:0.32930352905331006\n",
            "torch.Size([80, 42])\n",
            "Epoch [9888/10000], train_Loss: 2.733355263049436e-13,test_Loss:4.5746989250183105, r2_store:0.3293035069104666\n",
            "torch.Size([80, 42])\n",
            "Epoch [9889/10000], train_Loss: 9.687014645293202e-13,test_Loss:4.574695587158203, r2_store:0.32930369861648234\n",
            "torch.Size([80, 42])\n",
            "Epoch [9890/10000], train_Loss: 1.98319008784531e-12,test_Loss:4.574700832366943, r2_store:0.3293034692336345\n",
            "torch.Size([80, 42])\n",
            "Epoch [9891/10000], train_Loss: 2.8663328221351092e-12,test_Loss:4.574695110321045, r2_store:0.32930366108066045\n",
            "torch.Size([80, 42])\n",
            "Epoch [9892/10000], train_Loss: 3.531715935325974e-12,test_Loss:4.574702262878418, r2_store:0.32930336878259403\n",
            "torch.Size([80, 42])\n",
            "Epoch [9893/10000], train_Loss: 4.229840002561991e-12,test_Loss:4.574692726135254, r2_store:0.32930373543671787\n",
            "torch.Size([80, 42])\n",
            "Epoch [9894/10000], train_Loss: 4.158725447345191e-12,test_Loss:4.57470178604126, r2_store:0.32930346521275766\n",
            "torch.Size([80, 42])\n",
            "Epoch [9895/10000], train_Loss: 3.5743456805459317e-12,test_Loss:4.574694633483887, r2_store:0.3293035973145584\n",
            "torch.Size([80, 42])\n",
            "Epoch [9896/10000], train_Loss: 2.5561872497165128e-12,test_Loss:4.574700355529785, r2_store:0.32930338401535864\n",
            "torch.Size([80, 42])\n",
            "Epoch [9897/10000], train_Loss: 1.2861142272696524e-12,test_Loss:4.574698448181152, r2_store:0.3293034170141186\n",
            "torch.Size([80, 42])\n",
            "Epoch [9898/10000], train_Loss: 4.566125038837909e-13,test_Loss:4.5746989250183105, r2_store:0.3293034349283528\n",
            "torch.Size([80, 42])\n",
            "Epoch [9899/10000], train_Loss: 2.7568781133836817e-13,test_Loss:4.574700355529785, r2_store:0.32930343906862036\n",
            "torch.Size([80, 42])\n",
            "Epoch [9900/10000], train_Loss: 1.07612595050266e-12,test_Loss:4.574697971343994, r2_store:0.3293036167703811\n",
            "torch.Size([80, 42])\n",
            "Epoch [9901/10000], train_Loss: 1.8426371539703723e-12,test_Loss:4.574702262878418, r2_store:0.32930342159053294\n",
            "torch.Size([80, 42])\n",
            "Epoch [9902/10000], train_Loss: 1.6703146027766125e-12,test_Loss:4.574697494506836, r2_store:0.32930349168935946\n",
            "torch.Size([80, 42])\n",
            "Epoch [9903/10000], train_Loss: 1.2949343203630392e-12,test_Loss:4.574700832366943, r2_store:0.3293033645146104\n",
            "torch.Size([80, 42])\n",
            "Epoch [9904/10000], train_Loss: 1.0831905034383582e-12,test_Loss:4.574698448181152, r2_store:0.3293035101498001\n",
            "torch.Size([80, 42])\n",
            "Epoch [9905/10000], train_Loss: 5.790368184932504e-13,test_Loss:4.574698448181152, r2_store:0.3293034690763854\n",
            "torch.Size([80, 42])\n",
            "Epoch [9906/10000], train_Loss: 4.234439133967566e-13,test_Loss:4.574700355529785, r2_store:0.32930340498408717\n",
            "torch.Size([80, 42])\n",
            "Epoch [9907/10000], train_Loss: 1.7804972990767554e-12,test_Loss:4.574693202972412, r2_store:0.32930359123013153\n",
            "torch.Size([80, 42])\n",
            "Epoch [9908/10000], train_Loss: 4.303073088823828e-12,test_Loss:4.574706077575684, r2_store:0.3293032705886869\n",
            "torch.Size([80, 42])\n",
            "Epoch [9909/10000], train_Loss: 9.394721112165882e-12,test_Loss:4.574690341949463, r2_store:0.329303748717266\n",
            "torch.Size([80, 42])\n",
            "Epoch [9910/10000], train_Loss: 1.5821875060106905e-11,test_Loss:4.574707984924316, r2_store:0.3293032413182918\n",
            "torch.Size([80, 42])\n",
            "Epoch [9911/10000], train_Loss: 2.1524556442775733e-11,test_Loss:4.574687957763672, r2_store:0.3293039064100861\n",
            "torch.Size([80, 42])\n",
            "Epoch [9912/10000], train_Loss: 2.623011183255919e-11,test_Loss:4.574710369110107, r2_store:0.3293031516251791\n",
            "torch.Size([80, 42])\n",
            "Epoch [9913/10000], train_Loss: 3.285742858349927e-11,test_Loss:4.574685573577881, r2_store:0.3293040399338182\n",
            "torch.Size([80, 42])\n",
            "Epoch [9914/10000], train_Loss: 4.062484376676778e-11,test_Loss:4.574711322784424, r2_store:0.3293030191701245\n",
            "torch.Size([80, 42])\n",
            "Epoch [9915/10000], train_Loss: 4.597790551064129e-11,test_Loss:4.5746846199035645, r2_store:0.3293040658518541\n",
            "torch.Size([80, 42])\n",
            "Epoch [9916/10000], train_Loss: 4.6378144380465613e-11,test_Loss:4.574711799621582, r2_store:0.32930305366543655\n",
            "torch.Size([80, 42])\n",
            "Epoch [9917/10000], train_Loss: 4.035708572880381e-11,test_Loss:4.574687480926514, r2_store:0.329304040391151\n",
            "torch.Size([80, 42])\n",
            "Epoch [9918/10000], train_Loss: 3.057431391395582e-11,test_Loss:4.574708461761475, r2_store:0.3293032303257303\n",
            "torch.Size([80, 42])\n",
            "Epoch [9919/10000], train_Loss: 2.2068243066275528e-11,test_Loss:4.574690818786621, r2_store:0.32930374014742414\n",
            "torch.Size([80, 42])\n",
            "Epoch [9920/10000], train_Loss: 1.564878782112089e-11,test_Loss:4.574706077575684, r2_store:0.3293031894379599\n",
            "torch.Size([80, 42])\n",
            "Epoch [9921/10000], train_Loss: 1.0015629818560523e-11,test_Loss:4.5746941566467285, r2_store:0.3293036261201172\n",
            "torch.Size([80, 42])\n",
            "Epoch [9922/10000], train_Loss: 5.366926954936124e-12,test_Loss:4.57470178604126, r2_store:0.3293033763816051\n",
            "torch.Size([80, 42])\n",
            "Epoch [9923/10000], train_Loss: 3.225143025906152e-12,test_Loss:4.574697017669678, r2_store:0.3293036068892268\n",
            "torch.Size([80, 42])\n",
            "Epoch [9924/10000], train_Loss: 1.3249207503687743e-12,test_Loss:4.5746989250183105, r2_store:0.32930348415062294\n",
            "torch.Size([80, 42])\n",
            "Epoch [9925/10000], train_Loss: 3.854007499422274e-13,test_Loss:4.574698448181152, r2_store:0.3293033813100291\n",
            "torch.Size([80, 42])\n",
            "Epoch [9926/10000], train_Loss: 4.857947269280849e-13,test_Loss:4.574697494506836, r2_store:0.3293034627471807\n",
            "torch.Size([80, 42])\n",
            "Epoch [9927/10000], train_Loss: 3.229548518803721e-13,test_Loss:4.574698448181152, r2_store:0.3293035269058754\n",
            "torch.Size([80, 42])\n",
            "Epoch [9928/10000], train_Loss: 3.40621980491132e-13,test_Loss:4.574699401855469, r2_store:0.32930346504456676\n",
            "torch.Size([80, 42])\n",
            "Epoch [9929/10000], train_Loss: 3.3302597875553563e-13,test_Loss:4.574698448181152, r2_store:0.3293034489418656\n",
            "torch.Size([80, 42])\n",
            "Epoch [9930/10000], train_Loss: 2.640214435967181e-13,test_Loss:4.574698448181152, r2_store:0.32930346599095484\n",
            "torch.Size([80, 42])\n",
            "Epoch [9931/10000], train_Loss: 2.3792635071330503e-13,test_Loss:4.5746989250183105, r2_store:0.3293034675647273\n",
            "torch.Size([80, 42])\n",
            "Epoch [9932/10000], train_Loss: 2.6771502224277877e-13,test_Loss:4.5746989250183105, r2_store:0.3293034833444539\n",
            "torch.Size([80, 42])\n",
            "Epoch [9933/10000], train_Loss: 3.4202225470195136e-13,test_Loss:4.574697971343994, r2_store:0.32930353458067496\n",
            "torch.Size([80, 42])\n",
            "Epoch [9934/10000], train_Loss: 2.496315599977844e-13,test_Loss:4.574698448181152, r2_store:0.32930349679270043\n",
            "torch.Size([80, 42])\n",
            "Epoch [9935/10000], train_Loss: 3.684212765593664e-13,test_Loss:4.5746989250183105, r2_store:0.32930347133075033\n",
            "torch.Size([80, 42])\n",
            "Epoch [9936/10000], train_Loss: 1.7677317400675852e-13,test_Loss:4.574697494506836, r2_store:0.32930352717653266\n",
            "torch.Size([80, 42])\n",
            "Epoch [9937/10000], train_Loss: 6.05711336122694e-13,test_Loss:4.574699878692627, r2_store:0.3293033422751084\n",
            "torch.Size([80, 42])\n",
            "Epoch [9938/10000], train_Loss: 1.0800243078340488e-12,test_Loss:4.5746965408325195, r2_store:0.32930351394403357\n",
            "torch.Size([80, 42])\n",
            "Epoch [9939/10000], train_Loss: 1.0171579290646493e-12,test_Loss:4.574701309204102, r2_store:0.32930338716195307\n",
            "torch.Size([80, 42])\n",
            "Epoch [9940/10000], train_Loss: 9.170386889092996e-13,test_Loss:4.574697017669678, r2_store:0.3293035652801052\n",
            "torch.Size([80, 42])\n",
            "Epoch [9941/10000], train_Loss: 4.1380649449564155e-13,test_Loss:4.574698448181152, r2_store:0.32930348322322445\n",
            "torch.Size([80, 42])\n",
            "Epoch [9942/10000], train_Loss: 2.9236335574722716e-13,test_Loss:4.574700355529785, r2_store:0.32930338012098825\n",
            "torch.Size([80, 42])\n",
            "Epoch [9943/10000], train_Loss: 1.0203511213030536e-12,test_Loss:4.574697017669678, r2_store:0.32930351850863926\n",
            "torch.Size([80, 42])\n",
            "Epoch [9944/10000], train_Loss: 2.0935156819917866e-12,test_Loss:4.574702739715576, r2_store:0.3293033550170591\n",
            "torch.Size([80, 42])\n",
            "Epoch [9945/10000], train_Loss: 4.17500279140115e-12,test_Loss:4.574692726135254, r2_store:0.32930376127165273\n",
            "torch.Size([80, 42])\n",
            "Epoch [9946/10000], train_Loss: 8.342561017005146e-12,test_Loss:4.574706077575684, r2_store:0.3293033260106155\n",
            "torch.Size([80, 42])\n",
            "Epoch [9947/10000], train_Loss: 1.539282243334661e-11,test_Loss:4.5746870040893555, r2_store:0.3293039881894164\n",
            "torch.Size([80, 42])\n",
            "Epoch [9948/10000], train_Loss: 2.9987085731209007e-11,test_Loss:4.574713706970215, r2_store:0.3293030414906716\n",
            "torch.Size([80, 42])\n",
            "Epoch [9949/10000], train_Loss: 5.808010669627883e-11,test_Loss:4.574677467346191, r2_store:0.32930436814460384\n",
            "torch.Size([80, 42])\n",
            "Epoch [9950/10000], train_Loss: 1.0900243901934559e-10,test_Loss:4.5747270584106445, r2_store:0.329302381639899\n",
            "torch.Size([80, 42])\n",
            "Epoch [9951/10000], train_Loss: 2.018018668836774e-10,test_Loss:4.574660301208496, r2_store:0.32930498133343766\n",
            "torch.Size([80, 42])\n",
            "Epoch [9952/10000], train_Loss: 3.6111136303418334e-10,test_Loss:4.5747480392456055, r2_store:0.3293015626775406\n",
            "torch.Size([80, 42])\n",
            "Epoch [9953/10000], train_Loss: 6.270221564186329e-10,test_Loss:4.5746307373046875, r2_store:0.3293060628013592\n",
            "torch.Size([80, 42])\n",
            "Epoch [9954/10000], train_Loss: 1.0966559882419347e-09,test_Loss:4.57478666305542, r2_store:0.329300222921565\n",
            "torch.Size([80, 42])\n",
            "Epoch [9955/10000], train_Loss: 1.930175574926807e-09,test_Loss:4.574581623077393, r2_store:0.3293078833828065\n",
            "torch.Size([80, 42])\n",
            "Epoch [9956/10000], train_Loss: 3.3971274682187413e-09,test_Loss:4.574854373931885, r2_store:0.3292975802395023\n",
            "torch.Size([80, 42])\n",
            "Epoch [9957/10000], train_Loss: 5.96681548614697e-09,test_Loss:4.574493408203125, r2_store:0.3293112867269332\n",
            "torch.Size([80, 42])\n",
            "Epoch [9958/10000], train_Loss: 1.0569291220008381e-08,test_Loss:4.574976921081543, r2_store:0.3292930990216604\n",
            "torch.Size([80, 42])\n",
            "Epoch [9959/10000], train_Loss: 1.881553757243637e-08,test_Loss:4.574332237243652, r2_store:0.3293174141221583\n",
            "torch.Size([80, 42])\n",
            "Epoch [9960/10000], train_Loss: 3.364169387509719e-08,test_Loss:4.575193405151367, r2_store:0.3292847886240692\n",
            "torch.Size([80, 42])\n",
            "Epoch [9961/10000], train_Loss: 6.027845955713929e-08,test_Loss:4.574036598205566, r2_store:0.32932857730746357\n",
            "torch.Size([80, 42])\n",
            "Epoch [9962/10000], train_Loss: 1.0894451918375125e-07,test_Loss:4.575597286224365, r2_store:0.32926985771831385\n",
            "torch.Size([80, 42])\n",
            "Epoch [9963/10000], train_Loss: 1.9765279546390957e-07,test_Loss:4.573493480682373, r2_store:0.32934929442675764\n",
            "torch.Size([80, 42])\n",
            "Epoch [9964/10000], train_Loss: 3.6133928915660363e-07,test_Loss:4.5763444900512695, r2_store:0.3292416836492563\n",
            "torch.Size([80, 42])\n",
            "Epoch [9965/10000], train_Loss: 6.625856485698023e-07,test_Loss:4.572478771209717, r2_store:0.32938740472197325\n",
            "torch.Size([80, 42])\n",
            "Epoch [9966/10000], train_Loss: 1.2246517826497438e-06,test_Loss:4.577744483947754, r2_store:0.3291889240743189\n",
            "torch.Size([80, 42])\n",
            "Epoch [9967/10000], train_Loss: 2.2675053514831234e-06,test_Loss:4.570574760437012, r2_store:0.3294597353972343\n",
            "torch.Size([80, 42])\n",
            "Epoch [9968/10000], train_Loss: 4.236032054905081e-06,test_Loss:4.580391883850098, r2_store:0.329089888635838\n",
            "torch.Size([80, 42])\n",
            "Epoch [9969/10000], train_Loss: 7.918287337815855e-06,test_Loss:4.566952705383301, r2_store:0.3295964314087192\n",
            "torch.Size([80, 42])\n",
            "Epoch [9970/10000], train_Loss: 1.4952564015402459e-05,test_Loss:4.585434913635254, r2_store:0.3288985702393896\n",
            "torch.Size([80, 42])\n",
            "Epoch [9971/10000], train_Loss: 2.8172429665573873e-05,test_Loss:4.5599751472473145, r2_store:0.3298549771269521\n",
            "torch.Size([80, 42])\n",
            "Epoch [9972/10000], train_Loss: 5.393915489548817e-05,test_Loss:4.595177173614502, r2_store:0.32852036982248456\n",
            "torch.Size([80, 42])\n",
            "Epoch [9973/10000], train_Loss: 0.0001026244499371387,test_Loss:4.5464301109313965, r2_store:0.3303454904854978\n",
            "torch.Size([80, 42])\n",
            "Epoch [9974/10000], train_Loss: 0.0001988764852285385,test_Loss:4.614185810089111, r2_store:0.3277700632885958\n",
            "torch.Size([80, 42])\n",
            "Epoch [9975/10000], train_Loss: 0.0003805641899816692,test_Loss:4.52016544342041, r2_store:0.33126349135923483\n",
            "torch.Size([80, 42])\n",
            "Epoch [9976/10000], train_Loss: 0.0007462484645657241,test_Loss:4.651533603668213, r2_store:0.32623208273972004\n",
            "torch.Size([80, 42])\n",
            "Epoch [9977/10000], train_Loss: 0.0014306023949757218,test_Loss:4.469247817993164, r2_store:0.3328505042165798\n",
            "torch.Size([80, 42])\n",
            "Epoch [9978/10000], train_Loss: 0.002902225824072957,test_Loss:4.72797155380249, r2_store:0.32253520818792725\n",
            "torch.Size([80, 42])\n",
            "Epoch [9979/10000], train_Loss: 0.005619262345135212,test_Loss:4.365478992462158, r2_store:0.33543880951473437\n",
            "torch.Size([80, 42])\n",
            "Epoch [9980/10000], train_Loss: 0.012010736390948296,test_Loss:4.879619598388672, r2_store:0.31428979747803576\n",
            "torch.Size([80, 42])\n",
            "Epoch [9981/10000], train_Loss: 0.022046443074941635,test_Loss:4.186318397521973, r2_store:0.3386166448838581\n",
            "torch.Size([80, 42])\n",
            "Epoch [9982/10000], train_Loss: 0.04870607703924179,test_Loss:5.101971626281738, r2_store:0.3006131798375674\n",
            "torch.Size([80, 42])\n",
            "Epoch [9983/10000], train_Loss: 0.07301042228937149,test_Loss:3.9838223457336426, r2_store:0.3337912849679754\n",
            "torch.Size([80, 42])\n",
            "Epoch [9984/10000], train_Loss: 0.1336841881275177,test_Loss:5.064541339874268, r2_store:0.2963164829482461\n",
            "torch.Size([80, 42])\n",
            "Epoch [9985/10000], train_Loss: 0.07588427513837814,test_Loss:4.270964622497559, r2_store:0.3382268505127066\n",
            "torch.Size([80, 42])\n",
            "Epoch [9986/10000], train_Loss: 0.014071626588702202,test_Loss:4.357985973358154, r2_store:0.34402163917855666\n",
            "torch.Size([80, 42])\n",
            "Epoch [9987/10000], train_Loss: 0.015756383538246155,test_Loss:5.083047866821289, r2_store:0.31131654400800524\n",
            "torch.Size([80, 42])\n",
            "Epoch [9988/10000], train_Loss: 0.05838267132639885,test_Loss:4.10266637802124, r2_store:0.3391169576816122\n",
            "torch.Size([80, 42])\n",
            "Epoch [9989/10000], train_Loss: 0.06887286901473999,test_Loss:4.569718360900879, r2_store:0.32179701338552935\n",
            "torch.Size([80, 42])\n",
            "Epoch [9990/10000], train_Loss: 0.007371829356998205,test_Loss:4.972579002380371, r2_store:0.30932984812457576\n",
            "torch.Size([80, 42])\n",
            "Epoch [9991/10000], train_Loss: 0.04342181235551834,test_Loss:4.146892547607422, r2_store:0.34419224028957796\n",
            "torch.Size([80, 42])\n",
            "Epoch [9992/10000], train_Loss: 0.07930493354797363,test_Loss:4.631798267364502, r2_store:0.3234727752649833\n",
            "torch.Size([80, 42])\n",
            "Epoch [9993/10000], train_Loss: 0.009239624254405499,test_Loss:4.706738471984863, r2_store:0.31171598131680145\n",
            "torch.Size([80, 42])\n",
            "Epoch [9994/10000], train_Loss: 0.031851377338171005,test_Loss:3.9736428260803223, r2_store:0.33408258050228545\n",
            "torch.Size([80, 42])\n",
            "Epoch [9995/10000], train_Loss: 0.05506047606468201,test_Loss:4.435524940490723, r2_store:0.3207760340097948\n",
            "torch.Size([80, 42])\n",
            "Epoch [9996/10000], train_Loss: 0.005249709822237492,test_Loss:4.850051403045654, r2_store:0.3072089054318303\n",
            "torch.Size([80, 42])\n",
            "Epoch [9997/10000], train_Loss: 0.03996678814291954,test_Loss:4.229348182678223, r2_store:0.33617995033099546\n",
            "torch.Size([80, 42])\n",
            "Epoch [9998/10000], train_Loss: 0.03420654684305191,test_Loss:4.418257236480713, r2_store:0.33219276026053324\n",
            "torch.Size([80, 42])\n",
            "Epoch [9999/10000], train_Loss: 0.007924603298306465,test_Loss:4.957019805908203, r2_store:0.3085844048148543\n",
            "torch.Size([80, 42])\n",
            "Epoch [10000/10000], train_Loss: 0.04567210003733635,test_Loss:4.3658552169799805, r2_store:0.33810785435992174\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 划分数据集为训练集和测试集\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
        "\n",
        "# 将数据转换为PyTorch张量\n",
        "X_train = torch.Tensor(X_train.values)\n",
        "y_train = torch.Tensor(y_train.values).view(-1, 1)  # 将目标数据调整为列向量\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "y_test = torch.Tensor(y_test.values).view(-1, 1)  # 将目标数据调整为列向量\n",
        "\n",
        "# 定义CNN模型\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 64, 64)  # 根据输入大小调整线性层的输入大小\n",
        "        self.fc2 = nn.Linear(64, 1)  # 输出一个连续的回归值\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# # 定义神经网络模型\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self, input_size):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.fc1 = nn.Linear(input_size, 64)\n",
        "#         self.relu1 = nn.ReLU()  # 添加ReLU激活函数\n",
        "#         self.fc2 = nn.Linear(64, 32)\n",
        "#         self.relu2 = nn.ReLU()  # 添加ReLU激活函数\n",
        "#         self.fc3 = nn.Linear(32, 1)\n",
        "#         self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.fc1(x) # 应用ReLU激活函数\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.relu2(self.fc2(x))  # 应用ReLU激活函数\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.fc3(x)\n",
        "#         x = self.dropout(x)\n",
        "#         return x\n",
        "\n",
        "# 定义神经网络模型\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(p=0.3)  # dropout训练\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)  # 在回归中，输出层通常不使用激活函数\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# 创建模型实例\n",
        "input_size = X_train.shape[1]\n",
        "model = Net(input_size)\n",
        "# model = CNNModel()\n",
        "\n",
        "# 定义均方误差损失函数和优化器\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 训练模型\n",
        "num_epochs = 10000\n",
        "num_plot=100\n",
        "train_plot=[]\n",
        "dev_plot=[]\n",
        "r2_list=[]\n",
        "step=int(num_epochs/num_plot)\n",
        "for epoch in range(num_epochs):\n",
        "    print(X_train.size())\n",
        "    # 前向传播\n",
        "    outputs = model(X_train)\n",
        "\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # 反向传播和优化\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # 测试模型\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_outputs = model(X_test)\n",
        "        test_loss = criterion(test_outputs, y_test)\n",
        "        r2 = r2_score(test_outputs, y_test)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], train_Loss: {loss.item()},test_Loss:{test_loss.item()}, r2_store:{r2}')\n",
        "        if epoch%step==0:\n",
        "          train_plot.append(loss.item())\n",
        "          dev_plot.append(test_loss.item())\n",
        "          r2_list.append(r2)\n",
        "    # print(f'Test Mean Squared Error (MSE): {test_loss.item()}')\n",
        "\n",
        "t = list(range(1, num_epochs + 1, step))\n",
        "plt.title('mse')\n",
        "plt.plot(t, train_plot, color='red', label='train mse')\n",
        "plt.plot(t, dev_plot, color='blue', label='dev mse')\n",
        "\n",
        "plt.legend()\n",
        "plt.ylim(0,10)\n",
        "plt.show()\n",
        "\n",
        "plt.title('r2')\n",
        "plt.plot(t, r2_list, color='red', label='r2_list')\n",
        "plt.ylim(-1,1)\n",
        "plt.legend()\n",
        "# plt.ylim(0,10)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezAiwy-s3_GH",
        "outputId": "766fff9a-8612-41b0-9b18-230201cf4ceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[14555528.0, 173109.1875, 76168.03125, 29948.806640625, 8589.5595703125, 2638.425537109375, 1654.9788818359375, 717.1921997070312, 458.5187072753906, 367.20068359375, 304.4831848144531, 288.59722900390625, 274.01495361328125, 263.7897033691406, 255.0748748779297, 245.58154296875, 237.83261108398438, 230.21255493164062, 223.54373168945312, 217.6713104248047, 212.16732788085938, 207.21591186523438, 202.74966430664062, 198.65478515625, 194.9128875732422, 191.43751525878906, 188.15933227539062, 185.11720275878906, 182.42453002929688, 179.930908203125, 177.5941619873047, 175.4064483642578, 173.32357788085938, 171.25523376464844, 169.3544464111328, 167.8666534423828, 167.20968627929688, 166.67562866210938, 167.2655029296875, 168.36402893066406, 168.9976348876953, 169.02359008789062, 168.5924072265625, 167.89549255371094, 167.03884887695312, 166.19561767578125, 165.4131317138672, 164.68319702148438, 164.0052032470703, 163.36550903320312, 162.74501037597656, 162.14053344726562, 161.55233764648438, 160.9764862060547, 160.41476440429688, 159.86973571777344, 159.33987426757812, 158.82513427734375, 158.3233642578125, 157.83380126953125, 157.3563995361328, 156.88919067382812, 156.42556762695312, 155.97618103027344, 155.53799438476562, 155.10877990722656, 154.6869659423828, 154.27053833007812, 153.85707092285156, 153.44761657714844, 153.04183959960938, 152.63821411132812, 152.2374267578125, 151.84133911132812, 151.44815063476562, 151.0589141845703, 150.67234802246094, 150.2896270751953, 149.91075134277344, 149.53457641601562, 149.16171264648438, 148.79229736328125, 148.42654418945312, 148.06358337402344, 147.7046356201172, 147.34841918945312, 146.99549865722656, 146.64437866210938, 146.29757690429688, 145.95346069335938, 145.61349487304688, 145.27682495117188, 144.94395446777344, 144.61427307128906, 144.28819274902344, 143.96560668945312, 143.65872192382812, 143.34190368652344, 143.02720642089844, 142.70982360839844]\n"
          ]
        }
      ],
      "source": [
        "print(dev_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpRLnh6OfpR9",
        "outputId": "c120e9e9-1cc0-4fc5-cfa0-46c467bf412b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[268339.78125, 493039.5625, 53700.2265625, 37000.6171875, 12740.8876953125, 4199.96142578125, 1431.60546875, 576.1301879882812, 192.1226806640625, 78.60606384277344, 38.97517776489258, 19.69007682800293, 14.177583694458008, 12.247934341430664, 10.952315330505371, 9.967523574829102, 8.959409713745117, 8.136252403259277, 7.478572845458984, 6.938460350036621, 6.492982387542725, 6.127853870391846, 5.8306684494018555, 5.586463451385498, 5.384247303009033, 5.209819316864014, 5.059847354888916, 4.928833961486816, 4.766226768493652, 4.60635232925415, 4.4631781578063965, 4.339550971984863, 4.229368686676025, 4.110690116882324, 3.993617296218872, 3.875629425048828, 3.7701072692871094, 3.6736724376678467, 3.6075024604797363, 3.555830717086792, 3.5133235454559326, 3.476522445678711, 3.4435126781463623, 3.4132347106933594, 3.383958339691162, 3.35683012008667, 3.3317809104919434, 3.3083863258361816, 3.2863357067108154, 3.265479326248169, 3.2467846870422363, 3.229179859161377, 3.212366819381714, 3.1962361335754395, 3.180673599243164, 3.165597438812256, 3.150981903076172, 3.136728525161743, 3.1228394508361816, 3.1092891693115234, 3.0960254669189453, 3.083066701889038, 3.070443630218506, 3.0580527782440186, 3.045877695083618, 3.033935308456421, 3.0222175121307373, 3.0107078552246094, 2.999391794204712, 2.9883246421813965, 2.9774374961853027, 2.966744899749756, 2.9562506675720215, 2.945992946624756, 2.935887098312378, 2.926069736480713, 2.916550874710083, 2.9072225093841553, 2.898073196411133, 2.8891613483428955, 2.8803718090057373, 2.871769428253174, 2.863356828689575, 2.8550829887390137, 2.846986770629883, 2.8390467166900635, 2.8310675621032715, 2.823134422302246, 2.8152949810028076, 2.8075835704803467, 2.800025701522827, 2.792586326599121, 2.785278558731079, 2.778143882751465, 2.771195650100708, 2.7645108699798584, 2.7580082416534424, 2.7516818046569824, 2.7455263137817383, 2.73952317237854]\n"
          ]
        }
      ],
      "source": [
        "print(train_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ4VRd1EbXIO",
        "outputId": "d5c8ab52-5afa-429e-fdf1-79aa48a697c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.1013],\n",
              "        [ 1.9285],\n",
              "        [ 2.7023],\n",
              "        [ 2.5839],\n",
              "        [ 0.2606],\n",
              "        [-2.7002],\n",
              "        [ 2.7023],\n",
              "        [ 4.7595],\n",
              "        [ 1.8779],\n",
              "        [ 2.7023],\n",
              "        [13.4137],\n",
              "        [ 2.6441],\n",
              "        [ 2.7023],\n",
              "        [ 2.3672],\n",
              "        [ 0.2155],\n",
              "        [ 2.7023],\n",
              "        [20.8173],\n",
              "        [ 3.5201],\n",
              "        [ 4.6199],\n",
              "        [ 2.2991]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI7q1pGSbfbS",
        "outputId": "632bd295-03f8-486c-f046-48703a6ce812"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [3.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [3.],\n",
              "        [1.],\n",
              "        [4.],\n",
              "        [1.],\n",
              "        [4.],\n",
              "        [0.],\n",
              "        [4.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [6.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [0.]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "3-b1701n4PdC",
        "outputId": "cb0d95fe-67d2-49c3-cfff-7c73827fe866"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGzCAYAAAAFROyYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGwUlEQVR4nO3dd3xUVf7/8fekh5IEAiREgkRBOoggEMEeRUUFRVdc3B8iigVUZBVlFRRXpezqYseytq8iLqtiWUURFERD6ChFyoKCaEJNQkuA5P7+ODuTQtAkzNx7Z+b1fDzOY+7M3AxnrkrenvM553osy7IEAADgIhFOdwAAAKAyAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAAHAdAgoAv3vooYfk8Xi0fv16XXfddUpMTFTjxo01duxYWZalrVu3ql+/fkpISFBqaqoef/zxCj//9NNPq3379qpTp44aNGigbt26adq0aRXO2bZtm2644QalpKQoNjZW7du31yuvvGLn1wQQQAQUAAFzzTXXqLS0VBMnTlSPHj30yCOPaMqUKbrgggt0wgknaNKkSWrZsqXuvvtuzZ8/X5L00ksv6Y477lC7du00ZcoUjR8/XqeeeqpycnJ8n5uXl6eePXvqiy++0IgRI/Tkk0+qZcuWGjp0qKZMmeLQtwXgTx7LsiynOwEgtDz00EMaP368hg0bphdeeEGSVFJSohYtWmjbtm2aMGGC7r33XklSfn6+0tLS9Ic//EGvvfaa+vfvr40bN2rVqlXH/Pwbb7xRn3zyib7//nslJyf7Xr/22mv16aef6tdff1V8fHxgvySAgGIEBUDA3Hjjjb7jyMhIdevWTZZlaejQob7Xk5KS1Lp1a23atMn3/Oeff9bixYur/EzLsvTuu+/qsssuk2VZ2rlzp6/16dNHBQUFWrZsWWC/GICAI6AACJjmzZtXeJ6YmKi4uDg1atToqNf37NkjSbr33ntVr149de/eXa1atdLw4cP1zTff+M7dsWOH8vPz9eKLL6px48YV2pAhQyRJ27dvD/A3AxBoUU53AEDoioyMrNZrkhkZkaS2bdtq3bp1+vjjjzVr1iy9++67eu655zRu3DiNHz9epaWlkqTrrrtOgwcPrvKzOnXq5KdvAMApBBQArlO3bl1dc801uuaaa3To0CFdeeWVevTRRzVmzBg1btxY9evXV0lJibKyspzuKoAAYYoHgKvs2rWrwvOYmBi1a9dOlmXp8OHDioyM1IABA/Tuu+9WWUi7Y8cOu7oKIIAYQQHgKhdeeKFSU1PVq1cvpaSkaO3atXrmmWfUt29f1a9fX5I0ceJEffnll+rRo4duuukmtWvXTrt379ayZcv0xRdfaPfu3Q5/CwDHi4ACwFVuvvlmvfXWW3riiSe0b98+NWvWTHfccYceeOAB3zkpKSlatGiRHn74Yb333nt67rnnlJycrPbt22vSpEkO9h6Av7APCgAAcB1qUAAAgOsQUAAAgOsQUAAAgOvUOKDMnz9fl112mdLS0uTxeDRz5swK71uWpXHjxqlp06aKj49XVlaWNmzYUOGc3bt3a9CgQUpISFBSUpKGDh2qffv2HdcXAQAAoaPGAWX//v3q3Lmznn322Srfnzx5sp566ilNnTpVOTk5qlu3rvr06aOioiLfOYMGDdLq1as1e/Zsffzxx5o/f76GDRtW+28BAABCynGt4vF4PHr//ffVv39/SWb0JC0tTX/+85919913S5IKCgqUkpKi1157TQMHDtTatWvVrl07LV68WN26dZMkzZo1S5dccol+/vlnpaWlHf+3AgAAQc2v+6Bs3rxZubm5FbafTkxMVI8ePZSdna2BAwcqOztbSUlJvnAiSVlZWYqIiFBOTo6uuOKKoz63uLhYxcXFvuelpaXavXu3kpOT5fF4/PkVAABAgFiWpb179yotLU0REb89iePXgJKbmyvJbKJUXkpKiu+93NxcNWnSpGInoqLUsGFD3zmVTZgwQePHj/dnVwEAgEO2bt2qZs2a/eY5QbGT7JgxYzRq1Cjf84KCAjVv3lxbt25VQkKCgz2rpgMHpKZNzfEvv0hnny1t2CB9/LF05pkVz332Wekvf5Guvlp6+eXf/eiHH5Yef1waNkz6298C0HcAAPyksLBQ6enpvttW/Ba/BpTU1FRJUl5enpp6fyH/7/mpp57qO2f79u0Vfu7IkSPavXu37+cri42NVWxs7FGvJyQkBEdAiSp3mcv/Q0lIMK28Bg3M45EjR79XhebNzeOePdU6HQAAx1WnPMOv+6BkZGQoNTVVc+bM8b1WWFionJwcZWZmSpIyMzOVn5+vpUuX+s6ZO3euSktL1aNHD392xz0q/4MoKTGPUVXkw/h483jwYLU+2jublpdXy74BAOBCNR5B2bdvnzZu3Oh7vnnzZq1YsUINGzZU8+bNNXLkSD3yyCNq1aqVMjIyNHbsWKWlpflW+rRt21YXXXSRbrrpJk2dOlWHDx/WiBEjNHDgwPBYwWNZZnREkiIjj36/hgHFO+h0jPIdAACCUo0DypIlS3Tuuef6nntrQwYPHqzXXntNo0eP1v79+zVs2DDl5+erd+/emjVrluLi4nw/89Zbb2nEiBE6//zzFRERoQEDBuipp57yw9dxqWONoPghoDCCAgAIRUF5N+PCwkIlJiaqoKAgOGpQiorKgkdBgdS6tRnyWL5c+l9tjs8XX0gXXCB17Ch9993vfvSePVLDhub44EGpXA4EAMBVavL7m3vx2CGANShJSVJMjDlmFAUAECoIKHbzcw2Kx1M2zUMdCgAgVBBQ7BDAGhSpbIuVX3+tRd8AAHAhAordLMvvAeWEE8zjtm3H2TcAAFyCgGKH2tagVLN+2bs6+5dfatk/AABchoBit+rWoEhSuRsk/hZGUAAAoYaAYofa1KBI1Z7mYQQFABBqCCh2Ky0tm7qpKqBER5e9Xs2AwggKACDUEFDsUH4ExTt6IlVdgyLVuFCWERQAQKghoNjNW38iVT2CItU4oHhHUPLzpQMHat81AADcgoBih/IjKAEIKAkJUp065phRFABAKCCg2C0AUzweD3UoAIDQQkCxQ4BHUKSygMIICgAgFBBQ7FaTgFKDghJvoSwjKACAUEBAscOxRlAijnH52e4eABDmCCh2+61t7r1qEVBYagwACCUEFLv91jb3Xt4lOYygAADCFAHFbtUJKIygAADCHAHFLt46lAAFlPKreKp5E2QAAFyLgGK3ANWgNG1qHouLpd27a9k3AABcgoBitwCNoMTGSo0amWPqUAAAwY6AYpcAT/FI1KEAAEIHAcVuAQworOQBAIQKAopdvCMoAapBkQgoAIDQQUCxG1M8AAD8LgKKXWyoQWEEBQAQKggodvMGlABM8TCCAgAIFQQUu1SuQWEEBQCAYyKg2M2GGpTt26XDh2vRNwAAXIKAYhcbalAaNzYzR5Yl5ebWoo8AALgEAcVuAaxBiYgo2/KeOhQAQDAjoNjFhhoUiToUAEBoIKDYraZTPDW8NTEreQAAoYCAYpfa1KCUlNS42pURFABAKCCg2K0mW91LtV7JQ0ABAAQzAopdajKCEhtbdn4t90JhigcAEMwIKHarTkDxeKS4OHPMZm0AgDBEQLFLTUZQJLa7BwCENQKK3apTgyId93b3hYXSvn017BsAAC5BQLGLTSMo9etL9eqZY0ZRAADBioBit+oGlDp1zCObtQEAwhABxS42jaBI1KEAAIIfAcVuAa5BkRhBAQAEPwKKXRwYQSGgAACCFQHFbjYEFDZrAwAEOwKK3bwBxYYpnq1ba/yjAAC4AgHFLt4pHm8NSgBHUE45xTyuXVvjmyEDAOAKBBS72TDF07q1GaApLJS2bKnxjwMA4DgCil1sLJKNiZHatDHH339f4x8HAMBxBBS72VCDIkkdO5pHAgoAIBgRUOxiYw2KREABAAQ3AordbJjikQgoAIDgRkCxi401KFJZQPnhB+nQoVp9BAAAjiGg2K2mNSgHDtTqj2neXEpIMH/cunW1+ggAABxDQLGLzTUoHo/UoYM5ZpoHABBsCCh2s2mKR6IOBQAQvAgodrG5BkUioAAAghcBxW427YMiEVAAAMGLgGIXm2tQpLKAsmWLVFBQ648BAMB2BBS72TjF06CB1KyZOV61qtYfAwCA7Qgodqlcg2LDFI/ENA8AIDgRUOxW0xGUw4fLpoVqgYACAAhGBBS71LYGRaJQFgAQdvweUEpKSjR27FhlZGQoPj5eJ598sv7617/KsizfOZZlady4cWratKni4+OVlZWlDRs2+Lsr7lTTERTJbwGl3D8CAABcze8BZdKkSXr++ef1zDPPaO3atZo0aZImT56sp59+2nfO5MmT9dRTT2nq1KnKyclR3bp11adPHxUVFfm7O+5R0xqUiAgpNtYcH0dAadPGZKH8fGnbtlp/DAAAtvJ7QPn222/Vr18/9e3bVy1atNBVV12lCy+8UIsWLZJkRk+mTJmiBx54QP369VOnTp30xhtv6JdfftHMmTP93R33qe4IiuSXQtnYWKl1a3PMNA8AIFj4PaCcccYZmjNnjtavXy9JWrlypRYsWKCLL75YkrR582bl5uYqKyvL9zOJiYnq0aOHsrOzq/zM4uJiFRYWVmhBp6Y1KBIreQAAYcvvAeW+++7TwIED1aZNG0VHR6tLly4aOXKkBg0aJEnKzc2VJKWkpFT4uZSUFN97lU2YMEGJiYm+lp6e7u9u28fmERSJgAIACD5+Dyj/+te/9NZbb2natGlatmyZXn/9df3973/X66+/XuvPHDNmjAoKCnxt69atfuyxTSqPoPxeDYpEQAEAhK1q/JasmXvuucc3iiJJHTt21E8//aQJEyZo8ODBSk1NlSTl5eWpadOmvp/Ly8vTqaeeWuVnxsbGKtZbMBrsHBxBWbPGbKsSHX1cHwcAQMD5fQTlwIEDioio+LGRkZEqLS2VJGVkZCg1NVVz5szxvV9YWKicnBxlZmb6uzvuUdO7GUt+CygnnijVq2fCyf9KgwAAcDW/j6BcdtllevTRR9W8eXO1b99ey5cv1xNPPKEbbrhBkuTxeDRy5Eg98sgjatWqlTIyMjR27FilpaWpf//+/u6O+3g3I7ExoEREmFGU7Gxp0SKpffvj+jgAAALO7wHl6aef1tixY3Xbbbdp+/btSktL080336xx48b5zhk9erT279+vYcOGKT8/X71799asWbMUFxfn7+64l401KJJ04YUmoLz3njRkyHF/HAAAAeWxrODbX7SwsFCJiYkqKChQQkKC092pnmbNKu6UNm+edNZZv/0z114rTZ8u/eMf0siRx/XHr14tdehg6k+2b5eSko7r4wAAqLGa/P7mXjxOsXGKRzLTOm3bmjqUDz887o8DACCgCCh28RbJetk8xSNJf/iDeZwxwy8fBwBAwBBQnGLzCIokXX21efz8c3NvHgAA3IqAYpfKIygOBBTvNM+hQ0zzAADcjYDiFAcCilQ2isI0DwDAzQgodnFBDYpUVofy+edSQYHfPhYAAL8ioDjFoREUpnkAAMGAgGIXF9SgeHmnef71L79+LAAAfkNAcYoLAgrTPAAAtyKg2MUlNSgS0zwAAPcjoDjFwREUj6dsFOWdd/z60QAA+AUBxS4uqkGRpIEDzeN//mNuCwQAgJsQUJzicEBp21a6+WZzfNNNUlGR3/8IAABqjYBil9rUoNSpYx4DEFAkadIkqWlTacMG6a9/DcgfAQBArRBQnOLwCIokJSZKzz1njidPllauDMgfAwBAjRFQ7HI8NShFRZJl+b9Pkvr3lwYMkI4ckW680TwCAOA0AopTahJQpIAWiTz9tBlNWbJEeuqpgP0xAABUGwHFLsezD4oUsGkeydSh/P3v5viBB6QffgjYHwUAQLUQUJwSUY1LHxVVFmQOHAhod4YOlc45x+SgM8+UcnIC+scBAPCbCCh2KT+CEhFx9IjKsdStax737/d/n8rxeKTp06WuXaWdO6Vzz2WXWQCAcwgoTqjO9I5X/frmce/ewPSlnJQU6auvpIsuMiMpV1whTZ0a8D8WAICjEFDsUn7EpDoFsl42BhRJqlfPjJwMHSqVlkq33irdf3/AFhEBAFAlAooTXBxQJCk6WnrpJWn8ePP8scekYcOkkhLbugAACHMEFCfUJKDUq2ce9+0LTF+OweORxo0zQSUiQnr5ZekPf2BLfACAPQgodik/xePSGpSq3HijNGOGFBMjvfee1LevY10BAIQRAooTXD7FU9mVV0qffmoGc+bONSt8duxwrDsAgDBAQLFLkBTJHst550lffik1aiQtXSpdemnAt2YBAIQxAooTgjCgSFK3btLXX0sNG0qLFknXXUfhLAAgMAgodgnSGpTK2rSRPvjA1KS8/740erTTPQIAhCICihOCdATFq3dv6bXXzPETT0jPPutodwAAIYiAYpcgr0Gp7NprpUcfNcd33CF9/LGz/QEAhBYCihNCIKBI0pgxZTvODhzIXZABAP5DQLFLbWtQvBu1uTCgeDzS88+bZcf795uQwkZuAAB/IKA4oTYjKDbvJFtd0dHSm29KjRtLK1dK99zjdI8AAKGAgGKXEKtBKS8tTXr9dXP8zDPSzJmOdgcAEAIIKE4I4mXGx3LxxdLdd5vjG26Qtmxxtj8AgOBGQLHL8Y6gHDjg+l3RHn1UOv10ac8e6Y9/lI4ccbpHAIBgRUBxQm0CiuTaOhSvmBhp+nQpIUH65hvp4Yed7hEAIFgRUOxS2xGU2NiyKSGXT/NI0kknSS+8YI4fe0xavNjZ/gAAghMBxQk1qUHxeIKmDsVr4EDTSkqkwYOlgwed7hEAINgQUOxS2xEUydV7oRzLM89IqanS2rXS2LFO9wYAEGwIKE6oaUAJshEUSUpOll56yRw/8YS5CzIAANVFQLHL8YyguHyztmO59FKz5NiypOuvD7ruAwAcREBxQk1qUKSgHEHx+sc/pObNpU2bpNGjne4NACBYEFDs4o8RlCAMKAkJ0iuvmOPnn5c+/9zZ/gAAggMBxQlhFFAk6fzzpREjzPENN5iN3AAA+C0EFLuE6QiK16RJUqtW0rZt0h13ON0bAIDbEVCcEEY1KF516khvvCFFRJi7H7/3ntM9AgC4GQHFLmE+giJJPXtK995rjm+5Rdq+3dn+AADci4DihDDYqO1YHnxQ6tRJ2rFDuvlmswQZAIDKCChOCMMpHq/YWOn//k+KjpZmzjTHAABURkCxC1M8Pp06SePHm+Pbb5e2bHG2PwAA9yGgOCFMdpL9LffcI2VmSoWF5oaCpaVO9wgA4CYEFLswglJBVJRZ1VO3rvTVV9KUKU73CADgJgQUJ4RxDUp5LVuarfAlacwYadUqZ/sDAHAPAopdGEGp0o03mpsKHjokXXedVFzsdI8AAG5AQHFCbQNKUZF05Ij/++Mgj0d6+WWpUSNp5UqzDBkAAAKKXfwxgiKF5ChKSor00kvmePJkad48Z/sDAHAeAcUJNa1BiYkxG4dIIRlQJKl/f2noULNx26BB0s6dTvcIAOAkAopdjmcERQrpOhSvJ5+UWrc2NxS84QZ2mQWAcEZAcQIBpUp160rvvGN2m/3oI+npp53uEQDAKQQUu/hrBCWENmurSufO0uOPm+N77pGWL3e2PwAAZxBQnFDTGhQpLEZQvG67zdSkHDokXXNNWHxlAEAlAQko27Zt03XXXafk5GTFx8erY8eOWrJkie99y7I0btw4NW3aVPHx8crKytKGDRsC0RX3oAal2jwe6Z//lNLTpQ0bpFtvpR4FAMKN3wPKnj171KtXL0VHR+vTTz/VmjVr9Pjjj6tBgwa+cyZPnqynnnpKU6dOVU5OjurWras+ffqoqKjI391xJwLK72rYUJo2zVyqt96SJk1yukcAADvVYq7ht02aNEnp6el69dVXfa9lZGT4ji3L0pQpU/TAAw+oX79+kqQ33nhDKSkpmjlzpgYOHOjvLrkDIyg11ru39NRT0vDhZiv8U06RrrzS6V4BAOzg9xGUDz/8UN26ddPVV1+tJk2aqEuXLnrJuwuXpM2bNys3N1dZWVm+1xITE9WjRw9lZ2dX+ZnFxcUqLCys0IIaNSjVdttt0u23m+PrrpOWLnW2PwAAe/g9oGzatEnPP/+8WrVqpc8++0y33nqr7rjjDr3++uuSpNzcXElSSkpKhZ9LSUnxvVfZhAkTlJiY6Gvp6en+7nbgHe8ISr165jHMAookPfGEdNFF0sGD0uWXm31SAAChze8BpbS0VKeddpoee+wxdenSRcOGDdNNN92kqVOn1vozx4wZo4KCAl/bunWrH3vsAKZ4aiQqSpo+XWrfXvrlF+myy0J+tTUAhD2/B5SmTZuqXbt2FV5r27attmzZIklKTU2VJOXl5VU4Jy8vz/deZbGxsUpISKjQgk75ERSmeGosMdFs3ta4sdkbZcAA7nwMAKHM7wGlV69eWrduXYXX1q9frxNPPFGSKZhNTU3VnDlzfO8XFhYqJydHmZmZ/u6OOzGCUisZGdKHH0p16kiff27u2RNiN3cGAPyP3wPKXXfdpYULF+qxxx7Txo0bNW3aNL344osaPny4JMnj8WjkyJF65JFH9OGHH+r777/X//t//09paWnq37+/v7vjHuwk6xc9e0ozZ5r7J777rjRsmFRa6nSvAAD+5vdlxqeffrref/99jRkzRg8//LAyMjI0ZcoUDRo0yHfO6NGjtX//fg0bNkz5+fnq3bu3Zs2apbi4OH93x50YQTkuF1xgalKuukp69VUpKclsj18+AwIAgpvHsoJvj87CwkIlJiaqoKAgeOpRzjlHmjfPHH/0kXTppTX7+YULpcxMqUULafNmf/cuKL3+unT99eb4oYekBx90sjcAgN9Tk9/f3IvHCYyg+MXgwdKTT5pjb0AJvrgNAKgKAcUJBBS/ueOOsm3wH35Yuu8+QgoAhAICil38tVHboUOmwWf06LKRlMmTpZEjCSkAEOwIKE44nn1QJEZRqnDHHZJ3L8CnnpJuuYXVPQAQzAgodjneEZToaCk21hwTUKp0883Sa69JERHSiy9Kf/yjFC43yAaAUENAcUJtAopEHUo1DB4svfWWyXPvvGOWJO/a5XSvAAA1RUCxy/GOoEhs1lZNAwdKs2aZ7fEXLJDOOEPatMnpXgEAaoKA4oTa1KBIjKDUwHnnSd98I6WnS+vXmx1oFy1yulcAgOoioNjFnyMoBJRqad/e7G/XpYu0Y4d09tlm+gcA4H4EFCcQUGyTlibNny/17WsKZq+7Trr7bm4yCABuR0CxS/kRFKZ4bFWvnvTBB9L995vnjz8uXXwxxbMA4GYEFCfUdgTFu1kbAaXGIiOlRx6RZsyQ6taVvvhCOv10aeVKp3sGAKgKAcUu1KC4wlVXSdnZ0kknmXsu9uwpvfwyO88CgNsQUJxAQHFUx47S4sXSJZeYupSbbjL7p+zf73TPAABeBBS7UIPiKg0bSh99JE2caPLi//2f1L27tGaN0z0DAEgEFGcwguIKERHSvfdKc+dKTZuacHL66dI//8mUDwA4jYBiF3aSda2zzpJWrJCysqQDB6Qbb5T+8Adpzx6newYA4YuA4gRGUFynSRPps8+kSZPMDNy//y117ix9/bXTPQOA8ERAsQs1KK4XESGNHi19+63UsqW0dat0zjnSX/4iFRc73TsACC8EFCcwguJqp58uLV8uDRkilZZKEyZIXbtKS5Y43TMACB8EFLv4owaFjdpsU6+e9Mor0rvvmumf1avNnimMpgCAPQgoTvDHCArLTGxx5ZUmnAwcKJWUmNGU004z00AAgMAhoNjFn6t4jhzhf+Nt1KiR9PbbZaMpa9ZIvXpJt9zCSh8ACBQCit08HlONWRveKR6JaR4HXHmlCSc33GCev/CC1LatNH06A1oA4G8EFLt4R1BqO3oimdU/8fHmmIDiiORks5HbV19JrVtLeXnStddKffpIP/zgdO8AIHQQUOxW2yXGXmzW5gpnn23uhDx+vBQbK82ebe7xc/fdUmGh070DgOBHQLGLP0ZQJJYau0hsrDRunLRqlXTppaY06PHHzcjKG2+YJcoAgNohoNiNgBJyWrY0Nx78z3/McW6uuTtyz57S/PlO9w4AghMBxW7HG1DYC8W1LrnEjKZMmGD+MS1ebKaCrrhCWr/e6d4BQHAhoNjFO8XjrxoUAoorxcZK990nbdwo3XyzWbA1c6bUvr10++1mdAUA8PsIKHZjiicspKRIU6dK339vRlaOHJGeeUY6+WSzGy37pwDAbyOg2IUi2bDUrp2pTZkzR+reXTpwwEwBZWRIjz3GYiwAOBYCit0IKGHpvPOkhQvNdE+HDlJBgXT//VKLFiawsDQZACoioNiFGpSw5/FI/fpJK1ZIb70ltWol7dplpnxatJAeecQEFwAAAcV+jKCEvchI6Y9/NNvm/9//mX1T9uyRxo6VTjzRBJa8PKd7CQDOIqDYxV81KAkJ5pH/1Q56UVHSddeZuyVPm2bu61NQYKZ8TjxRuvVW6b//dbqXAOAMAordjjegNGpkHnfuPP6+wBUiI839fFatkt5/X+rRw9yseupU6ZRTpKuvlr79lhsSAggvBBS7+KsGpUkT87hjx/F9DlwnIkLq31/KzjY3I7zoIrNd/r//LfXqZXamfftt6fBhp3sKAIFHQLHb8Y6gNG5sHrdvP/6+wJU8HrMD7aefSt99J91wg9kAbtEiU7uSkWEKaqlTARDKCCh28VcNijegFBaaeQCEtI4dpX/+U9qyxdw5OSVF2rbNFNSmp5saloULmf4BEHoIKHY73oDSoEHZZ1CHEjaaNDF3Tv7pJ+nNN810z+HDZrlyZqbUrZsJMgcOON1TAPAPAopd/FWDEhFRVihLHUrYiY2VBg0ydSqLF0vXX29eW7ZMuvFGKS1NGjlSWrfO6Z4CwPEhoNjteEdQJOpQIMmMmrz6qpny+dvfpJNOMsuUn3xSatNGuuACsyroyBGnewoANUdAsYu/alCksoDCCAokJSdLd98tbdhgCmsvvdT86/bFF9KVV5YV1XInZQDBhIBit+Od4pEIKKhSRIRZmvzRR9KmTdJ995nZwJ9/LiuqvfpqafZss3wZANyMgGIXf46gsBcKfof3JoRbt5rt9Hv2NFM9//63dOGF5j5AEydKv/7qdE8BoGoEFLsxxQMbxcWZpcjZ2dLKldKIEVJiohlhGTPGjKpcfrm5yzIbwAFwEwKKXQJRg0KRLGqgUyfp6aelX36RXnvN7E5bUmKmhK64QmrWzNSyfPed0z0FAAKK/ahBgcPq1JEGD5YWLJB++EEaPdpsALd9u/T441LnzlKXLtKUKWRgAM4hoNiFGhS4UOvW0qRJplblgw/Mqp/oaGnFCumuu8y+KpdfLr33HhsXA7AXAcVu1KDAhaKjTRB5911TOPvMM1L37mVTQAMGmLAyYoS0ZAlb6wMIPAKKXQJRg5KfLx06dPyfB5STnCwNHy7l5Ehr1kj33mvCye7d0rPPSqefLnXoIE2ebOpZACAQCCh280cNSsOGZtMLifvxIKDatjXLkbdskWbNkgYONCuDvMElPd3svTJzphltAQB/IaDYzR8jKNyPBzaLjJT69JHeftvsSPvii2YVUGmp9NlnZhXQKaeYbfYLC53uLYBQQECxiz+neCTqUOCYxETpppvMKqANG8xISoMGZm+VkSPNcuW77pJ+/NHpngIIZgQUuxFQEEJatjRTQFu3SlOnmpsU7t1rlii3bGmmhJYscbqXAIIRAcUu3hEUf9SgSGzWBlepW1e6+WZp9Wpzw8ILLjA1Ke+8Y4pqzznHHO/f73RPAQQLAord/DWCwl4ocCHvDQs//9zspfKnP5lMPm+eGU1p0kS69lrpww/ZVwXAbyOg2IUaFISZzp2lN96QNm+W7r9fOukk6cABafp0qV8/86/w5ZebwtpVq9hbBUBFBBS7+XuKh4ACl2vWTHrkEWnjRrO3ineH2r17zSZwI0dKHTua1669Vnr+eTNVRGABwpufflvidwVqBIUaFAQJj8fsTtu9u/T3v0vLl0tz5pj29ddm+fL06aZJZiX9mWdKZ59tWqdOZdv/AAh9BBS7UYMCKCJC6trVtNGjTT1KdrY0f75p335r9iB8/33TJLOUuXxg6dzZfwOSANyH/7ztQg0KcEyxsWalzznnmOeHDklLl5ri2nnzzJ4re/aY4toPPzTn1K8v9e4tnXWWeezaVYqPd+obAPC3gA+YTpw4UR6PRyNHjvS9VlRUpOHDhys5OVn16tXTgAEDlJeXF+iuuIO/a1D27JEOH/bPZwIuERMjZWZK991nli3v2WPqVyZNkvr2lRISTA3Lp59KY8aYkZXERKlnT2nUKGnGDLNRHHUsQPAK6AjK4sWL9cILL6hTp04VXr/rrrv0n//8RzNmzFBiYqJGjBihK6+8Ut98800gu+Msf4+gNGxoPtOypF27pNRU/3wu4EJRUWX1K6NHmz1Wvvuu4pRQbq4JMTk50j/+YX6uUSOzD8vpp0unnSZ16WLuH+T9zxGAewUsoOzbt0+DBg3SSy+9pEceecT3ekFBgf75z39q2rRpOu+88yRJr776qtq2bauFCxeqZ8+eR31WcXGxisttmlAYjDf7SEgwj0lJ/vm8yEhz29mdO02hLAEFYSQy0oSNLl2kO+80Of3HH01Q+eYbadEiE2B27jSjLJ9+WvazycnSqaean+3Y0RTftm1rppkAuEfAAsrw4cPVt29fZWVlVQgoS5cu1eHDh5WVleV7rU2bNmrevLmys7OrDCgTJkzQ+PHjA9VVe9x3n7mb2qBB/vvMJk3M38DUoSDMeTxSRoZp3v/EioqklSulxYvNdvvLl5u7MO/aVbZ6yCsyUmrdWurQQWrXTmrf3rSWLaXoaGe+ExDuAhJQpk+frmXLlmnx4sVHvZebm6uYmBglVRpJSElJUW5ubpWfN2bMGI0aNcr3vLCwUOnp6X7tc8CdcIJ0++3+/UwKZYFjiouTevQwzauoyGwKt3y5GWH57jvp++9NjcuaNaaVFxUlnXyyucdQ69amnXKKCS4pKUwVAYHk94CydetW3XnnnZo9e7bi4uL88pmxsbGKZfz1aAQUoEbi4qRu3Uzzsixp2zYTVtasMZvErV5tjvfvl9atM62yevVMUGnZ0uySe/LJZY/Nm/uv3AwIV34PKEuXLtX27dt12mmn+V4rKSnR/Pnz9cwzz+izzz7ToUOHlJ+fX2EUJS8vT6nUUdQMm7UBx83jMbvdNmsmXXJJ2eulpdLPP5cFlHXrpB9+MDvi/vSTtG+fud/QihVHf2Zysllt1K+fdOGFJswAqBm/B5Tzzz9f33//fYXXhgwZojZt2ujee+9Venq6oqOjNWfOHA0YMECStG7dOm3ZskWZmZn+7k5oY7M2IGAiIsxISPPm5u7M5RUXm3sMbdwobdggbdpk2n//a17ftcvch+iNN0zx7fnnS5ddZtoJJzjzfYBg4/eAUr9+fXXo0KHCa3Xr1lVycrLv9aFDh2rUqFFq2LChEhISdPvttyszM7PKAln8BqZ4AEfExpq6lDZtjn7vyBGzsdyHH0offGCCyyefmHbrrWZDOW9Y6dKFOhbgWBy5s8U//vEPXXrppRowYIDOOusspaam6r333nOiK8GNgAK4TlSU2RH3iSfMCMuqVdKjj5pN5Dwes0PuQw+ZoNKsmXTzzeamiQcOON1zwF08lhV8ey0WFhYqMTFRBQUFSvDuLxKOvvxSOu88879xa9c63RsAv2P7duk//zGB5PPPTRGuV1yc+c+5b1/TTjzRuX4CgVKT398ElGC2erXZuKFhQzPpDSBoFBWZ+wx99JFpW7ZUfL9Dh7KwkpnJjRERGggo4WL7drMZg2Tux8PfYEBQsiwzFfSf/5j27bdmFZFXUpLUp49ZZXTRRWX18UCwIaCEi5ISs82lZZkbkXjDCoCgtmuX9NlnJqzMmiXt3l32nsdj9nG55BLp4ovNMXuuIFgQUMJJo0bmb7PvvzdjwgBCSkmJuQHiJ5+YwFJ535VGjcxeKxdfbEZZvLXzgBsRUMJJu3amQHbOHFNhByCk/fKLGVX55BNp9myp/L1TvaMrF11kwkqPHsz8wl1q8vvbkWXG8COWGgNhJS1NuuEG6d//NvcKnTfP3Iv01FPNbO/ixdJf/yr17m1GV666SnrppaOLcAG3I1sHOwIKELaio6WzzjJtwgTp11/N6Mpnn5nRld27pXffNU0yOxL06WPa2WdLdeo423/gtxBQgh0BBcD/NG0qDRliWkmJtGSJCSuzZpk6lh9+MO3JJ6WYGDPKcuGFpnXubLb3B9yCfx2DHffjAVCFyEhTgzJunFm2vHOnNGOGdNNN5v5Chw5Jc+ea6aHTTpNSU6U//lF69VVzk0TAaYygBDvuaAygGho0MPUoV11lalXWrze72c6ebTal3rFDevtt0ySpdWtzk8QLLjDTQYmJzvYf4YeAEuyY4gFQQx6PCSCtW0u3325GUxYuNGFl9mxTaLtunWnPPGNGY7p3l7KyTOvZ00wRAYHEMuNgN3euuZd727bSmjVO9wZACNizx4yqfPGFCSwbN1Z8v04d6cwzTVg5/3zqV1B97IMSTlatkjp2NOsJGUUBEAA//mi2WvriC/NY+a+ahg2lc881WzGdf750yilmlAaojIASTvLyTHWbx2Pux8Oe1wACqLTU/H/RnDmmzZsn7dtX8Zy0NBNWvI07M8OLgBJOjhwxmyFIJqxwFzEANjp82CxnnjvXtG++kYqLK56TkVE2wnLuuSbAIDwRUMJNcrLZkWnVKql9e6d7AyCMHTwoZWeXBZZFi8yeLOWdcooJKueeK51zDvc5DScElHDToYO0erXZkenCC53uDQD47N0rff21Kbr98ktp2TKzzLm8tm3LwsrZZzMQHMpq8vubZcah4OSTTUDZuJGAAsBV6teXLrnENEnKz5fmzzdh5auvpJUrzf1O166VnnvOnNOuXVlYOftsRljCFQElFLRsaR43bHC2HwDwO5KSpMsvN00ys9PewDJvngksa9aY5g0sbdqUhZWzz6aGJVwQUEJBq1bmsfJmBQDgcg0bSv37myZJu3aVTQnNmyd9913ZPYReeMGc07KluUHi2WebxxYtHOo8AooalFAwZ47ZMal1a/NfMQCEiN27pQULzHTQvHnSihVmqXN56ekmqJx5pnls04Z9WNyKItlw89NP5n8hoqNNCT17oQAIUQUFZinzvHmmLV1qdlsor1EjE1a87dRTpSjmC1yBgBJuSkvN3tPFxdKmTWbTAQAIA/v3m/sIzZ9v2sKFUlFRxXPq1ZMyM8sCS48eUny8M/0NdwSUcNSunSmDZ6kxgDBWXGxGVb7+2rQFC8yoS3nR0VLXrias9O4t9epltpNC4BFQwlG/ftKHH0rPPivddpvTvQEAVygpMbsweAPL119Lv/xy9Hlt25qg4g0sJ59MHUsgsA9KOGKpMQAcJTJS6tTJtOHDzSZxmzebOhbvCIt3H5a1a6WXXzY/l5IinXGGCStnnCGddpoUG+vsdwk3BJRQwVJjAPhdHo900kmm/elP5rWdO6VvvzWhZcECc2+hvDzp/fdNk6SYGKlbt7LQkpnJBnKBxhRPqPjiC+mCC1hqDADHqajIhJRvvy1rO3Ycfd7JJ5dNC/Xubf76jYiwv7/BhBqUcMRSYwAICMuS/vtfM8LiDSyrVx99T6GGDcsCy5lnMi1UFQJKOGKpMQDYJj/fLGn2Tgvl5Jj/NywvLk7q3r2s8PaMM8xW/+GMgBKuWGoMAI44dEhavtwU3npDy86dFc/xeKT27SsGloyM8FotREAJVyw1BgBXsCxp/XoTVLyBpapFlqmpZWGlVy+pSxdTkBuqWGYcrlhqDACu4PGYotnWraWhQ81reXllq4W++cZsKJebK737rmmSqVk5/XQTWM44w6wWatLEue/hJAJKKGGpMQC4VkqKdMUVpkmmZmXJEhNWsrNNeNm504y2LFhQ9nMnnVQWVjIzpY4dw+PeQmHwFcMIIygAEDTi48vuDySZaaENG8pGWbKzpTVrzLqHTZukN98059WpY0ZZMjOlnj3NvYVSU537HoFCDUooYakxAISUggKzQujbb01gyck5+t5CknTiiSao9OhhNpTr0kWqX9/+/v4eimTDVUmJidaHDrHUGABCUGmp2YszO7sssFS1J4vHI51yirkpYteu7gktBJRwxlJjAAgrhYWmliUnR1q0yBTfbt169Hne0NKtm9lErmtX6dRTpcREO/vKKp7w1bKlCSgbNxJQACAMJCRI551nmtf27SaolG9bt0rr1pn21ltl57ZsaUZXTj1V6tzZPKalOb8/CwEl1HhX8lAoCwBhq0kT6eKLTfMqH1qWLTPtp5/M/89u3CjNmFF2bnKyWR49aZL9ffcioIQalhoDAKpQVWjZtcvsgLtihWkrV5pB+F27TFmjkwgooYalxgCAakpOlrKyTPMqKjLLm50u8SSghBrvCMqmTSb+stQYAFADcXGmiNZpEU53AH7WrJm5kcPhw9KWLU73BgCAWiGghJrISOnkk80x0zwAgCBFQAlF3joUCmUBAEGKgBKKWGoMAAhyBJRQxEoeAECQI6CEog4dzOOiRebGDQAABBkCSijq0cPcEWrHDrMDDwAAQYaAEopiYqTzzzfHs2Y52xcAAGqBgBKqLrrIPBJQAABBiIASqvr0MY/Z2VJ+vqNdAQCgpggooapFC6lNG7Pd/Zw5TvcGAIAaIaCEMqZ5AABBioASysoHFMtyti8AANQAASWUnXWWuS3lzz+be2cDABAkCCihLD5eOuccc8w0DwAgiBBQQt3FF5vHTz91th8AANQAASXUeetQvv5a2rfP2b4AAFBNBJRQ16qVlJEhHTokffWV070BAKBaCCihzuNhuTEAIOgQUMIBAQUAEGT8HlAmTJig008/XfXr11eTJk3Uv39/rVu3rsI5RUVFGj58uJKTk1WvXj0NGDBAeXl5/u4KvM49V4qOlv77X2nDBqd7AwDA7/J7QJk3b56GDx+uhQsXavbs2Tp8+LAuvPBC7d+/33fOXXfdpY8++kgzZszQvHnz9Msvv+jKK6/0d1fgVb++dPbZ5njCBGf7AgBANXgsK7BbjO7YsUNNmjTRvHnzdNZZZ6mgoECNGzfWtGnTdNVVV0mSfvjhB7Vt21bZ2dnq2bPnUZ9RXFys4uJi3/PCwkKlp6eroKBACQkJgex+6MjOlnr1MjvKzptnNnEDAMBGhYWFSkxMrNbv74DXoBQUFEiSGjZsKElaunSpDh8+rKysLN85bdq0UfPmzZWdnV3lZ0yYMEGJiYm+lp6eHuhuh57MTGnYMHN8yy1mVQ8AAC4V0IBSWlqqkSNHqlevXurQoYMkKTc3VzExMUpKSqpwbkpKinJzc6v8nDFjxqigoMDXtm7dGshuh64JE6QmTaS1a6W//c3p3gAAcEwBDSjDhw/XqlWrNH369OP6nNjYWCUkJFRoqIUGDaR//MMcP/KIKZoFAMCFAhZQRowYoY8//lhffvmlmjVr5ns9NTVVhw4dUn5+foXz8/LylJqaGqjuwOvaa6WsLKmoSLrtNu5yDABwJb8HFMuyNGLECL3//vuaO3euMjIyKrzftWtXRUdHa86cOb7X1q1bpy1btigzM9Pf3UFlHo/0/PNSbKz0+efScY5uAQAQCH4PKMOHD9ebb76padOmqX79+srNzVVubq4OHjwoSUpMTNTQoUM1atQoffnll1q6dKmGDBmizMzMKlfwIABatpTuv98cX3+99PjjUkmJo10CAKA8vy8z9ng8Vb7+6quv6vrrr5dkNmr785//rLffflvFxcXq06ePnnvuuWpP8dRkmRKOobhYuuYa6YMPzPOzzpJef11q0cLRbgEAQldNfn8HfB+UQCCg+IllSf/8p3TXXeZOx/XqSU8+KQ0ZYqaCAADwI1ftgwIX83ikG2+UVq6Uevc2IWXoUKlLF+mdd5j2AQA4hoAC6aSTpK++kiZPNqMoK1dKAwdKbdtKr7zCpm4AANsRUGBERkr33CP99JP00ENmz5QNG8yISosW0gMPSD/+6HAnAQDhgoCCiho2lB580ASVv/9datpU+vVX6dFHzUjLxRdLM2dKhw873VMAQAgjoKBq9etLf/6zGTX517/M5m6WJc2aJV1xhZSaKt18s5kaKi11urcAgBDDKh5U38aN0ssvm+XI5e+blJYmXX21CS69eklRUc71EQDgWiwzRmCVlJiRk7fflv79b+l/d6yWZKaILr1U6tfPjLrwzwcA8D8EFNinuNhM+7z3nvTxx9Lu3WXvRUVJPXqYoHLBBVL37lJ0tHN9BQA4ioACZxw5In3zjdmd9qOPzJRQeXXrSpmZ0plnmn1XevaU6tRxpq8AANsRUOAOP/4offFFWdu1q+L7UVFS+/ZS585lrVMnqXFjR7oLAAgsAgrcp7RUWr1a+vpracEC8/jzz1Wf27Ch1Lq1aW3aSK1amRscnnyyGYUBAAQlAgrcz7KkrVul5cvNzrXe9t///vbPNW1qgsqJJ0rNm5vHE0+U0tNN498HAHAtAgqC14EDZgfbH36Q1q0zbeNG08oX4B5L/fpSs2amnXDC0S0tTWrSxOycCwCwFQEFoWnPHjPC8t//Slu2mN1uvY8//1y9ACNJERFSSooJK6mpZlSmfEtNNS0lRYqPD+x3AoAwUpPf3+yoheDRoIHUrZtpVdm/X9q2zYSVrVvNcfn2yy9mg7nSUrN9/6+//v6fmZhogkqTJubR25o0qdgaN5aSkswdogEAx42AgtBRt650yimmHUtJibRjhwkr27aZwOINK96Wl2deLy42m9AVFEjr1//+nx8VJTVqZMKKtzVqVNaSk8sevcd16hBqAKAKBBSEl8jIsimc00479nmWZYJJbq4JLHl50vbtZcc7dpjn3tf27jX7wOTmVrwNwO+JiTFhpWHDsscGDcyj99jbkpLKjhMTzc8CQIgioABV8XhMIEhKMkudf09RkbRzpwku3rZzZ1nbscPsA7Nrl3m+a5d06JBp1Z1uqqxOnbI+JiZWbElJZkVTYmLFR2+rX988xsczggPAlQgogD/ExZWtHqoOyzI1M7t2meLe3bvLjvfsOfpxzx4pP988FhaazzhwwLRffql9vyMjpXr1ygJL/fplz72tcvDxBiLvcVKS+f4EHQB+REABnODxmCBQr57Zx6UmSkpMSMnPLwst3lqZyq2wsOJxYaGZjtq714SkkpKy949HdHTZ6Ezl0ZrKozbe4/KhqHzjbtgAREABgk9kZFktSm2VlpoRnL17K4aWffuOPi4oMEHoWI+lpdLhw2VTWMcrLu7o0FJ5ZMcb7sofV9Xq1jVTYRERx98vALYioADhKCKi7Jd9WlrtP8eyTJApP1rjffSGn8rPy7/uDUN795p6HMnU8xQVmbodf6lb17TywcX7+FutTp2qn5d/ZNM/ICAIKABqz+MpCzrHq7i44ghO5eZ9r/yj93j//oo/u3+/aV7e59u3H38/K4uJqRhYKrf4+KqfV/XobZWfx8dT54OwQ0AB4A6xsaYlJ/vn80pLpYMHy4KMN6R4j8u/9nvtwIGKxwcOmNEjqWw1Vn6+f/r9W+LiKgaWygHmWI/eVvn5sVpsbMXj2FjCEWxHQAEQmiIiyqZmUlL8+9mWZaahvMHl4MGKQebgQXPsfaz8mve5t3lDT/nXvK+XlJT9ud7prz17/Pt9qsMbVMoHmPKPld+v7vPqtpiYsuOoKAJTGCCgAEBNeTxlIxf+GvE5lsOHK4aWoqKjg4w3uFR+Xv614uKKr5U/x/ua9xzvY3nFxaZ5l7k7yeM5OrRUPvY+L/9Y+biq59V5vfznVh59Ijz5DQEFANwsOrpsGbedLMtMXZUPNt7wUjnIVH6tfKv8WlXnVKeVllbsm7c/bhMRUb1ptKqm06qaXqvqvapGo8ofx8SEREgioAAAjuYdpYiNtT8cVeXIERNUvKHJ27zPy7/urQuq/H7l13/vnMOHq/65yuHJuwJNMkHKO2XnpMojPseaLqs80lT++IwzpKuucuwrEFAAAO4XFWVa3bpO9+RopaUmpFSeKqtqeq3yOd4RparOqzxSdazRqKIiE6bK84aqfftq/70OHCCgAAAQtMpP6yQlOdMHb0iqanrsWKM+vzUCVVws9ejhzHf5HwIKAADBrnxIChHs/wwAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFyHgAIAAFzH0YDy7LPPqkWLFoqLi1OPHj20aNEiJ7sDAABcwrGA8s4772jUqFF68MEHtWzZMnXu3Fl9+vTR9u3bneoSAABwCccCyhNPPKGbbrpJQ4YMUbt27TR16lTVqVNHr7zyilNdAgAALhHlxB966NAhLV26VGPGjPG9FhERoaysLGVnZx91fnFxsYqLi33PCwoKJEmFhYWB7ywAAPAL7+9ty7J+91xHAsrOnTtVUlKilJSUCq+npKTohx9+OOr8CRMmaPz48Ue9np6eHrA+AgCAwNi7d68SExN/8xxHAkpNjRkzRqNGjfI9Ly0t1e7du5WcnCyPx+O3P6ewsFDp6enaunWrEhIS/Pa5OBrX2j5ca/twre3F9baPv661ZVnau3ev0tLSfvdcRwJKo0aNFBkZqby8vAqv5+XlKTU19ajzY2NjFRsbW+G1pKSkgPUvISGBf9ltwrW2D9faPlxre3G97eOPa/17IydejhTJxsTEqGvXrpozZ47vtdLSUs2ZM0eZmZlOdAkAALiIY1M8o0aN0uDBg9WtWzd1795dU6ZM0f79+zVkyBCnugQAAFzCsYByzTXXaMeOHRo3bpxyc3N16qmnatasWUcVztopNjZWDz744FHTSfA/rrV9uNb24Vrbi+ttHyeutceqzlofAAAAG3EvHgAA4DoEFAAA4DoEFAAA4DoEFAAA4DoEFAAA4DoElHKeffZZtWjRQnFxcerRo4cWLVrkdJeCyoQJE3T66aerfv36atKkifr3769169ZVOKeoqEjDhw9XcnKy6tWrpwEDBhy1o/CWLVvUt29f1alTR02aNNE999yjI0eO2PlVgs7EiRPl8Xg0cuRI32tca//Ztm2brrvuOiUnJys+Pl4dO3bUkiVLfO9blqVx48apadOmio+PV1ZWljZs2FDhM3bv3q1BgwYpISFBSUlJGjp0qPbt22f3V3G1kpISjR07VhkZGYqPj9fJJ5+sv/71rxVuLMe1rr358+frsssuU1pamjwej2bOnFnhfX9d2++++05nnnmm4uLilJ6ersmTJ9euwxYsy7Ks6dOnWzExMdYrr7xirV692rrpppuspKQkKy8vz+muBY0+ffpYr776qrVq1SprxYoV1iWXXGI1b97c2rdvn++cW265xUpPT7fmzJljLVmyxOrZs6d1xhln+N4/cuSI1aFDBysrK8tavny59cknn1iNGjWyxowZ48RXCgqLFi2yWrRoYXXq1Mm68847fa9zrf1j9+7d1oknnmhdf/31Vk5OjrVp0ybrs88+szZu3Og7Z+LEiVZiYqI1c+ZMa+XKldbll19uZWRkWAcPHvSdc9FFF1mdO3e2Fi5caH399ddWy5YtrWuvvdaJr+Rajz76qJWcnGx9/PHH1ubNm60ZM2ZY9erVs5588knfOVzr2vvkk0+s+++/33rvvfcsSdb7779f4X1/XNuCggIrJSXFGjRokLVq1Srr7bfftuLj460XXnihxv0loPxP9+7dreHDh/uel5SUWGlpadaECRMc7FVw2759uyXJmjdvnmVZlpWfn29FR0dbM2bM8J2zdu1aS5KVnZ1tWZb5DygiIsLKzc31nfP8889bCQkJVnFxsb1fIAjs3bvXatWqlTV79mzr7LPP9gUUrrX/3HvvvVbv3r2P+X5paamVmppq/e1vf/O9lp+fb8XGxlpvv/22ZVmWtWbNGkuStXjxYt85n376qeXxeKxt27YFrvNBpm/fvtYNN9xQ4bUrr7zSGjRokGVZXGt/qhxQ/HVtn3vuOatBgwYV/g659957rdatW9e4j0zxSDp06JCWLl2qrKws32sRERHKyspSdna2gz0LbgUFBZKkhg0bSpKWLl2qw4cPV7jObdq0UfPmzX3XOTs7Wx07dqywo3CfPn1UWFio1atX29j74DB8+HD17du3wjWVuNb+9OGHH6pbt266+uqr1aRJE3Xp0kUvvfSS7/3NmzcrNze3wrVOTExUjx49KlzrpKQkdevWzXdOVlaWIiIilJOTY9+XcbkzzjhDc+bM0fr16yVJK1eu1IIFC3TxxRdL4loHkr+ubXZ2ts466yzFxMT4zunTp4/WrVunPXv21KhPjm117yY7d+5USUnJUdvsp6Sk6IcffnCoV8GttLRUI0eOVK9evdShQwdJUm5urmJiYo66E3VKSopyc3N951T1z8H7HspMnz5dy5Yt0+LFi496j2vtP5s2bdLzzz+vUaNG6S9/+YsWL16sO+64QzExMRo8eLDvWlV1Lctf6yZNmlR4PyoqSg0bNuRal3PfffepsLBQbdq0UWRkpEpKSvToo49q0KBBksS1DiB/Xdvc3FxlZGQc9Rne9xo0aFDtPhFQEBDDhw/XqlWrtGDBAqe7EpK2bt2qO++8U7Nnz1ZcXJzT3QlppaWl6tatmx577DFJUpcuXbRq1SpNnTpVgwcPdrh3oeVf//qX3nrrLU2bNk3t27fXihUrNHLkSKWlpXGtwxBTPJIaNWqkyMjIo1Y45OXlKTU11aFeBa8RI0bo448/1pdffqlmzZr5Xk9NTdWhQ4eUn59f4fzy1zk1NbXKfw7e92AsXbpU27dv12mnnaaoqChFRUVp3rx5euqppxQVFaWUlBSutZ80bdpU7dq1q/Ba27ZttWXLFkll1+q3/v5ITU3V9u3bK7x/5MgR7d69m2tdzj333KP77rtPAwcOVMeOHfWnP/1Jd911lyZMmCCJax1I/rq2/vx7hYAiKSYmRl27dtWcOXN8r5WWlmrOnDnKzMx0sGfBxbIsjRgxQu+//77mzp171DBf165dFR0dXeE6r1u3Tlu2bPFd58zMTH3//fcV/iOYPXu2EhISjvolEc7OP/98ff/991qxYoWvdevWTYMGDfIdc639o1evXkctl1+/fr1OPPFESVJGRoZSU1MrXOvCwkLl5ORUuNb5+flaunSp75y5c+eqtLRUPXr0sOFbBIcDBw4oIqLir6XIyEiVlpZK4loHkr+ubWZmpubPn6/Dhw/7zpk9e7Zat25do+kdSSwz9po+fboVGxtrvfbaa9aaNWusYcOGWUlJSRVWOOC33XrrrVZiYqL11VdfWb/++quvHThwwHfOLbfcYjVv3tyaO3eutWTJEiszM9PKzMz0ve9d+nrhhRdaK1assGbNmmU1btyYpa/VUH4Vj2Vxrf1l0aJFVlRUlPXoo49aGzZssN566y2rTp061ptvvuk7Z+LEiVZSUpL1wQcfWN99953Vr1+/KpdndunSxcrJybEWLFhgtWrViqWvlQwePNg64YQTfMuM33vvPatRo0bW6NGjfedwrWtv79691vLly63ly5dbkqwnnnjCWr58ufXTTz9ZluWfa5ufn2+lpKRYf/rTn6xVq1ZZ06dPt+rUqcMy4+P19NNPW82bN7diYmKs7t27WwsXLnS6S0FFUpXt1Vdf9Z1z8OBB67bbbrMaNGhg1alTx7riiiusX3/9tcLn/Pjjj9bFF19sxcfHW40aNbL+/Oc/W4cPH7b52wSfygGFa+0/H330kdWhQwcrNjbWatOmjfXiiy9WeL+0tNQaO3aslZKSYsXGxlrnn3++tW7dugrn7Nq1y7r22mutevXqWQkJCdaQIUOsvXv32vk1XK+wsNC68847rebNm1txcXHWSSedZN1///0VlqxyrWvvyy+/rPLv6MGDB1uW5b9ru3LlSqt3795WbGysdcIJJ1gTJ06sVX89llVuiz4AAAAXoAYFAAC4DgEFAAC4DgEFAAC4DgEFAAC4DgEFAAC4DgEFAAC4DgEFAAC4DgEFAAC4DgEFAAC4DgEFAAC4DgEFAAC4zv8HiXp5AJpZTxIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "t = list(range(1, num_epochs + 1, step))\n",
        "plt.title('mse')\n",
        "plt.plot(t, train_plot, color='red', label='train mse')\n",
        "plt.plot(t, dev_plot, color='blue', label='dev mse')\n",
        "plt.ylim(0,100)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNWGBn8zVaXXClU5qkjPa4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "38466d9810db9ba864eb70591a184bcd86ce8ae48728be4aa03eee6a39bd0ede"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}